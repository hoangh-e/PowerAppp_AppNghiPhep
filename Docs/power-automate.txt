Tell us about your PDF experience.

Microsoft Power Automate documentation
Discover how to make the most of Power Automate with online training courses, docs, and
videos covering product capabilities and how-to articles. Learn how to quickly create automated
workflows between your favorite apps and services to synchronize files, get notifications, collect
data, and more.

G E T  S T A R T E D W H A T ' S  N E W
What is Power Automate? What's new in Power Automate?

T R A I N I N G C O N C E P T
Power Automate training Troubleshoot

Create and design

Try/Buy Create flows AI copilot capabilities
Try Power Automate Create automated flows Copilot in cloud flows
Buy Power Automate Create scheduled flows Copilot in Process Mining

Create desktop flows Copilot in desktop flows

Plan with the process Use solutions Integrate with other
mining capability products

Use solutions to distribute
Understand your processes flows Use flows in Teams
and identify opportunities with Create a cloud flow in a Build SharePoint workflows
process mining solution
Dig into the details with Power
Automate Process Mining



Streamline workflows and Implement healthy application Send email, schedule meetings,
identify inefficiencies with task lifecycle management (ALM) add contacts, and more
mining using solutions
Best practices guidance
Plan a Power Automate project
Manage, govern, and scale
adoption with the Automation
Kit
Apply best practices for
automation adoption

Administer and extend

Administer Power Extend Power
Automate Automate
Use the Power Platform admin Enterprise developer, ISV, and
center partner guide
Administer environments and Work with cloud flows using
resources code
Set up data loss prevention Work with desktop flows using
policies code

Build and certify custom
connectors

Use

Use flows with Use flows with... Use business process
Dataverse flows

Teams
Add a row SharePoint Understand business process
Delete a row flows

Email
Upload or download files and Create a business process flow

Forms
images Add custom controls in

Approvals business process flows
Apply best practices for using
business process flow columns

Related content

Power Platform Power Apps Power BI



One-stop learning resource for Quickly build low-code apps Turn your unrelated sources of
Power Platform applications that modernize processes and data into coherent, visually
and features, with admin, solve tough business immersive, and interactive
developer, and guidance… challenges in your organizati… insights.

Power Pages Dynamics 365 Microsoft Azure
Design, host, and administer Empower your organization Learn how this ever-expanding
secure, modern, and low-code with the next generation of set of cloud computing
business websites. CRM and ERP applications. services can help your

organization meet its busines…



What is Power Automate?
Article • 04/04/2025

With its automation capabilities, Power Automate helps you streamline your business
processes and automate repetitive tasks. Its intuitive interface and many connectors
allow you to create workflows with little to no knowledge of coding. You can drag and
drop components and set up workflows to save time and improve efficiency. Power
Automate can handle simple tasks like sending notifications and more complex
processes across multiple apps and services. It's flexible and scalable, making it useful
for various automation needs in a modern workplace.

Before you can create a workflow, you need to sign up for Power Automate with any
email address. If you never used an online Microsoft product with that address, you
need to register it. Learn more in Sign up and sign in for Power Automate.

Once you have access, you're ready to get started using Power Automate!

Types of flows
With Power Automate you can create cloud flows, desktop flows, or business process
flows.

Check out this video to learn more about the different types of flows.
https://learn-video.azurefd.net/vod/player?id=0f11bc32-0ef4-437b-b15b-
dfb3cf47ee04&locale=en-us&embedUrl=%2Fpower-automate%2Fflow-types

Cloud flows
Create a cloud flow when you want your automation to be triggered either
automatically, instantly, or via a schedule.

ﾉ Expand table

Flow type Use case Automation target

Automated Create an automation that is triggered by an Connectors for cloud or on-
flows event such as arrival of an email from a specific premises services connect

person, or a mention of your company in social your accounts and enable
media. them to talk to each other.

Instant Start an automation by selecting a button. You Wide range of tasks such as
flows can automate repetitive tasks from your desktop requesting an approval, an



Flow type Use case Automation target

or mobile devices. For example, instantly send a action in Teams or SharePoint.
reminder to the team with a push of a button
from your mobile device.

Scheduled Schedule an automation such as daily data upload Tasks that need to be
flows to SharePoint or a database. automated on a schedule.

Desktop flows
Use desktop flows to automate tasks on the web or the desktop.

Business process flows
Business process flows provide a guide for people to get work done. They provide a
streamlined user experience that leads people through the processes their organization
defined for interactions that need to be advanced to a conclusion of some kind. This
user experience can be tailored so that people with different security roles can have an
experience that best suits the work they do.

Create and manage flows in Power Apps
Your Power Automate license also gives you rights to create and manage flows in Power
Apps. For example, after you sign in to Power Apps, you can select Flows in the left
navigation pane. You can also create and manage flows through the Power Automate
pane within Power Apps Studio.

Related information
Determine which automation method (flow type) to use
Overview of cloud flows
Introduction to desktop flows
Business process flows overview
Add canvas apps and cloud flows to a solution in Power Apps

Feedback
Was this page helpful?



 Yes  No

Provide product feedback



Adopt automation with Copilot in
Power Automate
Article • 02/18/2025

Copilot in Power Automate accelerates your journey to adopting automation and
transforming your processes. It enhances these scenarios by using the instructions you
give Copilot written in natural language to surface possible solutions that can achieve
desired results. Copilot stays with you all the way during creation to guide you through
your entire process.

Use the following sections to learn how to use Copilot features in Power Automate.

Copilot in cloud flows
Copilot in cloud flows allows you to create automation that helps streamline your
workflow through quick and easy natural language expressions. You can create a flow by
describing what you need through multiple steps of conversation.

Create a flow using the cloud flows designer with Copilot
Get contextual help with flows from the Microsoft Copilot Studio bot
Use flows as plugins in Copilot for Microsoft 365 (preview)

Copilot in Process Mining
Copilot in Process Mining ingestion navigates you through the ingestion experience in
Process Mining. Copilot in Process Mining process analytics helps you generate process
insights through natural language. Copilot can then take the data you collected and
easily summarize findings from it quantitatively and qualitatively.

Copilot in Process Mining ingestion (preview)
Copilot in Process Mining process analytics (preview)

Copilot in desktop flows
Copilot in desktop flows offers various capabilities to enhance your automation
experience. You can analyze desktop flow activity, create flows using natural language,
repair automation errors, and get answers to product-related questions. These features
democratize access to insights and streamline your workflow.



Get started with Copilot in Power Automate for desktop (preview)
Create desktop flows using Record with Copilot (preview)
Natural language to script powered by copilot (preview)
Repair flow automation errors (preview)
Use Copilot to analyze desktop flow activity (preview)
Use Copilot to get answers to product-related questions

Copilot in automation center
Copilot in automation center enables makers, business analysts, and members of the
Center of Excellence team to easily retrieve information about past flow runs, work
queue performance, and general product features. You can get this information by
asking questions in natural language.

Copilot
Use Copilot to analyze automation activity and ask product questions

Enable or disable Copilot in Power Automate
If a region has GPUs (UK, Australia, US, India), we turn on Copilot by default. In this
scenario, an admin needs to contact support and they use a PowerShell script to turn it
off only at tenant level. Environment level support isn't available. If a region doesn't
have GPUs (everywhere else except sovereign clouds), we turn on Copilot by default by
toggling on the cross-geo data sharing. In this scenario, if you want to disable Copilot,
you can toggle off the cross-geo data sharing in Power Platform admin center at the
tenant level.

To learn more, go to Availability by region.

Related information
Responsible AI FAQs for Power Automate
Understand the cloud flows designer
Troubleshoot in Copilot

Feedback
Was this page helpful?  Yes  No



Provide product feedback



What's new in Power Automate?
Article • 07/26/2024

This article provides resources that you can use to learn about the features that have
been released recently, features that will be released soon, and known issues.

Weekly releases
For information about the new features, fixes, and improvements that were released in
the past few weeks, see Released versions for Microsoft Power Automate.

７ Note

Releases are rolled out over several days. New or updated functionality might not
appear immediately.

Release plans
Get familiar with upcoming features and plan your deployments by reading the 2023
release wave 1 plan.

Preview and Experimental features
Get early access to functionalities and updates before they are available worldwide
through Preview features  and Experimental features.

Related information
Power Platform release plans

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Sign up and sign in for Power Automate
Article • 06/22/2023

Starting with Power Automate, as an individual, is easy! Before you can create a cloud
flow, sign up by using any email address. If you've never used an online Microsoft
product with that address, you'll need to take a few moments to register it.

Sign up free
If you haven't used other online Microsoft products, you'll need to sign up.

1. In Power Automate , select Try free in the upper-right corner.
2. Enter your email address.
3. Select the right arrow.

Sign in
If you've used other Microsoft online products, either for work or yourself, all you need
to do is sign in.

1. In Power Automate , select Sign in in the upper-right corner.

2. On the sign-in page, enter your email address and password.

3. After you've signed in, you'll see a product consent dialog that asks you to consent
to the Microsoft Online Subscription Agreement , and asks you to sign up for
marketing and promotional emails from Power Automate. If you agree to the
terms and conditions, you'll be able to start using Power Automate.

Use paid features
Anyone can sign up and get a free plan for Power Automate. If your organization has
purchased Microsoft 365 or Dynamics 365, you may already have access to Power
Automate. You can also start a 90 day free trial, or purchase a Power Automate license if
you want to use the paid features. Learn more about billing.

For administration information, go to Flows in your organization Q&A.

Troubleshooting



In many cases, you can register for Power Automate by following the simple process
described previously in this topic. However, this table summarizes the most common
reasons why you might not be able to sign up, and describes available workarounds.

Symptom / error message Cause and workaround

No Microsoft account You signed up with an email that doesn't yet have a Microsoft
created yet 
 account created for it. Select the Sign up now link on that page
You receive a message after and you'll be able to create a new Microsoft account for your
entering your email during email. You can use your existing email to create a Microsoft
signup:
 account.

That Microsoft account
doesn't exist. Enter a
different account or get a
new one.

.gov or .mil email addresses
 You cannot currently sign up for Power Automate with a .gov or
You receive a message like .mil address. Instead, you can sign in with any Microsoft Account
the following during signup:
 email address such as a @outlook.com address.

Power Automate
unavailable: Power
Automate is not available for
users with .gov or .mil email
addresses at this time. Use
another work email address
or check back later.

Self-service signup You have selected Sign up instead of of Sign in. If you select Sign
disabled
 in in the top of the home page you will be able to access Power

Automate.
You receive a message like
the following during signup:

We can't finish signing you
up. Your IT department has
turned off signup for Power
Automate. Contact them to
complete signup. 

or

We can't finish signing you
up. It looks like Microsoft
Power Automate isn't
currently available for your
work or school.



Symptom / error message Cause and workaround

Email address is not an Your organization uses IDs to sign in to Office 365 and other
Office 365 ID
 Microsoft services, and those IDs differ from your email address.

For example, your email address might be
You receive a message like Nancy.Smith@contoso.com, but your ID might be
the following during signup:
 nancys@contoso.com. To complete signup, use the ID that your
We can't find you at organization has assigned to you for signing in to Office 365 or
contoso.com. Do you use a other Microsoft services.
different ID at work or
school? Try signing in with
that, and if it doesn't work,
contact your IT department.

Next steps
Start with a template, which is a prebuilt flow that's set up for you.
Start from blank, if you already have a process in mind and can't find a template
for it.
Get help planning your cloud flow project.



Get started with Power Automate
Article • 04/01/2025

Power Automate allows you to optimize your business processes across your
organization and automate repetitive tasks. This service helps you create automated
workflows between your favorite apps and services to synchronize files, get notifications,
collect data, and more. It does this with the help of task mining and process mining.

Get started from the home page
The Power Automate home page offers you various options for creating your own flows
and learning about the key features for Power Automate. You can get a quick sense of
what's possible and how Power Automate can help your business.

If your organization has AI enabled, then it also includes the new Copilot features.

To learn more, select the following links.

Legend:

1. Left navigation pane
2. Search
3. Environment information and settings
4. AI Copilot
5. Learning tools and more
6. Ask a chatbot



1 – Left navigation pane
Find what you need with the left navigation pane. When you sign in to Power Automate
home page , the left navigation pane shows the following menu items:

Legend:

1. Home: Takes you to the Power Automate home page.

2. Create: Create flows by using Copilot, templates or build your own.

3. Templates: View and search for templates you can use to create flows.

4. Learn: Learn experience takes you to the Power Automate product documentation.

5. My Flows: If you created a flow, or someone else created one and shared it with
you, you can view or edit it.

6. Your most used pages: When you first sign in, items such as Approvals, Solutions,
Process mining, AI models, and Desktop Flow Activity appear in the left
navigation menu by default. Use the More menu item to unpin any of these items
and pin something else.



7. More: Pin your most used items to the left navigation pane, such as Tables, Cloud
flow activity, Connections, and more.

8. Power Platform: Explore other Power Platform products.

Pin and unpin
Pin your most used pages in the navigation pane so you can quickly access features that
you use frequently. Links to other pages are available through the More menu item.
When you pin an item, it appears in the middle section above More.

When you sign in, the left navigation pane contains Templates, Approvals, Solutions,
Process mining, AI models, and Desktop Flow Activity. However, you can pin and unpin
pages to customize it to your preference.

To pin or unpin an item from the left navigation pane, select More, and then select the
 pin button or  unpin button.

You can also unpin an item by selecting the vertical ellipsis (⋮) next to the item > Unpin.

Discover all
Select Discover all to see the Discover page on the left navigation pane.



To keep it pinned, select the  pin button.

Move up or move down
When you have some pages pinned in the navigation pane, you can move them up or
down.

To move a page up or down, select the vertical ellipsis (⋮) next to the menu item that you
want to move, and then select Move up or Move down.

Power Platform
From the left navigation pane, select Power Platform to access Power Platform services
such as Power Platform admin center, Power BI, and Power Apps.

2 – Search
Use the Search field at the top of the screen to create flows.

3 – Environment information and settings
View your environment information and settings.



Choose an environment
Environments create boundaries between different types of work. For example, an
organization might have separate environments for different departments. Many
organizations use environments to separate flows that are still being developed from
those that are ready for widespread use. You might have access to multiple
environments or only one. If you have the appropriate permissions, you might even be
able to create your own environments.

To verify which environment you're in, find the environment switcher near the right side
of the header.

With the environment selector, environments are grouped into two categories: Build
Flows and Other environments. Select Filter to filter the list of environments by your
role, data platform (Dataverse or none), and environment type, such as production or
sandbox.



Environments where you have either system administrator and/or system customizer
security role membership appear under Build flows. The Other environments list
displays environments where you have read-only permissions, and can access approvals.

 Tip

Hover over an environment in the list to view the details of the environment.

Filter environments by role

ﾉ Expand table

Filter role Power Platform role or description

Admin System administrator

Environment administrator



Filter role Power Platform role or description

Maker with data access System administrator

System customizer

Maker without full data access Environment maker (with or without Dataverse)

Run only user User without maker-level access

７ Note

To view the environment list in the environment switcher in Power Automate,
you must have the Environment Maker, System Customizer, or System
Administrator security role in the environment. For information about
predefined security roles, see Predefined security roles in the Microsoft
Power Platform admin guide.
Make sure that you're in the correct environment before you create a flow, an
app, or a similar component. You can't easily move components from one
environment to another.
Every member in an organization can access the default environment. Like
any environment, users can see flows where they have sufficient privileges to
access a flow.
When you create a flow in one environment, you aren't able to see it from
another environment.

Learn more in Environments overview.

FAQ about environments
Why does Power Automate show different environments compared to Power Apps?

Power Automate and Power Apps both show environments with administrator access
and environment maker access.

Power Apps shows environments with app contributor access, when users without a
maker-level security role assigned but with edit permission to at least one canvas app in
the environment. Learn more in Choose an environment in Power Apps.

Power Automate shows environments user can approve approvals. Users are granted
read access to environments that have approvals.



Since approvals are frequently used in Power Automate, users could have read access to
many environments.

How do I get access to environments?

You can view access in the Power Platform admin center, by logging in using an account
with environment administrator permissions. If you don't have administrator privileges,
contact your administrator to obtain access.

Once in admin center, select the Users and Teams options under the access panel,
environment admin could find everyone/teams has access to the environment.
Environment admin could also change the security roles for a particular user.

More information: Manage environments in Power Platform admin center.

Settings
Select the gear icon to perform tasks such as identify your Power Automate licenses, and
open the page where you can perform administrative tasks.

Admin Center: Opens the Power Platform admin center.

View all Power Automate Settings: View or update your language and time
settings, notifications, or access directories.

View My Licenses: View your licenses. To learn more, go to Licensing overview for
Microsoft Power Platform.

Themes: From the list of themes, select a theme for your organization.

Password: Change your password.

Contact preferences: Update your contact information.



Help
In the header, select the question mark icon to find more information about Power
Automate.

Here are some examples of what you can find with the help feature:

Find links to documentation.
Browse the Power Automate training on Microsoft Learn.
Access the Power Automate Community, where you can share information with
users in other organizations.
Get announcements on the newest features in the Power Automate blog.

4 - AI Copilot
If your organization has AI enabled, then you see Start building your flow with Copilot
on the Power Automate Home screen.



To learn more, go to Get started with Copilot in Power Automate (preview).

5 – Learning tools and more
The Home page gives you access to learning tools, videos, community forums, and
more. Scroll down the screen to view all the product related tools.

Here's the list of the main categories:

Learning for every level: Discover learning modules you can take to learn how to
use Power Automate.

More to explore in Power Automate: Discover all that Power Automate has to
offer such as video how-tos and the Power Automate Community forum.

What's new: Learn about upcoming events and new and updated product features.

6 - Ask a chatbot
Get contextual help while building your flow using the Power Platform virtual agent. To
learn more, go to Get contextual help with flows from the Microsoft Copilot Studio bot.

Related information
Training: Get started with Power Automate (module)
Training: Automate a business process using Power Automate (learning path)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Overview of cloud flows
Article • 10/09/2024

Create a cloud flow when you want your automation to be triggered either
automatically, instantly, or via a schedule.

This video gives an overview of cloud flows.
https://www.microsoft.com/en-us/videoplayer/embed/RWL2mo?postJsllMsg=true

ﾉ Expand table

Flow type Use case Automation target

Automated Create an automation that is triggered by an Connectors for cloud or on-
flows event such as arrival of an email from a specific premises services connect

person, or a mention of your company in social your accounts and enable
media. them to talk to each other.

Instant Start an automation with a click of a button. You Wide range of tasks such as
flows can automate for repetitive tasks from your requesting an approval, an

desktop or mobile devices. For example, instantly action in Teams or SharePoint.
send a reminder to the team with a push of a
button from your mobile device.

Scheduled Schedule an automation such as daily data upload Tasks that need to be
flows to SharePoint or a database. automated on a schedule.

Find your flows easily
You might have a need to find a flow within a large number of flows. Finding your flows
is easy—just use the search box on the Cloud flows, Desktop flows, or Shared with me
tab to display only flows that match the search terms you enter.

 New flow   Import  Search

Home
Flows Install 

Create
Cloud flows Desktop flows Shared with me

Templates

Learn
Flow icoNname Modified Type

My flows

 Schedule a reply to a message to be sent at a later time - 2 3 da aygs oago Instant
Approvals

Solutions  Schedule a new message 3 mon atghos ago Instant

Process mining
 Create task in Planner when a new response is submitted 3 mon atghos ago Automated

Desktop flow activity

More  Create a task in Planner and post message in Teams 3 mon atghos ago Automated

Power Platform
 Follow up on a message 3 mon atghos ago Instant



７ Note

The search filter finds only flows that have been loaded into the page. If you don't
find your flow, try selecting Load more at the bottom of the page.

More options to find your flow
If you can't find your flow, try one of the options in the following table.

ﾉ Expand table

Scenario Solution

The flow might be in a To change environments, go to Environment information and
different environment. settings.

The flow was shared. Check the Shared with me tab in My Flows menu option. (For an
example, refer to the screenshot in Find your flows easily in this
article.)

You might have been removed Contact the flow owner to be re-added. To find out if you’re an
as an owner of the flow. owner of the flow, go to Remove an owner.

The flow might have been To restore the flow, go to Restore deleted flows.
deleted.

Related information
Training: Describe building automation with Microsoft Power Automate (module)
Training: Create and Manage Automated Processes by using Power Automate
(learning path)
Training: Automate a business process using Power Automate (learning path)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Get started with Copilot in cloud flows
Article • 04/01/2025

Copilot in cloud flows allows you to create automation that helps streamline your
workflow through quick and easy natural language expressions. You can create a flow by
describing what you need through multiple steps of conversation.

The cloud flows copilot can perform the following actions:

Understand your intent, and create a flow based on the scenario prompt you
provide.
Auto-set up connections on your behalf to get you to a working automation as
soon as possible.
Apply the necessary parameters in the flow based on your prompt.
Respond to your requests to make changes to your flow, such as update actions
and replace actions.
Answer questions about your flow and product. For example, you can ask Copilot
questions about your flow like, What does my flow do? to get a summary of what
the flow does. You can also ask Copilot product questions like, How do I access
child flows? and How do I access licenses?.
Suggest a description for the flow when editing the flow's details.

） Important

Copilot is new technology that is still being developed. It is optimized for use
with English language and has limited support with other languages. As such,
parts of it may appear in English rather than your preferred language.
This capability is powered by Azure OpenAI Service.
More information: Responsible AI FAQs for Power Automate, Responsible AI
FAQ for Copilot in cloud flows, FAQ for Copilot data security and privacy in
Microsoft Power Platform

Availability by region
You need a Power Platform environment in the following regions to use Copilot in Power
Automate cloud flows.

ﾉ Expand table



Region Copilot availability

Preview region Copilot is enabled by default at the beginning of October 2023,
unless an admin turns it off.

Regions with copilot GPUs Copilot is enabled by default, unless an admin turns it off.
(United States, Australia,
United Kingdom, India)

Europe and all other Copilot is enabled in the Europe region (using Sweden and
regions, including France Switzerland GPUs) by default, unless admins manually opt out of
and Canada, except for cross-geo data sharing settings from the Power Platform admin
Sovereign clouds center . More information: Turn on copilots and generative AI

features

Sovereign clouds and There's no access for MSA users or Sovereign cloud users to copilot
personal Microsoft service features. You need to use an organization ID and in a non-
account (MSA) users Sovereign cloud region.

７ Note

If your environment is in the region previously listed and you still don’t see the
Copilot in cloud flows experience, contact your admin. An admin can turn the
Copilot feature off or on in the Power Platform admin center. In some geographic
regions outside the United States, Australia, United Kingdom, an admin needs to
turn the cross geo calls on to enable Copilot.

More information: Availability by region

Create a flow using the cloud flows designer
with Copilot
Follow these steps to create a flow using the cloud flows designer with Copilot.

1. Sign in to Power Automate .

2. On the navigation menu to the left, select Home and begin to describe your
scenario.

Conversation first (preview) provides a new way to interact with Copilot in Power
Automate. You can go to this experience from the home page by selecting Chat
with Copilot about my idea, or any of the predefined items above the input field.



3. Alternatively, you can continue to interact with Copilot by typing what you want
your flow to do. You can also select one of the AI generated suggested flow
descriptions based on your manual prompt entry.

To learn how to write a good prompt, go to How to write a good prompt in this
article.

4. When you're ready to proceed, select Generate.

If you manually enter a prompt and it's vague, Copilot assists you in building it to
completion. You can use this stage of the flow building process to ask questions, or
further describe what you would like to achieve with your automation.

5. Copilot begins to depict the structure of the flow, which it generates based on
your prompts. Select Next to proceed and verify any connections that are part of
the flow are configured correctly.

6. To finalize your flow, configure the required settings.

7. Select Create flow.

The cloud flows designer with Copilot opens with your flow.



8. On the panel to the right, follow the Copilot suggestions to complete the flow
setup, ask questions, or make edits to your flow using Edit with Copilot.

9. When your flow is complete, select Save this flow.

10. Once your flow is saved, we recommend that you test it. Do this by selecting Test
in the upper-right corner.

Troubleshoot in Copilot
The new troubleshoot in Copilot feature can assist you in identifying and resolving
errors that might occur during testing of cloud flows or when reviewing flow run history.
You can use this Copilot feature when the new designer experience is enabled.

To learn more, go to Troubleshoot in Copilot.

How to write a good prompt



Writing good prompts includes more than just being specific with your request, or
saying how you want your results to be displayed. Copilot lets you try out different
variations of prompts to help you evaluate what works best. If the initial results aren’t
what you’re looking for, try tweaking your prompt and running it again.

For better and more accurate results, provide prompts in When X happens, do Y
format.
Be as specific as possible. Instead of a generic prompt like, I want to process an
email, try this prompt instead: When an email arrives, I want to post the subject of
the email to 'Contoso' Teams General channel.
If possible, mention the connector in your prompt. For example, include Outlook,
Teams, Forms, or other.
Try tweaking your prompt to further fine tune.

For more general information about writing prompts with generative AI, go to The art of
the prompt: How to get the best out of generative AI .

Examples of interactions with Copilot
This section describes some example scenarios of how you can interact with Copilot.

ﾉ Expand table

From the Home page or Describe it to Inside canvas
design it

When an email arrives from Ask Copilot to edit the flow: I want to send the
contoso@gmail.com, post in Teams. email subject to Teams channel.

Ask Copilot what your flow does: What does my
flow do?

When an item is created in SharePoint, Edit the flow with this prompt: I want to send the
send me a mobile notification. item title to notification.

Edit the flow with this prompt: I don’t want to
receive mobile notification. Send me an email
instead.

 Tip

For more examples you can try out, go to the prompt library in the Sample
Solutions Gallery .



Edit a flow using the designer with copilot
capabilities
In addition to using Copilot to create a starting flow, you can also change or complete
your existing flows.

1. Sign in to Power Automate .

2. On the left navigation pane, select My flows.

3. Find your flow, select the vertical ellipses (⋮), and then select Edit.

Alternatively, access the cloud flows designer with copilot capabilities from the
flow Details page of your existing flow by selecting the flow name from My flows
> Edit.

Your flow opens with the Copilot pane on the side. You can now edit your flow by
using the cloud flows designer with copilot capabilities. Try typing the following
prompts:
a. Delete action X
b. I want to send an email at the end of the flow with subject equal to the

SharePoint file name.
c. Instead of email, I want to post message on Teams channel.
d. Check if each of the SharePoint items being returned has a title that equals

'USB', and if so, send an email.

Frequently asked questions
Use this section to find answers to frequently asked questions.

Why don’t I see the cloud flow designer with Copilot in
my Power Automate experience?

Check if the environment you’re using is in the copilot available region in the table
in the Availability by region section of this article. Your Microsoft Power Platform
admin can help review and verify the region.
Ask your admin if they requested Microsoft Support to disable the Copilot, if the
region is supposed to enable Copilot by default.
Ask your admin if they enabled Copilot by toggling on Allow data movement for
generative AI features from the Power Platform admin center. To learn more, go to
Enable copilots and generative AI features.



How do I enable Copilot?
If you're not in the region listed in the table in the Availability by region section where
Copilot is enabled by default, your admin can enable Copilot for an environment from
the Power Platform admin center by consenting to data movement. To learn more, go to
Enable copilots and generative AI features.

How do I disable Copilot in the cloud flows designer?
Refer to the table in the Availability by region section in this article. If you aren't in the
region with GPUs (infrastructure to support Copilot), you can toggle off the cross-geo
data sharing settings from the Power Platform admin center . However, If you're in the
region with native GPUs with Copilot on by default, you can disable Copilot for your
tenant by contacting Microsoft Support. You can disable and re-enable at tenant level
easily using a PowerShell script.

How is Copilot in cloud flows different from the text
generation model in AI Builder?
Copilot in cloud flows is designed to help you create and edit Power Automate flows
just by describing them in everyday language, providing helpful guidance along the
way.

The text generation model in AI Builder lets you use the GPT model directly in your
Power Automate flows and your apps built in Power Apps for various scenarios such as
text summarization, draft responses, classify text, and more.

To learn more, go to Text generation model overview (preview).

What are the limitations of the cloud flows designer with
the copilot experience?
You can’t edit flows in the cloud flows designer with the Copilot experience if your flow
has any of the following flows capabilities:

A non-Open API flow (older connection format).

 Tip

If there's Peek code on an action and if you see the APIConnection value
instead of OpenAPIConnection in Kind field , it's a non-Open API flow.



A flow with a comment.

A flow contains an unsupported hybrid trigger. Hybrid triggers don't require
connections, and are triggered manually from outside of Power Automate. The
hybrid triggers, which aren't supported are:

When a flow is run from business process flow (Dataverse).
For a selected message (v2 Teams). We plan to enable worldwide by July end.
Teams On Compose Message (Teams). We plan to enable worldwide by July end.
Microsoft 365 Compliance Connector.

A flow contains a Power Apps V1 trigger.

A flow contains Perform a Changeset Request (Dataverse).

A flow contains a Power Pages component.

A solution flow using connections instead of connection reference isn't supported.
We recommend that you use connection reference instead.

Email auto-complete suggestions in Send Email/Post message in Teams actions.
HTML editor in Send Email action.
Copy/Paste supporting Scope, Condition, Do until cosntructs.
Ability to make manual trigger fields optional.

You can’t use the cloud flows designer with Copilot if you’re using a personal Microsoft
account. For example, you can’t use someone@live.com. Use a work or school account
like someone@contoso.com instead.

The cloud flows Copilot supports English language only for models.

There are some missing functionalities in the cloud flows
designer with copilot capabilities. What do I do?
As we continue to innovate, we're introducing a new designer alongside our classic
designer. While the classic designer remains valuable, the new designer is our future
direction. While the classic designer isn't supported indefinitely, the new designer is
gradually becoming the primary interface.

If you prefer to access features not yet available in the new designer, or encounter any
limitations or known issues, you can temporarily revert to the classic designer. To do
this, turn off the New designer toggle on the menu in the cloud flows designer.



Why do I get this error "O.split(...).at is not a function"
when signing in?
Power Automate designer doesn't support browsers that are more than two (2) years
old. You could see the previously mentioned or similar errors in the designer if your
browser version isn't current. It's generally a good idea to update your browser to latest
version to avoid such issues.

Why do I get this error "The provided flow name contains
invalid characters" when importing a flow in a new
tenant?
This is a temporary gap, which you can work around by adding a query parameter
v3=false  in your URL.

Why do I not see dynamic content from triggers like
'When a response is submitted' or why is the flow
automatically putting an unnecessary loop?
This might be because of a temporary issue where the Split On setting of the trigger is
off. If you enable the setting, the issue should go away.

1. On the action configuration pane, select the Settings tab.
2. Under the Split On heading, move the toggle to On.

What licenses do I need to access Copilot in Power
Automate cloud flows?
You need a standalone Power Automate license, or a seeded Microsoft 365 license, or
PowerApps/Dynamics license, to access and use Copilot. MSA users (@microsoft.com)
without an org ID aren't able to use the experience.



Related information
Responsible AI FAQs for Power Automate
FAQ for Copilot in cloud flows
FAQ for Copilot data security and privacy in Microsoft Power Platform
Language availability for Power Platform
Geographical availability for Power Platform
Training: Use Copilot in Power Automate (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



What is the cloud flows designer?
Article • 03/24/2025

You can create, configure, and customize your cloud flows with the classic designer or
the cloud flows designer. For a description of the types of cloud flows, go to Overview
of cloud flows.

７ Note

Here are some visual cues that tell you that you're using the new cloud flows
designer (not the classic designer):

The cards in the flow are small.
The standalone action configuration pane appears on the left when you select
a card.

More information: Identify differences between the classic designer and the new
cloud flows designer

Here's a screenshot of the AI-powered cloud flows designer's features and a legend is
available to give you more context.

Legend:

1. Left arrow button: Return to the previous page.



2. Undo and Redo buttons: Reverse or reinstate modifications you made to the flow.
3. Send feedback button: Send us feedback about your flow creation experience or

general comments about the AI-powered designer.
4. Version history button: Track and manage changes made to your flows over time.

It records every modification, enabling you to view previous versions, compare
changes, and, if necessary, revert to an earlier version. Learn more in Drafts and
versioning for cloud flows.

5. Flow checker button: Check your flow for errors.
6. Save draft button: Save a draft of your flow.
7. Test button: Test your flow to make sure that it works as you intended.
8. Publish button: Publish your flow so that your flow runs when the trigger event is

performed.
9. Copilot button: Show or hide the Copilot pane. The Copilot pane appears by

default when the AI-powered designer opens.
10. New designer toggle: Switch between the classic designer and the new cloud

flows designer. Learn more in Identify differences between the classic designer and
the new cloud flows designer.

11. Action/trigger name: The action or trigger card that is selected in your flow in the
center of the page (the canvas).

12. More commands button: Add a note to the selected card, pin an action, or delete
the card. There are two ways to pin an action. Learn more in View two action panes
simultaneously.

13. Collapse button: Hide the pane. When the pane is collapsed, the Expand button
(>>) appears in the upper-left corner. Select it to show the pane again.

14. Action configuration pane: After you select an action card to configure on the
canvas, the action configuration pane opens on the left side of the AI-powered
designer.

15. Canvas: The canvas is where you build your flow. It's free-flowing and therefore
allows for easier navigation.

16. Copilot pane: Copilot stays with you during your flow editing and fit-and-finish
journey. It can help you update and make changes to your flow, based on your
conversational-style prompt. It can also help answer flow-related and product-
related questions.

Undo and Redo
To reverse or reinstate modifications you made to the flow, you can use the Undo and
Redo command bar buttons. For example, if you added or configured an action, or
made significant adjustments to the flow, these features allow you to conveniently revert
to a previous state or redo changes you previously canceled.



Send feedback
We want to hear from you to help us measure and improve our impact. To provide your
feedback, select Send Feedback, answer the three questions in the feedback form that
opens, and then select Submit.



Save draft button
Select Save draft to save a draft of your flow. If there are no errors, the message, "Your
flow is ready to go. We recommend you test it" appears in the upper left with a green
check.

If an error is found, a description of the error and a red X appear in the upper left. The
following screenshot shows an example of an error message.

The error also appears on the card that caused the error in your flow. Correct the error,
and then select Save again.



When there are no errors, your next step should be to test your flow.

Test button
After your flow is saved successfully, Test becomes active. To test your flow, select Test >
After your flow is successfully saved, the Test button becomes available. To test your
flow, select Test, select the Manually option, and then select Test.

Instructions appear and tell you what you must do to test your flow. The following
screenshot shows an example of an instructional message.

To test your flow, follow the instructions. In this example, you must send an email. The
flow test then runs. When the test finishes running, a green check mark appears on each
card, together with the number of seconds that it took to be processed.

Testing is part of the planning for a Power Automate project. To learn more, go to
Introduction: Planning a Power Automate project.

More commands



Select the More commands (⋮) button to add a note to the selected card in your flow,
pin an action, or to delete the card.

Select Add a note to describe the purpose of the card in your flow. After you add a
note, a note symbol appears in the lower right of the card. To view the note, hover over
this symbol.

Select Pin action to pin the action card to the top of the action configuration pane. This
feature is useful when you want to compare two actions side by side, or copy values
across two actions. Learn more in View two action panes simultaneously.

Action configuration pane
Use the action configuration pane to customize parameters, settings, and code for the
selected card in your flow.

Parameters
On the Parameters tab, you can use the blue Insert token (lightning bolt) and Insert
expression (fx) buttons next to the Inputs field to quickly enter values for the selected
action card.



To insert a dynamic token into the Inputs field, select the Insert token (lightning bolt)
button. In the pop-up window that opens, search for or scroll to find the tokens that you
can use. After you select a token, it appears in the Inputs field.

To insert an expression into the Inputs field, select the Insert expression (fx) button. In
the pop-up window that opens, select a function to start your expression. To complete
your expression, place the cursor in the function, and then select Dynamic content.
Search for or select the content/tokens to add, and then select Add. Your completed
expression appears in the Inputs field.

To learn more about expressions, go to Reference guide to workflow expression
functions.

Alternatively, use the keyboard to enter a slash (/) in the Inputs field. Then select the
dynamic content/token and expression pop-ups.

Settings
On the Settings tab, you can set the action time-out, network retry policy, how an action
should run, security input and output, and tracking properties. The following table
provides a description of the settings.

ﾉ Expand table

Setting Description

General In the Action Timeout field, set the maximum duration between retries and
asynchronous responses for the selected action. This setting doesn't change the
request time-out of a single request.

Networking In the Retry Policy field, select a retry policy for intermittent failures. The default
setting is an exponential interval policy that is set to retry four times. You can also
set your own exponential or fixed interval settings, or choose none at all.

Run After In the Run After field, configure how an action should run after the execution of
any of the preceding flow actions. For example, you can choose to run an action



Setting Description

after the preceding action runs successfully, times out, skips, or fails.

Security Use the Secure inputs and Secure outputs toggles to turn the operations, and
references of output properties, on or off.

Tracking Set the key and value of tracked properties.

Configurable trigger polling setting
In select triggers such as When an item is created-Sharepoint, and more, you can
manually configure the trigger polling setting. This means you can configure how often
the flow should check for new items in Sharepoint and others. This in turn ensures how
quickly your flow responds to any changes or trigger events. The default polling period
is three (3) minutes, which means the flow checks every three (3) minutes if a new item
was created.

1. On the action configuration pane, select the Parameters tab.

2. Under the How often do you want to check for items? heading, enter the interval
number and the frequency from the dropdown menu.

 How often do you want to check for items?

Recurrence *

Interval * Frequency *
3 Minute 

Code View
To view the code behind any card in your flow, select the card on the canvas, and then
select Code View in the action configuration pane. As you customize the code on the
Parameters tab, you can view the new code on the Code View tab.

The following screenshot shows an example of the code for the Compose action card.



Copy and paste actions
You can copy actions to the clipboard whether they're atomic actions or container
actions. Examples of atomic actions are Compose , Get items , Create item , and others.
Examples of container actions are Scope , Switch , Condition , Apply to each , and others.

To copy and paste an action, follow these steps.

1. Right-click on any action (or trigger) you want to copy.



2. On the canvas, select + on the canvas to add an action, and then select Paste an
action.

You can copy and paste actions across different parts of your flow, or in between
flows.

After you paste your action, the copied action name is followed by -copy.

If you don't have access to a mouse, you can use your keyboard. To copy, press Ctrl + C.
To paste, press Ctrl + V.

Canvas
For easy navigation, you can drag your flow on the canvas. You configure the actions of
each card in the action configuration pane on the left. The cards on the canvas are



compact to allow for easy visibility and navigation, especially in large flows.

Drop zones
The canvas contains AI-powered designer drop zones to help you easily drag cloud flow
actions. Blue dashed lines represent the drop zones.

Zoom buttons
Depending on the size and complexity of your flow, you might want to adjust its size on
the canvas as you're building it. Use the zoom buttons to zoom in, zoom out, fit to
screen, and toggle a minimap. The buttons appear when the Action configuration pane
is closed.

The bottom button is for the minimap. Use it to focus on a specific section of a large
flow.

Expression editor and token picker



The expression editor in the designer is multi-line, which allows you to easily create and
edit long, complex expressions. A gripper allows you to temporarily expand the box by
one or two (1-2) lines, as needed. If that's not enough, you can expand the popup to a
full page view. A search box allows you to search for tokens and functions, both in the
Dynamic content view and Function view.

 Tip

You can use a forward slash ( / ) keyboard shortcut to invoke the token
picker/expression editor popup when you're on an action field.

Learn how to use the expression editor in Create, update, and fix expressions with
Copilot expression assistant (preview).

Disable an action or enable static results on an action
On the designer, if you want to disable an action rather than remove it entirely, go to
the Testing tab of the action and enable static outputs by turning on the Enable Static



Result toggle. When the flow runs, this essentially treats the action as successful,
without actually running the action.

Similarly, if you want to see how your flow reacts if a certain action fails with a code or
succeeds with a code, you can use the same capability of static outputs available on the
action to mock the action execution to your needs.

When static outputs are disabled, the toggle label is Enable Static Result. When static
outputs are enabled, the toggle label is Disable Static Result.

View two action panes simultaneously
One the new designer, you can pin an action pane so that you can open a second action
pane next to it. This can be useful to compare two similar actions, or copy values across



two actions.

To pin an action, you can either right-click the action on the canvas and select Pin
action. Alternatively, in the action pane, you can select Pin action in the More
commands dropdown menu.

Once you pin an action, any other selected action panes are placed to the right of the
pinned action pane.

To unpin an action, you have two options:

Right-click the action on the canvas and select Unpin action.
Select the Pin icon on the action pane.

Identify differences between the classic
designer and the new cloud flows designer
To quickly identify which designer version you're using, ask yourself the following
questions:



Are the action cards on the flow small or large?
Is the action configuration pane inline or in a separate pane?

７ Note

The new cloud flows designer has smaller cards to facilitate easy navigation. It also
has a standalone action configuration pane on the left.

Designer resiliency and save flow with errors
The new designer automatically saves a copy of the flow to browser storage upon failed
save, even with errors. This capability comes in handy on two occasions: 1) When the
underlying service is going through an outage and when makers need to avoid losing
their unsaved changes, by exiting out of their flows, or 2) For non-solution flows, which
lack the 'Save draft' functionality, makers can exit out of their flow with errors and come
back at a later time to fix the errors and save the flow.

A info banner appears on the designer notifying when designer is able to save the flow
copy to browser's storage. Makers can now exit out of their flow.

Upon revisiting the flow on the designer, the previously saved version loads on the
designer by default. The unsaved copy is recoverable through the 'Recover' button on
the info banner.



When you select Recover, the unsaved browser copy of the flow is loaded on the
designer, on top of which you can make updates.

You can now fix errors on this copy of the flow and save it. If you don't save this copy,
the previously saved version of the flow is still accessible upon reloading the tab.

２ Warning

Saving this copy overrides the previously saved version of the flow. It also
clears the browser storage, as there are no unsaved changes on the flow.
Clearing the browser cache deletes the saved copy of the flow from the
browser.
If you still need access to the unsaved flow copy, don't clear cache orcookies
from the browser.



Limitations and known issues
You might notice that some functionalities that were in the classic designer aren't
available in the cloud flows designer yet. Currently, the designer doesn't support the
following items:

Non-Open API flows (If there's Peek code on an action and if you see the API
Connection value instead of Open API Connection in Kind field, it's a non-Open
API flow.)

These are legacy flows, probably created a long time ago when Open API
support wasn't available.
We have plans to migrate them to Open API format, with no fixed
announcement date. In the meantime, if you want to work with the latest
functionalities in the new designer/Copilot experience, consider recreating the
flow in new designer until the migration plan is announced.

Some hybrid triggers:
When a flow is run from business process flow (Dataverse)
Microsoft 365 Compliance Connector

A comment
Power Pages connector
Power Apps v1 trigger
Perform a changeset request action (Dataverse)
A solution flow using connections instead of connection reference isn't supported.
We recommend that you use connection reference instead.

As we continue to innovate, we're introducing a new designer alongside our classic
designer. While the classic designer remains valuable, the new designer is our future
direction. While the classic designer isn't supported indefinitely, the new designer is
gradually becoming the primary interface.

If you prefer to access features not yet available in the new designer, or encounter any
limitations or known issues, you can temporarily revert to the classic designer. Simply
turn off the New designer toggle on the menu in the cloud flows designer.

７ Note

The Power Automate cloud flows designer isn't yet available in integration surfaces
such as Power Apps, Teams, and others.



If a flow is saved too soon on load, it might be saved without advanced parameters if
those parameters weren't fetched yet. As a workaround, you can avoid saving a flow too
soon on load. Alternatively, use the classic designer.

FAQ
This section highlights some of the most frequently asked questions about working with
Power Automate classic designer and cloud flows designer.

Why do I get this error "O.split(...).at is not a function"
when signing in?
Power Automate designer doesn't support browsers that are more than two (2) years
old. You could see the aforementioned or similar errors in the designer if your browser
version is old. It's generally a good idea to update your browser to latest version to
avoid such issues.

Why do I get this error "The provided flow name contains
invalid characters" when importing a flow in a new
tenant?
This error is a temporary gap, which you can work around by adding a query parameter
v3=false  in your URL.

Why don't I see new or updated SharePoint or Excel
column values in my flow?
Power Automate designer requires a flow action to be re-added in order to pick up new
entities of the underlying action. For example, if you have a SharePoint Get item action
in your flow and Sharepoint item has four (4) columns, the flow allows you to access all
four column values of the SharePoint item. Now, if you navigate to SharePoint, add a
fifth column, and come back to the flow, you can't access the fifth column unless you
delete the Get item action and re-add it again to force the designer to pick up the latest
changes. The same behavior applies in Excel columns, Dataverse, OneDrive folder/files,
and others.

Will the new cloud flows designer eventually replace the
classic designer fully?



Yes, once the issues noted here are resolved and the new cloud flows designer can cover
most, if not all, of the classic designer scenarios. At this time, the classic designer will be
fully replaced.

Related information
Learn how to work with Copilot in cloud flows. You can get started with these articles:

Get started with Copilot in cloud flows
FAQ for Copilot expression assistant

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Get started with triggers
Article • 03/28/2025

A trigger is an event that starts a cloud flow. For example, you want to get a notification
in Microsoft Teams when someone sends you an email. In this case, receiving an email is
the trigger that starts this flow.

Power Automate offers connectors to services such as SharePoint and Outlook. Most
connectors offer prebuilt triggers that you can use to start your flows. Here's a partial
look at the triggers that Office 365 Outlook connector provides by default.

Learn more about triggers in this quick video:

https://learn-video.azurefd.net/vod/player?id=523050f3-8402-4a8a-ad86-
108a1c6d2518&locale=en-us&embedUrl=%2Fpower-automate%2Ftriggers-
introduction

Choose the right trigger
Triggers can be started instantly or manually, on a schedule, or automatically when an
external event occurs, such as when an email arrives. The following table lists some
common trigger scenarios and the type of flow you should create.

ﾉ Expand table

Trigger scenario Flow type

Run a cloud flow with a tap of a button on your mobile device to remind your Instant/manual
team to join the daily team meeting. You can trigger these flows manually from
any device.



Trigger scenario Flow type

Run a cloud flow on a schedule, for example, to send a weekly project report. Scheduled
Choose when (date and time) and frequency (monthly/daily/hourly, and more).
More information: Run flows on a schedule

Create a cloud flow that performs tasks automatically after an event occurs, for Automated
example, a cloud flow that notifies you by email when someone tweets with a
keyword you specify. More information: Create a cloud flow from scratch

Add a trigger to an existing flow
When you edit a trigger in an existing flow, the new trigger must be the first step of the
flow.

1. Edit the flow and delete the existing trigger.

2. After you delete the trigger, Power Automate prompts you to select a new trigger.

3. Search for the connector and then select the app icon. The following screenshot
shows the results if you search for Share.

4. When you select the app icon, the corresponding triggers and actions are listed.
Select the trigger that best suits your needs.

Licensing for premium connectors
You need a standalone Power Automate license  to access all premium, on-premises,
and custom connectors. For flows that are in-context of an app built in Power Apps, you
can leverage Power Apps license . Microsoft 365 plan licenses can use standard
connectors but can't use premium connectors. To learn more about licensing, go to the
Power Platform Licensing Guide .

To find your license, do the following steps.

1. Sign in to Power Automate .



2. Select My flows.
3. Select a cloud flow.
4. Go to the Details section and view the details under Plan.

Customize a trigger by adding conditions
Sometimes, you might need to customize a trigger so that it fires only when certain
conditions are met. For example, you might be using SharePoint's When an item is
created or modified trigger in Power Automate. This trigger fires for every change to
SharePoint items. However, you might want the flow to only trigger when an item is
created or the status is marked as Approved. While you can filter other events by adding
conditions to the flow, the flow still runs and the calls are counted as an API request.
This causes you to reach your API request limits faster. To avoid it, you can write
expressions in trigger conditions, avoiding a run if the condition in trigger isn't met.

Learn more about conditions in this quick video:

https://learn-video.azurefd.net/vod/player?id=fd4468f4-6d56-499e-98d0-
4d98086cf9d5&locale=en-us&embedUrl=%2Fpower-automate%2Ftriggers-introduction

Use trigger conditions to reduce flow runs
Trigger conditions can help streamline your flows and reduce the number of
unnecessary runs. This helps keep flow runs and Power platform requests consumption
low. With trigger conditions, you can set up multiple conditions that must be met before
a flow is triggered.

For example, you need to create a flow that processes every approved invoice. Without
trigger conditions, your flow would trigger every time an invoice email is received, even
if the invoice isn't approved. This can result in the flow running 1,000 times for 1,000
invoices, even though only 50 of them are approved.

By adding a trigger condition to trigger only when an invoice is approved, the flow runs
only 50 times. This means it consumes fewer Power Platform requests. If the trigger
condition isn't met, the flow isn't triggered, and no run history is logged.

This is especially important in pay-as-you-go environments, where every flow run is
charged. By reducing the number of runs, you can keep your costs low while still
achieving your desired outcomes.

７ Note



Power Automate uses either the classic cloud flows designer or the new
modern designer with Copilot capabilities. To identify which designer you’re
using, go to the Note section in Explore the cloud flows designer.
When you switch between the classic and new designer, you're asked to save
your flow. You can't save and switch until all errors are resolved.

New designer

[This topic is prerelease documentation and is subject to change.]

To set a trigger condition:

1. Select the trigger of the flow.

2. Select Settings.

3. Next to Trigger conditions, select Add.

4. Add an expression.

７ Note

Every trigger condition must start with a the @ symbol.



As an alternative, follow the instructions in Easily create expressions.

5. If you have multiple filter conditions to add, Select + Add and add
expressions.

By default, all conditions must be met for the condition to be true. If any
condition is optional, you need OR, and then use the syntax @or (test1,
test2,test3) .

Easily create expressions
Your flow can generate expressions for you.

1. On your flow, select the + sign in the down arrow, and then select Add an
action.

2. Search for and select the Filter array action.
3. On the Filter array card, create your condition.
4. Select Edit in advanced mode and copy the expression.
5. Paste the expression into the trigger condition.
6. Remove the Filter array action.

Related information
Training: Describe building automation with Microsoft Power Automate (module)
Training: Enhance productivity with Power Automate and the Office 365 Outlook
Connector (module)
Training: Streamline SharePoint processes with Power Automate (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Get contextual help with flows from the
Microsoft Copilot Studio bot
Article • 10/23/2024

Real-time, in-product help is available from the documentation and the Copilot Studio
bot to solve the most common workflow scenarios. While building your flows, you can
access content from the documentation, community, blogs, and templates.

Use in-product help
７ Note

In-product help is available while you create or edit cloud and desktop flows.

1. Select the ? on a connector, action, or trigger to start the in-product help
experience.



2. The right pane opens with details about the action and provides documentation
links for that action.

In the following example, the Send an email (V2) action is selected, showing help
topics regarding the top email scenarios, an overview of the action, and more.

If you select ? on a different action, the help pane updates to show guidance
documents for the currently selected action.

 Tip

In product help is contextual, always displaying content that's relevant to the
currently selected action, trigger, or connector.






Get help from the community
Now that you've displayed the in-product help, follow these steps to use the various
topics.

1. Select any link from the list of help topics.

The corresponding documentation opens.

2. Expand the Community section.

The community results about the action are displayed.



3. Select an item to go to specific community thread.






4. You can also get help from blog posts if you select the Blog link.

Get conversational self-help from the bot
1. Select Ask a chatbot.

The chat bot lists the most requested topics and provides a field that you can use
to ask the bot questions.



2. Choose one of the topics.

The bot gives an overview and then provides the next level of topics.

3. Find the right topic.

The bot provides the steps and links to the corresponding documentation with a
detailed explanation, showing examples and images.



4. Select Yes to indicate that you've found an answer to your question.

5. Select No if the bot didn't provide the answer that your're looking for.



6. Select Yes to check the knowledge database and enter another question.






7. Select a category to see the corresponding results



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Add multiple actions and advanced
options to a cloud flow
Article • 10/09/2024

Customize a cloud flow by adding one or more advanced options and multiple actions
for the same trigger. For example, add an advanced option that sends an email message
as high priority. In addition to sending mail when an item is added to a list created in
Microsoft Lists, create a file in Dropbox that contains the same information.

 Tip

For detailed information about using SharePoint with Power Automate, go to the
SharePoint documentation.

Prerequisites
Create a cloud flow

Add another action
In this procedure, you'll add an action in the middle of the flow. This action will save a
file in your Dropbox, archiving the item in the list.

1. Sign into Power Automate .

2. On the left pane, select My flows.

3. In the list of flows, select the Edit icon next to the flow you want to edit.

4. Select New step, enter dropbox in the search field, and select Create file -
Dropdown in the Actions list.



5. If prompted, provide your Dropbox credentials.

6. Select the folder icon on the right side of the Folder path box.

7. Select > and then choose the folder in which you want to place the new file.

8. Enter the name of the new file into the File name box. Be sure to append an
extension, such as ".txt", to the file name. Here, let's use the TweetId in the file's
name to ensure uniqueness of the files. You may have to select See more to find
the TweetId token.

9. Add the text that you want the file to contain by typing into the File content box.
You can also add tokens into the File content box.



） Important

If the file name you enter matches an existing file's name in the selected
folder, the existing file will be overwritten.

10. Save your flow.

11. Send a tweet that contains the keyword you specified.

Within a minute, a file is created in your Dropbox account.

Reorder or delete an action
To receive email after the file is created in Dropbox, move the Dropbox action by
dragging its title bar above the email action. Release the Dropbox action over the
arrow between the trigger (When a new tweet is posted) and the email action.
(The cursor indicates whether the action is positioned correctly.)

７ Note



You can't move a step before another if you're using any outputs from that
step.

To delete an action, select ... (the ellipsis) near the right edge of the title bar for the
action you want to delete, select Delete, and then select OK.

Note: You can't delete an action if you're using any outputs from it anywhere in
the flow. First, remove those outputs from the fields, and then you can delete the
action.

Copy and paste actions
If you want to duplicate actions while designing a cloud flow, you can copy and paste
them. For example, if you're building a condition and want similar actions in the If yes
side and the If no side, you can build the first action in one side and then copy it to the
other side. This is an alternative to creating both actions from scratch.

To copy an action
1. On the action menu heading, select ... (the ellipses).



2. Select Copy to my clipboard.

3. Select New step where you want your action to go.

Notice the My clipboard tab that lets you choose from all of the actions that
you've copied.

4. Select the item you want to paste.

Add advanced options
Start with a cloud flow that has a Send an email (V2) action.

1. On the bottom of the Send an email (V2) card, select Show advanced options.

You'll see the advanced options for sending an email. The word Show changes to
Hide so that you can toggle the advanced options.



2. From the Importance dropdown list, select High.

3. Select Hide advanced options.

4. Save your flow.

Use co-presence to get notified of all editors
Power Automate displays the list of other makers who are editing a flow simultaneously.
The list of editors is updated periodically.



Add comments to actions and triggers
Makers can have threaded comments with colleagues as they build their flows. They can
add or edit comments, reply to comment threads, and resolve and delete comment
threads. It's possible to have multiple comment threads for both actions and triggers.

） Important

Comments are supported for environments that have a Dataverse database.

Follow these steps to add a comment to any action or trigger in your flow.

1. On the trigger or action heading, select ... (the ellipsis).

2. Select New Comment.

The comments pane opens.



3. Enter a comment to your action with an @mention to others. If you do this, an
email notification will be sent to them when you select the Send icon.

If the person you want to @mention isn't a co-owner of the flow, they'll get the
Share and notify option. Select this option to share the flow with the other user,
and send an email notification automatically.

4. Enter your comments in the Start a conversation box on the Comments pane, and
then post it.

The Power Automate designer provides visual cues on the action cards to display the
number of comment threads contained within each.

Limitations



Makers must save the flow at least once before they can add a comment.
The comment thread count icons don't appear for control actions such as
condition, switch, and scope.
Comments aren't allowed for managed solution flows.
The Share and notify option is available only for non-solution aware flows. For
solution aware flows, @mentioning is limited to users who are already co-owners
of the flow.

Address conflicts from multiple edits
If multiple users make changes to the flow simultaneously, Power Automate presents
appropriate options to the maker to minimize conflicts during a save operation. A maker
can choose to refresh the flow definition or save a copy of the flow to keep their
changes.

New expression editor for actions
(experimental feature)
Do you struggle with writing expressions in your flow actions? You can make use of the
improved expression editor in experimental mode. To use the improved expression
editor, enable the Experimental Features setting and select fx on an action.

The large expression editor view helps you manage rich and complex expressions.



The expression editor allows you to choose dynamic content in the expressions
without having to switch tabs.

The expression editor preserves expressions with errors and unblocks the view to
work in parallel on other parts of flow.

７ Note



Some actions might not support the new expression editor.

Related information
Training: Use Dataverse triggers and actions in Power Automate (module)
Training: Integrate Power Automate with SharePoint HTTP actions (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Use generative actions in cloud flows
(preview)
Article • 04/01/2025

[This article is prerelease documentation and is subject to change.]

Generative actions are a new type of action that is authored, tested, and executed
through an AI runtime. You specify only the intent of the action and the AI chooses the
right set of actions in the right order based on your input, context, and intent.

） Important

This is a preview feature.
Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.

Benefits of generative actions
Generative actions simplify automation by reducing the need for detailed specifications,
adapt to changing scenarios using AI intelligence, and handle complex tasks involving
multiple steps and integrations.

Generative actions can simplify and accelerate the automation process by reducing
the need for specifying the conditions and action sets to execute.
Generative actions can adapt to changing scenarios and data sources by
leveraging the AI runtime's intelligence and reasoning capabilities.
Generative actions can handle complex and dynamic tasks that involve multiple
steps, conditions, loops, branches, and integrations.

Author generative actions
You can author generative actions in the cloud flows designer in Power Automate. When
you give the system an intent, the AI generates suggested inputs, outputs, and actions
to use in the action. You can choose to accept the AI suggestions, or reject them and
add your own inputs and outputs.



In addition to inputs and outputs, the system also provides connectors and actions that
it can use to achieve its intended automation goal. You can choose to accept, reject, or
add your own.

Once you create the action, you can preview how it behaves by providing sample inputs
and verifying what the action does. In the preview phase, the action pauses before
taking any action. You can run this multiple times.

Create a generative action
To create a generative action, you start in cloud flows designer.

1. Sign in to Power Automate .

2. On the navigation menu to the left, create a cloud flow using one of the following
options:

a. Select Create > one of the following options under Start from blank:

Automated cloud flow

Instant cloud flow

Scheduled cloud flow

Describe it to design it

Desktop flow

Or

b. Select My flows > New flow > one of the following menu options under Build
your own from blank:

Automated cloud flow
Instant cloud flow
Scheduled cloud flow
Describe it to design it



Desktop flow

3. Give your flow a name, select a trigger, or follow the directions to build a flow.

4. Go to the designer by selecting Create or Create flow, depending on the flow type
you selected.

5. In the designer, select the plus sign (+) to create an action, and then select Add
generative action (preview).

6. In the Parameters tab, select + New generative action.

7. To describe the automation you want to create, enter the intent of your
automation in as many details as you like. Then, get an AI suggested action plan by
selecting Generate.

AI generated suggestions



AI generates suggested input and output types to use in the flow. AI also generates
suggested connectors and actions that it can use to achieve the automation goal.

Inputs are texts that the generative action uses to execute the plan. This text can be
passed dynamically from previous cloud flow actions. Inputs are limited to 2,500
characters.

Outputs are text that the generative action creates that can be used in succeeding
actions in the flow.

 Tip

To remove additional detail or HTML and reduce input character count, review and
use the Compose action on dynamic input.

Finalize your generative action
Finalize your generative action and preview it before execution. This allows you to make
sure that the generative action is working as expected, and make necessary changes
before adding it to your cloud flow.

1. Review, accept, or reject these suggestions.

If you don't accept suggestions, they're deleted when you preview or add
your generative action to the flow.
You can add custom inputs, outputs, connectors, and actions if they aren't
suggested.



The generative action doesn't execute on actions that aren't first added to
the plan.

2. To preview your generative action, select the Preview tab.

3. Provide sample inputs for your generative action, such as an order ID or a
customer name.

The generative action shows you its thought process as it analyzes the inputs you
provided against the intent of the automation. The generative action runs and
pauses before taking any action while it's in preview. The logic, the data behind
each action, and the expected outputs display.

4. Modify the inputs, outputs, or actions if needed, and run the preview again. Once
you're satisfied with the preview, exit the preview mode.

5. When you're satisfied with your generative action, select Add to add it to your
cloud flow.

Add references to a generative action
You can add up to three Microsoft OneDrive documents as references. The generative
action can use them as part of its execution.

The Microsoft Word document must be labeled as non-confidential and reside in the
owner's OneDrive. Each Word document must be fewer than 10 MB.

Monitor a generative action
You can monitor the run history and the performance of your generative action from the
My flows page in Power Automate. You can also edit or customize your generative
action at any time in the cloud flow designer.

To monitor and edit a generative action, follow these steps:

1. From the My flows page, select the Generative actions tab.

You can display the list of your generative actions, their status, and their last run
time.

2. To monitor the run history of a generative action, select the generative action
name > Run history.



The details of each run, such as the start time, end time, duration, status, inputs,
and outputs, display. The reasoning behind each action that the generative action
called, and the data that was used also display.

3. To edit or customize a generative action, select the generative action name > Edit.

You can modify the instruction set or intent of the generative action, or the inputs,
outputs, or actions that the generative action uses.

4. Save your changes and preview your generative action again.

Known limitations
The following limitations apply to generative actions in cloud flows:

Only text based inputs are supported.

Cancelling the cloud flow doesn't cancel the running generative action. It must be
canceled separately.

Currently limited to the following connectors:
SharePoint
Office 365 Outlook
OneDrive for work or school
Planner
Microsoft Teams
Notifications
Office 365 Users
Approvals
Excel online for Business

７ Note

if you wish to include more connectors in your generative actions use case,
contact your representative.

Data loss prevention (DLP) policies for cloud flows are supported exclusively at the
generative action level. Differentiating connectors as Business or Non-Business
between cloud flow connections and generative action connections isn't currently
supported.

Related information



FAQ for generative actions in cloud flows

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Add a condition to a cloud flow
Article • 12/16/2022

Use a condition to specify that a cloud flow performs one or more tasks only if a
condition is true or false. For example, you can use a condition that indicates that you'll
get an email only if a tweet that contains a keyword is retweeted at least 10 times.

Here's a video tutorial about conditions.
https://www.microsoft.com/en-us/videoplayer/embed/RWKUx0?postJsllMsg=true

Prerequisites
Create a cloud flow from a template. This tutorial uses this template  as the example.

Add a condition
This tutorial uses an example with a Twitter trigger and a SharePoint action.

1. Sign into Power Automate .

2. On the left pane, select My flows.

3. On the list of flows, select the flow you want to edit by placing a check mark in the
circle and then selecting More commands (the three dots).

4. Select Edit.

5. Under the last action, select New step > Condition.

6. On the Condition card, select an empty area in box on the left.

The Dynamic content list opens.



7. Select the Retweet count parameter to add it to the box.

8. In the box in the middle of the Condition card, select is greater than or equal to.

9. In the box on the right, enter 10.

Now that you've configured the condition, continue with the following steps to
send an email if the Retweet count is more than 10.

10. Select Add an action on the If yes send of the condition.

11. Enter Send an email into the search box, and then select Send an email (V2).



12. Configure the Send an email (V2) card to your liking, indicating the contents of the
email that the flow sends if the Retweet count is greater than 10.

You can also configure the If no side of the condition if you'd like to take an when
the Retweet count is less than 10.

13. Save the flow.

 Tip

You can create complex conditions by using the Add button on the condition card.



Learn about all the available expressions.

Next step
Learn how to use expressions in conditions in advanced mode.



Associate flows with apps
Article • 11/21/2024

From the Power Automate portal, you can associate automated and scheduled flows
with apps in Power Apps and with Dynamics 365 apps. You can then manage flows and
apps together and more easily keep track of dependencies. If the associated app is
missing in any environment, the flow alerts you about the missing dependency. This
feature also ensures that apps are always up to date.

This feature can provide relief to makers who often struggle to keep track of which flows
are used by which apps. Without the association, flows can break if the corresponding
app isn't present in the environment. The result can be frustration and delays.

Add an association
To make an association between a flow and an app, follow these steps. For consistency
and continuity, the association is then preserved as the flow is deployed in other
environments. In this way, it helps reduce errors and speed up the development process.

1. Sign in to Power Automate .

2. On the left navigation pane, select My flows.

3. Find and select the flow that you want to associate with an app.

4. On the Associated Apps tile in the lower right, select Edit.

5. On the Associated Apps page, select Add association.

6. By default, the Power Apps tab is selected and shows the apps in Power Apps that
use the same data sources as the flow. To find Dynamics 365 apps, select the
Dynamics 365 tab.



７ Note

If you can't find your app, go to Why can't I find my app in the list of apps?
in the "FAQ" section of this article.

7. Select one or more apps, and then select Save.

8. To view the associated apps, go back to the flow details.

Remove an association
To remove an association between a flow and an app, follow these steps.

1. Sign in to Power Automate .
2. On the Associated Apps tile in the lower right, select Edit.
3. Select the app that you want to delete.
4. When a trash can symbol appears next to the app name, select it.
5. On the Remove app association page, select Remove.

FAQ

Why can't I find my app in the list of apps?



Your app might not be listed for one of the following reasons:

You don't have access to the app.
The app isn't installed in the environment.
The app doesn't use the same data sources as the flow.

I associated 10 apps. So why are only four apps shown on
the flow details page?
The Associated Apps tile on the flow details page shows only the top four apps. To view
the whole list, select Edit. All apps then appear on the Associated Apps page.

I'm deploying the flow into production. Will I have to
associate again after the flow is in production?
You need to make the association only once in the lower environments. The association
is then preserved as the flow is deployed in other environments.

Why is the status of my app association shown as failed?
The Associated Apps page shows the status of your apps.

The Association failed status might be caused by one of the following reasons:

The app is removed from the environment.
The app is edited and no longer uses the same data sources as the flow.
You no longer have access to the app.

My flow has a Power Apps trigger. So why is the
Associated Apps tile blank?
This is a known issue. If a flow has a Power Apps trigger, the apps that use that flow
aren't automatically shown. We plan to implement the functionality soon.



I have a Power Apps per app license. How can I ensure
that the in-context flows run?
A Power Apps per app license allows for a limited set of Power Automate capabilities. If
the flow is supporting an app in Power Apps, associate the flow with the app. After the
association is made, users who have a Power Apps per app license can use the flow.

Why are my end-user's Power Automate flow connections
not working in Power Apps?
It might be that the connection for the current user has become unauthenticated. For
instance, the user might have changed their password. The flow will continuously fail.
Power Apps doesn't try to automatically repair these connections or re-prompt the end
user for updated credentials. This is a known issue for Microsoft SharePoint Online and
non-Entra based connections. Refreshing the session might work. Alternatively, you
might need to wrap the flow in an IfError()  and in the failure case, invoke all the
dependent connections directly to trigger reauthentication and then rerun the flow.

I'm an admin and want to associate flows and apps in
bulk. Is there an admin command?
Use the PowerShell command Add-AdminFlowPowerAppContext to associate flows and
apps in bulk.

This is also described in the How can I associate in-context flows to Power
Apps/Dynamics 365 apps? section of the Power Automate licensing FAQ.

Related information
How can I associate in context flows to Power Apps/Dynamics365 apps
Can I use service principal in flows, and does it count against my request limits?

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Use data operations
Article • 10/09/2024

In this article, you learn about some common data operations in Power Automate, such
as compose, join, select, filter arrays, create tables, and parse JSON. Use these
operations to manipulate data when you create flows.

７ Note

The different sections in this article aren't related and aren't dependent upon each
other. The different sections use different examples.

Here's a quick video about data operations.
https://www.microsoft.com/en-us/videoplayer/embed/RWKXdo?postJsllMsg=true

Prerequisites
Access to Power Automate .
A tool to send HTTP POST requests with a JSON array to your flow.

Use the compose action
Use the Data Operation - Compose action to save yourself from having to enter the
same data multiple times as you're designing a cloud flow. In this example, you need to
enter an array of digits— [0,1,2,3,4,5,6,7,8,9]—several times while you design your
flow. You can use the compose action to save the array, as described in the following
procedure.

1. Search for compose, and then select the Compose - Data Operation action.



1. In the Inputs box, enter the array that you want to reference later.

 Tip

To make the Compose card easier to find later, rename it by selecting the text
Compose on the title bar of the card and entering a name that's easy to remember.

When you need to access the contents of the compose action, do so by following these
steps.

1. Add an action, such as Join - Data Operation.

2. Select the control to which you'd like to add the contents you saved in the
compose action.



The Add dynamic content from the apps and connectors used in this flow screen
opens.

3. On the Dynamic content tab, in the Compose section, select Outputs.

Use the join action
Use the Data Operation - Join action to delimit an array with the separator of your
choice. For example, your flow receives a web request that includes the following array
of email addresses: ["d@example.com", "k@example.com", "dal@example.com"] . However,
your email program requires addresses to be formatted in a single string, separated with
semicolons. You use the Data Operation - Join action to change the comma delimiter (,)
to a semicolon (;) by following these steps:

1. Add a new action, search for Join, and then select Data Operation - Join.

2. In the From box, enter the array, and in the Join with box, enter a semicolon (;).



3. Save your flow, and then run it.

4. After your flow runs, the output of the Data Operation – Join action will be a string
with the addresses joined by semicolons, as shown in the following screenshot.

Use the select action
Use the Data Operation – Select action to transform the shape of objects in an array.
For example, you can add, remove, or rename elements in each object in an array.

７ Note

Although you can add or remove elements by using the select action, you can't
change the number of objects in the array.



In this example, data enters your flow via a web request in this format:

JSON

[ { "first": "Eugenia", "last": "Lopez" }, { "first": "Elizabeth", "last": 
"Moore" } ]

You want to reshape the incoming data by renaming first  to FirstName  and last  to
FamilyName , and adding a new member named FullName  that combines first  and last
(separated with a space).

JSON

[ { "FirstName": "Eugenia", "FamilyName": "Lopez", "FullName": "Eugenia 
Lopez" }, { "FirstName": "Elizabeth", "FamilyName": "Moore", "FullName": 
"Elizabeth Moore" } ]

To do this:

1. Add the When an HTTP request is received trigger to your flow.

2. Select Use sample payload to generate schema.

3. In the box that appears, paste a sample of your source data array, and then select
Done.



4. Add the Data Operation – Select action, and then configure it as shown in the
following screenshot.

Use the filter array action
Use the Filter array - Data Operation action to reduce the number of objects in an array
to a subset that matches the criteria you provide.

７ Note

You can't use the filter array action to change the shape of objects in the
array.
The text on which you filter is case-sensitive.

In this example, you use the filter array action on this array:

JSON

[ { "first": "Eugenia", "last": "Lopez" }, { "first": "Elizabeth", "last": 
"Moore" } ]

This example creates a new array that contains only objects in which first  is set to
Eugenia .

1. Find, and then add, the Filter array action to your flow.

2. Configure the filter array action as shown in the following screenshot.



3. Save, and then run your flow.

Use the create CSV table action
Use the Create CSV table - Data Operation action to change a JSON array input into a
comma-separated value (CSV) table. You can keep the headers visible in the CSV output.
In this example, you convert the following array into a CSV table:

JSON

[ { "first": "Eugenia", "last": "Lopez" }, { "first": "Elizabeth", "last": 
"Moore" } ]

1. Find, add, and then configure the Create CSV table - Data Operation action to
resemble the following image.

The Body token in this image comes from a When a HTTP request is received
action; however, you can get the input for the Create CSV table action from the
output of any previous action in your flow, or you can enter it directly in the From
box.

2. Save, and then run your flow.

When your flow runs, the Create CSV table action displays the output shown in the
following screenshot.



Use the create HTML table action
Use the Create HTML table - Data Operation action to change a JSON array input into
an HTML table. You can keep the headers visible in the HTML output.

To do this, follow the steps in the previous Use the create CSV table action section for
creating a CSV table. Use the Create HTML table - Data Operation action instead of
Create CSV table.

 Tip

If you plan to send the HTML table via email, remember to select IsHtml in the
email action.

Related information
Training: Use Dataverse triggers and actions in Power Automate (module)
Training: Integrate Power Automate flows and Dataverse (learning path)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Customize or format date and time
values in a flow
Article • 01/24/2024

This article provides steps to customize or format date and time values in a Power
Automate flow.

When working with date and time values in a Power Automate flow, you might find that
the date and time format isn't what you expected, or you might want to customize the
format of the output. You can do this by passing format strings to
the formatDateTime function.

Format date and time
The formatDateTime()  function in Power Automate enables you to manipulate and
format date and time values in various display formats. It also offers an easy way to
handle data and time across different time zones.

The formatDateTime()  function takes two parameters:

Timestamp: The timestamp is the date and time value that needs to be formatted.

It can be a manual string or dynamic content. When entered manually, the
timestamp is expected to follow the ISO 8601 format ("yyyy-MM-ddTHH:mm:ssZ").

Format string: The format string specifies the output format for the date and time.

The format string parameter of the formatDateTime() function can either be a
standard format string or a custom format string.

Standard format strings
A standard format string uses a single character (for example, d, g, or G) as the format
specifier.

Examples

The format string  g  corresponds to the General date/time pattern (short time):

formatDateTime('2009-06-15T13:45:30', 'g')  // Returns the format 6/15/2009 1:45
PM



The format string  D  corresponds to the Long date pattern:

formatDateTime('2009-06-15T13:45:30', 'D')  // Returns the format Monday, June
15, 2009

For more information and examples of using standard date and time format strings, go
to Standard date and time format strings.

Custom format strings
A custom format string is any string with more than one character (for
example,  M/dd/yyyy h:mm tt ) that can control the visibility, positioning, and precision of
the month, day, year, hour, second, and so on, of the date and time value.

Examples

The format string  M/dd/yyyy h:mm tt  represents the same pattern as the standard
format string  g  as described in Standard format strings:

formatDateTime('2009-06-15T13:45:30', 'M/dd/yyyy h:mm tt')  // Returns the
format 6/15/2009 1:45 PM

The format string  HH:mm:ss tt  returns the 24 hour format:

formatDateTime('2009-06-15T13:45:30', 'M/dd/yyyy HH:mm:ss tt')  // Returns the
format 6/15/2009 13:45:30 PM

The format string hh:mm:ss tt returns the 12 hour format:

formatDateTime('2009-06-15T13:45:30', 'yyyy/MM/dd hh:mm:ss tt')  // Returns the
format 2009/06/15 1:45:30 PM

utcNow()  function used as the timestamp to automatically fetch the current date
and time in UTC, and the format string  dd-MM-yyyy  to display the date and time:

formatDateTime(utcNow(), 'MMMM dd, yyyy, HH:mm')  //Returns the current date
time in the format June 15, 2009, 16:50

utcNow()  function used as the timestamp to automatically fetch the current date
and time in UTC, and the format string  dd-MM-yyyy  to display the date but not
time:

formatDateTime(utcNow(), 'dd-MM-yyyy')  //Returns the current date in the format
15-06-2009



For more information and examples of using custom date and time format strings, go to
Custom date and time format strings.

Use in a flow
To use a date and time value in a flow, follow these steps.

1. In the flow, select the input field where you want to enter the formatted date and
time value.

2. Go to Add dynamic content and select the Expression tab to open the expression
editor.

3. Type formatDateTime().

Alternatively, look for it under Date and time functions.

4. Provide the value to be formatted, surrounded by single quotes.

Dynamic content can be used but shouldn't be surrounded by single quotes.

5. Provide the format string, surrounded by single quotes.

6. The full expression should look like the following examples:

formatDateTime('<your-value>', 'dd/MM/yyyy hh:mm tt')

formatDateTime('<dynamic-value>', 'dd/MM/yyyy hh:mm tt')



7. Select OK.

Example with dynamic content
Dynamic contents are variables produced by triggers and actions within a flow
diagram. They enable users to select field references from previous steps and write
expressions.

This example walks through a simple flow that demonstrates the use of the
formatDateTime()  function with dynamic content. The trigger used in this example is a
manually triggered flow that requires user input.

1. Sign in to Power Automate .

2. Set up the trigger for the flow. This example uses Date as the input.

a. On the left navigation pane, select Create > Instant cloud flow.

b. In the Flow name field, enter a name for your flow.

c. In the Choose how to trigger this flow list, select Manually trigger a flow.

d. Select Create.

e. Select the Manually trigger a flow card.

f. On the Paramaters tab, select + Add an input > Date.

g. In the field to the right, enter 2023-10-22.

3. Add the Send an email (v2) action.

a. Below the Manually trigger a flow card, select the plus sign (+) > Add an
action.

b. In the Search field, start typing Send an email (v2) and select it from the list
when you see it.



c. Select the Body field in the email, and then select fx (Insert Expression).

d. Select Dynamic content.

The dynamic content shown here is related to the trigger. It links together the
trigger and actions that need to be taken.

e. In the field above Dynamic content, start typing formatDateTime and select it
from the dropdown menu when it appears.

f. Scroll down the Dynamic content list and select Trigger date. If it doesn't
appear, select See More.

This variable's dynamic content comes from the date field in the trigger.

g. Provide the format string (surrounded by single quotes) based on the desired
output format for the date. In this example, MM/dd/yyyy format is used.

The full expression looks like this:

formatDateTime(triggerBody()?['date'], 'MM/dd/yyyy')

h. Select Add.

4. In the Parameters tab, insert an email in the To field, and a subject in the Subject
field.



5. Select Save.

6. After running the flow, the email received shows the date in the specified
MM/dd/yyyy format.

Example with Convert time zone
Power Automate uses Coordinated Universal Time (UTC) by default. To handle date and
time values in other time zones, you can use formatDateTime  in conjunction with the
convertTimeZone  function.

For example, to display the current time in Eastern Standard time, you can use the
following syntax:

formatDateTime(convertTimeZone(utcNow(), 'UTC', 'Eastern Standard Time'), 'yyyy-MM-

dd HH:mm:ss')  // Returns the date time adjusted for Eastern Standard time

Related information
For more information on the date and time function, select the following articles.

Convert a time zone
formatDateTime function reference
Format dates by examples
Training: Introduction to expressions in Power Automate (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Convert a time zone
Article • 01/31/2024

This article provides steps to convert the time zone to the intended time zone in a
Power Automate trigger or action.

When passing datetimes through triggers and actions in Power Automate flows, you
might find that the time zone isn't what you expected, or you might wish to convert the
time zone (frequently in Coordinated Universal Time (UTC)) to your local time. You can
do this using the Convert time zone action or the convertTimeZone  expression.

Dates are passed through services in varying formats or time zones, so each connector
might use a different datetime format or time zone. Some services strictly use UTC time
to avoid confusion.

Convert a time zone using an action
Power Automate has a built-in operation called Convert time zone.

1. Sign in to Power Automate .

2. Find your flow and select Edit to add an action.

3. In the Search box, type convert time zone and choose the built-in Convert time
zone operation.

4. Add the required and optional inputs for the Convert time zone operation.



Base time: The datetime you wish to convert.
Source time zone: The time zone that the datetime is currently in.
Destination time zone: The time zone you want to convert your date to.
Format string (Optional): The string that specifies the desired format of the
converted time.

For ways to find the current time zone, go to the Common format scenarios
section in this article.

Convert a time zone using an expression
Power Automate has an expression function convertTimeZone  that converts a timestamp
from the source time zone to the target time zone.

Here's an example of the function in the console:

Console

convertTimeZone(timestamp: string, sourceTimeZone: string, 
destinationTimeZone: string, format?: string)

The function takes the following parameters:

timestamp : The datetime you wish to convert.
sourceTimeZone : The time zone the datetime is currently in.
destinationTimeZone : The time zone you want to convert your date to.
format  (optional): The format of the time zone you wish to convert your date to.

Example: Convert a time zone
This example converts a time zone to the specified time zone and format.

Console

convertTimeZone('2018-01-01T80:00:00.0000000Z', 'UTC', 'Pacific Standard 



Time', 'D')

It returns the result: Monday, January 1, 2018 .

Example: Use dynamic content
This is an example of using dynamic content in the expression. Here, the triggerBody()?
['Date']  timestamp is the dynamic content you want to format. The source time zone is
UTC . The destination time zone is Eastern Standard Time . The format is the custom
format string HH:mm .

Console

convertTimeZone(triggerBody()?['Date'],'UTC','Eastern Standard 
Time','HH:mm')

To learn more about this expression function, go to convertTimeZone.

To learn more about the format string parameter, go to standard date and time format
strings and custom date and time format strings.

Common format scenarios
This section covers various scenarios and how to apply the appropriate format.

Decipher a datetime
Datetimes might have different formats. If your datetime has a Z  at the end, it
means it's in UTC time.

Example: 2020-04-10T01:28:14.0406387Z

You might receive an error that states your date time string isn't in the correct
format.

Example: 'The date time string must match ISO8601 format.'

To learn more about how to correctly format your datetime string, go to
convertTimeZone.

Check the time zone of an output



If you're unsure what format the datetime time zone is currently in, you can run your
flow and see the datetime output format.

In this example, the Get forecast for today operation outputs the timestamp for when
you got the forecast.

This datetime uses the ISO-8601 datetime format. This operation outputs the datetime
in the UTC time zone.

Convert a timestamp to or from UTC
To convert a timestamp from the source time zone to UTC, or from UTC to the target
time zone, use the convertFromUtc and convertToUtc expression functions.

Limitations
There might be limitations in some connectors for how the time zone displays. To learn
more about each connector, go to Connector reference overview.

Related information



Customize or format date and time values in a flow
Reference guide to workflow expression functions in Azure Logic Apps and Power
Automate

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Use expressions in conditions to check
multiple values
Article • 03/24/2025

In this tutorial, you learn to use expressions and conditions to compare multiple values
in Advanced mode.

When you create a cloud flow, you can use the Condition card in basic mode to quickly
compare a single value with another value. However, there are times when you need to
compare multiple values. For example, you might want to check the value of a few
columns in a spreadsheet or database table.

You can use any combination of the following logical expressions in your conditions.

ﾉ Expand table

Expression Description Example

and Takes two arguments and returns This expression returns false:
true if both values are true. and(greater(1,10),equals(0,0))
Note: Both arguments must be
Booleans.

or Takes two arguments and returns This expression returns true:
true if either argument is true. or(greater(1,10),equals(0,0))
Note: Both arguments must be
Booleans.

equals Returns true if two values are For example, if parameter1 is someValue,
equal. this expression returns true:

equals(parameters('parameter1'),
'someValue')

less Takes two arguments and returns This expression returns true:
true if the first argument is less less(10,100)
than the second argument.
Note: The supported types are
integer, float, and string.

lessOrEquals Takes two arguments and returns This expression returns true:
true if the first argument is less lessOrEquals(10,10)
than or equal to the second
argument.
Note: The supported types are
integer, float, and string.



Expression Description Example

greater Takes two arguments and returns This expression returns false:
true if the first argument is greater(10,10)
greater than the second
argument.
Note: The supported types are
integer, float, and string.

greaterOrEquals Takes two arguments and returns This expression returns false:
true if the first argument is greaterOrEquals(10,100)
greater than or equal to the
second argument.
Note: The supported types are
integer, float, and string.

empty Returns true if the object, array, or This expression returns true:
string is empty. empty('')

not Returns the opposite of a boolean This expression returns true:
value. not(contains('200 Success','Fail'))

if Returns a specific value if the This expression returns "yes":
expression results in true or false. if(equals(1, 1), 'yes', 'no')

Prerequisites
Here's what you need to complete this walkthrough.

Access to Power Automate.
Your own spreadsheet with the tables described later in this walkthrough. Be sure
to save your spreadsheet in a location such as Dropbox or Microsoft OneDrive so
that Power Automate can access it.
Microsoft 365 Outlook (While we use Outlook here, you can use any supported
email service in your flows.)

Use the 'or' expression
Sometimes your workflow needs to take an action if the value of an item is valueA or
valueB. For example, you might be tracking the status of tasks in a spreadsheet table.
Assume that the table has a column named Status and the possible values in this
column are:

completed
blocked



unnecessary
not started

Here's an example of what the spreadsheet might look like:

Given the preceding spreadsheet, you want to use Power Automate to remove all rows
with a Status column that is set to completed or unnecessary.

Let's create the flow.

Start with a blank flow
1. Sign into Power Automate .

2. On the left pane, select My flows.

3. Select New flow > Scheduled cloud flow.

Add a trigger to your flow
1. Give your flow a name.

2. Set the schedule to run the flow once daily.

3. Select the Create button to go to the next step.

７ Note

Power Automate uses either the classic cloud flows designer or the new
modern designer with Copilot capabilities. To identify which designer you’re
using, go to the Note section in Explore the cloud flows designer.
When you switch between the classic and new designer, you're asked to save
your flow. You can't save and switch until all errors are resolved.

Select the spreadsheet and get all rows



New designer

You can use Copilot to create the flow for you, or create it manually.

Create a flow with Copilot
1. Ask Copilot to create a flow for you. Type the following prompt in Copilot:

Every week, list rows in an Excel table, and if the Status column equals
Succeeded or claim manager's email is jake@contoso.com, delete Excel row.

2. Select Submit .

After you submit the prompt, Copilot creates the flow for you. You need to fill
in details for the flow to work, such as parameters for various actions added
by Copilot.

Create a flow manually
Alternatively, you can perform the following procedure to create the same flow
manually:

1. Add a new step by selecting the plus sign (+) > Add an action.

2. Search for rows > Excel Online (Business) > the Get a row action that
corresponds to the spreadsheet that you're using.

For example, if you're using Google Sheets, select Google Sheets - Get rows.

3. Select the List rows present in a table action.



4. Select the Location, Document Library, File, and Table that contain your data.



Check the status column of each row
New designer

1. Add a new step by selecting the plus sign (+) > Add an action.

2. On the Add an action screen, search for apply to each, and then select the
Apply to each under Control.

3. Add the value token to the Select an output from previous steps box by
selecting the lightning rod icon.

This value token represents the spreadsheet table and all of its data.

4. On the Apply to each card, add a new step by selecting the plus sign (+) >
Add an action.

5. Search for condition, and then select the Condition control.

6. Add the following OR expression. This OR expression checks the value of each
row in the table.

If the value of the Status column is completed Or unnecessary, the OR
expression evaluates to true.

Here's an example of a Condition card.



Delete matching rows from the spreadsheet

New designer

1. Select the plus sign (+) to add an action on the True branch of the condition.

The True branch runs if the Or condition evaluates to true.

2. Search for Excel Online (Business) and then select Delete a row.

3. On the Delete a row panel, set the Location, Document Library, File, and
Table boxes exactly as you set these boxes on the List rows present in a table
card earlier in this tutorial.

4. In the Key Column dropdown list, select _PowerAppsId_.



5. In the Key Value field, insert the _PowerAppsId_ dynamic value.

6. Save your flow.

Run the flow with the 'or' expression
The flow runs after you save it. If you created the spreadsheet shown earlier in this
tutorial, here's what it looks like after the run completes.

Notice all data from rows that had completed or unnecessary in the Status column
were deleted.

Use the 'and' expression
Assume you have a spreadsheet table with two columns. The column names are Status
and Assigned. Assume also that you want to delete all rows if the Status column's value
is blocked and the Assigned column's value is John Wonder. To accomplish this task,
follow all steps earlier in this tutorial, but when you edit the Condition card in advanced
mode, use the and expression shown here.

@and(equals(item()?['Status'], 'blocked'), equals(item()?['Assigned'], 'John

Wonder'))

Here's an example of a Condition card.

Run the flow with the 'and' expression



If you followed the steps in this tutorial, your spreadsheet should look similar to the
following screenshot.

After your flow runs, your spreadsheet should look similar to the following screenshot.

Use the 'empty' expression
Notice that there are several empty rows in the spreadsheet now. To remove them, use
the empty expression to identify all rows that don't have text in the Assigned and Status
columns.

To accomplish this task, follow all steps listed in the Use the 'and' expression section
earlier in this tutorial. When you edit the Condition card in advanced mode, use the
following empty expression.

@and(empty(item()?['Status']), empty(item()?['Assigned']))

Your Condition card should look similar to the following screenshot.

After your flow runs, the spreadsheet should look similar to the following screenshot.



Notice extra lines are removed from the table.

Use the 'greater' expression
Imagine you bought baseball tickets for your coworkers and you use a spreadsheet to
ensure you get reimbursed by each person. You can quickly create a cloud flow that
sends a daily email to each person who didn't paid the full amount.

Use the greater expression to identify the employees who didn't pay the full amount.
You can then automatically send a reminder email to them.

Here's a view of the spreadsheet.

Here's the implementation of the greater expression that identifies all persons who paid
less than the amount due from them.

@greater(item()?['Due'], item()?['Paid'])

Use the 'less' expression
Imagine you bought baseball tickets for your coworkers, and you use a spreadsheet to
ensure you get reimbursed by each person by the date to which everyone agreed. You
can create a cloud flow that sends a reminder email to each person who didn't pay the
full amount if the current date is less than one day before the due date.

Use the and expression with the less expression since there are two conditions being
validated.

ﾉ Expand table

Condition to validate Expression to Example
use

Has the full amount due been greater @greater(item()?['Due'], item()?
paid? ['Paid'])

Is the due date less than one day less @less(item()?['DueDate'],
away? addDays(utcNow(),1))



Combine the 'greater' and 'less' expressions in
an 'and' expression
Use the greater expression to identify the employees who paid less than the full amount
due and use the less expression to determine if the payment due date is less than one
day away from the current date. You can then use the Send an email action to send
reminder emails to those employees who didn't pay in full and the due date is less than
one day away.

Here's a view of the spreadsheet table.

Here's the implementation of the and expression that identifies all employees who paid
less than the amount due from them and the due date is less than one day away from
the current date.

@and(greater(item()?['Due'], item()?['Paid']), less(item()?['dueDate'],

addDays(utcNow(),1)))

Use functions in expressions
Some expressions get their values from runtime actions that might not yet exist when a
cloud flow starts to run. To reference or work with these values in expressions, you can
use functions that the Workflow Definition Language provides. More information. To
learn more, go to Reference guide to workflow expression functions in Azure Logic Apps
and Power Automate.

Related information
Training: Introduction to expressions in Power Automate (module)

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Create, update, and fix expressions with
Copilot expression assistant (preview)
Article • 03/24/2025

[This article is prerelease documentation and is subject to change.]

This feature is available to tenants where Copilot is enabled. On the modern designer,
you can use this functionality to create, update, or fix expression with the help of
Copilot.

） Important

This is a preview feature.
Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.

Open the expression editor
Once you open the expression editor, you can use the instructions in the following
scenarios to create and edit your expressions.

1. Select the action that contains the operation you want to edit.
2. In the action configuration pane, select the field that you want to edit.
3. Select fx.

Scenario 1: Create an expression with natural
language
Use Copilot to create an expression with natural language.

1. On the expression editor, select Create expression with Copilot.

The user experience that displays is the user experience for expression assistant.

2. In the text box, write a prompt to generate an expression for, and select Create
expression.



You can reference the flow’s dynamic content in your prompt using their names to
build expressions around. For example, assume you have first name, last name,
phone number, and TriggerDate as dynamic data in your flow. You can ask
following sample prompts:

Concatenate first name and last name.
Grab last four characters of Phone Number.
Convert Phone number from Integer to String.
Format TriggerDate to 'DD-MM' format.

Scenario 2: Update an existing expression with
natural language
If you have an existing expression that you created manually or through the expression
assistant, you can select Create expression with Copilot in expression editor. Now it
understands the context of the expression, and any prompt you write is used to modify
the existing expression.

To finalize the update, follow this procedure:

1. To return the updated expression, select Create expression.
2. To apply to expression editor, select OK.
3. To apply to your flow, select Add.

For example, select an expression.



Then, select Create expression with Copilot. Next, describe how you want to update this
existing expression and select Update.

Finally, select OK to apply the Copilot generated expression.



Scenario 3: Fix an invalid expression using a
button
You can use the same experience to fix erroneous expressions. The following example
shows an erroneous expression that has a missing parenthesis after 'Phone' [variables
function opening parenthesis didn't close].



At this point, when you select Create expression with Copilot, it automatically fixes the
expression that is currently loaded in expression editor.

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Store and manage values in variables
Article • 04/04/2025

This article shows how to create and work with variables to store values in your cloud
flows. For example, variables can help you track the number of times a loop runs. To
iterate over an array or check an array for a specific item, you can use a variable to
reference the index number 'apply to each' array item.

You can create variables for data types such as integer, float, boolean, string, array, and
object. After you create a variable, you can perform other tasks, for example:

Get or reference the variable's value.
Increase or decrease the variable by a constant value, also known as increment and
decrement.
Assign a different value to the variable.
Insert or append the variable's value as the last item in a string or array.

Variables exist and are global only within the cloud flow that creates them. Also, they
persist across any loop iterations inside the flow.

When you reference a variable, use the variable's name as the token, not the action's
name, which is the usual way to reference an action's outputs.

２ Warning

By default, each iteration in the 'apply to each' loops run sequentially. You can run
the loop iterations in parallel to improve performance. If you use variables in the
'apply to each' loops, you must run the loop iterations sequentially if it's important
for your loop variables to return predictable results.

Prerequisites
Before you can add actions for creating and working with variables, your flow must start
with a trigger. You can't use a mobile device to add variables.

Access to Power Automate .
A cloud flow in which you want to create the variable.
If you're new to Power Automate, review Get started with Power Automate and
Overview of cloud flows.



７ Note

Power Automate uses either the classic cloud flows designer or the new
modern designer with Copilot capabilities. To identify which designer you’re
using, go to the Note section in Explore the cloud flows designer.
When you switch between the classic and new designer, you're asked to save
your flow. You can't save and switch until all errors are resolved.

Initialize a variable
New designer

You can create a variable and declare its data type and initial value all within one
action in your flow. You can only declare variables at the global level, not within
scopes, conditions, and loops.

1. Sign in to Power Automate .

2. Create or open a cloud flow.

3. Under the step where you want to add a variable, follow one of these steps.

To add an action below the last step, select the plus sign (+).
To add an action between steps, move your input device pointer over the
connecting arrow so that the plus sign (+) appears. Select the plus sign
(+) > Add an action.

4. In the search box under Add an action, enter initialize variable as your filter.

5. From the Actions list, select Initialize variable - Variable.

6. Provide the following information about your variable.

ﾉ Expand table

Property Required Value Description

Name Yes <variable- The name for the variable to initialize.
name>

Type Yes <variable- The data type for the variable.
type>



Property Required Value Description

Value No <start- The initial value for your variable.
value> Tip: Although optional, set this value as a best

practice so you always know the start value for
your variable.

Example:

7. Add the other actions that you want. When you're done, select Save.

７ Note

Although the Initialize variable action has a variable  section structured as an
array, the action can create only one variable at a time. Each new variable
requires an individual Initialize variable action.

Examples of other variable types
String variable

JSON

   "name": "myStringVariable",
   "type": "String",
   "value": "lorem ipsum"

Boolean variable



JSON

   "name": "myBooleanVariable",
   "type": "Boolean",
   "value": false

Array with integers

JSON

   "name": "myArrayVariable",
   "type": "Array",
   "value": [1, 2, 3]

Array with strings

JSON

   "name": "myArrayVariable",
   "type": "Array",
   "value": ["red", "orange", "yellow"]

Get the variable's value
To retrieve or reference a variable's contents, you can use the variables()  function in
the Power Automate designer.

For example, this expression gets the items from the array variable by using the
variables()  function. The string()  function returns the variable's contents in string
format: "1, 2, 3, red"

JSON

@{string(variables('myArrayVariable'))}

Increment variable
To increase or increment a variable by a constant value, add the Increment variable
action to your flow.

７ Note



The Increment variable action works only with integer and float variables.

New designer

1. In the Power Automate designer, under the step where you want to increase
an existing variable, select the plus sign (+).

To add an action between steps, move your input device pointer over the
connecting arrow until the plus sign (+) appears. Select the plus sign (+) >
Add an action.

2. In the search box, enter increment variable as your filter.

3. In the Actions list, select Increment variable - Variable.

4. Provide this information for incrementing your variable:

ﾉ Expand table

Property Required Value Description

Name Yes <variable- The name for the variable to increment
name>

Value No <increment- The value used for incrementing the variable.
value> The default value is one.

Tip: Although optional, set this value as a
best practice so you always know the specific
value for incrementing your variable.

Example:



5. When you're done, select Save on the designer toolbar.

Example: Create loop counter
Variables are commonly used for counting the number of times that a loop runs. This
example shows how to create and use variables for this task by creating a loop that
counts the attachments in an email.

New designer

1. In Power Automate, create a cloud flow and add a trigger that checks for new
email and any attachments.

This example uses the Office 365 Outlook trigger for When a new email
arrives (V3). You can set up this trigger to fire only when the email has
attachments. However, you can use any connector that checks for new emails
with attachments, such as the Outlook.com connector.

2. In the trigger, to check for attachments and pass those attachments into your
flow, select Yes for these properties:

Include Attachments
Only with Attachments

3. Add the Initialize variable action with the following values:

Name: Count
Type: Integer
Value: 0 (start value)

4. Add an apply to each loop to cycle through the attachments.
a. Under the Initialize variable action, select New step.
b. In the search box, enter apply to each as your search filter, and select

Apply to each.



5. In the loop, select inside the Select an output from previous steps box. When
the dynamic content list appears, select Attachments.

The Attachments property passes an array, which has all email attachments
from the email, into your loop.

6. In the Apply to each loop, select the plus sign (+) for Add an action.

7. In the search box, enter increment variable as your filter.

8. From the actions list, select Increment variable.

７ Note

The Increment variable action must appear inside the loop.

9. In the Increment variable action, from the Name list, select the Count
variable.

10. Under the loop, add any action that sends you the number of attachments. In
your action, include the value from the Count variable. For example, in the
following screenshot, Send an email (V2) sends the number of attachments:



11. On the designer toolbar, select Save.

Decrement variable
To decrease or decrement a variable by a constant value, follow the steps for increasing a
variable except that you find and select the Decrement variable action instead. This
action works only with integer and float variables.

Here are the properties for the Decrement variable action:

ﾉ Expand table

Property Required Value Description

Name Yes <variable- The name for the variable to decrement
name>



Property Required Value Description

Value No <increment- The value for decrementing the variable. The default
value> value is one.

Tip: Although optional, set this value as a best practice
so you always know the specific value for decrementing
your variable.

Set variable
To assign a different value to an existing variable, follow the steps for increasing a
variable except that you:

1. Find and select the Set variable action instead.

2. Provide the variable name and value you want to assign. Both the new value and
the variable must have the same data type. The value is required because this
action doesn't have a default value.

Here are the properties for the Set variable action:

ﾉ Expand table

Property Required Value Description

Name Yes <variable- The name for the variable to change
name>

Value Yes <new-value> The value you want to assign the variable. Both must
have the same data type.

７ Note

Unless you're incrementing or decrementing variables, changing variables inside
loops might create unexpected results if you run loops in parallel. For these cases,
try setting your loop to run sequentially, which is the default setting.

Append to variable
For variables that store strings or arrays, you can insert or append a variable's value as
the last item in those strings or arrays. You can follow the steps for increasing a variable
except that you follow these steps instead:



1. Find and select one of these actions based on whether your variable is a string or
an array.

Append to string variable
Append to array variable

2. Provide the value to append as the last item in the string or array. This value is
required.

Here are the properties for the Append to... actions:

ﾉ Expand table

Property Required Value Description

Name Yes <variable- The name for the variable to change
name>

Value Yes <append-value> The value you want to append, which can have any
type

Related information
Power Automate connectors

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Manage sensitive input like passwords
Article • 12/16/2022

Some inputs like passwords need to be omitted from the logs. Power Automate uses
Sensitive text inputs to store these "confidential" values.

Follow these steps to turn on Secure Inputs and Secure Outputs to work with sensitive
content from connectors.

1. On the top right corner of an action, select (…).

2. Select Settings.

3. Turn on the Secure Inputs and Secure Outputs properties to prevent these values
from being shown in the logs.



4. Select Done.

You'll notice that the action now has a lock icon on the top right, indicating special
handling for input and output values.



 Tip

Follow the same steps to configure inputs as given earlier in this article to pass the
output from this connector to a desktop flow, and then turn on Secure Text in the
Settings.



Cancel or resubmit flow runs in bulk
Article • 02/20/2025

You can cancel or resubmit your flow runs in bulk instead of one at a time, which can be
a huge time saver.

Resubmit flow runs initiated by instant triggers
Administrators can enable users to resubmit flow runs initiated by instant triggers.
Instant triggers, which are used to manually start flows, can be activated through Power
Automate, a mobile app, or a button in a canvas app, among other methods.

） Important

Starting on February 6, 2025, we'll change the functionality of the Power Platform
Admin setting Power Automate flow run resubmission. Previously, users could
disable flow run resubmissions initiated by instant triggers for all users. With the
update, users can resubmit their own flows initiated by instant triggers but aren't
able to resubmit flows initiated by others. The state of the Power Platform admin
center toggle on your tenant remains unchanged, as this update is rolled out in
February.

ﾉ Expand table

Scenario matrix January 2025 feature release February 2025 feature update
(currently rolling out)

Feature setting User can't resubmit their own User can resubmit their own flows
disabled in Power flows initiated by instant triggers, initiated by instant triggers, but
Platform admin or resubmit flows initiated by disallowed to resubmit flows initiated
center another user. by another user.

Feature setting User can resubmit their own flows User can resubmit their own flows
enabled in Power initiated by instant triggers and initiated by instant triggers and also
Platform admin also resubmit flows initiated by resubmit flows initiated by another
center another user. user.

There are two options to enable flow run resubmission for flows initiated by instant
triggers, which are through Power Platform admin center and by using PowerShell.



Power Platform admin center
1. Sign in to your Power Platform admin center account.
2. Select Settings and then search for Power Automate flow run resubmission.
3. Choose whether to enable or disable the functionality using the toggle.

Apply tenant setting using PowerShell prerequisites
To perform the administration operations in the cmdlets, you need the following:

Any of these roles from Microsoft Entra ID: Tenant admin, Power Platform
administrator, or Dynamics 365 Service Administrator. These roles can access the
Power Apps admin PowerShell cmdlets without requiring a Power Apps plan for
administrative access. However, these administrators need to sign in to the Power
Platform admin center at least once before using the PowerShell cmdlets. If this
isn't done, the cmdlets fail with an authorization error.

Power Platform administrator or Dynamics 365 administrator permissions are
required to search through another user's resources. Environment admins only
have access to those environments and environment resources for which they have
permissions.

For Dataverse for Teams environments, you must be a Power Platform
administrator to manage environments where you aren't the owner of the team in
Microsoft Teams.

７ Note

It takes approximately an hour for the function to become enabled after the
PowerShell commands are applied.

1. Sign in to your tenant account:

PowerShell

 Add-PowerAppsAccount -Endpoint "prod" -TenantID <Tenant_ID>

1. Retrieve and store your tenant settings in TenantSettings:

PowerShell

 $tenantSettings = Get-TenantSettings



1. Set the powerPlatform.powerAutomate.disableFlowRunResubmission  flag to False, to
allow flow run resubmissions for cloud flows initialized by instant triggers.

PowerShell

 $tenantSettings.powerPlatform.powerAutomate.disableFlowRunResubmission= 
$False
 Set-TenantSettings -RequestBody $tenantSettings

Learn more about PowerShell commands in PowerShell support for Power Apps and
Power Automate.

Resubmit flow runs
You can resubmit previous runs of a flow in bulk. To do this, follow these steps:

1. Sign in to Power Automate .

2. On the left panel, select My flows.

3. On the right panel, select the cloud flow that you want to resubmit or cancel.

4. Select All runs.

 Tip



The flow must have runs to cancel or resubmit the flow runs.
You can resubmit or cancel up to 20 flows at a time.

5. On the Run history page, select the flow runs that you want to resubmit or cancel.

6. Select Resubmit flow run(s).

） Important

The number of flows that you can resubmit is limited based on the maximum
number of API calls for the connectors in the flow.

Cancel flow runs
You can cancel flow runs on the related flow's Run history page, or by using a
template . The bulk cancel feature available through the flow portal is most efficient
when you cancel up to 20 flows at a time. We recommend that you use the template
linked previously in this section for more than 20 runs when possible. This also applies
to runs in the hundreds. Alternatively, you can use the bulk cancel feature for all flows in
Waiting or Running status regardless of the count. To set an expectation of how this
utility functions review the following details.

Cancel flow runs in bulk on the flow 'Run history' page
1. To cancel flows, navigate to the flow portal and select My flows.

2. Next to the flow, select the ellipses (…) > Run history.

Alternatively, you can select the flow name > All runs from the 28-day run history
list.



3. You can manually select up to 20 flows that are in Waiting or Running state.

To initiate the bulk cancellation feature instead, select Cancel all flow runs in the
Run history menu at the top of the screen.

4. After you select Cancel all flows, a message appears asking you to initiate the bulk
utility. Select Yes. If you're concerned about further unwanted flow runs being
initiated, you can turn off the flow.

5. If there are more than 20 flows in Waiting or Running status, another message
might appear to indicate that it might take several minutes for the flow run
statuses to change to Canceling. This message means your flows are suspended,
and no further actions are executed for flows that are already Running. Flows in
Waiting status are also terminated without actions being executed.

6. Get the updated status changes in the run history list by periodically refreshing
your browser screen.



７ Note

Flows in the Running state are suspended and change to a state of
Canceling before eventually changing to Canceled.
This process can sometimes take up to 24 hours more.
In this scenario, the flows are suspended, and no further actions are
executed.
If you select a flow run in the Canceling state, it might appear that the
spinner near an action is in motion, but it's in a suspended state. When
flows are actually running, a notification banner displays to indicate your
flow is running. This isn't the case for suspended flows in the Canceling
state.

The following screenshot shows the banner when a flow is running. A suspended flow in
the Canceling status doesn't contain this banner.

Flows that exceeded the concurrency setting might be visible in the Waiting state
alongside other flow runs in the Canceling state. This is by design. The flows were
suspended when the bulk cancel was submitted unless they were triggered after the
feature was used. The state changes to Canceling when their turn to be processed
comes up in the queue.



You can ensure that flows in the Running or Waiting state before submitting a bulk
cancel request were suspended and eventually change to the Canceled state.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Design flows with Microsoft Visio
Article • 07/26/2024

The Power Automate designer is a rich tool in which you can configure every detail of
your logic. However, sometimes you may want to just sketch your flow logic before you
start building your flow. To do this, use Microsoft Visio directly from within Power
Automate.

 Tip

Many processes share a common model but have minor variations throughout an
organization. You can save time within your organization by using Visio to create a
master workflow model that others will then adjust with specialized parameters.

７ Note

This feature isn't available for GCC (Government Community Cloud), GCC High, or
DoD (Department of Defense) customers.

Prerequisites
A Power Automate  account.
The Microsoft Visio desktop app (English version).
Expertise in using Microsoft Visio.

Design a workflow in Visio
1. Sign in to Power Automate .

2. From the left pane, select Templates.



3. From the menu at the top, select Visio.

4. From the list of Visio templates, select Basic Flow BPMN Diagram.

） Important

Visio warns you that files from the Internet could harm your device. If you are
comfortable, select YES on the warning message.



The Visio designer opens.

5. Use the BPMN basic shapes to design your workflow .



Prepare to export your workflow to Power
Automate
Follow these steps to prepare your workflow so that you can export it to Power
Automate.

1. Select the Process tab.

2. Select Prepare to Export from the Power Automate group of icons.

The Prepare to Export group opens.



3. On the Flow Mapping tab of the Prepare to Export group, map your BPMN
diagram to Power Automate controls.

4. On the Triggers and Actions tab of the Prepare to Export group, select each
shape, and then select either a trigger or an action to map your BPMN diagram to
Power Automate triggers and actions. This mapping is to represent that shape in
Power Automate.

You can export your workflow when no issues remain on the Prepare to Export
control.

Export your workflow
1. Select the Export to Flow button to export your workflow diagram to Power

Automate.

2. Name your flow and then select the Create flow button.



3. You should see a success report similar to this one.

You can now run or make edits to your flow from the Power Automate designer, just like
any other flow.

 Tip

Use Visio's sharing and commenting capabilities to collaborate with multiple
stakeholders and quickly create a complete workflow .



Related information
Get started with Power Automate
Build multi-step flows
Design a cloud flow with Microsoft Visio

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Reference guide to workflow expression
functions in Azure Logic Apps and
Power Automate
Article • 03/27/2025

Applies to: Azure Logic Apps (Consumption + Standard)

For workflow definitions in Azure Logic Apps and Power Automate, some expressions
get their values from runtime actions that might not yet exist when your workflow starts
running. To reference or process the values in these expressions, you can use expression
functions provided by the Workflow Definition Language.

７ Note

This reference page applies to both Azure Logic Apps and Power Automate, but
appears in the Azure Logic Apps documentation. Although this page refers
specifically to logic app workflows, these functions work for both flows and logic
app workflows. For more information about functions and expressions in Power
Automate, review Use expressions in conditions.

For example, you can calculate values by using math functions, such as the add()
function, when you want the sum from integers or floats. Here are other example tasks
that you can perform with functions:

ﾉ Expand table

Task Function syntax Result

Return a string in lowercase toLower('<text>') "hello"
format.

For example:
toLower('Hello')

Return a globally unique guid() "c2ecc88d-88c8-4096-912c-
identifier (GUID). d6f2e2b138ce"

To find functions based on their general purpose, review the following tables. Or, for
detailed information about each function, see the alphabetical list.

Functions in expressions



To show how to use a function in an expression, this example shows how you can get
the value from the customerName  parameter and assign that value to the accountName
property by using the parameters() function in an expression:

JSON

"accountName": "@parameters('customerName')"

Here are some other general ways that you can use functions in expressions:

ﾉ Expand table

Task Function syntax in an expression

Perform work with an item by passing that item to "@<functionName>(<item>)"
a function.

1. Get the parameterName's value by using the "@<functionName>
nested parameters()  function. (parameters('<parameterName>'))"
2. Perform work with the result by passing that
value to functionName.

1. Get the result from the nested inner function "@<functionName2>(<functionName>
functionName. (<item>))"
2. Pass the result to the outer function
functionName2.

1. Get the result from functionName. "@<functionName>(<item>).
2. Given that the result is an object with property <propertyName>"
propertyName, get that property's value.

For example, the concat()  function can take two or more string values as parameters.
This function combines those strings into one string. You can either pass in string
literals, for example, "Sophia" and "Owen" so that you get a combined string,
"SophiaOwen":

JSON

"customerName": "@concat('Sophia', 'Owen')"

Or, you can get string values from parameters. This example uses the parameters()
function in each concat()  parameter and the firstName  and lastName  parameters. You
then pass the resulting strings to the concat()  function so that you get a combined
string, for example, "SophiaOwen":



JSON

"customerName": "@concat(parameters('firstName'), parameters('lastName'))"

Either way, both examples assign the result to the customerName  property.

Considerations for using functions
The designer doesn't evaluate runtime expressions that are used as function
parameters at design time. The designer requires that all expressions can be fully
evaluated at design time.

Function parameters are evaluated from left to right.

In the syntax for parameter definitions, a question mark (?) that appears after a
parameter means the parameter is optional. For example, see getFutureTime().

Function expressions that appear inline with plain text require enclosing curly
braces ({}) to use the expression's interpolated format instead. This format helps
avoid parsing problems. If your function expression doesn't appear inline with
plain text, no curly braces are necessary.

The following example shows the correct and incorrect syntax:

Correct: "<text>/@{<function-name>('<parameter-name>')}/<text>"

Incorrect: "<text>/@<function-name>('<parameter-name>')/<text>"

OK: "@<function-name>('<parameter-name>')"

The following sections organize functions based on their general purpose, or you can
browse these functions in alphabetical order.

String functions
To work with strings, you can use these string functions and also some collection
functions. String functions work only on strings.

ﾉ Expand table



String Task
function

chunk Split a string or collection into chunks of equal length.

concat Combine two or more strings, and return the combined string.

endsWith Check whether a string ends with the specified substring.

formatNumber Return a number as a string based on the specified format

guid Generate a globally unique identifier (GUID) as a string.

indexOf Return the starting position for a substring.

isFloat Return a boolean that indicates whether a string is a floating-point number.

isInt Return a boolean that indicates whether a string is an integer.

lastIndexOf Return the starting position for the last occurrence of a substring.

length Return the number of items in a string or array.

nthIndexOf Return the starting position or index value where the nth occurrence of a
substring appears in a string.

replace Replace a substring with the specified string, and return the updated string.

slice Return a substring by specifying the starting and ending position or value. See
also substring.

split Return an array that contains substrings, separated by commas, from a larger
string based on a specified delimiter character in the original string.

startsWith Check whether a string starts with a specific substring.

substring Return characters from a string, starting from the specified position. See also
slice.

toLower Return a string in lowercase format.

toUpper Return a string in uppercase format.

trim Remove leading and trailing whitespace from a string, and return the updated
string.

Collection functions
To work with collections, generally arrays, strings, and sometimes, dictionaries, you can
use these collection functions.



ﾉ Expand table

Collection Task
function

chunk Split a string or collection into chunks of equal length.

contains Check whether a collection has a specific item.

empty Check whether a collection is empty.

first Return the first item from a collection.

intersection Return a collection that has only the common items across the specified
collections.

item If this function appears inside a repeating action over an array, return the
current item in the array during the action's current iteration.

join Return a string that has all the items from an array, separated by the specified
character.

last Return the last item from a collection.

length Return the number of items in a string or array.

reverse Reverse the order of items in an array.

skip Remove items from the front of a collection, and return all the other items.

sort Sort items in a collection.

take Return items from the front of a collection.

union Return a collection that has all the items from the specified collections.

Logical comparison functions
To work with conditions, compare values and expression results, or evaluate various
kinds of logic, you can use these logical comparison functions. For the full reference
about each function, see the alphabetical list.

７ Note

If you use logical functions or conditions to compare values, null values are
converted to empty string ( "" ) values. The behavior of conditions differs when you



compare with an empty string instead of a null value. For more information, see the
string() function.

ﾉ Expand table

Logical comparison Task
function

and Check whether all expressions are true.

equals Check whether both values are equivalent.

greater Check whether the first value is greater than the second value.

greaterOrEquals Check whether the first value is greater than or equal to the second
value.

if Check whether an expression is true or false. Based on the result,
return a specified value.

isFloat Return a boolean that indicates whether a string is a floating-point
number.

isInt Return a boolean that indicates whether a string is an integer.

less Check whether the first value is less than the second value.

lessOrEquals Check whether the first value is less than or equal to the second
value.

not Check whether an expression is false.

or Check whether at least one expression is true.

Conversion functions
To change a value's type or format, you can use these conversion functions. For
example, you can change a value from a Boolean to an integer. For more information
about how Azure Logic Apps handles content types during conversion, see Handle
content types. For the full reference about each function, see the alphabetical list.

７ Note

Azure Logic Apps automatically or implicitly performs base64 encoding and
decoding, so you don't have to manually perform these conversions by using the
encoding and decoding functions. However, if you use these functions anyway in



the designer, you might experience unexpected rendering behaviors in the
designer. These behaviors affect only the functions' visibility and not their effect
unless you edit the functions' parameter values, which removes the functions and
their effects from your code. For more information, see Implicit data type
conversions.

ﾉ Expand table

Conversion function Task

array Return an array from a single specified input. For multiple inputs, see
createArray.

base64 Return the base64-encoded version for a string.

base64ToBinary Return the binary version for a base64-encoded string.

base64ToString Return the string version for a base64-encoded string.

binary Return the binary version for an input value.

bool Return the Boolean version for an input value.

createArray Return an array from multiple inputs.

dataUri Return the data URI for an input value.

dataUriToBinary Return the binary version for a data URI.

dataUriToString Return the string version for a data URI.

decimal Return the decimal number for a decimal string.

decodeBase64 Return the string version for a base64-encoded string.

decodeDataUri Return the binary version for a data URI.

decodeUriComponent Return a string that replaces escape characters with decoded versions.

encodeUriComponent Return a string that replaces URL-unsafe characters with escape
characters.

float Return a floating point number for an input value.

int Return the integer version for a string.

json Return the JavaScript Object Notation (JSON) type value or object for a
string or XML.

string Return the string version for an input value.



Conversion function Task

uriComponent Return the URI-encoded version for an input value by replacing URL-
unsafe characters with escape characters.

uriComponentToBinary Return the binary version for a URI-encoded string.

uriComponentToString Return the string version for a URI-encoded string.

xml Return the XML version for a string.

Implicit data type conversions
Azure Logic Apps automatically or implicitly converts between some data types, so you
don't have to manually perform these conversions. For example, if you use non-string
values where strings are expected as inputs, Azure Logic Apps automatically converts
the non-string values into strings.

For example, suppose a trigger returns a numerical value as output:

triggerBody()?['123']

If you use this numerical output where string input is expected, such as a URL, Azure
Logic Apps automatically converts the value into a string by using the curly braces ( {} )
notation:

@{triggerBody()?['123']}

Base64 encoding and decoding
Azure Logic Apps automatically or implicitly performs base64 encoding or decoding, so
you don't have to manually perform these conversions by using the corresponding
functions:

base64(<value>)

base64ToBinary(<value>)

base64ToString(<value>)

base64(decodeDataUri(<value>))

concat('data:;base64,',<value>)

concat('data:,',encodeUriComponent(<value>))

decodeDataUri(<value>)

７ Note



If you manually add any of these functions while using the designer, either directly
to a trigger or action or by using the expression editor, navigate away from the
designer, and then return to the designer, the function disappears from the
designer, leaving behind only the parameter values. This behavior also happens if
you select a trigger or action that uses this function without editing the function's
parameter values. This result affects only the function's visibility and not the effect.
In code view, the function is unaffected. However, if you edit the function's
parameter values, the function and its effect are both removed from code view,
leaving behind only the function's parameter values.

Math functions
To work with integers and floats, you can use these math functions. For the full reference
about each function, see the alphabetical list.

ﾉ Expand table

Math function Task

add Return the result from adding two numbers.

div Return the result from dividing two numbers.

max Return the highest value from a set of numbers or an array.

min Return the lowest value from a set of numbers or an array.

mod Return the remainder from dividing two numbers.

mul Return the product from multiplying two numbers.

rand Return a random integer from a specified range.

range Return an integer array that starts from a specified integer.

sub Return the result from subtracting the second number from the first number.

Date and time functions
To work with dates and times, you can use these date and time functions. For the full
reference about each function, see the alphabetical list.

ﾉ Expand table



Date or time Task
function

addDays Add days to a timestamp.

addHours Add hours to a timestamp.

addMinutes Add minutes to a timestamp.

addSeconds Add seconds to a timestamp.

addToTime Add specified time units to a timestamp. See also getFutureTime.

convertFromUtc Convert a timestamp from Universal Time Coordinated (UTC) to the
target time zone.

convertTimeZone Convert a timestamp from the source time zone to the target time zone.

convertToUtc Convert a timestamp from the source time zone to Universal Time
Coordinated (UTC).

dateDifference Return the difference between two dates as a timespan.

dayOfMonth Return the day of the month component from a timestamp.

dayOfWeek Return the day of the week component from a timestamp.

dayOfYear Return the day of the year component from a timestamp.

formatDateTime Return the date from a timestamp.

getFutureTime Return the current timestamp plus the specified time units. See also
addToTime.

getPastTime Return the current timestamp minus the specified time units. See also
subtractFromTime.

parseDateTime Return the timestamp from a string that contains a timestamp.

startOfDay Return the start of the day for a timestamp.

startOfHour Return the start of the hour for a timestamp.

startOfMonth Return the start of the month for a timestamp.

subtractFromTime Subtract a number of time units from a timestamp. See also getPastTime.

ticks Return the ticks  property value for a specified timestamp.

utcNow Return the current timestamp as a string.



Workflow functions
These workflow functions can help you:

Get details about a workflow instance at run time.
Work with the inputs used for instantiating logic apps or flows.
Reference the outputs from triggers and actions.

For example, you can reference the outputs from one action and use that data in a later
action. For the full reference about each function, see the alphabetical list.

ﾉ Expand table

Workflow function Task

action Return the current action's output at runtime, or values from other
JSON name-and-value pairs. See also actions.

actions Return an action's output at runtime, or values from other JSON
name-and-value pairs. See also action.

body Return an action's body  output at runtime.

formDataMultiValues Create an array with the values that match a key name in form-data
or form-encoded action outputs.

formDataValue Return a single value that matches a key name in an action's form-
data or form-encoded output.

item If this function appears inside a repeating action over an array,
return the current item in the array during the action's current
iteration.

items If this function appears inside a Foreach or Until loop, return the
current item from the specified loop.

iterationIndexes If this function appears inside an Until loop, return the index value
for the current iteration. You can use this function inside nested
Until loops.

listCallbackUrl Return the "callback URL" that calls a trigger or action.

multipartBody Return the body for a specific part in an action's output that has
multiple parts.

outputs Return an action's output at runtime.

parameters Return the value for a parameter that is described in your workflow
definition.



Workflow function Task

result Return the inputs and outputs from the top-level actions inside the
specified scoped action, such as For_each , Until , and Scope .

trigger Return a trigger's output at runtime, or from other JSON name-
and-value pairs. See also triggerOutputs and triggerBody.

triggerBody Return a trigger's body  output at runtime. See trigger.

triggerFormDataValue Return a single value matching a key name in form-data or form-
encoded trigger outputs.

triggerMultipartBody Return the body for a specific part in a trigger's multipart output.

triggerFormDataMultiValues Create an array whose values match a key name in form-data or
form-encoded trigger outputs.

triggerOutputs Return a trigger's output at runtime, or values from other JSON
name-and-value pairs. See trigger.

variables Return the value for a specified variable.

workflow Return all the details about the workflow itself during run time.

URI parsing functions
To work with uniform resource identifiers (URIs) and get various property values for
these URIs, you can use these URI parsing functions. For the full reference about each
function, see the alphabetical list.

ﾉ Expand table

URI parsing function Task

uriHost Return the host  value for a uniform resource identifier (URI).

uriPath Return the path  value for a uniform resource identifier (URI).

uriPathAndQuery Return the path  and query  values for a uniform resource identifier (URI).

uriPort Return the port  value for a uniform resource identifier (URI).

uriQuery Return the query  value for a uniform resource identifier (URI).

uriScheme Return the scheme  value for a uniform resource identifier (URI).



Manipulation functions: JSON & XML
To work with JSON objects and XML nodes, you can use these manipulation functions.
For the full reference about each function, see the alphabetical list.

ﾉ Expand table

Manipulation Task
function

addProperty Add a property and its value, or name-value pair, to a JSON object, and
return the updated object.

coalesce Return the first non-null value from one or more parameters.

removeProperty Remove a property from a JSON object and return the updated object.

setProperty Set the value for a JSON object's property and return the updated object.

xpath Check XML for nodes or values that match an XPath (XML Path Language)
expression, and return the matching nodes or values.

---------------------------------

All functions - alphabetical list
This section lists all the available functions in alphabetical order.

A

action
Return the current action's output at runtime, or values from other JSON name-and-
value pairs, which you can assign to an expression. By default, this function references
the entire action object, but you can optionally specify a property whose value you want.
See also actions().

You can use the action()  function only in these places:

The unsubscribe  property for a webhook action so you can access the result from
the original subscribe  request
The trackedProperties  property for an action



The do-until  loop condition for an action

action()
action().outputs.body.<property>

ﾉ Expand table

Parameter Required Type Description

<property> No String The name for the action object's property whose value you
want: name, startTime, endTime, inputs, outputs, status, code,
trackingId, and clientTrackingId. In the Azure portal, you can
find these properties by reviewing a specific run history's
details. For more information, see REST API - Workflow Run
Actions.

ﾉ Expand table

Return value Type Description

<action-output> String The output from the current action or property

actions
Return an action's output at runtime, or values from other JSON name-and-value pairs,
which you can assign to an expression. By default, the function references the entire
action object, but you can optionally specify a property whose value that you want. For
shorthand versions, see body(). For the current action, see action().

 Tip

The actions()  function returns output as a string. If you need to work with a
returned value as a JSON object, you first need to convert the string value. You can
transform the string value into a JSON object using the Parse JSON action.

７ Note

Previously, you could use the actions()  function or the conditions  element when
specifying that an action ran based on the output from another action. However, to
declare explicitly dependencies between actions, you must now use the dependent



action's runAfter  property. To learn more about the runAfter  property, see Catch
and handle failures with the runAfter property.

actions('<actionName>')
actions('<actionName>').outputs.body.<property>

ﾉ Expand table

Parameter Required Type Description

<actionName> Yes String The name for the action object whose output you want

<property> No String The name for the action object's property whose value you
want: name, startTime, endTime, inputs, outputs, status,
code, trackingId, and clientTrackingId. In the Azure portal,
you can find these properties by reviewing a specific run
history's details. For more information, see REST API -
Workflow Run Actions.

ﾉ Expand table

Return value Type Description

<action-output> String The output from the specified action or property

Example

This example gets the status  property value from the X action Get user  at runtime:

actions('Get_user').outputs.body.status

And returns this result: "Succeeded"

add
Return the result from adding two numbers.



add(<summand_1>, <summand_2>)

ﾉ Expand table

Parameter Required Type Description

<summand_1>, <summand_2> Yes Integer, Float, or mixed The numbers to add

ﾉ Expand table

Return value Type Description

<result-sum> Integer or Float The result from adding the specified numbers

Example

This example adds the specified numbers:

add(1, 1.5)

And returns this result: 2.5

addDays
Add days to a timestamp.

addDays('<timestamp>', <days>, '<format>'?)

ﾉ Expand table

Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

<days> Yes Integer The positive or negative number of days to add

<format> No String A numeric format string that is either a single format
specifier or a custom format pattern. The default format for
the timestamp is "o" (yyyy-MM-ddTHH:mm:ss.fffffffK),
which complies with ISO 8601  and preserves time zone



Parameter Required Type Description

information.

If the format isn't a valid value, an error is generated.

ﾉ Expand table

Return value Type Description

<updated-timestamp> String The timestamp plus the specified number of days

Example 1

This example adds 10 days to the specified timestamp:

addDays('2018-03-15T00:00:00Z', 10)

And returns this result: "2018-03-25T00:00:00.0000000Z"

Example 2

This example subtracts five days from the specified timestamp:

addDays('2018-03-15T00:00:00Z', -5)

And returns this result: "2018-03-10T00:00:00.0000000Z"

addHours
Add hours to a timestamp.

addHours('<timestamp>', <hours>, '<format>'?)

ﾉ Expand table



Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

<hours> Yes Integer The positive or negative number of hours to add

<format> No String A numeric format string that is either a single format
specifier or a custom format pattern. The default format for
the timestamp is "o" (yyyy-MM-ddTHH:mm:ss.fffffffK),
which complies with ISO 8601  and preserves time zone
information.

If the format isn't a valid value, an error is generated.

ﾉ Expand table

Return value Type Description

<updated-timestamp> String The timestamp plus the specified number of hours

Example 1

This example adds 10 hours to the specified timestamp:

addHours('2018-03-15T00:00:00Z', 10)

And returns this result: "2018-03-15T10:00:00.0000000Z"

Example 2

This example subtracts five hours from the specified timestamp:

addHours('2018-03-15T15:00:00Z', -5)

And returns this result: "2018-03-15T10:00:00.0000000Z"

addMinutes
Add minutes to a timestamp.



addMinutes('<timestamp>', <minutes>, '<format>'?)

ﾉ Expand table

Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

<minutes> Yes Integer The positive or negative number of minutes to add

<format> No String A numeric format string that is either a single format
specifier or a custom format pattern. The default format for
the timestamp is "o" (yyyy-MM-ddTHH:mm:ss.fffffffK),
which complies with ISO 8601  and preserves time zone
information.

If the format isn't a valid value, an error is generated.

ﾉ Expand table

Return value Type Description

<updated-timestamp> String The timestamp plus the specified number of minutes

Example 1

This example adds 10 minutes to the specified timestamp:

addMinutes('2018-03-15T00:10:00Z', 10)

And returns this result: "2018-03-15T00:20:00.0000000Z"

Example 2

This example subtracts five minutes from the specified timestamp:

addMinutes('2018-03-15T00:20:00Z', -5)

And returns this result: "2018-03-15T00:15:00.0000000Z"



addProperty
Add a property and its value, or name-value pair, to a JSON object, and return the
updated object. If the property already exists at runtime, the function fails and throws an
error.

addProperty(<object>, '<property>', <value>)

ﾉ Expand table

Parameter Required Type Description

<object> Yes Object The JSON object where you want to add a property

<property> Yes String The name for the property to add

<value> Yes Any The value for the property

ﾉ Expand table

Return value Type Description

<updated-object> Object The updated JSON object with the specified property

To add a parent property to an existing property, use the setProperty()  function, not
the addProperty()  function. Otherwise, the function returns only the child object as
output.

setProperty(<object>, '<parent-property>', addProperty(<object>['<parent-
property>'], '<child-property>', <value>)

ﾉ Expand table

Parameter Required Type Description

<object> Yes Object The JSON object where you want to add a property

<parent- Yes String The name for parent property where you want to add the
property> child property



Parameter Required Type Description

<child- Yes String The name for the child property to add
property>

<value> Yes Any The value to set for the specified property

ﾉ Expand table

Return value Type Description

<updated-object> Object The updated JSON object whose property you set

Example 1

This example adds the middleName  property to a JSON object, which is converted from a
string to JSON by using the JSON() function. The object already includes the firstName
and surName  properties. The function assigns the specified value to the new property
and returns the updated object:

addProperty(json('{ "firstName": "Sophia", "lastName": "Owen" }'), 
'middleName', 'Anne')

Here's the current JSON object:

JSON

{
   "firstName": "Sophia",
   "surName": "Owen"
}

Here's the updated JSON object:

JSON

{
   "firstName": "Sophia",
   "middleName": "Anne",
   "surName": "Owen"
}

Example 2



This example adds the middleName  child property to the existing customerName  property
in a JSON object, which is converted from a string to JSON by using the JSON() function.
The function assigns the specified value to the new property and returns the updated
object:

setProperty(json('{ "customerName": { "firstName": "Sophia", "surName": 
"Owen" } }'), 'customerName', addProperty(json('{ "customerName": { 
"firstName": "Sophia", "surName": "Owen" } }')['customerName'], 
'middleName', 'Anne'))

Here's the current JSON object:

JSON

{
   "customerName": {
      "firstName": "Sophia",
      "surName": "Owen"
   }
}

Here's the updated JSON object:

JSON

{
   "customerName": {
      "firstName": "Sophia",
      "middleName": "Anne",
      "surName": "Owen"
   }
}

addSeconds
Add seconds to a timestamp.

addSeconds('<timestamp>', <seconds>, '<format>'?)

ﾉ Expand table



Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

<seconds> Yes Integer The positive or negative number of seconds to add

<format> No String A numeric format string that is either a single format
specifier or a custom format pattern. The default format for
the timestamp is "o" (yyyy-MM-ddTHH:mm:ss.fffffffK),
which complies with ISO 8601  and preserves time zone
information.

If the format isn't a valid value, an error is generated.

ﾉ Expand table

Return value Type Description

<updated-timestamp> String The timestamp plus the specified number of seconds

Example 1

This example adds 10 seconds to the specified timestamp:

addSeconds('2018-03-15T00:00:00Z', 10)

And returns this result: "2018-03-15T00:00:10.0000000Z"

Example 2

This example subtracts five seconds to the specified timestamp:

addSeconds('2018-03-15T00:00:30Z', -5)

And returns this result: "2018-03-15T00:00:25.0000000Z"

addToTime
Add the specified time units to a timestamp. See also getFutureTime().



addToTime('<timestamp>', <interval>, '<timeUnit>', '<format>'?)

ﾉ Expand table

Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

<interval> Yes Integer The number of specified time units to add

<timeUnit> Yes String The unit of time to use with interval: "Second", "Minute",
"Hour", "Day", "Week", "Month", "Year"

<format> No String A numeric format string that is either a single format
specifier or a custom format pattern. The default format for
the timestamp is "o" (yyyy-MM-ddTHH:mm:ss.fffffffK),
which complies with ISO 8601  and preserves time zone
information.

If the format isn't a valid value, an error is generated.

ﾉ Expand table

Return value Type Description

<updated-timestamp> String The timestamp plus the specified number of time units

Example 1

This example adds one day to the specified timestamp:

addToTime('2018-01-01T00:00:00Z', 1, 'Day')

And returns this result: "2018-01-02T00:00:00.0000000Z"

Example 2

This example adds one day to the specified timestamp:

addToTime('2018-01-01T00:00:00Z', 1, 'Day', 'D')



And returns the result using the optional "D" format: "Tuesday, January 2, 2018"

and
Check whether all expressions are true. Return true when all expressions are true, or
return false when at least one expression is false.

and(<expression1>, <expression2>, ...)

ﾉ Expand table

Parameter Required Type Description

<expression1>, <expression2>, ... Yes Boolean The expressions to check

ﾉ Expand table

Return Type Description
value

true or false Boolean Return true when all expressions are true. Return false when at least one
expression is false.

Example 1

These examples check whether the specified Boolean values are all true:

and(true, true)
and(false, true)
and(false, false)

And returns these results:

First example: Both expressions are true, so returns true .
Second example: One expression is false, so returns false .
Third example: Both expressions are false, so returns false .

Example 2

These examples check whether the specified expressions are all true:



and(equals(1, 1), equals(2, 2))
and(equals(1, 1), equals(1, 2))
and(equals(1, 2), equals(1, 3))

And returns these results:

First example: Both expressions are true, so returns true .
Second example: One expression is false, so returns false .
Third example: Both expressions are false, so returns false .

array
Return an array from a single specified input. For multiple inputs, see createArray().

array('<value>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The string for creating an array

ﾉ Expand table

Return value Type Description

[<value>] Array An array that contains the single specified input

Example

This example creates an array from the "hello" string:

array('hello')

And returns this result: ["hello"]

B



base64
Return the base64-encoded version for a string.

７ Note

Azure Logic Apps automatically or implicitly performs base64 encoding and
decoding, so you don't have to manually perform these conversions by using the
encoding and decoding functions. However, if you use these functions anyway, you
might experience unexpected rendering behaviors in the designer. These behaviors
affect only the functions' visibility and not their effect unless you edit the functions'
parameter values, which removes the functions and their effects from your code.
For more information, see Base64 encoding and decoding.

base64('<value>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The input string

ﾉ Expand table

Return value Type Description

<base64-string> String The base64-encoded version for the input string

Example

This example converts the "hello" string to a base64-encoded string:

base64('hello')

And returns this result: "aGVsbG8="

base64ToBinary



Return the binary version for a base64-encoded string.

７ Note

Azure Logic Apps automatically or implicitly performs base64 encoding and
decoding, so you don't have to manually perform these conversions by using the
encoding and decoding functions. However, if you use these functions anyway in
the designer, you might experience unexpected rendering behaviors in the
designer. These behaviors affect only the functions' visibility and not their effect
unless you edit the functions' parameter values, which removes the functions and
their effects from your code. For more information, see Base64 encoding and
decoding.

base64ToBinary('<value>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The base64-encoded string to convert

ﾉ Expand table

Return value Type Description

<binary-for-base64-string> String The binary version for the base64-encoded string

Example

This example converts the "aGVsbG8=" base64-encoded string to a binary string:

base64ToBinary('aGVsbG8=')

For example, suppose you're using an HTTP action to send a request. You can use
base64ToBinary()  to convert a base64-encoded string to binary data and send that data
using the application/octet-stream  content type in the request.

base64ToString



Return the string version for a base64-encoded string, effectively decoding the base64
string. Use this function rather than decodeBase64(), which is deprecated.

７ Note

Azure Logic Apps automatically or implicitly performs base64 encoding and
decoding, so you don't have to manually perform these conversions by using the
encoding and decoding functions. However, if you use these functions anyway in
the designer, you might experience unexpected rendering behaviors in the
designer. These behaviors affect only the functions' visibility and not their effect
unless you edit the functions' parameter values, which removes the functions and
their effects from your code. For more information, see Base64 encoding and
decoding.

base64ToString('<value>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The base64-encoded string to decode

ﾉ Expand table

Return value Type Description

<decoded-base64-string> String The string version for a base64-encoded string

Example

This example converts the "aGVsbG8=" base64-encoded string to just a string:

base64ToString('aGVsbG8=')

And returns this result: "hello"

binary



Return the base64-encoded binary version of a string.

binary('<value>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The string to convert

ﾉ Expand table

Return value Type Description

<binary-for-input-value> String The base64-encoded binary version for the specified string

Example

For example, you're using an HTTP action that returns an image or video file. You can
use binary()  to convert the value to a base-64 encoded content envelope model. Then,
you can reuse the content envelope in other actions, such as Compose . You can use this
function expression to send the string bytes with the application/octet-stream  content
type in the request.

body
Return an action's body  output at runtime. Shorthand for
actions('<actionName>').outputs.body . See actions().

body('<actionName>')

ﾉ Expand table

Parameter Required Type Description

<actionName> Yes String The name for the action's body  output that you want

ﾉ Expand table



Return value Type Description

<action-body-output> String The body  output from the specified action

Example

This example gets the body  output from the Get user  X action:

body('Get_user')

And returns this result:

JSON

"body": {
    "FullName": "Contoso Corporation",
    "Location": "Generic Town, USA",
    "Id": 283541717,
    "UserName": "ContosoInc",
    "FollowersCount": 172,
    "Description": "Leading the way in transforming the digital workplace.",
    "StatusesCount": 93,
    "FriendsCount": 126,
    "FavouritesCount": 46,
    "ProfileImageUrl": 
"https://pbs.twimg.com/profile_images/908820389907722240/gG9zaHcd_400x400.jp
g"
}

bool
Return the Boolean version of a value.

bool(<value>)

ﾉ Expand table

Parameter Required Type Description

<value> Yes Any The value to convert to Boolean.



If you're using bool()  with an object, the value of the object must be a string or integer
that can be converted to Boolean.

ﾉ Expand table

Return value Type Description

true  or false Boolean The Boolean version of the specified value.

Outputs

These examples show the different supported types of input for bool() :

ﾉ Expand table

Input value Type Return value

bool(1) Integer true

bool(0) Integer false

bool(-1) Integer true

bool('true') String true

bool('false') String false

C

chunk
Split a string or array into chunks of equal length.

chunk('<collection>', '<length>')
chunk([<collection>], '<length>')

ﾉ Expand table

Parameter Required Type Description

<collection> Yes String or Array The collection to split

<length> Yes The length of each chunk



ﾉ Expand table

Return value Type Description

<collection> Array An array of chunks with the specified length

Example 1

This example splits a string into chunks of length 10:

chunk('abcdefghijklmnopqrstuvwxyz', 10)

And returns this result: ['abcdefghij', 'klmnopqrst', 'uvwxyz']

Example 2

This example splits an array into chunks of length 5.

chunk(createArray(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), 5)

And returns this result: [ [1,2,3,4,5], [6,7,8,9,10], [11,12] ]

coalesce
Return the first non-null value from one or more parameters. Empty strings, empty
arrays, and empty objects aren't null.

coalesce(<object_1>, <object_2>, ...)

ﾉ Expand table

Parameter Required Type Description

<object_1>, <object_2>, ... Yes Any, can mix types One or more items to check for null

ﾉ Expand table



Return value Type Description

<first-non-null- Any The first item or value that isn't null. If all parameters are null, this
item> function returns null.

Example

These examples return the first non-null value from the specified values, or null when all
the values are null:

coalesce(null, true, false)
coalesce(null, 'hello', 'world')
coalesce(null, null, null)

And returns these results:

First example: true
Second example: "hello"
Third example: null

concat
Combine two or more strings, and return the combined string.

concat('<text1>', '<text2>', ...)

ﾉ Expand table

Parameter Required Type Description

<text1>, <text2>, ... Yes String At least two strings to combine

ﾉ Expand table

Return value Type Description

<text1text2...> String The string created from the combined input strings.



Return value Type Description

Note: The length of the result must not exceed 104,857,600 characters.

７ Note

Azure Logic Apps automatically or implicitly performs base64 encoding and
decoding, so you don't have to manually perform these conversions when you use
the concat()  function with data that needs encoding or decoding:

concat('data:;base64,',<value>)

concat('data:,',encodeUriComponent(<value>))

However, if you use this function anyway in the designer, you might experience
unexpected rendering behaviors in the designer. These behaviors affect only the
function's visibility and not the effect unless you edit the function's parameter
values, which removes the function and the effect from your code. For more
information, review Base64 encoding and decoding.

Example

This example combines the strings "Hello" and "World":

concat('Hello', 'World')

And returns this result: "HelloWorld"

contains
Check whether a collection has a specific item. Return true when the item is found, or
return false when not found. This function is case-sensitive.

contains('<collection>', '<value>')
contains([<collection>], '<value>')

Specifically, this function works on these collection types:

A string to find a substring



An array to find a value
A dictionary to find a key

ﾉ Expand table

Parameter Required Type Description

<collection> Yes String, Array, or Dictionary The collection to check

<value> Yes String, Array, or Dictionary, respectively The item to find

ﾉ Expand table

Return value Type Description

true or false Boolean Return true when the item is found. Return false when not found.

Example 1

This example checks the string "hello world" for the substring "world" and returns true:

contains('hello world', 'world')

Example 2

This example checks the string "hello world" for the substring "universe" and returns
false:

contains('hello world', 'universe')

convertFromUtc
Convert a timestamp from Universal Time Coordinated (UTC) to the target time zone.

convertFromUtc('<timestamp>', '<destinationTimeZone>', '<format>'?)

ﾉ Expand table



Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

<destinationTimeZone> Yes String The name for the target time zone. For time zone
names, review Microsoft Windows Default Time
Zones.

<format> No String A numeric format string that is either a single
format specifier or a custom format pattern. The
default format for the timestamp is "o" (yyyy-MM-
ddTHH:mm:ss.fffffffK), which complies with ISO
8601  and preserves time zone information.

If the format isn't a valid value, an error is
generated.

ﾉ Expand table

Return value Type Description

<converted- String The timestamp converted to the target time zone without the
timestamp> timezone UTC offset.

Example 1

This example converts a timestamp to the specified time zone:

convertFromUtc('2018-01-01T08:00:00.0000000Z', 'Pacific Standard Time')

And returns this result: "2018-01-01T00:00:00.0000000"

Example 2

This example converts a timestamp to the specified time zone and format:

convertFromUtc('2018-01-01T08:00:00.0000000Z', 'Pacific Standard Time', 'D')

And returns this result: "Monday, January 1, 2018"

convertTimeZone



Convert a timestamp from the source time zone to the target time zone.

convertTimeZone('<timestamp>', '<sourceTimeZone>', '<destinationTimeZone>', 
'<format>'?)

ﾉ Expand table

Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

<sourceTimeZone> Yes String The name for the source time zone. For time zone
names, see Microsoft Windows Default Time
Zones, but you might have to remove any
punctuation from the time zone name.

<destinationTimeZone> Yes String The name for the target time zone. For time zone
names, see Microsoft Windows Default Time
Zones, but you might have to remove any
punctuation from the time zone name.

<format> No String A numeric format string that is either a single
format specifier or a custom format pattern. The
default format for the timestamp is "o" (yyyy-MM-
ddTHH:mm:ss.fffffffK), which complies with ISO
8601  and preserves time zone information.

If the format isn't a valid value, an error is
generated.

ﾉ Expand table

Return value Type Description

<converted-timestamp> String The timestamp converted to the target time zone

Example 1

This example converts the source time zone to the target time zone:

convertTimeZone('2018-01-01T08:00:00.0000000Z', 'UTC', 'Pacific Standard 
Time')



And returns this result: "2018-01-01T00:00:00.0000000"

Example 2

This example converts a time zone to the specified time zone and format:

convertTimeZone('2018-01-01T80:00:00.0000000Z', 'UTC', 'Pacific Standard 
Time', 'D')

And returns this result: "Monday, January 1, 2018"

convertToUtc
Convert a timestamp from the source time zone to Universal Time Coordinated (UTC).

convertToUtc('<timestamp>', '<sourceTimeZone>', '<format>'?)

ﾉ Expand table

Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

<sourceTimeZone> Yes String The name for the source time zone. For time zone
names, see Microsoft Windows Default Time Zones, but
you might have to remove any punctuation from the
time zone name.

<format> No String A numeric format string that is either a single format
specifier or a custom format pattern. The default format
for the timestamp is "o" (yyyy-MM-
ddTHH:mm:ss.fffffffK), which complies with ISO 8601
and preserves time zone information.

If the format isn't a valid value, an error is generated.

ﾉ Expand table

Return value Type Description

<converted-timestamp> String The timestamp converted to UTC



Example 1

This example converts a timestamp to UTC:

convertToUtc('01/01/2018 00:00:00', 'Pacific Standard Time')

And returns this result: "2018-01-01T08:00:00.0000000Z"

Example 2

This example converts a timestamp to UTC:

convertToUtc('01/01/2018 00:00:00', 'Pacific Standard Time', 'D')

And returns this result: "Monday, January 1, 2018"

createArray
Return an array from multiple inputs. For single input arrays, see array().

createArray('<object1>', '<object2>', ...)

ﾉ Expand table

Parameter Required Type Description

<object1>, <object2>, ... Yes Any, but not mixed At least two items to create the array

ﾉ Expand table

Return value Type Description

[<object1>, <object2>, ...] Array The array created from all the input items

Example

This example creates an array from these inputs:



createArray('h', 'e', 'l', 'l', 'o')

And returns this result: ["h", "e", "l", "l", "o"]

D

dataUri
Return a data uniform resource identifier (URI) for a string.

dataUri('<value>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The string to convert

ﾉ Expand table

Return value Type Description

<data-uri> String The data URI for the input string

Example

This example creates a data URI for the "hello" string:

dataUri('hello')

And returns this result: "data:text/plain;charset=utf-8;base64,aGVsbG8="

dataUriToBinary
Return the binary version for a data uniform resource identifier (URI). Use this function
rather than decodeDataUri(). Although both functions work the same way,



dataUriBinary()  is preferred.

dataUriToBinary('<value>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The data URI to convert

ﾉ Expand table

Return value Type Description

<binary-for-data-uri> String The binary version for the data URI

Example

This example creates a binary version for this data URI:

dataUriToBinary('data:text/plain;charset=utf-8;base64,aGVsbG8=')

And returns this result:

"0110010001100001011101000110000100111010011101000110010101111000011101000010111101

1100000

11011000110000101101001011011100011101101100011011010000110000101110010011100110110

01010111

01000011110101110101011101000110011000101101001110000011101101100010011000010111001

10110010

10011011000110100001011000110000101000111010101100111001101100010010001110011100000

111101"

dataUriToString
Return the string version for a data uniform resource identifier (URI).



dataUriToString('<value>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The data URI to convert

ﾉ Expand table

Return value Type Description

<string-for-data-uri> String The string version for the data URI

Example

This example creates a string for this data URI:

dataUriToString('data:text/plain;charset=utf-8;base64,aGVsbG8=')

And returns this result: "hello"

dateDifference
Return the difference between two timestamps as a timespan. This function subtracts
startDate  from endDate , and returns the result as timestamp in string format.

dateDifference('<startDate>', '<endDate>')

ﾉ Expand table

Parameter Required Type Description

<startDate> Yes String A string that contains a timestamp

<endDate> Yes String A string that contains a timestamp

ﾉ Expand table



Return Type Description
value

<timespan> String The difference between the two timestamps, which is a timestamp in
string format. If startDate  is more recent than endDate , the result is a
negative value.

Example

This example subtracts the first value from the second value:

dateDifference('2015-02-08', '2018-07-30')

And returns this result: "1268.00:00:00"

dayOfMonth
Return the day of the month from a timestamp.

dayOfMonth('<timestamp>')

ﾉ Expand table

Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

ﾉ Expand table

Return value Type Description

<day-of-month> Integer The day of the month from the specified timestamp

Example

This example returns the number for the day of the month from this timestamp:

dayOfMonth('2018-03-15T13:27:36Z')



And returns this result: 15

dayOfWeek
Return the day of the week from a timestamp.

dayOfWeek('<timestamp>')

ﾉ Expand table

Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

ﾉ Expand table

Return Type Description
value

<day-of- Integer The day of the week from the specified timestamp where Sunday is 0,
week> Monday is 1, and so on

Example

This example returns the number for the day of the week from this timestamp:

dayOfWeek('2018-03-15T13:27:36Z')

And returns this result: 4

dayOfYear
Return the day of the year from a timestamp.

dayOfYear('<timestamp>')



ﾉ Expand table

Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

ﾉ Expand table

Return value Type Description

<day-of-year> Integer The day of the year from the specified timestamp

Example

This example returns the number of the day of the year from this timestamp:

dayOfYear('2018-03-15T13:27:36Z')

And returns this result: 74

decimal
Returns a decimal number in a string as a decimal number. You can use this function
when you're working with data that requires decimal precision and also as input for
logical comparison functions and math functions. To capture and preserve precision
when you use the result from the decimal() function, wrap any decimal output with the
string function. This usage is shown in the following examples below where you can lose
precision if you use the decimal result as a number.

７ Note

The decimal precision that's discussed in the context for this function and the Azure
Logic Apps runtime is the same as the .NET decimal precision.

decimal('<value>')

ﾉ Expand table



Parameter Required Type Description

<value> Yes String The decimal number in a string

ﾉ Expand table

Return value Type Description

<decimal> Decimal Number The decimal number for the input string

Example 1

This example creates a decimal that's used as a number:

decimal('1.2345678912312131') // Returns 1.234567891231213.

Example 2

This example creates a decimal and then converts the result to a string for precision
preservation:

string(decimal('1.2345678912312131')) // Returns "1.2345678912312131".

Example 3

This example uses a math function on two decimal numbers and uses the result as a
number:

add(decimal('1.2345678912312131'), decimal('1.2345678912312131')) // Returns 
2.469135782462426.

Example 4

This example uses a math function on two decimal numbers and converts the result to a
string for precision preservation:



string(add(decimal('1.2345678912312131'), decimal('1.2345678912312131'))) // 
Returns "2.4691357824624262".

decodeBase64 (deprecated)
This function is deprecated, so use base64ToString() instead.

decodeDataUri
Return the binary version for a data uniform resource identifier (URI). Consider using
dataUriToBinary(), rather than decodeDataUri() . Although both functions work the same
way, dataUriToBinary()  is preferred.

７ Note

Azure Logic Apps automatically or implicitly performs base64 encoding and
decoding, so you don't have to manually perform these conversions by using the
encoding and decoding functions. However, if you use these functions anyway in
the designer, you might experience unexpected rendering behaviors in the
designer. These behaviors affect only the functions' visibility and not their effect
unless you edit the functions' parameter values, which removes the functions and
their effects from your code. For more information, see Base64 encoding and
decoding.

decodeDataUri('<value>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The data URI string to decode

ﾉ Expand table

Return value Type Description

<binary-for-data-uri> String The binary version for a data URI string



Example

This example returns the binary version for this data URI:

decodeDataUri('data:text/plain;charset=utf-8;base64,aGVsbG8=')

And returns this result:

"0110010001100001011101000110000100111010011101000110010101111000011101000010111101

1100000

11011000110000101101001011011100011101101100011011010000110000101110010011100110110

01010111

01000011110101110101011101000110011000101101001110000011101101100010011000010111001

10110010

10011011000110100001011000110000101000111010101100111001101100010010001110011100000

111101"

decodeUriComponent
Return a string that replaces escape characters with decoded versions.

decodeUriComponent('<value>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The string with the escape characters to decode

ﾉ Expand table

Return value Type Description

<decoded-uri> String The updated string with the decoded escape characters

Example

This example replaces the escape characters in this string with decoded versions:



decodeUriComponent('https%3A%2F%2Fcontoso.com')

And returns this result: "https://contoso.com"

div
Return the result from dividing two numbers. To get the remainder result, see mod().

div(<dividend>, <divisor>)

ﾉ Expand table

Parameter Required Type Description

<dividend> Yes Integer or The number to divide by the divisor
Float

<divisor> Yes Integer or The number that divides the dividend, but can't be
Float zero

ﾉ Expand table

Return value Type Description

<quotient- Integer or The result from dividing the first number by the second number. If
result> Float either the dividend or divisor has Float type, the result has Float

type.

Note: To convert the float result to an integer, try creating and
calling a function in Azure from your logic app.

Example 1

Both examples return this value with Integer type: 2

div(10,5)
div(11,5)



Example 2

Both examples return this value with Float type: 2.2

div(11,5.0)
div(11.0,5)

E

encodeUriComponent
Return a uniform resource identifier (URI) encoded version for a string by replacing URL-
unsafe characters with escape characters. Consider using uriComponent(), rather than
encodeUriComponent() . Although both functions work the same way, uriComponent()  is
preferred.

７ Note

Azure Logic Apps automatically or implicitly performs base64 encoding and
decoding, so you don't have to manually perform these conversions by using the
encoding and decoding functions. However, if you use these functions anyway in
the designer, you might experience unexpected rendering behaviors in the
designer. These behaviors affect only the functions' visibility and not their effect
unless you edit the functions' parameter values, which removes the functions and
their effects from your code. For more information, see Base64 encoding and
decoding.

encodeUriComponent('<value>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The string to convert to URI-encoded format

ﾉ Expand table



Return value Type Description

<encoded-uri> String The URI-encoded string with escape characters

Example

This example creates a URI-encoded version for this string:

encodeUriComponent('https://contoso.com')

And returns this result: "https%3A%2F%2Fcontoso.com"

empty
Check whether a collection is empty. Return true when the collection is empty, or return
false when not empty.

empty('<collection>')
empty([<collection>])

ﾉ Expand table

Parameter Required Type Description

<collection> Yes String, Array, or Object The collection to check

ﾉ Expand table

Return value Type Description

true or false Boolean Return true when the collection is empty. Return false when not empty.

Example

These examples check whether the specified collections are empty:

empty('')
empty('abc')



And returns these results:

First example: Passes an empty string, so the function returns true .
Second example: Passes the string "abc", so the function returns false .

endsWith
Check whether a string ends with a specific substring. Return true when the substring is
found, or return false when not found. This function isn't case-sensitive.

endsWith('<text>', '<searchText>')

ﾉ Expand table

Parameter Required Type Description

<text> Yes String The string to check

<searchText> Yes String The ending substring to find

ﾉ Expand table

Return Type Description
value

true or false Boolean Return true when the ending substring is found. Return false when not
found.

Example 1

This example checks whether the "hello world" string ends with the "world" string:

endsWith('hello world', 'world')

And returns this result: true

Example 2

This example checks whether the "hello world" string ends with the "universe" string:



endsWith('hello world', 'universe')

And returns this result: false

equals
Check whether both values, expressions, or objects are equivalent. Return true when
both are equivalent, or return false when they're not equivalent.

equals('<object1>', '<object2>')

ﾉ Expand table

Parameter Required Type Description

<object1>, <object2> Yes Various The values, expressions, or objects to compare

ﾉ Expand table

Return Type Description
value

true or false Boolean Return true when both are equivalent. Return false when not
equivalent.

Example

These examples check whether the specified inputs are equivalent.

equals(true, 1)
equals('abc', 'abcd')

And returns these results:

First example: Both values are equivalent, so the function returns true .
Second example: Both values aren't equivalent, so the function returns false .

F



first
Return the first item from a string or array.

first('<collection>')
first([<collection>])

ﾉ Expand table

Parameter Required Type Description

<collection> Yes String or Array The collection where to find the first item

ﾉ Expand table

Return value Type Description

<first-collection-item> Any The first item in the collection

Example

These examples find the first item in these collections:

first('hello')
first(createArray(0, 1, 2))

And return these results:

First example: "h"
Second example: 0

float
Convert a string version for a floating-point number to an actual floating point number.
You can use this function only when passing custom parameters to an app, for example,
a logic app workflow or Power Automate flow. To convert floating-point strings
represented in locale-specific formats, you can optionally specify an RFC 4646 locale
code.



float('<value>', '<locale>'?)

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The string that has a valid floating-point number to convert.
The minimum and maximum values are the same as the limits
for the float data type.

<locale> No String The RFC 4646 locale code to use.

If not specified, default locale is used.

If locale isn't a valid value, an error is generated that the
provided locale isn't valid or doesn't have an associated locale.

ﾉ Expand table

Return Type Description
value

<float- Float The floating-point number for the specified string. The minimum and
value> maximum values are the same as the limits for the float data type.

Example 1

This example creates a string version for this floating-point number:

float('10,000.333')

And returns this result: 10000.333

Example 2

This example creates a string version for this German-style floating-point number:

float('10.000,333', 'de-DE')

And returns this result: 10000.333



formatDateTime
Return a timestamp in the specified format.

formatDateTime('<timestamp>', '<format>'?, '<locale>'?)

ﾉ Expand table

Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

<format> No String A numeric format string that is either a single format specifier
or a custom format pattern. The default format for the
timestamp is "o" (yyyy-MM-ddTHH:mm:ss.fffffffK), which
complies with ISO 8601  and preserves time zone
information.

<locale> No String The locale to use. If unspecified, the value is en-us . If locale
isn't a valid value, an error is generated.

ﾉ Expand table

Return value Type Description

<reformatted- String The updated timestamp in the specified format and locale, if
timestamp> specified.

Examples

formatDateTime('03/15/2018') // Returns '2018-03-15T00:00:00.0000000'.
formatDateTime('03/15/2018 12:00:00', 'yyyy-MM-ddTHH:mm:ss') // Returns 
'2018-03-15T12:00:00'.
formatDateTime('01/31/2016', 'dddd MMMM d') // Returns 'Sunday January 31'.
formatDateTime('01/31/2016', 'dddd MMMM d', 'fr-fr') // Returns 'dimanche 
janvier 31'.
formatDateTime('01/31/2016', 'dddd MMMM d', 'fr-FR') // Returns 'dimanche 
janvier 31'.
formatDateTime('01/31/2016', 'dddd MMMM d', 'es-es') // Returns 'domingo 
enero 31'.

formDataMultiValues



Return an array with values that match a key name in an action's form-data or form-
encoded output.

formDataMultiValues('<actionName>', '<key>')

ﾉ Expand table

Parameter Required Type Description

<actionName> Yes String The action whose output has the key value you want

<key> Yes String The name for the key whose value you want

ﾉ Expand table

Return value Type Description

[<array-with-key-values>] Array An array with all the values that match the specified key

Example

This example creates an array from the "Subject" key's value in the specified action's
form-data or form-encoded output:

formDataMultiValues('Send_an_email', 'Subject')

And returns the subject text in an array, for example: ["Hello world"]

formDataValue
Return a single value that matches a key name in an action's form-data or form-encoded
output. If the function finds more than one match, the function throws an error.

formDataValue('<actionName>', '<key>')

ﾉ Expand table



Parameter Required Type Description

<actionName> Yes String The action whose output has the key value you want

<key> Yes String The name for the key whose value you want

ﾉ Expand table

Return value Type Description

<key-value> String The value in the specified key

Example

This example creates a string from the "Subject" key's value in the specified action's
form-data or form-encoded output:

formDataValue('Send_an_email', 'Subject')

And returns the subject text as a string, for example: "Hello world"

formatNumber
Return a number as a string that's based on the specified format.

text

formatNumber(<number>, <format>, <locale>?)

ﾉ Expand table

Parameter Required Type Description

<number> Yes Integer The value that you want to format.
or
Double

<format> Yes String A composite format string that specifies the format that you
want to use. For the supported numeric format strings, see
Standard numeric format strings, which are supported by
number.ToString(<format>, <locale>) .



Parameter Required Type Description

<locale> No String The locale to use as supported by
number.ToString(<format>, <locale>) . If unspecified, the
value is en-us . If locale isn't a valid value, an error is
generated.

ﾉ Expand table

Return value Type Description

<formatted- String The specified number as a string in the format that you specified. You
number> can cast this return value to an int  or float .

Example 1

Suppose that you want to format the number 1234567890 . This example formats that
number as the string "1,234,567,890.00".

formatNumber(1234567890, '0,0.00', 'en-us')

*Example 2"

Suppose that you want to format the number 1234567890 . This example formats the
number to the string "1.234.567.890,00".

formatNumber(1234567890, '0,0.00', 'is-is')

Example 3

Suppose that you want to format the number 17.35 . This example formats the number
to the string "$17.35".

formatNumber(17.35, 'C2')

Example 4



Suppose that you want to format the number 17.35 . This example formats the number
to the string "17,35 kr".

formatNumber(17.35, 'C2', 'is-is')

G

getFutureTime
Return the current timestamp plus the specified time units.

getFutureTime(<interval>, <timeUnit>, <format>?)

ﾉ Expand table

Parameter Required Type Description

<interval> Yes Integer The number of time units to add

<timeUnit> Yes String The unit of time to use with interval: "Second", "Minute",
"Hour", "Day", "Week", "Month", "Year"

<format> No String Either a single format specifier or a custom format pattern.
The default format for the timestamp is "o" (yyyy-MM-
ddTHH:mm:ss.fffffffK), which complies with ISO 8601  and
preserves time zone information.

If the format isn't a valid value, an error is generated that the
provided format isn't valid and must be a numeric format
string.

ﾉ Expand table

Return value Type Description

<updated-timestamp> String The current timestamp plus the specified number of time units

Example 1



Suppose the current timestamp is "2018-03-01T00:00:00.0000000Z". This example adds
five days to that timestamp:

getFutureTime(5, 'Day')

And returns this result: "2018-03-06T00:00:00.0000000Z"

Example 2

Suppose the current timestamp is "2018-03-01T00:00:00.0000000Z". This example adds
five days and converts the result to "D" format:

getFutureTime(5, 'Day', 'D')

And returns this result: "Tuesday, March 6, 2018"

getPastTime
Return the current timestamp minus the specified time units.

getPastTime(<interval>, <timeUnit>, <format>?)

ﾉ Expand table

Parameter Required Type Description

<interval> Yes Integer The number of specified time units to subtract

<timeUnit> Yes String The unit of time to use with interval: "Second", "Minute",
"Hour", "Day", "Week", "Month", "Year"

<format> No String Either a single format specifier or a custom format pattern.
The default format for the timestamp is "o" (yyyy-MM-
ddTHH:mm:ss.fffffffK), which complies with ISO 8601  and
preserves time zone information.

If the format isn't a valid value, an error is generated that the
provided format isn't valid and must be a numeric format
string.



ﾉ Expand table

Return value Type Description

<updated-timestamp> String The current timestamp minus the specified number of time units

Example 1

Suppose the current timestamp is "2018-02-01T00:00:00.0000000Z". This example
subtracts five days from that timestamp:

getPastTime(5, 'Day')

And returns this result: "2018-01-27T00:00:00.0000000Z"

Example 2

Suppose the current timestamp is "2018-02-01T00:00:00.0000000Z". This example
subtracts five days and converts the result to "D" format:

getPastTime(5, 'Day', 'D')

And returns this result: "Saturday, January 27, 2018"

greater
Check whether the first value is greater than the second value. Return true when the first
value is more, or return false when less.

greater(<value>, <compareTo>)
greater('<value>', '<compareTo>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes Integer, Float, or String The first value to check whether greater
than the second value



Parameter Required Type Description

<compareTo> Yes Integer, Float, or String, The comparison value
respectively

ﾉ Expand table

Return Type Description
value

true or Boolean Return true when the first value is greater than the second value. Return
false false when the first value is equal to or less than the second value.

Example

These examples check whether the first value is greater than the second value:

greater(10, 5)
greater('apple', 'banana')

And return these results:

First example: true
Second example: false

greaterOrEquals
Check whether the first value is greater than or equal to the second value. Return true
when the first value is greater or equal, or return false when the first value is less.

greaterOrEquals(<value>, <compareTo>)
greaterOrEquals('<value>', '<compareTo>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes Integer, Float, or String The first value to check whether greater
than or equal to the second value



Parameter Required Type Description

<compareTo> Yes Integer, Float, or String, The comparison value
respectively

ﾉ Expand table

Return Type Description
value

true or Boolean Return true when the first value is greater than or equal to the second
false value. Return false when the first value is less than the second value.

Example

These examples check whether the first value is greater or equal than the second value:

greaterOrEquals(5, 5)
greaterOrEquals('apple', 'banana')

And return these results:

First example: true
Second example: false

guid
Generate a globally unique identifier (GUID) as a string, for example, "c2ecc88d-88c8-
4096-912c-d6f2e2b138ce":

guid()

Also, you can specify a different format for the GUID other than the default format, "D",
which is 32 digits separated by hyphens.

guid('<format>')



ﾉ Expand table

Parameter Required Type Description

<format> No String A single format specifier for the returned GUID. By default, the
format is "D", but you can use "N", "D", "B", "P", or "X".

ﾉ Expand table

Return value Type Description

<GUID-value> String A randomly generated GUID

Example

This example generates the same GUID, but as 32 digits, separated by hyphens, and
enclosed in parentheses:

guid('P')

And returns this result: "(c2ecc88d-88c8-4096-912c-d6f2e2b138ce)"

I

if
Check whether an expression is true or false. Based on the result, return a specified
value. Parameters are evaluated from left to right.

if(<expression>, <valueIfTrue>, <valueIfFalse>)

ﾉ Expand table

Parameter Required Type Description

<expression> Yes Boolean The expression to check

<valueIfTrue> Yes Any The value to return when the expression is true



Parameter Required Type Description

<valueIfFalse> Yes Any The value to return when the expression is false

ﾉ Expand table

Return value Type Description

<specified-return- Any The specified value that returns based on whether the expression
value> is true or false

Example

This example returns "yes"  because the specified expression returns true. Otherwise,
the example returns "no" :

if(equals(1, 1), 'yes', 'no')

indexOf
Return the starting position or index value for a substring. This function isn't case-
sensitive, and indexes start with the number 0.

indexOf('<text>', '<searchText>')

ﾉ Expand table

Parameter Required Type Description

<text> Yes String The string that has the substring to find

<searchText> Yes String The substring to find

ﾉ Expand table

Return value Type Description

<index-value> Integer The starting position or index value for the specified substring.

If the string isn't found, return the number -1.



Example

This example finds the starting index value for the "world" substring in the "hello world"
string:

indexOf('hello world', 'world')

And returns this result: 6

int
Convert the string version for an integer to an actual integer number.

int('<value>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The string version for the integer to convert. The minimum and
maximum values are the same as the limits for the integer data
type.

ﾉ Expand table

Return Type Description
value

<integer- Integer The integer version for the specified string. The minimum and maximum
result> values are the same as the limits for the integer data type.

Example

This example creates an integer version for the string "10":

int('10')

And returns this result: 10



isFloat
Return a boolean indicating whether a string is a floating-point number. By default, this
function uses the invariant culture for the floating-point format. To identify floating-
point numbers represented in other locale-specific formats, you can optionally specify
an RFC 4646 locale code.

isFloat('<string>', '<locale>'?)

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The string to examine

<locale> No String The RFC 4646 locale code to use

ﾉ Expand table

Return value Type Description

<boolean- Boolean A boolean that indicates whether the string is a floating-point
result> number

Example 1

This example checks whether a string is a floating-point number in the invariant culture:

isFloat('10,000.00')

And returns this result: true

Example 2

This example checks whether a string is a floating-point number in the German locale:

isFloat('10.000,00', 'de-DE')



And returns this result: true

isInt
Return a boolean that indicates whether a string is an integer.

isInt('<string>')

ﾉ Expand table

Parameter Required Type Description

<string> Yes String The string to examine

ﾉ Expand table

Return value Type Description

<boolean-result> Boolean A boolean that indicates whether the string is an integer

Example

This example checks whether a string is an integer:

isInt('10')

And returns this result: true

item
When used inside a repeating action over an array, return the current item in the array
during the action's current iteration. You can also get the values from that item's
properties.

item()



ﾉ Expand table

Return value Type Description

<current-array-item> Any The current item in the array for the action's current iteration

Example

This example gets the body  element from the current message for the "Send_an_email"
action inside a for-each loop's current iteration:

item().body

items
Return the current item from each cycle in a for-each loop. Use this function inside the
for-each loop.

items('<loopName>')

ﾉ Expand table

Parameter Required Type Description

<loopName> Yes String The name for the for-each loop

ﾉ Expand table

Return value Type Description

<item> Any The item from the current cycle in the specified for-each loop

Example

This example gets the current item from the specified for-each loop:

items('myForEachLoopName')



iterationIndexes
Return the index value for the current iteration inside an Until loop. You can use this
function inside nested Until loops.

iterationIndexes('<loopName>')

ﾉ Expand table

Parameter Required Type Description

<loopName> Yes String The name for the Until loop

ﾉ Expand table

Return value Type Description

<index> Integer The index value for the current iteration inside the specified Until loop

Example

This example creates a counter variable and increments that variable by one during each
iteration in an Until loop until the counter value reaches five. The example also creates a
variable that tracks the current index for each iteration. During each iteration in the Until
loop, the example increments the counter value and then assigns the counter value to
the current index value and then increments the counter value. While in the loop, this
example references the current iteration index by using the iterationIndexes  function:

iterationIndexes('Until_Max_Increment')

JSON

{
   "actions": {
      "Create_counter_variable": {
         "type": "InitializeVariable",
         "inputs": {
            "variables": [ 
               {
                  "name": "myCounter",
                  "type": "Integer",
                  "value": 0
               }
            ]



         },
         "runAfter": {}
      },
      "Create_current_index_variable": {
         "type": "InitializeVariable",
         "inputs": {
            "variables": [
               {
                  "name": "myCurrentLoopIndex",
                  "type": "Integer",
                  "value": 0
               }
            ]
         },
         "runAfter": {
            "Create_counter_variable": [ "Succeeded" ]
         }
      },
      "Until_Max_Increment": {
         "type": "Until",
         "actions": {
            "Assign_current_index_to_counter": {
               "type": "SetVariable",
               "inputs": {
                  "name": "myCurrentLoopIndex",
                  "value": "@variables('myCounter')"
               },
               "runAfter": {
                  "Increment_variable": [ "Succeeded" ]
               }
            },
            "Compose": {
               "inputs": "'Current index: ' 
@{iterationIndexes('Until_Max_Increment')}",
               "runAfter": {
                  "Assign_current_index_to_counter": [
                     "Succeeded"
                    ]
                },
                "type": "Compose"
            },           
            "Increment_variable": {
               "type": "IncrementVariable",
               "inputs": {
                  "name": "myCounter",
                  "value": 1
               },
               "runAfter": {}
            }
         },
         "expression": "@equals(variables('myCounter'), 5)",
         "limit": {
            "count": 60,
            "timeout": "PT1H"
         },



         "runAfter": {
            "Create_current_index_variable": [ "Succeeded" ]
         }
      }
   }
}

J

json
Return the JavaScript Object Notation (JSON) type value, object, or array of objects for a
string or XML.

json('<value>')
json(xml('value'))

） Important

Without an XML schema that defines the output's structure, the function might
return results where the structure greatly differs from the expected format,
depending on the input.

This behavior makes this function unsuitable for scenarios where the output must
conform to a well-defined contract, for example, in critical business systems or
solutions.

ﾉ Expand table

Parameter Required Type Description

<value> Yes String or XML The string or XML to convert

ﾉ Expand table



Return Type Description
value

<JSON- JSON native The JSON native type value, object, or array of objects from the
result> type, object, or input string or XML.

array

- If you pass in XML that has a single child element in the root
element, the function returns a single JSON object for that child
element.

- If you pass in XML that has multiple child elements in the root
element, the function returns an array that contains JSON objects
for those child elements.

- If the string is null, the function returns an empty object.

Example 1

This example converts this string into a JSON value:

json('[1, 2, 3]')

And returns this result: [1, 2, 3]

Example 2

This example converts this string into JSON:

json('{"fullName": "Sophia Owen"}')

And returns this result:

JSON

{
  "fullName": "Sophia Owen"
}

Example 3



This example uses the json()  and xml()  functions to convert XML that has a single
child element in the root element into a JSON object named person  for that child
element:

json(xml('<?xml version="1.0"?> <root> <person id="1"> <name>Sophia Owen</name>

<occupation>Engineer</occupation> </person> </root>'))

And returns this result:

JSON

{
   "?xml": { 
      "@version": "1.0" 
   },
   "root": {
      "person": {
         "@id": "1",
         "name": "Sophia Owen",
         "occupation": "Engineer"
      }
   }
}

Example 4

This example uses the json()  and xml()  functions to convert XML that has multiple
child elements in the root element into an array named person  that contains JSON
objects for those child elements:

json(xml('<?xml version="1.0"?> <root> <person id="1"> <name>Sophia Owen</name>

<occupation>Engineer</occupation> </person> <person id="2"> <name>John Doe</name>

<occupation>Engineer</occupation> </person> </root>'))

And returns this result:

JSON

{
   "?xml": {
      "@version": "1.0"
   },
   "root": {
      "person": [
         {
            "@id": "1",
            "name": "Sophia Owen",
            "occupation": "Engineer"



         },
         {
            "@id": "2",
            "name": "John Doe",
            "occupation": "Engineer"
         }
      ]
   }
}

intersection
Return a collection that has only the common items across the specified collections. To
appear in the result, an item must appear in all the collections passed to this function. If
one or more items have the same name, the last item with that name appears in the
result.

intersection([<collection1>], [<collection2>], ...)
intersection('<collection1>', '<collection2>', ...)

ﾉ Expand table

Parameter Required Type Description

<collection1>, Yes Array or Object, The collections from where you want
<collection2>, ... but not both only the common items

ﾉ Expand table

Return value Type Description

<common- Array or Object, A collection that has only the common items across
items> respectively the specified collections

Example

This example finds the common items across these arrays:

intersection(createArray(1, 2, 3), createArray(101, 2, 1, 10), 
createArray(6, 8, 1, 2))



And returns an array with only these items: [1, 2]

join
Return a string that has all the items from an array and has each character separated by
a delimiter.

join([<collection>], '<delimiter>')

ﾉ Expand table

Parameter Required Type Description

<collection> Yes Array The array that has the items to join

<delimiter> Yes String The separator that appears between each character in the
resulting string

ﾉ Expand table

Return value Type Description

<char1><delimiter><char2> String The resulting string created from all the items in the
<delimiter>... specified array.

Note: The length of the result must not exceed
104,857,600 characters.

Example

This example creates a string from all the items in this array with the specified character
as the delimiter:

join(createArray('a', 'b', 'c'), '.')

And returns this result: "a.b.c"

L



last
Return the last item from a collection.

last('<collection>')
last([<collection>])

ﾉ Expand table

Parameter Required Type Description

<collection> Yes String or Array The collection where to find the last item

ﾉ Expand table

Return value Type Description

<last-collection-item> String or Array, respectively The last item in the collection

Example

These examples find the last item in these collections:

last('abcd')
last(createArray(0, 1, 2, 3))

And returns these results:

First example: "d"
Second example: 3

lastIndexOf
Return the starting position or index value for the last occurrence of a substring. This
function isn't case-sensitive, and indexes start with the number 0.

lastIndexOf('<text>', '<searchText>')



ﾉ Expand table

Parameter Required Type Description

<text> Yes String The string that has the substring to find

<searchText> Yes String The substring to find

ﾉ Expand table

Return value Type Description

<ending-index- Integer The starting position or index value for the last occurrence of the
value> specified substring.

If the string or substring value is empty, the following behavior occurs:

If only the string value is empty, the function returns -1 .

If the string and substring values are both empty, the function returns 0 .

If only the substring value is empty, the function returns the string length minus 1.

Examples

This example finds the starting index value for the last occurrence of the substring
world  substring in the string hello world hello world . The returned result is 18 :

lastIndexOf('hello world hello world', 'world')

This example is missing the substring parameter, and returns a value of 22  because the
value of the input string ( 23 ) minus 1 is greater than 0.

lastIndexOf('hello world hello world', '')

length
Return the number of items in a collection.



length('<collection>')
length([<collection>])

ﾉ Expand table

Parameter Required Type Description

<collection> Yes String or Array The collection with the items to count

ﾉ Expand table

Return value Type Description

<length-or-count> Integer The number of items in the collection

Example

These examples count the number of items in these collections:

length('abcd')
length(createArray(0, 1, 2, 3))

And return this result: 4

less
Check whether the first value is less than the second value. Return true when the first
value is less, or return false when the first value is more.

less(<value>, <compareTo>)
less('<value>', '<compareTo>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes Integer, Float, or String The first value to check whether less
than the second value



Parameter Required Type Description

<compareTo> Yes Integer, Float, or String, The comparison item
respectively

ﾉ Expand table

Return Type Description
value

true or Boolean Return true when the first value is less than the second value. Return false
false when the first value is equal to or greater than the second value.

Example

These examples check whether the first value is less than the second value.

less(5, 10)
less('banana', 'apple')

And return these results:

First example: true
Second example: false

lessOrEquals
Check whether the first value is less than or equal to the second value. Return true when
the first value is less than or equal, or return false when the first value is more.

lessOrEquals(<value>, <compareTo>)
lessOrEquals('<value>', '<compareTo>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes Integer, Float, or String The first value to check whether less than
or equal to the second value



Parameter Required Type Description

<compareTo> Yes Integer, Float, or String, The comparison item
respectively

ﾉ Expand table

Return Type Description
value

true or Boolean Return true when the first value is less than or equal to the second value.
false Return false when the first value is greater than the second value.

Example

These examples check whether the first value is less or equal than the second value.

lessOrEquals(10, 10)
lessOrEquals('apply', 'apple')

And return these results:

First example: true
Second example: false

listCallbackUrl
Return the "callback URL" that calls a trigger or action. This function works only with
triggers and actions for the HttpWebhook and ApiConnectionWebhook connector
types, but not the Manual, Recurrence, HTTP, and APIConnection types.

listCallbackUrl()

ﾉ Expand table

Return value Type Description

<callback-URL> String The callback URL for a trigger or action

Example



This example shows a sample callback URL that this function might return:

"https://prod-01.westus.logic.azure.com:443/workflows/<*workflow-

ID*>/triggers/manual/run?api-version=2016-10-

01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=<*signature-ID*>"

M

max
Return the highest value from a list or array with numbers that is inclusive at both ends.

max(<number1>, <number2>, ...)
max([<number1>, <number2>, ...])

ﾉ Expand table

Parameter Required Type Description

<number1>, Yes Integer, Float, or The set of numbers from which you
<number2>, ... both want the highest value

[<number1>, Yes Array - Integer, The array of numbers from which you
<number2>, ...] Float, or both want the highest value

ﾉ Expand table

Return value Type Description

<max-value> Integer or Float The highest value in the specified array or set of numbers

Example

These examples get the highest value from the set of numbers and the array:

max(1, 2, 3)
max(createArray(1, 2, 3))

And return this result: 3



min
Return the lowest value from a set of numbers or an array.

min(<number1>, <number2>, ...)
min([<number1>, <number2>, ...])

ﾉ Expand table

Parameter Required Type Description

<number1>, Yes Integer, Float, or The set of numbers from which you
<number2>, ... both want the lowest value

[<number1>, Yes Array - Integer, The array of numbers from which you
<number2>, ...] Float, or both want the lowest value

ﾉ Expand table

Return Type Description
value

<min-value> Integer or The lowest value in the specified set of numbers or specified
Float array

Example

These examples get the lowest value in the set of numbers and the array:

min(1, 2, 3)
min(createArray(1, 2, 3))

And return this result: 1

mod
Return the remainder from dividing two numbers. To get the integer result, see div().



mod(<dividend>, <divisor>)

ﾉ Expand table

Parameter Required Type Description

<dividend> Yes Integer or The number to divide by the divisor
Float

<divisor> Yes Integer or The number that divides the dividend, but can't be
Float zero

ﾉ Expand table

Return value Type Description

<modulo- Integer or The remainder from dividing the first number by the second
result> Float number

Example 1

This example divides the first number by the second number:

mod(3, 2)

And returns this result: 1

Example 2

This example shows that if one or both values are negative, the result matches the sign
of the dividend:

mod(-5, 2)
mod(4, -3)

The example returns these results:

First example: -1
Second example: 1



mul
Return the product from multiplying two numbers.

mul(<multiplicand1>, <multiplicand2>)

ﾉ Expand table

Parameter Required Type Description

<multiplicand1> Yes Integer or Float The number to multiply by multiplicand2

<multiplicand2> Yes Integer or Float The number that multiples multiplicand1

ﾉ Expand table

Return value Type Description

<product- Integer or The product from multiplying the first number by the second
result> Float number

Example

These examples multiple the first number by the second number:

mul(1, 2)
mul(1.5, 2)

And return these results:

First example: 2
Second example 3

multipartBody
Return the body for a specific part in an action's output that has multiple parts.

multipartBody('<actionName>', <index>)



ﾉ Expand table

Parameter Required Type Description

<actionName> Yes String The name for the action that has output with multiple
parts

<index> Yes Integer The index value for the part that you want

ﾉ Expand table

Return value Type Description

<body> String The body for the specified part

N

not
Check whether an expression is false. Return true when the expression is false, or return
false when true.

not(<expression>)

ﾉ Expand table

Parameter Required Type Description

<expression> Yes Boolean The expression to check

ﾉ Expand table

Return Type Description
value

true or false Boolean Return true when the expression is false. Return false when the
expression is true.

Example 1

These examples check whether the specified expressions are false:



not(false)
not(true)

And return these results:

First example: The expression is false, so the function returns true .
Second example: The expression is true, so the function returns false .

Example 2

These examples check whether the specified expressions are false:

not(equals(1, 2))
not(equals(1, 1))

And return these results:

First example: The expression is false, so the function returns true .
Second example: The expression is true, so the function returns false .

nthIndexOf
Return the starting position or index value where the nth occurrence of a substring
appears in a string.

nthIndexOf('<text>', '<searchText>', <occurrence>)

ﾉ Expand table

Parameter Required Type Description

<text> Yes String The string that contains the substring to find

<searchText> Yes String The substring to find

<occurrence> Yes Integer A number that specifies the nth occurrence of the substring
to find. If occurrence is negative, start searching from the
end.



ﾉ Expand table

Return Type Description
value

<index- Integer The starting position or index value for the nth occurrence of the specified
value> substring. If the substring isn't found or fewer than n occurrences of the

substring exist, return -1 .

Examples

nthIndexOf('123456789123465789', '1', 1) // Returns `0`.
nthIndexOf('123456789123465789', '1', 2) // Returns `9`.
nthIndexOf('123456789123465789', '12', 2) // Returns `9`.
nthIndexOf('123456789123465789', '6', 4) // Returns `-1`.

O

or
Check whether at least one expression is true. Return true when at least one expression
is true, or return false when all are false.

or(<expression1>, <expression2>, ...)

ﾉ Expand table

Parameter Required Type Description

<expression1>, <expression2>, ... Yes Boolean The expressions to check

ﾉ Expand table

Return Type Description
value

true or false Boolean Return true when at least one expression is true. Return false when all
expressions are false.

Example 1



These examples check whether at least one expression is true:

or(true, false)
or(false, false)

And return these results:

First example: At least one expression is true, so the function returns true .
Second example: Both expressions are false, so the function returns false .

Example 2

These examples check whether at least one expression is true:

JSON

or(equals(1, 1), equals(1, 2))
or(equals(1, 2), equals(1, 3))

And return these results:

First example: At least one expression is true, so the function returns true .
Second example: Both expressions are false, so the function returns false .

outputs
Return an action's outputs at runtime.

outputs('<actionName>')

ﾉ Expand table

Parameter Required Type Description

<actionName> Yes String The name for the action's output that you want

ﾉ Expand table



Return value Type Description

<output> String The output from the specified action

Example

This example gets the output from the X action Get user :

outputs('Get_user')

And returns this result:

JSON

{
  "statusCode": 200,
  "headers": {
    "Pragma": "no-cache",
    "Vary": "Accept-Encoding",
    "x-ms-request-id": "a916ec8f52211265d98159adde2efe0b",
    "X-Content-Type-Options": "nosniff",
    "Timing-Allow-Origin": "*",
    "Cache-Control": "no-cache",
    "Date": "Mon, 09 Apr 2018 18:47:12 GMT",
    "Set-Cookie": 
"ARRAffinity=b9400932367ab5e3b6802e3d6158afffb12fcde8666715f5a5fbd4142d0f0b7
d;Path=/;HttpOnly;Domain=twitter-wus.azconn-wus.p.azurewebsites.net",
    "X-AspNet-Version": "4.0.30319",
    "X-Powered-By": "ASP.NET",
    "Content-Type": "application/json; charset=utf-8",
    "Expires": "-1",
    "Content-Length": "339"
  },
  "body": {
    "FullName": "Contoso Corporation",
    "Location": "Generic Town, USA",
    "Id": 283541717,
    "UserName": "ContosoInc",
    "FollowersCount": 172,
    "Description": "Leading the way in transforming the digital workplace.",
    "StatusesCount": 93,
    "FriendsCount": 126,
    "FavouritesCount": 46,
    "ProfileImageUrl": 
"https://pbs.twimg.com/profile_images/908820389907722240/gG9zaHcd_400x400.jp
g"
  }
}



P

parameters
Return the value for a parameter that is described in your workflow definition.

parameters('<parameterName>')

ﾉ Expand table

Parameter Required Type Description

<parameterName> Yes String The name for the parameter whose value you want

ﾉ Expand table

Return value Type Description

<parameter-value> Any The value for the specified parameter

Example

Suppose that you have this JSON value:

JSON

{
  "fullName": "Sophia Owen"
}

This example gets the value for the specified parameter:

parameters('fullName')

And returns this result: "Sophia Owen"

parseDateTime
Return the timestamp from a string that contains a timestamp.



parseDateTime('<timestamp>', '<locale>'?, '<format>'?)

ﾉ Expand table

Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

<locale> No String The locale to use.

If not specified, the default locale is en-us .

If locale isn't a valid value, an error is generated.

<format> No String A numeric format string that is either a single format specifier
or a custom format pattern. The default format for the
timestamp is "o" (yyyy-MM-ddTHH:mm:ss.fffffffK), which
complies with ISO 8601  and preserves time zone
information. If the format isn't specified, attempt parsing with
multiple formats that are compatible with the provided
locale. If the format isn't a valid value, an error is generated.

ﾉ Expand table

Return value Type Description

<parsed- String The parsed timestamp in "o" (yyyy-MM-ddTHH:mm:ss.fffffffK) format,
timestamp> which complies with ISO 8601  and preserves time zone information.

Examples

parseDateTime('20/10/2014', 'fr-fr') // Returns '2014-10-
20T00:00:00.0000000'.
parseDateTime('20 octobre 2010', 'fr-FR') // Returns '2010-10-
20T00:00:00.0000000'.
parseDateTime('martes 20 octubre 2020', 'es-es') // Returns '2020-10-
20T00:00:00.0000000'.
parseDateTime('21052019', 'fr-fr', 'ddMMyyyy') // Returns '2019-05-
21T00:00:00.0000000'.
parseDateTime('10/20/2014 15h', 'en-US', 'MM/dd/yyyy HH\h') // Returns 
'2014-10-20T15:00:00.0000000'.



R

rand
Return a random integer from a specified range, which is inclusive only at the starting
end.

rand(<minValue>, <maxValue>)

ﾉ Expand table

Parameter Required Type Description

<minValue> Yes Integer The lowest integer in the range

<maxValue> Yes Integer The integer that follows the highest integer in the range that
the function can return

ﾉ Expand table

Return value Type Description

<random-result> Integer The random integer returned from the specified range

Example

This example gets a random integer from the specified range, excluding the maximum
value:

rand(1, 5)

And returns one of these numbers as the result: 1 , 2 , 3 , or 4

range
Return an integer array that starts from a specified integer.



range(<startIndex>, <count>)

ﾉ Expand table

Parameter Required Type Description

<startIndex> Yes Integer An integer value that starts the array as the first item

<count> Yes Integer The number of integers in the array. The count  parameter
value must be a positive integer that doesn't exceed
100,000.

Note: The sum of the startIndex  and count  values must not
exceed 2,147,483,647.

ﾉ Expand table

Return value Type Description

[<range-result>] Array The array with integers starting from the specified index

Example

This example creates an integer array that starts from the specified index and has the
specified number of integers:

range(1, 4)

And returns this result: [1, 2, 3, 4]

removeProperty
Remove a property from an object and return the updated object. If the property that
you try to remove doesn't exist, the function returns the original object.

removeProperty(<object>, '<property>')



ﾉ Expand table

Parameter Required Type Description

<object> Yes Object The JSON object from where you want to remove a property

<property> Yes String The name for the property to remove

ﾉ Expand table

Return value Type Description

<updated-object> Object The updated JSON object without the specified property

To remove a child property from an existing property, use this syntax:

removeProperty(<object>['<parent-property>'], '<child-property>')

ﾉ Expand table

Parameter Required Type Description

<object> Yes Object The JSON object whose property you want to remove

<parent- Yes String The name for parent property with the child property that
property> you want to remove

<child- Yes String The name for the child property to remove
property>

ﾉ Expand table

Return value Type Description

<updated-object> Object The updated JSON object whose child property that you removed

Example 1

This example removes the middleName  property from a JSON object, which is converted
from a string to JSON by using the JSON() function, and returns the updated object:



removeProperty(json('{ "firstName": "Sophia", "middleName": "Anne", 
"surName": "Owen" }'), 'middleName')

Here's the current JSON object:

JSON

{
   "firstName": "Sophia",
   "middleName": "Anne",
   "surName": "Owen"
}

Here's the updated JSON object:

JSON

{
   "firstName": "Sophia",
   "surName": "Owen"
}

Example 2

This example removes the middleName  child property from a customerName  parent
property in a JSON object, which is converted from a string to JSON by using the JSON()
function, and returns the updated object:

removeProperty(json('{ "customerName": { "firstName": "Sophia", 
"middleName": "Anne", "surName": "Owen" } }')['customerName'], 'middleName')

Here's the current JSON object:

JSON

{
   "customerName": {
      "firstName": "Sophia",
      "middleName": "Anne",
      "surName": "Owen"
   }
}



Here's the updated JSON object:

JSON

{
   "customerName": {
      "firstName": "Sophia",
      "surName": "Owen"
   }
}

replace
Replace a substring with the specified string, and return the result string. This function is
case-sensitive.

replace('<text>', '<oldText>', '<newText>')

ﾉ Expand table

Parameter Required Type Description

<text> Yes String The string that has the substring to replace

<oldText> Yes String The substring to replace

<newText> Yes String The replacement string

ﾉ Expand table

Return value Type Description

<updated-text> String The updated string after replacing the substring

If the substring isn't found, return the original string.

Example

This example finds the "old" substring in "the old string" and replaces "old" with "new":

replace('the old string', 'old', 'new')



And returns this result: "the new string"

result
Return the results from the top-level actions in the specified scoped action, such as a
For_each , Until , or Scope  action. The result()  function accepts a single parameter,
which is the scope's name, and returns an array that contains information from the first-
level actions in that scope. These action objects include the same attributes as the
attributes returned by the actions()  function, such as the action's start time, end time,
status, inputs, correlation IDs, and outputs.

７ Note

This function returns information only from the first-level actions in the scoped
action and not from deeper nested actions such as switch or condition actions.

For example, you can use this function to get the results from failed actions so that you
can diagnose and handle exceptions. For more information, see Get context and results
for failures.

result('<scopedActionName>')

ﾉ Expand table

Parameter Required Type Description

<scopedActionName> Yes String The name of the scoped action where you want the
inputs and outputs from the top-level actions inside
that scope

ﾉ Expand table

Return Type Description
value

<array- Array An array that contains arrays of inputs and outputs from each top-
object> object level action inside the specified scope

Example



This example returns the inputs and outputs from each iteration of an HTTP action
inside that's in a For_each  loop by using the result()  function in the Compose  action:

JSON

{
   "actions": {
      "Compose": {
         "inputs": "@result('For_each')",
         "runAfter": {
            "For_each": [
               "Succeeded"
            ]
         },
         "type": "compose"
      },
      "For_each": {
         "actions": {
            "HTTP": {
               "inputs": {
                  "method": "GET",
                  "uri": "https://httpstat.us/200"
               },
               "runAfter": {},
               "type": "Http"
            }
         },
         "foreach": "@triggerBody()",
         "runAfter": {},
         "type": "Foreach"
      }
   }
}

Here's how the example returned array might look where the outer outputs  object
contains the inputs and outputs from each iteration of the actions inside the For_each
action.

JSON

[
   {
      "name": "HTTP",
      "outputs": [
         {
            "name": "HTTP",
            "inputs": {
               "uri": "https://httpstat.us/200",
               "method": "GET"
            },
            "outputs": {



               "statusCode": 200,
               "headers": {
                   "X-AspNetMvc-Version": "5.1",
                   "Access-Control-Allow-Origin": "*",
                   "Cache-Control": "private",
                   "Date": "Tue, 20 Aug 2019 22:15:37 GMT",
                   "Set-Cookie": "ARRAffinity=0285cfbea9f2ee7",
                   "Server": "Microsoft-IIS/10.0",
                   "X-AspNet-Version": "4.0.30319",
                   "X-Powered-By": "ASP.NET",
                   "Content-Length": "0"
               },
               "startTime": "2019-08-20T22:15:37.6919631Z",
               "endTime": "2019-08-20T22:15:37.95762Z",
               "trackingId": "6bad3015-0444-4ccd-a971-cbb0c99a7.....",
               "clientTrackingId": "085863526764.....",
               "code": "OK",
               "status": "Succeeded"
            }
         },
         {
            "name": "HTTP",
            "inputs": {
               "uri": "https://httpstat.us/200",
               "method": "GET"
            },
            "outputs": {
            "statusCode": 200,
               "headers": {
                   "X-AspNetMvc-Version": "5.1",
                   "Access-Control-Allow-Origin": "*",
                   "Cache-Control": "private",
                   "Date": "Tue, 20 Aug 2019 22:15:37 GMT",
                   "Set-Cookie": "ARRAffinity=0285cfbea9f2ee7",
                   "Server": "Microsoft-IIS/10.0",
                   "X-AspNet-Version": "4.0.30319",
                   "X-Powered-By": "ASP.NET",
                   "Content-Length": "0"
               },
               "startTime": "2019-08-20T22:15:37.6919631Z",
               "endTime": "2019-08-20T22:15:37.95762Z",
               "trackingId": "9987e889-981b-41c5-aa27-f3e0e59bf69.....",
               "clientTrackingId": "085863526764.....",
               "code": "OK",
               "status": "Succeeded"
            }
         }
      ]
   }
]

reverse



Reverse the order of items in a collection. When you use this function with sort(), you
can sort a collection in descending order.

reverse([<collection>])

ﾉ Expand table

Parameter Required Type Description

<collection> Yes Array The collection to reverse

ﾉ Expand table

Return value Type Description

[<updated-collection>] Array The reversed collection

Example

This example reverses an array of integers:

reverse(createArray(0, 1, 2, 3))

And returns this array: [3,2,1,0]

S

setProperty
Set the value for JSON object's property and return the updated object. If the property
that you try to set doesn't exist, the property gets added to the object. To add a new
property, use the addProperty() function.

setProperty(<object>, '<property>', <value>)



ﾉ Expand table

Parameter Required Type Description

<object> Yes Object The JSON object whose property you want to set

<property> Yes String The name for the existing or new property to set

<value> Yes Any The value to set for the specified property

To set the child property in a child object, use a nested setProperty()  call instead.
Otherwise, the function returns only the child object as output.

setProperty(<object>, '<parent-property>', setProperty(<object>
['parentProperty'], '<child-property>', <value>))

ﾉ Expand table

Parameter Required Type Description

<object> Yes Object The JSON object whose property you want to set

<parent- Yes String The name for parent property with the child property
property> that you want to set

<child- Yes String The name for the child property to set
property>

<value> Yes Any The value to set for the specified property

ﾉ Expand table

Return value Type Description

<updated-object> Object The updated JSON object whose property you set

Example 1

This example sets the surName  property in a JSON object, which is converted from a
string to JSON by using the JSON() function. The function assigns the specified value to
the property and returns the updated object:



setProperty(json('{ "firstName": "Sophia", "surName": "Owen" }'), 'surName', 
'Hartnett')

Here's the current JSON object:

JSON

{
   "firstName": "Sophia",
   "surName": "Owen"
}

Here's the updated JSON object:

JSON

{
   "firstName": "Sophia",
   "surName": "Hartnett"
}

Example 2

This example sets the surName  child property for the customerName  parent property in a
JSON object, which is converted from a string to JSON by using the JSON() function. The
function assigns the specified value to the property and returns the updated object:

setProperty(json('{ "customerName": { "firstName": "Sophia", "surName": 
"Owen" } }'), 'customerName', setProperty(json('{ "customerName": { 
"firstName": "Sophia", "surName": "Owen" } }')['customerName'], 'surName', 
'Hartnett'))

Here's the current JSON object:

JSON

{
   "customerName": {
      "firstName": "Sophie",
      "surName": "Owen"
   }
}



Here's the updated JSON object:

JSON

{
   "customerName": {
      "firstName": "Sophie",
      "surName": "Hartnett"
   }
}

skip
Remove items from the front of a collection, and return all the other items.

skip([<collection>], <count>)

ﾉ Expand table

Parameter Required Type Description

<collection> Yes Array The collection whose items you want to remove

<count> Yes Integer A positive integer for the number of items to remove at the
front

ﾉ Expand table

Return value Type Description

[<updated-collection>] Array The updated collection after removing the specified items

Example

This example removes one item, the number 0, from the front of the specified array:

skip(createArray(0, 1, 2, 3), 1)

And returns this array with the remaining items: [1,2,3]



slice
Return a substring by specifying the starting and ending position or value. See also
substring().

slice('<text>', <startIndex>, <endIndex>?)

ﾉ Expand table

Parameter Required Type Description

<text> Yes String The string that contains the substring to find

<startIndex> Yes Integer The zero-based starting position or value for where to begin
searching for the substring

- If startIndex is greater than the string length, return an
empty string.

- If startIndex is negative, start searching at the index value
that's the sum of the string length and startIndex.

<endIndex> No Integer The zero-based ending position or value for where to end
searching for the substring. The character located at the
ending index value isn't included in the search.

- If endIndex isn't specified or greater than the string length,
search up to the end of the string.

- If endIndex is negative, end searching at the index value
that the sum of the string length and endIndex.

ﾉ Expand table

Return value Type Description

<slice-result> String A new string that contains the found substring

Examples

slice('Hello World', 2) // Returns 'llo World'.
slice('Hello World', 30) // Returns ''.
slice('Hello World', 10, 2) // Returns ''.



slice('Hello World', 0) // Returns 'Hello World'.
slice('Hello World', 2, 5) // Returns 'llo'.
slice('Hello World', 6, 20) // Returns 'World'.
slice('Hello World', -2) // Returns 'ld'.
slice('Hello World', 3, -1) // Returns 'lo Worl'.
slice('Hello World', 3, 3) // Returns ''.

sort
Sort items in a collection. You can sort the collection objects using any key that contains
a simple type.

sort([<collection>], <sortBy>?)

ﾉ Expand table

Parameter Required Type Description

<collection> Yes Array The collection with the items to sort

<sortBy> No String The key to use for sorting the collection objects

ﾉ Expand table

Return value Type Description

[<updated-collection>] Array The sorted collection

Example 1

This example sorts an array of integers:

sort(createArray(2, 1, 0, 3))

And returns this array: [0,1,2,3]

Example 2

This example sorts an array of objects by key:



sort(createArray(json('{ "first": "Amalie", "last": "Rose" }'), json('{ 
"first": "Elise", "last": "Renee" }')), 'last')

And returns this array: [{ "first": "Elise", "last": "Renee" }, {"first": "Amalie",
"last": "Rose" }')]

split
Return an array that contains substrings, separated by commas, based on the specified
delimiter character in the original string.

split('<text>', '<delimiter>')

ﾉ Expand table

Parameter Required Type Description

<text> Yes String The string to separate into substrings based on the specified
delimiter in the original string

<delimiter> Yes String The character in the original string to use as the delimiter

ﾉ Expand table

Return value Type Description

[<substring1>, Array An array that contains substrings from the original string,
<substring2>,...] separated by commas

Example 1

This example creates an array with substrings from the specified string based on the
specified character as the delimiter:

split('a_b_c', '_')

And returns this array as the result: ["a","b","c"]

Example 2



This example creates an array with a single element when no delimiter exists in the
string:

split('a_b_c', ' ')

And returns this array as the result: ["a_b_c"]

startOfDay
Return the start of the day for a timestamp.

startOfDay('<timestamp>', '<format>'?)

ﾉ Expand table

Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

<format> No String A numeric format string that is either a single format specifier
or a custom format pattern. The default format for the
timestamp is "o" (yyyy-MM-ddTHH:mm:ss.fffffffK), which
complies with ISO 8601  and preserves time zone
information.

If the format isn't a valid value, an error is generated.

ﾉ Expand table

Return value Type Description

<updated- String The specified timestamp but starting at the zero-hour mark for
timestamp> the day

Example

This example finds the start of the day for this timestamp:



startOfDay('2018-03-15T13:30:30Z')

And returns this result: "2018-03-15T00:00:00.0000000Z"

startOfHour
Return the start of the hour for a timestamp.

startOfHour('<timestamp>', '<format>'?)

ﾉ Expand table

Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

<format> No String A numeric format string that is either a single format specifier
or a custom format pattern. The default format for the
timestamp is "o" (yyyy-MM-ddTHH:mm:ss.fffffffK), which
complies with ISO 8601  and preserves time zone
information.

If the format isn't a valid value, an error is generated.

ﾉ Expand table

Return value Type Description

<updated- String The specified timestamp but starting at the zero-minute mark for
timestamp> the hour

Example

This example finds the start of the hour for this timestamp:

startOfHour('2018-03-15T13:30:30Z')

And returns this result: "2018-03-15T13:00:00.0000000Z"



startOfMonth
Return the start of the month for a timestamp.

startOfMonth('<timestamp>', '<format>'?)

ﾉ Expand table

Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

<format> No String A numeric format string that is either a single format specifier
or a custom format pattern. The default format for the
timestamp is "o" (yyyy-MM-ddTHH:mm:ss.fffffffK), which
complies with ISO 8601  and preserves time zone
information.

If the format isn't a valid value, an error is generated.

ﾉ Expand table

Return value Type Description

<updated- String The specified timestamp but starting on the first day of the month
timestamp> at the zero-hour mark

Example 1

This example returns the start of the month for this timestamp:

startOfMonth('2018-03-15T13:30:30Z')

And returns this result: "2018-03-01T00:00:00.0000000Z"

Example 2

This example returns the start of the month in the specified format for this timestamp:



startOfMonth('2018-03-15T13:30:30Z', 'yyyy-MM-dd')

And returns this result: "2018-03-01"

startsWith
Check whether a string starts with a specific substring. Return true when the substring is
found, or return false when not found. This function isn't case-sensitive.

startsWith('<text>', '<searchText>')

ﾉ Expand table

Parameter Required Type Description

<text> Yes String The string to check

<searchText> Yes String The starting string to find

ﾉ Expand table

Return Type Description
value

true or false Boolean Return true when the starting substring is found. Return false when not
found.

Example 1

This example checks whether the "hello world" string starts with the "hello" substring:

startsWith('hello world', 'hello')

And returns this result: true

Example 2

This example checks whether the "hello world" string starts with the "greetings"
substring:



startsWith('hello world', 'greetings')

And returns this result: false

string
Return the string version for a value.

string(<value>)

ﾉ Expand table

Parameter Required Type Description

<value> Yes Any The value to convert. If this value is null or evaluates to null, the
value is converted to an empty string ( "" ) value.

For example, if you assign a string variable to a non-existent
property, which you can access with the ?  operator, the null
value is converted to an empty string. However, comparing a
null value isn't the same as comparing an empty string.

ﾉ Expand table

Return Type Description
value

<string- String The string version for the specified value. If the value parameter is null or
value> evaluates to null, this value is returned as an empty string ( "" ) value.

Example 1

This example creates the string version for this number:

string(10)



And returns this result: "10"

Example 2

This example creates a string for the specified JSON object and uses the backslash
character (\) as an escape character for the double-quotation mark (").

string( { "name": "Sophie Owen" } )

And returns this result: "{ \\"name\\": \\"Sophie Owen\\" }"

sub
Return the result from subtracting the second number from the first number.

sub(<minuend>, <subtrahend>)

ﾉ Expand table

Parameter Required Type Description

<minuend> Yes Integer or Float The number from which to subtract the subtrahend

<subtrahend> Yes Integer or Float The number to subtract from the minuend

ﾉ Expand table

Return Type Description
value

<result> Integer or The result from subtracting the second number from the first
Float number

Example

This example subtracts the second number from the first number:

sub(10.3, .3)



And returns this result: 10

substring
Return characters from a string, starting from the specified position, or index. Index
values start with the number 0. See also slice().

substring('<text>', <startIndex>, <length>)

ﾉ Expand table

Parameter Required Type Description

<text> Yes String The string whose characters you want

<startIndex> Yes Integer A positive number equal to or greater than 0 that you want
to use as the starting position or index value

<length> No Integer A positive number of characters that you want in the
substring

７ Note

Make sure that the sum from adding the startIndex and length parameter values is
less than the length of the string that you provide for the text parameter.
Otherwise, you get an error, unlike similar functions in other languages where the
result is the substring from the startIndex to the end of the string. The length
parameter is optional and if not provided, the substring() function takes all the
characters beginning from startIndex to the end of the string.

ﾉ Expand table

Return value Type Description

<substring- String A substring with the specified number of characters, starting at the
result> specified index position in the source string

Example

This example creates a five-character substring from the specified string, starting from
the index value 6:



substring('hello world', 6, 5)

And returns this result: "world"

subtractFromTime
Subtract a number of time units from a timestamp. See also getPastTime.

subtractFromTime('<timestamp>', <interval>, '<timeUnit>', '<format>'?)

ﾉ Expand table

Parameter Required Type Description

<timestamp> Yes String The string that contains the timestamp

<interval> Yes Integer The number of specified time units to subtract

<timeUnit> Yes String The unit of time to use with interval: "Second", "Minute",
"Hour", "Day", "Week", "Month", "Year"

<format> No String A numeric format string that is either a single format
specifier or a custom format pattern. The default format for
the timestamp is "o" (yyyy-MM-ddTHH:mm:ss.fffffffK),
which complies with ISO 8601  and preserves time zone
information.

If the format isn't a valid value, an error is generated.

ﾉ Expand table

Return value Type Description

<updated-timestamp> String The timestamp minus the specified number of time units

Example 1

This example subtracts one day from this timestamp:



subtractFromTime('2018-01-02T00:00:00Z', 1, 'Day')

And returns this result: "2018-01-01T00:00:00.0000000Z"

Example 2

This example subtracts one day from this timestamp:

subtractFromTime('2018-01-02T00:00:00Z', 1, 'Day', 'D')

And returns this result using the optional "D" format: "Monday, January, 1, 2018"

T

take
Return items from the front of a collection.

take('<collection>', <count>)
take([<collection>], <count>)

ﾉ Expand table

Parameter Required Type Description

<collection> Yes String or The collection whose items you want
Array

<count> Yes Integer A positive integer for the number of items that you
want from the front

ﾉ Expand table

Return value Type Description

<subset> or String or Array, A string or array that has the specified number of items
[<subset>] respectively taken from the front of the original collection

Example



These examples get the specified number of items from the front of these collections:

take('abcde', 3)
take(createArray(0, 1, 2, 3, 4), 3)

And return these results:

First example: "abc"
Second example: [0, 1, 2]

ticks
Returns the number of ticks, which are 100-nanosecond intervals, since January 1, 0001
12:00:00 midnight (or DateTime.Ticks in C#) up to the specified timestamp. For more
information, see this topic: DateTime.Ticks Property (System).

ticks('<timestamp>')

ﾉ Expand table

Parameter Required Type Description

<timestamp> Yes String The string for a timestamp

ﾉ Expand table

Return value Type Description

<ticks-number> Integer The number of ticks since the specified timestamp

toLower
Return a string in lowercase format. If a character in the string doesn't have a lowercase
version, that character stays unchanged in the returned string.

toLower('<text>')



ﾉ Expand table

Parameter Required Type Description

<text> Yes String The string to return in lowercase format

ﾉ Expand table

Return value Type Description

<lowercase-text> String The original string in lowercase format

Example

This example converts this string to lowercase:

toLower('Hello World')

And returns this result: "hello world"

toUpper
Return a string in uppercase format. If a character in the string doesn't have an
uppercase version, that character stays unchanged in the returned string.

toUpper('<text>')

ﾉ Expand table

Parameter Required Type Description

<text> Yes String The string to return in uppercase format

ﾉ Expand table

Return value Type Description

<uppercase-text> String The original string in uppercase format

Example



This example converts this string to uppercase:

toUpper('Hello World')

And returns this result: "HELLO WORLD"

trigger
Return a trigger's output at runtime, or values from other JSON name-and-value pairs,
which you can assign to an expression.

Inside a trigger's inputs, this function returns the output from the previous
execution.

Inside a trigger's condition, this function returns the output from the current
execution.

By default, the function references the entire trigger object, but you can optionally
specify a property whose value that you want. Also, this function has shorthand versions
available, see triggerOutputs() and triggerBody().

trigger()

ﾉ Expand table

Return value Type Description

<trigger-output> String The output from a trigger at runtime

triggerBody
Return a trigger's body  output at runtime. Shorthand for trigger().outputs.body . See
trigger().

triggerBody()



ﾉ Expand table

Return value Type Description

<trigger-body-output> String The body  output from the trigger

triggerFormDataMultiValues
Return an array with values that match a key name in a trigger's form-data or form-
encoded output.

triggerFormDataMultiValues('<key>')

ﾉ Expand table

Parameter Required Type Description

<key> Yes String The name for the key whose value you want

ﾉ Expand table

Return value Type Description

[<array-with-key-values>] Array An array with all the values that match the specified key

Example

This example creates an array from the "feedUrl" key value in an RSS trigger's form-data
or form-encoded output:

triggerFormDataMultiValues('feedUrl')

And returns this array as an example result:
["https://feeds.a.dj.com/rss/RSSMarketsMain.xml"]

triggerFormDataValue
Return a string with a single value that matches a key name in a trigger's form-data or
form-encoded output. If the function finds more than one match, the function throws an



error.

triggerFormDataValue('<key>')

ﾉ Expand table

Parameter Required Type Description

<key> Yes String The name for the key whose value you want

ﾉ Expand table

Return value Type Description

<key-value> String The value in the specified key

Example

This example creates a string from the "feedUrl" key value in an RSS trigger's form-data
or form-encoded output:

triggerFormDataValue('feedUrl')

And returns this string as an example result:
"https://feeds.a.dj.com/rss/RSSMarketsMain.xml"

triggerMultipartBody
Return the body for a specific part in a trigger's output that has multiple parts.

triggerMultipartBody(<index>)

ﾉ Expand table

Parameter Required Type Description

<index> Yes Integer The index value for the part that you want



ﾉ Expand table

Return value Type Description

<body> String The body for the specified part in a trigger's multipart output

triggerOutputs
Return a trigger's output at runtime, or values from other JSON name-and-value pairs.
Shorthand for trigger().outputs . See trigger().

triggerOutputs()

ﾉ Expand table

Return value Type Description

<trigger-output> String The output from a trigger at runtime

trim
Remove leading and trailing whitespace from a string, and return the updated string.

trim('<text>')

ﾉ Expand table

Parameter Required Type Description

<text> Yes String The string that has the leading and trailing whitespace to
remove

ﾉ Expand table

Return value Type Description

<updatedText> String An updated version for the original string without leading or trailing
whitespace



Example

This example removes the leading and trailing whitespace from the string " Hello World
":

trim(' Hello World  ')

And returns this result: "Hello World"

U

union
Return a collection that has all the items from the specified collections. To appear in the
result, an item can appear in any collection passed to this function. If one or more items
have the same name, the last item with that name appears in the result.

union('<collection1>', '<collection2>', ...)
union([<collection1>], [<collection2>], ...)

ﾉ Expand table

Parameter Required Type Description

<collection1>, Yes Array or Object, but The collections from where you
<collection2>, ... not both want all the items

ﾉ Expand table

Return value Type Description

<updatedCollection> Array or Object, A collection with all the items from the specified
respectively collections - no duplicates

Example

This example gets all the items from these collections:



union(createArray(1, 2, 3), createArray(1, 2, 10, 101))

And returns this result: [1, 2, 3, 10, 101]

uriComponent
Return a uniform resource identifier (URI) encoded version for a string by replacing URL-
unsafe characters with escape characters. Use this function rather than
encodeUriComponent(). Although both functions work the same way, uriComponent()  is
preferred.

uriComponent('<value>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The string to convert to URI-encoded format

ﾉ Expand table

Return value Type Description

<encoded-uri> String The URI-encoded string with escape characters

Example

This example creates a URI-encoded version for this string:

uriComponent('https://contoso.com')

And returns this result: "https%3A%2F%2Fcontoso.com"

uriComponentToBinary
Return the binary version for a uniform resource identifier (URI) component.



uriComponentToBinary('<value>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The URI-encoded string to convert

ﾉ Expand table

Return value Type Description

<binary-for- String The binary version for the URI-encoded string. The binary content is
encoded-uri> base64-encoded and represented by $content .

Example

This example creates the binary version for this URI-encoded string:

uriComponentToBinary('https%3A%2F%2Fcontoso.com')

And returns this result:

"001000100110100001110100011101000111000000100101001100

11010000010010010100110010010001100010010100110010010001

10011000110110111101101110011101000110111101110011011011

110010111001100011011011110110110100100010"

uriComponentToString
Return the string version for a uniform resource identifier (URI) encoded string,
effectively decoding the URI-encoded string.

uriComponentToString('<value>')

ﾉ Expand table



Parameter Required Type Description

<value> Yes String The URI-encoded string to decode

ﾉ Expand table

Return value Type Description

<decoded-uri> String The decoded version for the URI-encoded string

Example

This example creates the decoded string version for this URI-encoded string:

uriComponentToString('https%3A%2F%2Fcontoso.com')

And returns this result: "https://contoso.com"

uriHost
Return the host  value for a uniform resource identifier (URI).

uriHost('<uri>')

ﾉ Expand table

Parameter Required Type Description

<uri> Yes String The URI whose host  value you want

ﾉ Expand table

Return value Type Description

<host-value> String The host  value for the specified URI

Example

This example finds the host  value for this URI:



uriHost('https://www.localhost.com:8080')

And returns this result: "www.localhost.com"

uriPath
Return the path  value for a uniform resource identifier (URI).

uriPath('<uri>')

ﾉ Expand table

Parameter Required Type Description

<uri> Yes String The URI whose path  value you want

ﾉ Expand table

Return Type Description
value

<path- String The path  value for the specified URI. If path  doesn't have a value, return
value> the "/" character.

Example

This example finds the path  value for this URI:

uriPath('https://www.contoso.com/catalog/shownew.htm?date=today')

And returns this result: "/catalog/shownew.htm"

uriPathAndQuery
Return the path  and query  values for a uniform resource identifier (URI).



uriPathAndQuery('<uri>')

ﾉ Expand table

Parameter Required Type Description

<uri> Yes String The URI whose path  and query  values you want

ﾉ Expand table

Return value Type Description

<path-query- String The path  and query  values for the specified URI. If path  doesn't
value> specify a value, return the "/" character.

Example

This example finds the path  and query  values for this URI:

uriPathAndQuery('https://www.contoso.com/catalog/shownew.htm?date=today')

And returns this result: "/catalog/shownew.htm?date=today"

uriPort
Return the port  value for a uniform resource identifier (URI).

uriPort('<uri>')

ﾉ Expand table

Parameter Required Type Description

<uri> Yes String The URI whose port  value you want

ﾉ Expand table



Return Type Description
value

<port- Integer The port  value for the specified URI. If port  doesn't specify a value, return
value> the default port for the protocol.

Example

This example returns the port  value for this URI:

uriPort('https://www.localhost:8080')

And returns this result: 8080

uriQuery
Return the query  value for a uniform resource identifier (URI).

uriQuery('<uri>')

ﾉ Expand table

Parameter Required Type Description

<uri> Yes String The URI whose query  value you want

ﾉ Expand table

Return value Type Description

<query-value> String The query  value for the specified URI

Example

This example returns the query  value for this URI:

uriQuery('https://www.contoso.com/catalog/shownew.htm?date=today')



And returns this result: "?date=today"

uriScheme
Return the scheme  value for a uniform resource identifier (URI).

uriScheme('<uri>')

ﾉ Expand table

Parameter Required Type Description

<uri> Yes String The URI whose scheme  value you want

ﾉ Expand table

Return value Type Description

<scheme-value> String The scheme  value for the specified URI

Example

This example returns the scheme  value for this URI:

uriScheme('https://www.contoso.com/catalog/shownew.htm?date=today')

And returns this result: "http"

utcNow
Return the current timestamp.

utcNow('<format>')

Optionally, you can specify a different format with the <format> parameter.



ﾉ Expand table

Parameter Required Type Description

<format> No String A numeric format string that is either a single format specifier
or a custom format pattern. The default format for the
timestamp is "o" (yyyy-MM-ddTHH:mm:ss.fffffffK), which
complies with ISO 8601  and preserves time zone information.

If the format isn't a valid value, an error is generated.

ﾉ Expand table

Return value Type Description

<current-timestamp> String The current date and time

Example 1

Suppose today is April 15, 2018 at 1:00:00 PM. This example gets the current timestamp:

utcNow()

And returns this result: "2018-04-15T13:00:00.0000000Z"

Example 2

Suppose today is April 15, 2018 at 1:00:00 PM. This example gets the current timestamp
using the optional "D" format:

utcNow('D')

And returns this result: "Sunday, April 15, 2018"

V

variables
Return the value for a specified variable.



variables('<variableName>')

ﾉ Expand table

Parameter Required Type Description

<variableName> Yes String The name for the variable whose value you want

ﾉ Expand table

Return value Type Description

<variable-value> Any The value for the specified variable

Example

Suppose the current value for a "numItems" variable is 20. This example gets the integer
value for this variable:

variables('numItems')

And returns this result: 20

W

workflow
Return all the details about the workflow itself during run time.

workflow().<property>

ﾉ Expand table

Parameter Required Type Description

<property> No String The name for the workflow property whose value you want



Parameter Required Type Description

By default, a workflow object has these properties: name , type ,
id , location , run , and tags .

- The run  property value is a JSON object that includes these
properties: name , type , and id .

- The tags  property is a JSON object that includes tags that are
associated with your logic app in Azure Logic Apps or flow in
Power Automate and the values for those tags. For more
information about tags in Azure resources, review Tag
resources, resource groups, and subscriptions for logical
organization in Azure.

Note: By default, a logic app has no tags, but a Power
Automate flow has the flowDisplayName  and environmentName
tags.

Example 1

This example returns the name for a workflow's current run:

workflow().run.name

Example 2

If you use Power Automate, you can create a @workflow()  expression that uses the tags
output property to get the values from your flow's flowDisplayName  or environmentName
property.

For example, you can send custom email notifications from the flow itself that link back
to your flow. These notifications can include an HTML link that contains the flow's
display name in the email title and follows this syntax:

<a href=https://flow.microsoft.com/manage/environments/@{workflow()['tags']

['environmentName']}/flows/@{workflow()['name']}/details>Open flow @{workflow()

['tags']['flowDisplayName']}</a>



X

xml
Return the XML version for a string that contains a JSON object.

xml('<value>')

ﾉ Expand table

Parameter Required Type Description

<value> Yes String The string with the JSON object to convert

The JSON object must have only one root property, which can't
be an array.
Use the backslash character (\) as an escape character for the
double quotation mark (").

ﾉ Expand table

Return value Type Description

<xml-version> Object The encoded XML for the specified string or JSON object

Example 1

This example converts the string to XML:

xml('<name>Sophia Owen</name>')

And returns this result XML:

XML

<name>Sophia Owen</name>

Example 2

This example creates the XML version for this string, which contains a JSON object:

xml(json('{ "name": "Sophia Owen" }'))



And returns this result XML:

XML

<name>Sophia Owen</name>

Example 3

Suppose you have this JSON object:

JSON

{
  "person": {
    "name": "Sophia Owen",
    "city": "Seattle"
  }
}

This example creates XML for a string that contains this JSON object:

xml(json('{"person": {"name": "Sophia Owen", "city": "Seattle"}}'))

And returns this result XML:

XML

<person>
  <name>Sophia Owen</name>
  <city>Seattle</city>
<person>

xpath
Check XML for nodes or values that match an XPath (XML Path Language) expression,
and return the matching nodes or values. An XPath expression, or just "XPath", helps you
navigate an XML document structure so that you can select nodes or compute values in
the XML content.

７ Note

In Consumption and Standard logic apps, all function expressions use the .NET
XPath library. XPath expressions are compatible with the underlying .NET library
and support only the expression that the underlying .NET library supports.



xpath('<xml>', '<xpath>')

ﾉ Expand table

Parameter Required Type Description

<xml> Yes Any The XML string to search for nodes or values that match an
XPath expression value

<xpath> Yes Any The XPath expression used to find matching XML nodes or
values

ﾉ Expand table

Return value Type Description

<xml-node> XML An XML node when only a single node matches the
specified XPath expression

<value> Any The value from an XML node when only a single
value matches the specified XPath expression

[<xml-node1>, <xml-node2>, ...] - Array An array with XML nodes or values that match the
or- [<value1>, <value2>, ...] specified XPath expression

Example 1

Suppose that you have this 'items'  XML string:

XML

<?xml version="1.0"?>
<produce>
  <item>
    <name>Gala</name>
    <type>apple</type>
    <count>20</count>
  </item>
  <item>
    <name>Honeycrisp</name>
    <type>apple</type>
    <count>10</count>
  </item>
</produce>



This example passes in the XPath expression, '/produce/item/name/text()' , to find the
nodes that match the <name></name>  node in the 'items'  XML string, and returns an
array with those node values:

xpath(xml(parameters('items')), '/produce/item/name/text()')

The example also uses the parameters() function to get the XML string from 'items'
and convert the string to XML format by using the xml() function.

Here's the result array populated with values of the nodes that match <name></name> :

[ Gala, Honeycrisp ]

Example 2

Following on Example 1, this example passes in the XPath expression,
'/produce/item/name[1]' , to find the first name  element that is the child of the item
element.

xpath(xml(parameters('items')), '/produce/item/name[1]')

Here's the result: Gala

Example 3

Following on Example 1, this example pass in the XPath expression,
'/produce/item/name[last()]' , to find the last name  element that is the child of the
item  element.

xpath(xml(parameters('items')), '/produce/item/name[last()]')

Here's the result: Honeycrisp

Example 4

In this example, suppose your items  XML string also contains the attributes,
expired='true'  and expired='false' :

XML

<?xml version="1.0"?>
<produce>
  <item>
    <name expired='true'>Gala</name>
    <type>apple</type>
    <count>20</count>
  </item>



  <item>
    <name expired='false'>Honeycrisp</name>
    <type>apple</type>
    <count>10</count>
  </item>
</produce>

This example passes in the XPath expression, '//name[@expired]' , to find all the name
elements that have the expired  attribute:

xpath(xml(parameters('items')), '//name[@expired]')

Here's the result: [ Gala, Honeycrisp ]

Example 5

In this example, suppose your items  XML string contains only this attribute, expired =
'true' :

XML

<?xml version="1.0"?>
<produce>
  <item>
    <name expired='true'>Gala</name>
    <type>apple</type>
    <count>20</count>
  </item>
  <item>
    <name>Honeycrisp</name>
    <type>apple</type>
    <count>10</count>
  </item>
</produce>

This example passes in the XPath expression, '//name[@expired = 'true']' , to find all
the name  elements that have the attribute, expired = 'true' :

xpath(xml(parameters('items')), '//name[@expired = 'true']')

Here's the result: [ Gala ]

Example 6

In this example, suppose your items  XML string also contains these attributes:

expired='true' price='12'

expired='false' price='40'



XML

<?xml version="1.0"?>
<produce>
  <item>
    <name expired='true' price='12'>Gala</name>
    <type>apple</type>
    <count>20</count>
  </item>
  <item>
    <name expired='false' price='40'>Honeycrisp</name>
    <type>apple</type>
    <count>10</count>
  </item>
</produce>

This example passes in the XPath expression, '//name[@price>35]' , to find all the name
elements that have price > 35 :

xpath(xml(parameters('items')), '//name[@price>35]')

Here's the result: Honeycrisp

Example 7

In this example, suppose your items  XML string is the same as in Example 1:

XML

<?xml version="1.0"?>
<produce>
  <item>
    <name>Gala</name>
    <type>apple</type>
    <count>20</count>
  </item>
  <item>
    <name>Honeycrisp</name>
    <type>apple</type>
    <count>10</count>
  </item>
</produce>

This example finds nodes that match the <count></count>  node and adds those node
values with the sum()  function:

xpath(xml(parameters('items')), 'sum(/produce/item/count)')

Here's the result: 30



Example 8

In this example, suppose you have this XML string, which includes the XML document
namespace, xmlns="https://contoso.com" :

XML

<?xml version="1.0"?><file xmlns="https://contoso.com">
<location>Paris</location></file>

These expressions use either XPath expression, /*[name()="file"]/*[name()="location"]
or /*[local-name()="file" and namespace-uri()="https://contoso.com"]/*[local-
name()="location"] , to find nodes that match the <location></location>  node. These
examples show the syntax that you use in either the designer or in the expression editor:

xpath(xml(body('Http')), '/*[name()="file"]/*[name()="location"]')

xpath(xml(body('Http')), '/*[local-name()="file" and namespace-

uri()="https://contoso.com"]/*[local-name()="location"]')

Here's the result node that matches the <location></location>  node:

<location xmlns="https://contoso.com">Paris</location>

） Important

If you work in code view, escape the double quotation mark (") by using the
backslash character (\). For example, you need to use escape characters when you
serialize an expression as a JSON string. However, if you're work in the designer or
expression editor, you don't need to escape the double quotation mark because
the backslash character is added automatically to the underlying definition, for
example:

Code view: xpath(xml(body('Http')), '/*[name()=\"file\"]/*
[name()=\"location\"]')

Expression editor: xpath(xml(body('Http')), '/*[name()="file"]/*
[name()="location"]')

Example 9

Following on Example 8, this example uses the XPath expression, 'string(/*
[name()="file"]/*[name()="location"])' , to find the value in the <location></location>



node:

xpath(xml(body('Http')), 'string(/*[name()="file"]/*[name()="location"])')

Here's the result: Paris

Next steps
Learn about the Workflow Definition Language

Feedback
Was this page helpful?  Yes  No

Provide product feedback | Get help at Microsoft Q&A



Submit a template to the Power Automate
gallery
Article • 04/09/2025

Templates help you to create flows more easily, and to imagine additional scenarios that would
benefit from a cloud flow.

1. On the left pane, select My flows.

2. Select and open a cloud flow you want to publish.

3. On the menu at the top, select Export > Package (.zip).

4. Please ensure the following details for your connector template so the end user is able to
search the right template:

No personal information or secret is included
Title is less than 75 characters
Description is less than 1024 characters.

1. To download the connector template files, select Export.

2. Upload the package to a storage blob and generate the SAS URL.



Ensure that your SAS URI is valid for at least 15 days.

Set up your Partner Center Seller account
This is a one-time process for creating a Seller account in Partner Center. Seller accounts go
through a vetting process before they can publish offers through Partner Center.

If you already have a Seller account, you need to enroll in the Microsoft 365 and Copilot
program.

To create a new Seller account, follow these steps:

1. If you have an existing developer account in Partner Center, use those same credentials to
access Partner Center.

If you don't have an account, then follow the steps in Create a Microsoft AI Cloud Partner
Program account in Partner Center.

2. Ensure you have the valid email address configured in your Entra ID account. To configure
the email ID, follow the steps in Manage user profile info.

７ Note

If the Email ID for the Entra account is missing, the certification request is auto-
rejected.

3. Before you can publish, verify your account information. Learn more in Verify your
account information when you enroll in a new Partner Center program.

4. Enroll in the Microsoft 365 and Copilot program.

Submit your package for certification
1. Sign in to Partner Center .

2. Under the Home heading, select Marketplace offers card.

3. On the Marketplace offers | Overview page, select Microsoft 365 and Copilot program.

4. On the Microsoft 365 and Copilot page, select New offer > Connectors & Agents in
Microsoft Copilot Studio.



5. In the Name field in the New Connectors & Agents in Microsoft Copilot Studio screen,
enter a unique name for your offer.

This name is used to help you identify your offer in Partner Center. We recommend that
you include the name of your connector and associated AI enabled connector.

Next, you're taken to the Product setup page. You don't need to enter information here. The
Status is marked as Complete to indicate there's nothing for you to do.

Package your connector based templates
1. On the navigation bar to the left, select Packages.
2. On the Packages tab in the SAS URI field, enter the link to the SAS URI of your package

containing the connector based template.
3. Ensure your package complies with Marketplace Policies for Power Platform listed in 5000

Power Platform Connectors.
4. Select Save draft.

Set properties
1. On the navigation bar to the left, select Properties.

2. On the Properties tab, do the following steps:
a. In the General Info group, choose up to three (3) categories that your connector

and/or AI enabled connector associates best with.
b. In the Legal and support info group, you need to provide three (3) pieces of

information.

i. In the first field, you can either enter an HTTPS URL to your End User Licensing
Agreement, or you can use the Microsoft commercial marketplace Standard
Contract. We recommend that you use the Standard Contract.

To choose the Standard Contract, select the checkbox.

ii. In the Privacy policy link field, enter the privacy link for your policies regarding the
user's personal information.

iii. In the Support document link field, enter the support link for customers to refer to
in case they have issues.

c. Select Save to save your draft.

Post-submission steps



1. After you submit your offer, wait 24 to 48 hours for Microsoft to review your offer.

You can review the status of your offer as it is progressing through certification lifecycle.
Inside your offer, go to the Product overview tab.

2. Within 48 hours, Microsoft updates the certification report in the Product overview tab.

If your package passed the certification guidelines, you're asked to move to next stage. If
it didn't pass, you're required to update the package based on the certification report and
resubmit the package.

3. Once the certification is completed in the Product overview for your offer under
Publisher signoff, select Go live.

Wait for deployment
The Power Automate team verifies and possibly modifies your template. If the team approves
your template, it appears in the gallery of templates for Power Automate. After your offer is
live, we deploy your connector template across all products and regions within 48 hours.

７ Note

If you want to update your offer content in future, for example, you want to submit
version upgrades to the connector template, follow the same rules: To initiate the
update request, select the Product overview tab for your certified offer, and select
the update present for the section you want to modify.
Templates are for use in the public gallery only. They aren't supported for private
use.



Turn a flow on or off, and delete a flow
Article • 06/15/2023

At times, you might want to turn off a cloud flow to prevent it from running, or
permanently delete a flow. Follow these steps to turn flows on or off, and delete a flow.

Turn off a flow
After you create a cloud flow, it's turned on by default. Follow these steps to turn off a
cloud flow.

1. On the left pane, select My Flows.

2. Select a cloud flow, and then select the vertical ellipsis (⋮).

3. On the menu that appears, select Turn off.

4. On the Details page, select the vertical ellipsis (⋮), and then select Details to verify
the new status.

７ Note

If you turn off a flow while it’s running, the flow runs will continue to run until all
pending flow runs are completed.

Turn on a flow
If you've turned off a cloud flow, but want to turn it back on so that it'll run again, follow
one of these steps.

If you're on the Details page, select Turn on on the menu at the top.

If you are on the Flows page:

1. Select a cloud flow, and then select the vertical ellipsis (⋮).



2. On the menu that appears, select Turn on. The status changes to On.

Delete a flow
If you need to delete a flow, follow these steps:

1. Before you delete the flow, go to the Details page and select All runs.

To cancel pending runs, follow the instructions in Cancel or resubmit flow runs in
bulk. Otherwise, some pending flow runs might continue to run to avoid data loss.

2. Once you've cancelled pending runs, return to the Details page and select Delete
on the menu at the top.

７ Note

If you deleted a flow accidentally and need to restore it, go to Restore deleted
flows.



Format data by examples
Article • 02/20/2025

Expressions in Power Automate is a powerful way to perform operations over data. You
can use the Format data by examples feature to access these expressions without
knowing the different functions and corresponding syntax that is needed to create the
expressions that you want. To format text, dates, and numbers, you can just provide
examples of the output format that you want the flow to produce, and Power Automate
automatically generates the expression formula to use.

Format dates by examples
In this sample scenario, imagine that there's a Microsoft list with products that you
purchased. You want to send an email whenever the list gets updated with new
products. By default, the SharePoint formats dates like this: 2022-09-18, but you'd like it
to display as September 18 in the email notification message. Let’s see how to change
the format of the date with format data by examples.

1. Edit your flow in the Power Automate designer.

2. Select the action into which you want to insert the formatted date, and then select
any text field on the card.

3. On the window that opens, select Expression > Format data by examples.



A list displays all items in your flow that can be formatted.

4. Select the item that you want to transform.

5. Provide an example of the original data for the item that you selected in the
previous step.

 Tip

You can go to the original data source or review a previous flow run to copy
an example value for the previous step.

6. Provide a sample of how you’d like the flow to transform the example.

7. Select Get expression.

Power Automate displays the expression that it recommends that you use to get
the output you want. You can test it with another value to confirm that the
expression does what you expect.

 Tip

If the expression that Power Automate recommends isn't what you expect,
you can add more examples to refine the expression that it recommends.



8. Select Apply when the results of the expression match your expectations.

Power Automate adds the expression to the flow.

Congratulations! You built an expression by providing an example.

Format numbers by examples
In this example, imagine you have a number that comes from a Microsoft Forms survey
as 5958. You want to format the number as a currency value before you store it in an
Excel file, like this $5,958. To direct your flow to format the number as a currency value,
provide an example of how Microsoft Forms returns the number and an example of how
you want your flow to format the number.

Power Automate uses the information you provide and then it suggests the expression
that does the transformation, as shown in the following screenshot.

Format text by examples
In the following scenario, imagine you have a registration form in which participants
provide their full name and you want to send a registration confirmation email with just
the first name. Instead of greeting the person by their full name, for example Casey
Jensen, we just want to say Casey.



Just provide an example and Power Automate suggests the right expression to achieve
this transformation, as the following screenshot displays.

Limitations
Format data by examples can format one text, number, or date at a time. More
complex structures like arrays aren't supported.

Format data by examples isn't available in environments based in South Africa,
GCC High, and DoD.

Related information
PROSE , a technology that enables programming by example, powers format data by
examples.

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Share a cloud flow
Article • 10/09/2024

Share a cloud flow with others in your organization and guest users so they can also
benefit from automation you've created. There are three primary ways to share a cloud
flow in Power Automate:

Add an owner to a cloud flow.
Share a cloud flow with run-only privileges.
Share a copy of a cloud flow.

Prerequisites
You must have either a Power Automate license (except the free license)  or a
seeded license (Office 365, Dynamics 365 Enterprise plans, Dynamics 365
Professional plans, Dynamics 365 Team Member, Power Apps (Canvas and Model
driven Apps)- Per App plans, Power Apps per user plan, Power Apps Plan 1
(grandfathered), Power Apps Plan 2 (grandfathered), Windows licenses) to share a
cloud flow.
You must be the creator or owner to add or remove owners from a cloud flow.

About embedded and other connections
Connections used in a cloud flow fall into two categories:

Embedded: These connections are used in the flow.
Other: These connections have been defined for a cloud flow, but aren't used in it.

If you stop using a connection in a cloud flow, that connection appears in the Other
connections list, where it remains until an owner includes it in the flow again. To make
changes to embedded connections, follow the steps in Modify a connection, later in this
article.

The list of connections appears under the list of owners in a cloud flow's properties.

Add an owner to a cloud flow
Adding an owner to a cloud flow is the most common way to share a cloud flow. Any
owner of a cloud flow can perform these actions:

View the run history.



Manage the properties of the flow (for example, start or stop the flow, add owners,
or update credentials for a connection).
Edit the definition of the flow (for example, add or remove an action or condition).
Add or remove other owners (but not the flow's creator), including guest users.
Delete the flow.

If you're the creator or an owner of a cloud flow, you'll find it listed on the Team flows
tab in Power Automate.

７ Note

Shared connections can be used only in the flow in which they were created.

Owners can use services in a cloud flow but can't modify the credentials for a
connection that another owner created.

To add more owners to a cloud flow:

1. Sign in to Power Automate , and then select My flows.

2. Select the flow that you want to share, select the vertical ellipsis (⋮), and then select
Share.

3. Enter the name, email address, or group name for the person or group that you
want to add as an owner.

The user or group you've selected becomes an owner of the flow.

Congratulations—you've created your team flow!

Add a list as a co-owner
You can add SharePoint lists as co-owners of a cloud flow so that everyone who has edit
access to the list automatically gets edit access to the flow. After the flow is shared, you
can simply distribute a link to it. More information: Training: Create and set up a
SharePoint list

Use a list when the flow is connected to SharePoint, and use a group in all other cases.

） Important

SharePoint users must have Edit permission or be a member of the Members
or Owners group to run flows in SharePoint.



Adding a list as a co-owner is not available in GCC High and DoD tenants.

Remove an owner
When you remove an owner whose credentials are used to access Power Automate
services, you should update the credentials for those connections so that the flow will
continue to run properly. To learn more, go to Modify a connection.

1. On the flow details page, in the Owners section, select Edit.

2. Select Delete (the trash can) for the owner you want to remove.

3. In the confirmation dialog box, select Remove.

Congratulations—the user or group that you removed is no longer listed as an owner of
the flow.

Modify a connection
You might need to change the owner of a connection in a cloud flow if you remove the
existing owner or if you just want to use a different account to sign in to an action or
trigger.

1. Go to the flow that you want to modify.

2. Select Edit.

3. Select the ellipsis (...) in the step where you want to edit the connection.

4. If you have a connection already, select it; if not, select Add new connection to
create a new connection, and then select Sign in to create your new connection.

Share a cloud flow with run-only permissions
Instant flows (that is, flows that use a manual trigger such as a button or an item being
selected) can be shared by using run-only permissions. Any user who's added as a run-
only user won't have access to edit or modify the flow in any way; they'll only have
permissions to trigger the flow.

To add a run-only user:

1. On the flow details page, in the Run only users section, select Edit.



2. In the Manage run-only permissions panel, specify the users and groups you want
to provide run-only access to.

3. As an owner, you can specify whether run-only users will need to provide their own
connections or you can choose use a connection that's already defined in the flow.

Congratulations—the user or group now has access to run the flow.

To remove a run-only user:

1. On the flow details page, in the Run only users section, select Edit.

2. In the Manage run-only permissions panel, select Delete (the trash can) next to
the user whose access you want to remove, and then select Save.

Congratulations—the user or group no longer has access to run this flow.

Send a copy of a cloud flow
You can send a copy of a cloud flow to another user, who can then use the definition of
the flow as a template. It provides a good way for you to share the general structure of a
cloud flow without sharing any connections, while also allowing the recipient to modify
their flow independently of yours, so they can make it fit their needs.

７ Note



Sending a copy creates an independent instance of the flow for the recipient. You
can't revoke access to the flow after you share it.

To send a copy of a cloud flow

1. On the flow details page command bar, select Send a copy.

2. On the Send a copy panel, you can edit the name and description of the flow you
want to share, and specify the users with whom you want to share it.

3. The recipient will receive an email stating that you have shared a cloud flow
template with them, and they can then create their own instance of that flow.

FAQ

Manage flows when the user who created a shared flow
leaves the organization
If the shared flow still has an active owner, the flow continues to run.

７ Note

If the flow uses any active or embedded connections that belong to the user who
has left the organization, those specific actions might fail. To fix this, follow the
steps in Modify a connection, earlier in this article to update the credentials.



If there's no active owner for a flow, you should change the owner. To change the owner
of a flow, make a copy of the flow, and then let the intended owner create the flow from
the copy.

Change the owner of a solution-aware cloud flow
Edit the details to change the ownership of a solution-aware cloud flow.

Change the owner of a non-solution-aware cloud flow
To change the ownership of a non-solution-aware cloud flow, you must create a new
flow via export/import, Save as, or Send a copy. In-place ownership change for non-
solution-aware cloud flows is not available because the owner is part of the flow
identity.

Share ownership of a solution-aware cloud flow with a
user who isn't in Dataverse
When you share ownership of a solution-aware cloud flow with a user who isn't in
Dataverse, that user gets added into Dataverse automatically to facilitate sharing. In a
default environment, Microsoft Entra ID (Microsoft Entra ID) users have the
EnvironmentMaker role. In a non-default environment, Microsoft Entra users and groups
are added into Dataverse but they aren't assigned the EnvironmentMaker role
automatically. Therefore, they may only be able to run the flow until an administrator
assigns them a role. If the user doesn't have an appropriate role, they will see a detailed
error message.

Can connections be provided by the user that runs the
flow?
Yes. When a connection is configured to be Provided by run-only user, then that
connection is provided by the user who runs (or invokes) the flow.

Can a connection provided by run-only user be used by
another user?
No. When a connection is configured to be Provided by run-only user then that
connection is provided by the user that runs (or "invokes") the flow. Embedded
connections are used by all users of the flow, but connections provided by a run-only



user are used only by the user that provides them. When the flow connects to a service
via a connector, then the Provided by run-only user connections will allow the flow to
act as the run-only user and access the data that the user has access to. If the flow is
exported, then the Provided by run-only user connections have a RuntimeSource value
of invoker.

Related information
Training: Share a cloud flow with Power Automate (module)
Training: Share and collaborate with Power Automate (learning path)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Support for guest users
Article • 03/07/2025

The Power Automate experience for guest users is the same as it is for nonguest users,
with some stipulations. A guest user can be a vendor or customer in a tenant of their
own organization who needs access to a tenant in another organization. Guest users
have the same experience in both the Power Automate portal and the Power Automate
mobile app. They're sometimes referred to as external users.

This article should help you understand the scenarios that are supported for guest users.

７ Note

Guest users aren't currently supported in Process Mining.

Prerequisites
A guest user must meet the following criteria:

Have a Power Automate license assigned through either the tenant that hosts the
flow, or the home tenant of the guest user. To learn more about licensing
implications, go to FAQs about licenses.
Sign in and consent to Power Automate.

Licensing requirements
A user can become a guest user if both these criteria are met:

They're invited to a tenant through the Microsoft Entra admin portal.
An Office 365 plan, or any plan with a Power Automate license is assigned to the
guest user.

Supported capabilities
A guest user can create flows, run flows, and make changes to flow runs. The following
sections provide details.

Sharing



If a guest user needs to only run a flow, they need to have the Sharing-Run Only role
assigned. If they need to edit flows and perform actions to flow runs such as canceling
or resubmitting a flow run, they need a co-owner role assigned.

Approvals
A guest user can be assigned an approval, receive an approval email, and be routed to
the Approvals page in the guest tenant to approve or reject.

Guest users can't see the approvals from their guest tenant while they're in their original
tenant, or from their original tenant while they're in their guest tenant.

Widgets
A guest user can create, manage, or run flows using widgets in apps like SharePoint,
Teams, Excel, Power BI, and more.

Search for a guest user
A nonguest user can search for, find, and select a guest user in a trigger or action. As
they start typing the name of the guest user, they see a list of names to choose from in
the dropdown list. When they see the name of the guest user, they can select it. This
saves the nonguest user time because they don't need to finish typing the entire name.

Some connectors don't support this capability.

Set up Business to Business (B2B) collaboration
To set up B2B collaboration between tenants in different clouds, both guest user and
nonguest user tenants need to configure their Microsoft cloud settings to enable
collaboration with the other cloud. Then, each tenant must configure inbound and
outbound cross-tenant access with the tenant in the other cloud. To learn more, go to
Configure Microsoft cloud settings for B2B collaboration.

Related information
Microsoft Entra B2B in government and national clouds
Assign Azure roles to external guest users using the Azure portal



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Support for service principal owned
flows
Article • 04/05/2024

Power Automate has the ability for service principal application users to own and run
flows to provide flexibility and stability in how organizations administer Power Automate
flows.

Service principal application users
A service principal is a non-human security identity that represents an application or
service that can own and manage resources within Azure and the Power Platform. To use
a service principal in the Power Platform, a service principal application user needs to be
created that represents the service principal through the portal or through API. An
application user can have connections shared with them and own resources such as
flows.

When to use service principal application user
We recommend that the flow runs under the service principal in the cases listed in this
section.

Mission critical flows that service departmental or enterprise-wide scenarios. This
insulates the flow ownership from the lifecycle of the owner and prevents issues
when:

The owner of the flow leaves the organization or their role changes.
Premium license of the flow owner were to be unassigned and their flow utilizes
premium capabilities.

If the organization uses DevOps pipelines to deploy the flow across Dev, Test, and
Production environments.

Since a service principal application user is a non-interactive user without a user license,
it's subject to non-licensed user limits and has special licensing and request limit
implications.

The flow connections need to be shared with the service principal application user in
order for them to successfully run the flow.

Prerequisites



To have a service principal own and run a flow, follow these steps.

1. Create a service principal application user representing the Microsoft Entra ID
service principal.

2. Share connections with the service principal application user.

3. Change the owner of the flow to the service principal application user using these
steps:

a. On Power Automate portal, open a flow.

b. On the Details section, select Edit.

c. Replace the Owner with the name of the service principal application user.

７ Note

A service principal application user can't be made a co-owner of a flow. You
can't find a service principal application user in the Owners edit dialog.



4. Turn on the flow so it's ready to run.

Licensing requirements
A service principal application user is a non-interactive user, so it can't have a user
license associated with it. Premium service principal application user-owned flows need
a Power Automate Process/Power Automate per-flow license. However, if a flow doesn't
utilize premium connectors, or is used exclusively within the context of a Dynamics 365
application, it's exempted from the need for a Power Automate process or Power
Automate per-flow license.

Power Platform request limits
To learn about service principal application user-owned flows, go to non-licensed user
limits.

ﾉ Expand table

Products Pooled non-licensed tenant-level Details
requests per 24 hours

Service principal flows in 500,000 base requests + 5,000 The following service principal
context of Dynamics 365 requests accrued per USL1 up to owned flows are considered in
Enterprise & Professional 10,000,000 max2 context of Dynamics 365 apps:
applications1 The flows can use both standard

and premium connectors. In an environment with
Dynamics 365 app installed and
using Dataverse connector to
talk to Dynamics entities in the
environment.

Or

Using first party Dynamics
connectors like finance and
operations.

Or

Flows associated with a
Dynamics 365 app.

Service principal flows in Flows using standard connectors The following service principal
context of Power Apps only - 25,000 base requests with owned flows are considered in

no per-license accrual for the context of Power Apps:



Products Pooled non-licensed tenant-level Details
requests per 24 hours

tenant.
Flows using premium connectors Triggered from the canvas apps.
need a Power Automate Process/
Power Automate per-flow license Or
and can get up to 250,000
requests per flow. Use Dataverse For a select

record trigger in model driven
app.

Or
Flows associated with a Power
App.

Service principal flows in Flows using standard connectors
a tenant with Power only - 25,000 base requests with
Automate licenses no per-license accrual for the

tenant
Flows using premium connectors
need a Power Automate Process/
Power Automate Per-flow license
and can get up to 250,000
requests per flow.

Tenant pool
Service principal flows in context of Dynamics 365 applications get 500,000 base
requests + 5,000 requests accrued per USL1 up to 10,000,000 max. However, to avoid a
poorly designed flow using up the tenant pool and impacting all service principal owned
flows in the tenant, a maker can now enable Tenant pool on core business flows.

1. Go to the Service principal flows in context of Dynamics application.

2. On the Details tile, select Edit, and then enable Tenant pool capacity.



Turning on tenant pool on the flow enables the flow to use higher Power Platform
requests. During the transition period, the flow that has tenant pool enabled can go up
to 10M Power Platform requests in 24 hours and the performance profile on the flow is
UnlimitedExtended. Service principal flows in context of Dynamics application with
tenant pool disabled can go up to 200K in Power Platform requests in 24 hours and the
performance profile on the flow is Medium.

All service principal flows created before October 20, 2023 have Tenant pool enabled
and use performance profile of UnlimitedExtended. A maker can disable the setting
anytime. All service principal flows created after October 20, 2023 have Tenant pool
disabled and use Medium performance profile. However, a maker can enable Tenant
pool on the flow anytime. Once it's enabled, the flow has a performance profile of
UnlimitedExtended and can scale up to 10M requests in 24 hours. It can take up to
seven (7) days for the change to reflect. To force refresh, edit and save the flow for the
change to take effect immediately.

Known issue
If a flow owned by a service principal tenant pool was turned on, importing the flow as
non application user throws an error.



Export and import a non-solution flow
Article • 01/31/2024

You can export and import non-solution flows by using packages. This feature allows
you to export one flow from one environment and import it to another. Export and
import packages have the file format .zip.

If you would like to export and import multiple flows, you can either use solutions, as
described in the Export a solution and Import a solution articles, or you can copy an
environment.

） Important

You must have third party cookies enabled to export and import non-solution
flows .
For application lifecycle management (ALM) capabilities in Microsoft Power
Platform environments, use Microsoft Dataverse and solutions instead of the
package export and import. More information: Overview of ALM
Flow packages can't be used with Dataverse solution packages because of
the package incompatibility.

Resources included in the package
When you export a flow, the dependent resources for your flow are also exported into
the package.

ﾉ Expand table

Resource Supported Import options

Flow Yes There are two options to import a flow into an environment:
Create as new: The flow is created as a new flow into the

environment where the package is imported.
Update: The flow already exists in the environment and is updated

when this package is imported.

Permissions required to import and export a
non-solution flow



Only the owner or co-owner of a flow can export the flow. To import a flow,
the Environment Maker is required on the destination environment.

Export a flow package
1. Sign in to Power Automate .

2. On the left navigation pane, select My Flows > Cloud flows, and then select the
flow you want to export.

3. On the menu, select the down arrow next to Export, and then select Package (.zip).

4. On the next screen, enter a name and description for your package.

5. (Optional) Configure the package.

a. Under Review Package Content in the ACTION field, select Configure (the tool
icon).

b. Select Update (default) or Create as new.

For a description of these options, go to the table in the Resources included in
the package section in this article.

c. Select Save.

6. (Optional) Add a comment.
a. Under the Review Package Content heading in the ACTION field, select

Comment (the speech balloon icon).
b. Enter your comment.
c. (Optional) You can view multiple lines in your comment by using the up and

down arrows in the scroll bar. Alternatively, you can enlarge the field by
selecting and dragging the diagonal lines on the lower right corner of the field.

d. Select Save. The icon in the ACTION column now contains quotation marks to
indicate there's a comment.

7. On the bottom right corner, select Export.

Your package starts downloading shortly after. If your download doesn't start
automatically, select Download.

8. When you're ready to import a flow, you'll need the downloaded .zip file.

Import a flow



1. On the left navigation pane, select My Flows.

2. On the menu, select Import > Import Package (Legacy).

3. Select Upload > your zip file > Open.

4. The Upload button now reads Uploading, and the name of your .zip file appears to
the left of the button.

When the upload is complete, the package details appear.

5. In the IMPORT SETUP column in the first row, select the content in the field, and
then select Create as New or Update from the Setup dropdown menu.

For a description of the fields in the Setup menu, go to Resources included in the
package.

6. Select Save.

7. Under Related Resources, do the following steps:
a. In the IMPORT SETUP column, select the contents of the field for each row.
b. In the Import setup dialog, select the item if it's required to set up the flow to

place a checkmark at the end of the row.



c. Select Save.

8. The Import button becomes active once you've successfully configured all the
required settings. Select Import.

Related information
Export a solution
Import a solution
Share a cloud flow
Send a copy of a cloud flow

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Drafts and versioning for cloud flows
Article • 02/28/2025

When you're authoring a solution cloud flow, you can save drafts in Microsoft Dataverse
before the flow is complete. Then, the flow can be published when you're ready to run
the flow. As you're evolving the flow, a version history is built up in Dataverse and can
be accessed on the version history panel.

Availability
The flow drafts and versioning feature set is available only for solution cloud flows.
Solution cloud flows can be created directly in a solution, added into a solution, or
created by default if the Create in Dataverse solutions environment setting is enabled.

The flow drafts and versioning feature set has been available in all regions since
February 7, 2025.

Save drafts
Save a draft of a flow whenever you want, even with errors. Make changes to your flow
with confidence at your own pace.

1. Open the flow in the designer.

2. Make changes as needed.

3. Select Save draft.

A confirmation message appears in the information bar.

The flow state is visible next to the flow title.

State indicator
The state of the flow (Draft or Published) shows beside the flow title to indicate if that
version of the flow was published, or if the flow has draft changes.

Publish a flow
When you're ready for changes to a flow to have an effect at runtime, the flow can be
published.



1. Open the flow in the designer.

2. Make changes as needed.

3. Select Publish.

A confirmation message appears in the information bar.

Version history
Review a flow's version history list to understand how it evolved. View flow versions
grouped by day with indicators for Latest version, Published, and Past published.

1. Open the flow in the designer.

2. Select Version history.

The version history panel opens.

Version restore
When you view a flow's version history list, you can select a previous version for review,
and optionally restore it as a new draft.

1. Open the flow in the designer.

2. Select Version history.

The version history panel opens.

3. Select a previous version.

4. Select Restore.

5. Confirm the restore action.

The flow is now the latest draft in the version history.

FAQ

Why is the drafts and versioning feature set only
available for solution cloud flows?



Dataverse is the storage used for drafts that aren't published. It's also the storage used
for version history. Solution cloud flows are defined in Dataverse, so they can have
drafts and a version history.

Why is the drafts and versioning feature set available
only in the new designer?
Drafts and versioning capabilities are available in the new cloud flows designer. Rather
than adding drafts and versioning support in the classic designer, we're investing in
additional drafts and versioning capabilities for the new cloud flows designer.

How do I change a non-solution cloud flow into a
solution cloud flow?
When you add your non-solution cloud flow into a solution, it adds the definition into
Dataverse so it can have versions.

Can co-owners see a full version history or only their own
changes?
Co-owners can see a full version history of changes from any user who made a change
to the flow.

Can notes or titles be added to versions?
Notes and titles can't be added to the version at this time.

Can drafts be tested?
Not at this time. Currently, flow changes need to be published and runnable to be
tested. We're exploring the concept of creating a second runtime representation of a
single flow to facilitate testing.

Is there a unique identifier for a version?
Timestamps are used to differentiate between versions. There's a GUID identifier used
for each version, but that doesn't show in the version history cards. A simple integer
identifier isn't available at this time.



Can the version history list be filtered?
Not at this time.

Can a summary of the version changes show in the
version history cards?
Not at this time.

Can copilot summarize the changes made to a flow over a
certain time period?
Not at this time.

Can versions be compared?
Versions can be compared by viewing them in succession, or by opening up another
browser tab to view a specific version. A side-by-side comparison of versions isn't
available at this time.

Can connection permissions be associated with a certain
version so a new connection authorization is needed
when a co-owner changes the flow?
Not at this time.

Which version is exported?
The last published version of a solution cloud flow is exported in a solution. Draft
versions and version history aren't exported.

What tables are used for drafts and version history?
Dataverse is the storage used for drafts and version history. Solution cloud flows are
defined in Dataverse, so they can have drafts and a version history. The ⁠Workflow table
has a row for the latest published and a row for the latest draft. The version history is
stored in the ⁠Component Version table.

Known issues



Changing flow URL: When a solution cloud flow is first published, the URL contains the
workflowUniqueId  and this changes with each version. If the published flow is
subsequently opened from the My Flows experience, then the FlowId  is used in the URL
and it doesn't change. If the published flow is subsequently opened from the Solution
Explorer experience, then the workflowUniqueId  is used in the URL and it does change.
We're planning to update the Solution Explorer experience to provide a static URL. In
the interim, if you need a static URL reference, then open the flow from the My Flows
experience.

Related information
Manage and edit a cloud flow
Create a solution
Create a cloud flow in a solution
Edit a solution-aware cloud flow
Set a preferred solution
Export a solution
Import a solution

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Add OAuth authentication for HTTP
request triggers
Article • 04/01/2025

You can use the When an HTTP request is received trigger to trigger workflows by
sending a request to an HTTP request to the endpoint generated from the flow. You can
restrict what users can trigger in this workflow by ensuring that only authenticated users
can trigger this workflow.

７ Note

This feature is being rolled out and might not be available in your region yet.

Choose an authentication parameter
The trigger has three modes for the authentication parameter:

1. Any user in my tenant: Ensures that any user in the same tenant as the maker is
able to trigger this workflow. This is the default setting for any new flows.

2. Specific users in my tenant: Ensures that only specific user IDs from the same
tenant can only trigger this workflow. You can provide email addresses of the
specific users in the Allowed users field. You can also provide object IDs of service
principal users if you intend to use this flow to be triggered only by SPN (service
principal name) users.

3. Anyone: Legacy setting for this trigger that has open access without any additional
authentication support. Anyone can trigger this workflow if they have access to the
URL and the associated JSON schema.

７ Note

If you select the Specific users in my tenant option and leave the allowed users
blank, the authentication scope is limited to the tenant. This means any user in the
tenant can trigger this workflow.

Choose the claims for your HTTP request



If you're restricting the workflow to be triggered only by authenticated users, you need
to ensure that the HTTP request contains the correct claims. The required claims are in
the following list:

"aud":  <audience of the flow service>. This is where you find the audience values
across different clouds. More information: Audience values
"iss":  <Issuer of the requestor>
"tid":  <tenant id of the requestor>
"oid":  <object id of the requestor>. Optional. This field is required only if you
have configured the trigger to restrict to specific users within the tenant.

You can check the claims of your request by pasting the bearer token within the
authorization header at https://jwt.io . For more information on extracting the tokens
programmatically, go to the Microsoft Authentication Library (MSAL).

Audience values
The following table shows the audience values across different clouds:

ﾉ Expand table

Cloud type Audience value

Public cloud https://service.flow.microsoft.com/

Government Community Cloud (GCC) https://gov.service.flow.microsoft.us/

Government Community Cloud High (GCCH) https://high.service.flow.microsoft.us/

China https://service.powerautomate.cn/

Department of Defense (DOD) https://service.flow.appsplatform.us/

View the parameter in the designer
Depending on your designer version, parameters appear in different locations.

７ Note

Power Automate uses either the classic cloud flows designer or the new
modern designer with Copilot capabilities. To identify which designer you’re
using, go to the Note section in Explore the cloud flows designer.



When you switch between the classic and new designer, you're asked to save
your flow. You can't save and switch until all errors are resolved.

New designer

The parameter shows on the configuration panel to the left.

Related information
Overview of the Microsoft Authentication Library (MSAL)
Regenerate the SAS key used in HTTP trigger flows

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Regenerate the SAS key used in HTTP
trigger flows
Article • 09/27/2024

This article provides instructions on how to regenerate the SAS (Shared Access
Signature) key used in HTTP trigger flows in Power Automate. Regenerating the SAS key
is essential for maintaining the security and functionality of your HTTP trigger flows.
Over time, the SAS key might become compromised or need to be updated to adhere
to security policies. By regenerating the key, you ensure that only authorized requests
can trigger your flow, which protects your data and processes from unauthorized access.

Step 1: Identify the SAS string being used by
your flow
Identifying the SAS string being used by your flow is crucial because it allows you to
confirm that the key regeneration process was successful. By noting the current SAS
string, you can compare it with the new string after regeneration to ensure that the
operation was executed correctly. This step helps in validating that the flow is using the
updated key, which is essential for maintaining the security and functionality of your
HTTP trigger flows.

To identify the SAS string being used by your flow:

1. Sign in to Power Automate .

2. Open your flow in the designer.



3. Copy the HTTP trigger URL.

https://<region>/workflows/<workflowid>/triggers/manual/paths/invoke?api-

version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=<value>

4. Make a note of the URL string that starts with sig= .

Once the key is regenerated, this value changes and serves as a confirmation that
the execution of the following steps was successful.

Step 2: Create the request to regenerate the
string
Creating the request to regenerate the SAS string is essential for maintaining the
security and functionality of your HTTP trigger flows. This multi-step process requires
using the browser tools. The steps in this section use Microsoft Edge browser.

To create the request to regenerate the string:

1. Navigate to the flow Details page (not the designer page).



2. In the Windows Settings menu, select More tools > Developer tools and navigate
to the Network tab.

3. Select Clear network log (or select Ctrl + L).

4. Select Record network log (or select Ctrl + E).

5. Refresh the page by selecting Ctrl + R.

6. Filter the items with api.flow and select the request that starts with runs?api-
version=.

7. From the Network tab > Headers subtab, copy the Request URL to a text editor.

8. Replace the word runs with regenerateAccessKey.



9. From the Network tab > Headers subtab, copy the Authorization header. Make
sure you don't include the next header in your selection.

10. Copy the following text in your text editor:

JSON

fetch('<regenerateAccessKeyUrl>', {
  method: 'POST',
  headers: {
    'Content-type': 'application/json; charset=UTF-8',
   'Authorization': '<Authentication Header>'
  }
})
.then(result => result.json())
.then(console.log)

11. In the fetch command, replace <regenerateAccessKeyUrl>  with the request URL you
constructed in Step 8 in your text editor.

12. Replace <regenerateAccessKeyUrl>  with the Authorization header you copied in
Step 9 to your text editor.

Congratulations! You're now ready with the command to regenerate the key.

Step 3: Execute the regenerate request
When you execute the regenerate request, the SAS key associated with your HTTP
trigger flow is regenerated. This means that a new key is created, and the old key is
invalidated. The new key is reflected in the sig=  parameter of the HTTP trigger URL. This
ensures that only requests with the new key can trigger the flow, enhancing the security
of your automation.

To execute the regenerate request:

1. Copy the code snippet from Step 2 that you constructed in the text editor.

2. Navigate to the Console tab and paste the text here.

3. Select Enter.

The command executes as Promise Pending.



4. Open your flow in the Power Automate designer and open the HTTP trigger action.

The Post URL should have a different value for sig=  than what was recorded at the
end of Step 1.

Congratulations! You successfully refreshed the SAS key.

Troubleshooting



If you encounter an error executing the command, make sure the text in the
command doesn't have any extra spacings and is well constructed.

If the command execution returns Rejected, the key might still be updated
successfully. It’s best to validate the flow URL to ensure the sig=  value is indeed
updated.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Change the owner of a cloud flow
Article • 03/01/2024

The flow owner plays a vital role in the management, control, and maintenance of Power
Automate flows. They have the authority to make changes, assign permissions, monitor
performance, and ensure the flow meets the organization's requirements. When a flow
is created, the creator is automatically set as the flow owner.

The flow owner responsibilities include the following:

Flow management: Full control over the flow, including the ability to edit, manage,
and delete it. They can make necessary modifications to the flow, update its
triggers and actions, or troubleshoot any issues that may arise.
Permissions and sharing: Determines who can access and use the flow. They can
share the flow with other users or teams within the organization.
Monitoring and troubleshooting: Monitoring their flow's performance, reviewing
run history, and addressing errors or exceptions.
Licensing: The licenses associated with the owner can have an effect on the flow.

In cases where ownership needs to be transferred, such as when a flow owner leaves the
organization or changes roles, providing a new flow owner ensures a smooth transition.
The previous flow owner can transfer ownership to another user to maintain continuity
and avoid disruptions in flow management.

If an administrator wants to make changes to a flow, they must first make themselves an
owner or co-owner. Flows are usually owned by regular users, but if you need to change
the owner to a Service Principal application user instead, go to Change the owner of a
cloud flow to a Service Principal application user.

Change the owner of a solution-aware cloud
flow
An owner, co-owner, or an admin can change the owner of a solution-aware flow to
another user to ensure business continuity. After the change of ownership completes,
the original owner and the new owner become co-owners of the flow.

You can change the owner to an individual (not a distribution list) or a user account
used as a service account. If the flow uses a service account, ensure it's licensed correctly
to avoid multiplexing.

Follow these steps to change the owner of a flow.



） Important

To perform this action, the flow must be a solution-aware flow.

1. Sign in to Power Automate .

2. On the menu to the left, either select My flows, or select Solutions and locate a
solution the flow is referenced by. non-

3. Select the flow for which you're changing the owner.

4. In the Details section, select Edit.

5. In the Owner section, remove the current owner.

6. Enter the email address of the new owner.

Once assigned, the new owner gets access to the run history and connection
references. The new owner can update the flow or reassign it to other users.

If the flow is a scheduled or automated flow, after the owner changes, the flow runs
under the license of the new owner and uses their Power Platform request limits. This
change can take up to seven (7) days to become effective. If you need the new owner to
take effect immediately, edit the flow, and then save it to force the flow to use the new
owner’s license.

If the flow is a manual flow, the flow runs under the license of the user who runs the
flow. The plan section shows whose license plan the flow uses.



Change the owner of a non-solution cloud flow
In-place ownership change for non-solution-aware cloud flows isn't available because
the owner is part of the flow identity.

If your environment has Dataverse, then the ideal way to change the ownership is
to add the flow into a solution so ownership can be changed.
If your environment doesn't have Dataverse, then you must create a new non-
solution cloud flow with export/import, Save as, or Send a copy.

Ownership and licensing
If flow ownership is changed to a new owner without a premium license and the flow
uses premium features, then a warning shows with information about next steps.



The flow can still be assigned to the new owner. The flow continues to run for 30 days,
allowing time for the new owner to purchase a license. If the new owner doesn't have a
premium license after the grace period, Power Automate turns off the flow. They can
turn it on anytime after purchasing the license.

Change the owner of a cloud flow to a service
principal application user
The following sections include various scenarios for changing ownership.

Service Principal application users
A Service Principal is a non-human security identity that represents an application or
service that can own and manage resources within Azure and the Power Platform. To use
a Service Principal within the Power Platform, a Service Principal application user needs
to be created that represents the service principal through the portal or through API. An
application user can have connections shared with them and own resources such as
flows.

A Service Principal application user is a non-interactive user, so it can't have a user
license associated with it. It's also subject to non-licensed user limits.

Service Principal application user ownership of flows



Power Automate has the ability for Service Principal application users to own and run
flows to provide flexibility and stability in how organizations administer Power Automate
flows. When the owners of flows change roles or leave the organization entirely, the
ownership of a flow needs to be changed to a different user or set of users. If the owner
of the flow is a Service Principal application user, then that ownership isn't tied to a user
that could leave the organization.

The flow connections need to be shared with the Service Principal application user in
order for them to successfully run the flow.

Since a Service Principal application user is a non-interactive user without a user license,
it's subject to non-licensed user limits and has special licensing and request limit
implications.

Change the owner of a flow to a Service Principal
application user
To change the owner of a flow to a Service Principal application user:

1. Open the Details edit dialog.

2. Replace the Owner with the name of the Service Principal application user.

A Service Principal application user can't be made a co-owner of a flow. Attempts
to find a Service Principal application user in the Owners edit dialog won't be
successful.

Enable a Service Principal to own and run a flow
To have a Service Principal own and run a flow, follow these steps.

1. Create a Service Principal application user representing the Microsoft Entra Service
Principal.

2. Share connections with the Service Principal application user.

3. Change the owner of the flow to the Service Principal application user using the
steps detailed here: Details > Edit > Owner.

4. Turn on the flow so it's ready to run.

5. Adjust licensing to deal with request limit implications as needed.



Examples are turning on Pay As You Go, associating the flow to an app, or
considering a Power Automate Process license (previously Power Automate per
flow).

See also
(Video) Microsoft Power Automate Tutorial - Export Import
The owner of a flow left the organization. How can we ensure it works without
interruptions?



Restore deleted flows
Article • 08/26/2024

If you or someone else accidentally deletes a non-solution or solution flow, you can
restore it within 21 days of deletion.

There are the two ways you can restore deleted flows.

Use the Power Automate Management connector to restore the deleted flows.
Use PowerShell to restore the deleted flows.

７ Note

The steps in this article apply to both non-solution and solution flows.
Flows that were deleted more than 21 days ago can't be recovered. Both
restore methods (PowerShell script and Power Automate Management
connector), as well as Microsoft Support can't help to restore them.
After you restore a flow, it defaults to the disabled state. You must manually
enable the flow, per your requirements.
Learn more about restoring a deleted desktop flow created by Power
Automate for desktop at Restore a deleted desktop flow.

Restore deleted flows with the Power Automate
Management connector
You can restore a deleted non-solution or solution flow within 21 days of deletion using
Power Automate. A non-solution flow is a flow that wasn't created inside a solution. As
an admin, all you need is a button flow with two Power Automate management
connector actions—List Flows as Admin and Restore Deleted Flows as Admin.

As part of this process, in four easy and quick steps, you'll first list deleted flows in an
environment using the List flows as Admin action. Then, you'll use the Restore Deleted
Flows as Admin action to restore the flow using flowName  property of the flow that you
retrieved from the List flows as Admin action.

1. Build a manual flow with a button trigger.



2. Add the List Flows as Admin action.

a. Select New Step.

b. Search for Power Automate Management Connector or List Flows as Admin
action.

c. Select the List Flows as Admin action.

d. In the Environment dropdown menu, select the environment the flow was
originally deleted from.

e. In the Include Soft-Deleted Flows dropdown menu, select Yes.

3. Run the flow to note the flowName  of the flow you want to retrieve.

a. Run the flow.

b. Expand the flow run.

c. Expand the raw OUTPUTS/value of the List Flows as Admin action.

You'll see all the flows in that environment you have access to as an admin,
including the ones that are soft deleted.

d. Using the "displayName" among other flow metadata, identify the flow you're
trying to recover and note the name in "name" field.



In the following screenshot, the name of the flow is highlighted in green. You'll
use this value for the next step.

4. Add the Restore Deleted Flows as Admin action and run the flow.

a. Add the Restore Deleted Flows as Admin action from the Power Automate
Management Connector.

b. In the Flow field, enter the name value from step 3.

c. Run the flow.



After the run has succeeded, you'll notice that the flow has been restored in a
disabled state in the environment it was originally deleted from.

Restore deleted flows with PowerShell
In this section, you'll learn about how to restore deleted flows using PowerShell.

Prerequisites for PowerShell
You must install the latest version of PowerShell cmdlets for Power Apps .
You must be an environment admin.



There must be an execution policy set on your device to run PowerShell scripts.

1. Open PowerShell with elevated privileges to begin.

2. Install the latest version of PowerShell cmdlets for Power Apps .

3. Sign in to your Power Apps environment.

Use this command to authenticate to an environment. This command opens a
separate window that prompts for your Microsoft Entra authentication details.

PowerShell



Add-PowerAppsAccount

4. Provide the credentials you want to use to connect to your environment.

5. Run the following script to get a list of flows in the environment, including flows
that were soft-deleted within the past 21 days.

If the IncludeDeleted  parameter isn't recognized, you might be working with an
older version of the PowerShell scripts. Ensure that you're using the latest
version  of the script modules and retry the steps.

PowerShell

Get-AdminFlow -EnvironmentName 41a90621-d489-4c6f-9172-81183bd7db6c -
IncludeDeleted $true
//To view examples: Get-Help Get-AdminFlow -Examples

 Tip

Navigate to the URL of any of the flows in your environment to get your
environment name
(https://make.powerautomate.com/Environments/ <EnvironmentName>/f
lows) which is required for subsequent steps. Don't omit the prefixed words in
the URL if your environment name contains it, for example, Default-
8ae09283902-....



6. Optionally, you can filter the list of flows if you know part of the name of the
deleted flow whose flowID you want to find. To do this, use a script similar to this
one that finds all flows (including flows that were soft-deleted) in environment
3c2f7648-ad60-4871-91cb-b77d7ef3c239 that contain the string "Testing" in their
display name. 256fe2cd306052f68b89f96bc6be643

PowerShell

Get-AdminFlow Testing -EnvironmentName 3c2f7648-ad60-4871-91cb-
b77d7ef3c239 -IncludeDeleted $true

7. Make a note of the FlowName  value of the flow you want to restore from the
previous step.

8. Run the following script to restore the soft-deleted flow with FlowName  value as
4d1f7648-ad60-4871-91cb-b77d7ef3c239 in an environment named Default-
55abc7e5-2812-4d73-9d2f-8d9017f8c877.

PowerShell

Restore-AdminFlow -EnvironmentName Default-55abc7e5-2812-4d73-9d2f-
8d9017f8c877 -FlowName 4d1f7648-ad60-4871-91cb-b77d7ef3c239
 //To view examples: Get-Help Restore-AdminFlow -Examples



9. Optionally, you can run the Restore-AdminFlow  script with the following arguments
to restore multiple deleted flows.

PowerShell

foreach ($id in @( "4d1f7648-ad60-4871-91cb-b77d7ef3c239", "eb2266a8-
67b6-4919-8afd-f59c3c0e4131" )) { Restore-AdminFlow -EnvironmentName 
Default-55abc7e5-2812-4d73-9d2f-8d9017f8c877 -FlowName $id; Start-Sleep 
-Seconds 1 }

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Overview of solution-aware flows
Article • 03/10/2023

When you host your flows in a solution, they become portable, making it effortless to
move them and all their components from one environment to another. A typical use
case is for an independent software vendor (ISV) to develop flows in a sandbox
environment, and then move those flows to a test environment. After testing, the ISV
would then move the flows to a production environment for clients who purchase these
flows. This process is much easier when you create your flows in solutions, and then
move the solutions and their contents.

Flows that you create in a solution are known as solution-aware flows. You can add
multiple flows to a single solution.

 Tip

The Application lifecycle management (ALM) with Microsoft Power Platform
guide provides detailed information about solution concepts and how to
implement a healthy ALM practice in your organization.

Prerequisites
You must have the following components to create solutions, and solution-aware flows.

Dataverse.

An environment with version 9.1.0.267 or later.

To check your version, go to Power Platform admin center , select Environments,
and then select the environment in which you are interested. The Details tab
displays all configuration information for the environment that you selected.

Create a solution
Follow these steps to create a solution.

1. Sign in to Power Automate .

2. On the menu to the left, select Solutions.



3. Select New solution.

4. Provide all required information for your new solution, including the Display
Name, Name, Publisher, and Version.

5. Select the Create button.



Your new solution might appear like this image.

Now that you've created your solution, it's time to add your flows to it.

Known limitations
There are certain limitations when using flows with solutions. For information about
these limitations, see Known limitations in the Power Apps docs.

See also
Create a cloud flow in a solution



Export a solution
Import a solution
Edit a solution-aware flow
Remove a solution-aware flow



Create a cloud flow in a solution
Article • 02/23/2024

Cloud flows you create in a solution are known as solution-aware cloud flows or solution
cloud flows. Follow these steps to create a solution-aware cloud flow.

Prerequisites
You need to have at least one solution before you can create a solution-aware flow.

Create a solution-aware cloud flow
1. Sign into Power Automate .

2. On the menu to the left, select Solutions.

3. Select the solution in which you'll create your flow.

4. Select New > Automation > Cloud flow > Automated.



 Tip

If an automated cloud flow doesn't meet your requirements, you can create
any other type of flow.

Power Automate opens.

5. Use the available connectors and triggers to build your flow.

In this example, we'll build a flow that sends a notification when an email arrives in
your inbox.

6. Give your flow a name.

7. Search for, new email in the Search all triggers box.



8. Select the When a new email arrives (V3) trigger.

9. Select Create.

10. Select New step.

11. Search for Notification, and then select the Send me a mobile notification action.

12. Add the Subject dynamic token to the Text field of the Send me a mobile
notification card.

13. Select Save to save your flow.

Your flow should look like the following screenshot.



14. Select Solutions to see your flow in the solution.

Find a solution-aware cloud flow
Solution-aware cloud flows can be found either in the My flows lists or in Solutions on
the left navigation pane.

Find a solution-aware cloud flow with 'My flows'
1. Sign in to Power Automate .

2. On the left navigation pane, select My flows.

3. Find the flow that you want to edit.



 Tip

Cloud flows you own are on the Cloud flows tab and flows for which you're a
co-owner are on the Shared with me tab.

The Shared with me tab shows the following solution cloud flows.

Flows you co-own.

Flows that are owned by a Dataverse team in which you're a member.

Flows that are co-owned by a Dataverse team in which you're a member

If you're the owner of a solution cloud flow, you can always find it on the Cloud flows
tab. If you have the 'run only' permission to a flow, you'll only see that flow on the My
flows tab if you're an owner or a co-owner too.

Find a solution-aware cloud flow via Solutions
1. Sign in to Power Automate .

2. On the menu to the left, select Solutions.

3. Select the solution that contains the flow you want to edit.

Find a solution that contains a solution-aware
cloud flow
Solution-aware cloud flows have a Solutions card in the flow details page that provides
a list of the solutions that reference that cloud flow. To open the solution, select the
solution name.

The Objects tab of a solution shows all the solution objects in the solution, such as
connection references, environment variables, or child flows that the flow might
reference. The Overview tab shows the details of the solution, such as the description
and status, and provides access to solution actions, such as export.

Add an existing cloud flow into a solution
1. Sign in to Power Automate .

2. On the menu to the left, select Solutions.



3. Select the solution that you want to add a cloud flow into.

4. Select Add existing > Automation > Cloud flow.

Solution-aware cloud flows will be in the From Dataverse tab and non-solution
cloud flows will be in the Outside Dataverse tab.

5. Select the desired cloud flow.

Some non-solution cloud flows can't be added into a solution. To learn more, go to
known limitations.

6. Select Add.

Add many flows into Dataverse solutions using
PowerShell
Administrators can use PowerShell to quickly add many or all non-solution cloud flows
into Dataverse solutions using the Add-AdminFlowsToSolution cmdlet. To learn more,
go to Add flows into Dataverse solutions via PowerShell.

See also
Add canvas apps and cloud flows to a solution by default
Create a solution
Export a solution
Import a solution
Edit a solution-aware flow
Remove a solution-aware flow



Create child flows
Article • 09/25/2023

Today, people are building flows that need dozens or hundreds of steps; however, if you
try to put all of these actions into a single flow, it can be difficult to navigate and
maintain that flow.

You can use child flows to easily manage flows, avoiding flows with hundreds of steps.
This approach is especially beneficial if you want to reuse tasks in multiple places in a
cloud flow, or even across multiple flows.

Let's look at an example where you have a child flow that you want to create or update
a contact in Dataverse based on that contact's name.

You will need a solution with two flows.

A child flow. This is the flow that is nested inside the parent flow and contains the
smaller tasks you want to run. You can have multiple child flows inside a parent
flow.
A parent flow. This flow can have any type of trigger and will call into the child
flow.

Create the child flow in a solution
1. Sign into Power Automate, select Solutions, and then select an existing solution.

Alternatively, you can create a solution if you don't want to use an existing
solution.

2. Select New > Automation > Cloud flow > Instant.

The Build an instant cloud flow screen appears.

3. Give your flow a name so that you can easily identify it later.

4. Select the Manually trigger a flow trigger.

5. Select Create.

6. Select Add an input.

The input you define here will be passed to the child flow from the parent flow.



7. For this walkthrough, the child flow creates a contact, so it needs input fields for
the Contact name and Contact email. Add a ContactName and a ContactEmail
input to the Manually trigger a flow card.

8. Build the logic that you want the child flow to run. This logic can contain as many
steps as you need.

After your steps, you need to return data to the parent flow. In this case you can
use one of the following two actions.

i. Respond to a Power App or flow (under the Power Apps connector).

ii. Response (on the premium HTTP request/response connector).

9. As with the trigger, you can define as many outputs as you want the child flow to
return to the parent flow. In the following screenshot, the child flow responds with
the ID of the contact.

You need to then test your child flow. You can manually trigger instant flows, so
you can test it right inside of the designer. Try it out with a couple different inputs,
and verify that the outputs are what you expect.

10. Lastly, if your flow uses anything other than built-in actions or the Microsoft
Dataverse connector, you need to update the flow to use the connections
embedded in the flow. To do this, go to the child flow's properties page, and then
select Edit in the Run only users tile.

11. In the pane that appears, for each connection used in the flow, you will need to
select Use this connection (<connection name>) instead of Provided by run-only



user.

12. Select Save.

７ Note

At this time, you can't pass connections from the parent flow to the child flow.
If you don't do this, you receive an error that states that the name cannot be
used as a child workflow because child workflows only support embedded
connections.

Create the parent flow in a solution
1. Build the parent flow in the same solution in which you created the child flow.

Alternatively, you can bring an existing flow into that solution. The parent flow can
have any type of trigger.

2. Find the place in your parent flow from which you want to call the child flow and
then add the Run a Child Flow action that's located under the Flows connector on
the Built-in tab.

3. Pick the child flow that you created earlier.

７ Note

You only see the flows to which you have access and are located in a solution.
Child flows must also have one of the three triggers mentioned previously.



4. After you select your child flow, you see the inputs that you defined in the child
flow. After the child flow action, you're able to use any of the outputs from that
child flow.

When the parent flow runs, it waits for the child flow to complete for the lifetime of
the flow (one year for flows that use built-in connections and Dataverse or 30 days
for all other flows).

5. Save and test this flow.

 Tip

When you export the solution that contains these two flows and import it into
another environment, the new parent and child flows are automatically linked,
so there's no need to update URLs.

Known issue
We are working to address the following known issue and limitation.

You should create the parent flow and all child flows directly in the same solution. If you
import a flow into a solution, you might get unexpected results.



Export a solution
Article • 01/20/2024

Follow these steps to move your solution and its dependencies to a new environment.

） Important

Before you export a solution, consider removing environment variable values in the
solution.

1. Sign in to Power Automate .

2. Select Solutions from the navigation bar on the left side of Power Automate.

3. Select the unmanaged solution that you want to export.

4. Select Export from the menu at the top of the screen.

5. The Before you export right pane appears. Choose from the following options.

Publish all changes - Notice that, when you export an unmanaged solution,
only published components are exported. We recommend that you select
Publish to confirm that all components are in the exported solution.
Check for issues - Run the solution checker against the solution to detect
performance and stability issues.

6. Select Next.

7. The Export this solution page appears on the right. Enter or select from the
following options, and then select Export.

Version number - Power Automate automatically increments your solution
version. You can accept the default version or enter your own.
Export as - Select the package type, either Managed or Unmanaged. More
information: Managed and unmanaged solutions

７ Note

The export can take several minutes to complete.

8. After the solution file export succeeds, you'll see a success notification on top of
the screen. Select Download from the top-right side of this notification to



download the solution zip file.

The downloaded solution zip file is available in the downloads folder for your web
browser.

9. Find the flows in the Workflows folder in the solution zip file.

Each exported workflow is represented as a JSON file. Flow definitions were
traditionally a compact block of JSON in a single line. In February 2022 the export
format was changed to multi-line formatted JSON to make them easier to read
and make them friendlier to revision tracking in source control.

Export a specific solution cloud flow
Solution cloud flows are exported and moved between environments in a solution. The
solution should contain all the solution components that the flow uses, such as
connection references, environment variables, and tables. Depending on the desired
scenario, the solution could also contain solution components that reference the flow,
such as apps and bots.

The flow details page contains a Solutions card that lists all the solutions that reference a
flow. If the flow is only in the default solution (the "all solution components" view), then
either add the flow into an existing solution, or create a new solution.

Tips
You can also find your solutions via the Solutions card in the flow details page of
solution-aware cloud flows. Alternatively, select the solution in which you're
interested from the Solutions card, select the Overview tab, and then use the
Export button there.

You can't export managed solutions. More information: Managed and unmanaged
solutions

Once a flow is solution-aware and in Dataverse, you must use the steps in this
article to export it. You cannot export a solution-aware cloud flow from the flow
details page.

To implement healthy application lifecycle management (ALM) in your
organization, use a source control system to store and collaborate on your
solutions, and automate the solution export process. More information: ALM basics
in the Power Platform ALM guide.



See also
Create a solution
Create a cloud flow in a solution
Import a solution
Edit a solution-aware flow
Environment variables overview



Import a solution
Article • 10/09/2024

After you exported your solution, you can import it into any environment that meets the
prerequisites. To import a solution, follow these steps.

 Tip

If you want to have your flows start automatically after you import a solution, use
the Microsoft Dataverse connector in your flow when you create it.

1. Sign in to Power Automate .

2. On the navigation bar to the left, select Solutions.

3. Select Import.

4. On the Import a solution page that opens, select Browse.

5. Find and select the solution that you want to import.

6. Select Open.

You should now see the Import a Solution page similar to the following image.

7. Select Next.

If there are no errors, the importation completes within a few moments.

７ Note



You can't import a solution into an environment in which the solution already
exists.

Solution component ownership after import
When the solution is imported, all components in that solution are owned by the user
who performs the import. These components include cloud flows, connection
references, apps, and any other components in the solution.

FAQ

What will the flow state be after import?
When you import a solution containing flows, the import process attempts to restore
them to the state they were in when exported. If the flows were on when exported and
any connection references get connections, then the flows should be turned on as part
of the import process.

If the flow already exists in the target environment, then the import of an update to that
flow doesn't affect the flow state. For example, if the flow is turned off in the target
environment and then an update is imported, the flow remains turned off.

If the importing user doesn't have permissions to all the
connections in the flow, will the flow be turned on?
If the importing user doesn't have permissions to all the connections in the flow, then
the connections need to be shared with the importing user so that they can turn on the
flow.

Does importing a solution cause flows to turn off?
When a solution is being imported, the flows in that solution are turned off and turned
on again. This impact can be minimized by using multiple smaller solutions.

Related information
Create a solution
Create a cloud flow in a solution



Export a solution
Edit a solution-aware flow
Remove a solution-aware flow
Use connection references
Manage connections in Power Automate
Import solutions (Power Apps)
Training: Import and export solutions with cloud flows (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Edit a solution-aware cloud flow
Article • 03/04/2024

You can edit solution-aware cloud flows in solutions or in my flows.

） Important

Stop your flow before you edit it so that you don't lose your changes.

Edit a solution-aware cloud flow via Solutions
1. Sign in to Power Automate , and then select Solutions from the menu on the left.

2. Select the solution that contains the flow you want to edit.

3. Select the vertical ellipsis (⋮) for your flow, and then select Turn off.

4. Select the vertical ellipsis (⋮) for your flow, and then select Edit.



5. Make your edits in the Power Automate designer, test your changes, and then save
your flow.

6. Turn on your flow if you'd like it to run.

Edit a solution-aware cloud flow via My flows
1. In Power Automate , select My flows from the menu on the left.

2. Find the flow you want to edit. Cloud flows that you own will be in the Cloud flows
tab and flows that you have co-ownership of will be in the Shared with me tab.

3. Select the vertical ellipsis (⋮) for your flow, and then select Turn off.

4. Select the vertical ellipsis (⋮) for your flow, and then select Edit.

5. Make your edits in the Power Automate designer, test your changes, and then save
your flow.

6. Turn on your flow if you'd like it to run.

２ Warning

When you edit solution-aware flows, it's possible for you to introduce unmanaged
customization layers into your managed solution-aware flows. Unmanaged
customization layers can impact your ability to update these flows in the future.



Duplicate a solution-aware cloud flow using
Save As
The Save As capability can be used to duplicate a solution cloud flow. If an unmanaged
solution is in context when Save As takes place, the flow will be added into that solution.
Solution cloud flows won't be added into a solution if there's no context, or if a
managed solution has context, so those flows can be located in the My flows list or in
the Default Solution.

Save As without solution context
1. In Power Automate , select My flows from the menu on the left.

2. Open the cloud flow you want to duplicate.

The flow details page will show a Solutions card listing any custom solutions the
flow is referenced by.

3. Select Save As.

4. On the Create a copy of this flow screen, enter a custom flow name if desired and
select Save.

The flow will now be visible in My flows.

７ Note

If the save takes a few seconds, it's possible to return to My flows before
that's completed. If that happens, refresh the browser screen to view the flow.



Save As with unmanaged solution context
1. In Power Automate , select Solutions from the menu on the left.

2. Open an unmanaged solution. This solution is now providing solution context.

3. Inside that solution, find and open the cloud flow you want to duplicate.

The flow details page will show a Solutions card listing the current solution and
any other custom solutions the flow is referenced by.

4. Select Save As.

5. On the Create a copy of this flow screen, enter a custom flow name if desired and
select Save.

The flow will now be visible in the solution. Upon opening that flow, it will have the
solution in the Solutions card in the flow details page.

See also
Manage and edit a cloud flow
Create a solution
Use drafts and versioning
Create a cloud flow in a solution
Set a preferred solution
Export a solution
Import a solution
Remove a solution-aware flow



Remove a solution-aware flow
Article • 12/16/2022

You can either remove a cloud flow from a solution, or delete the flow from an
environment entirely.

Action Result

Remove from The flow is removed from the selected solution, but it remains in the
this solution environment. You can use the flow in other solutions in the environment at a

later date.

Delete from The flow is deleted; it is not available in the environment.
this
environment

Remove a cloud flow from a solution
1. Sign in to Power Automate, and then select Solutions from the navigation bar.

2. Select the solution that contains the flow you want to remove from the solution.

3. Select ... (Commands) for your flow, select Remove, and then select either Remove
from this solution.



） Important

When you remove a cloud flow, it gets moved to the Default Solution, where you
can edit or delete the flow, or add it to another solution.

Delete a cloud flow from an environment
1. Sign in to Power Automate, and then select Solutions from the navigation bar.

2. Select the solution that contains the flow you want to delete from the
environment.

3. Select ... (Commands) for your flow, select Remove, and then select Delete from
this environment.



Learn more
Create a solution
Create a cloud flow in a solution
Export a solution
Import a solution
Edit a solution-aware flow



Troubleshoot common issues with
triggers
Article • 02/06/2025

Here are a few tips and tricks for troubleshooting issues with triggers.

Identify specific flow run
Sometimes, you might need to Identify specific flow runs to troubleshoot your flows.

My trigger doesn’t fire
1. A data loss prevention policy could be to blame.

Admins can create data loss prevention (DLP) policies that can act as guardrails to
help prevent users from unintentionally exposing organizational data. DLP policies
enforce rules for which connectors can be used together by classifying connectors
as either Business or Non-Business. If you put a connector in the Business group,
it can only be used with other connectors from that group in any given app or
flow.

If your flow violates a DLP policy, it's suspended, causing the trigger to not fire. To
know if your flow is suspended, try to edit the flow and save it. The flow checker
reports it if the flow violates a DLP policy. Your admin can change the DLP policy.

2. The trigger may be failing. Follow these steps to confirm:

a. Sign in to Power Automate .

b. Go to My flows, and then select your flow.

c. Do you see the following error in the Details?

This error means that Power Automate tried multiple times to establish a
connection to register the trigger and failed. Your flow won't trigger until this
problem is resolved.

One of the common reasons for this failure is that the Power Automate service
endpoints aren't part of the allow list. To fix it, confirm that your IT department has



added these endpoints to the allow list.

Here's the list of IP addresses and domains  that need to be added to your allow
list.

Refer to this support article  to learn more about how to fix issues with triggers.

After the problem is resolved, modify the flow and then save it. You can then change it
back to its original state, and then save it again. The flow becomes aware that its
configuration changed, and it tries to register its trigger again.

Verify connections
With the default settings, users only need to sign in to a connection once. They can then
use that connection until it's revoked by an admin. A possible scenario is that the
password for the connection can expire or there might be a policy in your organization
which sets the connector’s authentication token to expire after a specific amount of
time. Token lifetime policies are configured on Microsoft Entra ID. For more information,
review this Azure article or this support article .

Follow these steps to verify if your connections are broken:

1. Sign in to Power Automate .

2. Go to Data > Connections.

3. Find the connection that your flow uses.

4. Select Fix connections, and then update the credentials for your connection if
there's a Fix connection message next to the Status column.



Verify if the flow uses a premium connector trigger
1. Edit your flow to find the connector name for the trigger.

2. Go to the list of connectors  and then search for that connector. If the connector
is a premium connector, PREMIUM displays below the name of the connector.

A standalone Power Apps or Power Automate license is required to access all premium,
on-premises, and custom connectors. You can purchase licenses  at any time.

Check your license type
Follow these steps to view the type of license that you have:

1. Sign in to Power Automate .
2. Go to My flows in the left pane.
3. Select any flow.



4. In the Details section, find Plan. Your current license plan is listed.

Verify if trigger check is skipped
You just completed an event. For example, you added a new list item or sent an email
that should have triggered the flow, but the flow didn’t run.

Go to My flows in the left pane, and then select the flow. In the 28-day run history,
select All runs.

If you expect the flow to run but it didn’t run, see if it shows the trigger check was
skipped at that time. If the trigger check was skipped, it means that the trigger condition
wasn’t met for the flow to trigger. Verify the flow the inputs and trigger conditions to
confirm if you're using the latest configuration to trigger the flow.

Verify inputs and trigger conditions
Sometimes, the inputs and trigger conditions may cause failures. Follow these steps to
verify your inputs and conditions.

７ Note

Power Automate uses either the classic cloud flows designer or the cloud flows
designer with Copilot. To identify which designer you’re using, go to the Note
section in Understand the cloud flows designer with copilot capabilities.

Classic designer

1. Sign in to Power Automate .



2. Edit the flow.

3. Expand the first card to see what folders, sites, mailboxes, etc. are used in the
trigger.

4. On the card, select the ellipses (…) > Settings.

5. Find Trigger conditions.

If the field is empty, it means that there are no additional customizations and
that the title of the card (in this case, When an item is created or modified)
indicates when the trigger fires.

If there are additional customizations in Trigger Conditions, confirm that
you're using the expected or correct inputs to trigger the flow.



Check permissions
Verify that you have access to the folders, sites, or mailboxes that are used in the trigger.
For example, to be able to send email from a shared inbox via Power Automate, you
need permissions to send an email via the shared inbox. Send a test email from that
shared mailbox in Outlook.

Verify if admin mode is turned on



If an environment’s admin mode is turned on, all background processes, including flows
are turned off, causing the flow to not trigger.

Follow these steps to disable the admin mode.

1. Go to the Power Platform admin center  and sign in with Environment Admin or
System Administrator role credentials.

2. From the left-side menu, select Environments, and then select a sandbox or
production environment.

3. On the Details page, select Edit.
4. Under Administration mode, set the slider to Disabled.

If everything looks good but your flow is still not triggering, verify if your flow triggers
after every step.

Try these steps
1. Test the flow manually.
2. Remove, and then re-add the trigger.
3. Switch the connection.
4. Turn off, and then turn on the flow.
5. Export, and then import the flow.
6. Create a copy of the flow.
7. If the trigger uses special conditions, like when an email arrives in a specific folder,

remove the folder, and then add it again.

My trigger is firing for old events
There are two types of triggers—polling triggers and Webhook triggers.

If you turned off your flow and then turned it back on, depending on your trigger type,
your old triggers may be processed.

A polling trigger periodically makes a call to your service to look for new data, whereas a
Webhook trigger responds to a push of new data from the service.

See the following table to understand how your flow responds when it's turned back on.

ﾉ Expand table



Trigger type Description

Polling, such as When the flow is turned on again, all unprocessed or pending
the  recurrence  trigger events are processed. If you don't want to process pending items

when you turn your flow back on, delete and then recreate your
flow.

Webhook When the flow is turned on again, it processes new events that are
generated after the flow is turned on.

Follow these steps to determine the type of trigger that your flow uses.

Classic designer

1. On the title bar, select the ellipsis (...) > Peek code.

2. Find the recurrence  section with an interval frequency  element. If this section
is available, the trigger is a polling trigger.



My flow is triggered multiple times or some of
my actions run multiple times
You may encounter a scenario where a single flow run has some (or all) of its actions
duplicated. While the UI doesn't show this problem, you might see the results of the
flow being duplicated. For example, duplicate emails sent, or duplicate list items created.

One of the reasons this might happen is because of the "at-least-once" design of Azure
Logic Apps.

Most of the times, this indicates that there was an issue with the Azure service. Usually,
these issues are self-healed quickly. To ensure that your flows don't create duplication,
ensure you design them to be idempotent—which is to say that the flow needs to
account for the possibility of duplicate inputs.

An example of idempotency would be checking to see if a duplicate SharePoint
document already exists before trying to create it, or using key constraints in Dataverse
to prevent duplicate records getting created.



Another possibility is for flow triggering multiple times might be having copies of the
flow active in different environments that are triggering based on same condition. Use
trigger conditions to customize triggers to reduce the number of times it triggers.

My recurrence trigger runs ahead of schedule
Confirm that you've set the Start time on the Recurrence card to ensure it runs only at
the time that you need. For example, set Start time to '2022-10-10T10:00:00Z' to start
your trigger at 10:00 AM.

There's a delay before my trigger fires
If the trigger is a polling trigger, it wakes up periodically to check if any new events have
occurred. The wake-up time depends on the license plan on which the flow runs.

For example, your flows may run every 15 minutes if you’re on the Free license plan. On
the Free plan, if a cloud flow is triggered less than 15 minutes after its last run, it’s
queued until 15 minutes have elapsed.

And, if your license is the Flow for Office 365 plan (from your Enterprise license E3, E5,
etc.) or the Flow for Dynamics 365 plan, your flow won't run again until five minutes
have elapsed. So, it may be a few minutes between the time the triggering event occurs
and the time the flow begins.

Follow these steps to check the trigger wake up frequency.

Classic designer

1. Go to your flow trigger, and then select the ellipsis (...) > Peek code.

2. Find the interval frequency.



If it's taking much longer than expected for your flow to trigger, here are the two
likeliest reasons:

1. There's been too many calls to the connector or flow, causing it to be throttled. To
verify if your flow is being throttled, manually test the flow to see if it triggers
immediately. If it triggers immediately, it isn't throttled.

You can check the Power Automate analytics to learn more about your flows.

If your flow is frequently throttled, redesign your flow to use fewer actions. Learn
more about plan limits and tips to optimize flows to use fewer actions .

Additional tips:

a. Acquire a Power Automate Premium (previously Power Automate per user) or
Power Automate Process license (previously Power Automate per flow). After
this is acquired, open and then save the flow, in order to refresh the entitlement
associated with it, and to change the throttling mode.

b. Split the flow into several instances. If the flow processes data, you can divide
this data into subsets (per country/region, per business area, etc.).



c. After this, you can use Save As on the flow to create several instances that will
process their own data. Since the quota is per flow, this can be used as a
workaround.

2. There was a communication issue that prevents Power Automate from reacting to
trigger events. Potentially, because of a service outage, policy change, password
expiry, and so on, that caused the delay. You can view Help + support  to find out
if there are any active outages. You can also clear the cache of the browser and
then retry.

Power Apps trigger issues
Unable to rename actions in a cloud flow – This is a known issue for flows that use
Power Apps triggers. As a workaround to rename actions, remove the trigger. Rename
the actions, add your Power Apps trigger, and then configure variables wherever
needed.

After an app is published, make copies of the flows used by that app to make any
updates. Any update to a cloud flow that's referenced by a published app can break
existing users. Don't delete or turn off existing flows until all users have been upgraded
to the new published version of the app.

SharePoint trigger issues
SharePoint triggers, for example When a file is created or modified, don't fire if a file is
added or updated in a subfolder. If you need the flow to trigger on subfolders, create
multiple flows.

Users are unable to run flows that are shared
with them, but the owner can run the flow
You can try one of the following:

1. Fix or update connections.

If your flow uses a Manual trigger, it needs the connection of the user who is
triggering the flow. If it uses the Recurrence trigger, it can run on the flow maker's
connections.

2. Confirm the user has the appropriate license for the connections in the flow.



A Power Automate license is required for the user to perform any actions like save,
turn off, and more. A Power Apps, Dynamics 365, or Microsoft 365 license isn't
sufficient. Users with whom flows that use premium connectors are shared will
each need a Power Automate Premium (previously Power Automate per user) or
Power Automate Process license (previously Power Automate per flow) license to
edit or manually trigger the flow. If the user was previously able to save or modify
the flow, it's possible that their license has expired.

Alternatively, you can start a trial for the Per User plan for 90 days, after which you
need a paid plan to run or edit flows that use premium connectors. You can find
more information in the licensing page  or this support article .

My flows don't trigger after I change the environment
URL
To resolve this issue, edit each flow and save it. The triggers should start firing again.

Triggers aren't respecting expressions used in
them
For triggers, the value of expressions is calculated only when the flow is saved. For
example, if your trigger uses utcNow()  in an input, utcNow()  is calculated when you save
the flow, and the current UTC time is inserted into the trigger definition as a hardcoded
value. utcNow()  isn't recalculated every time the flow is triggered.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Watch your flows in action
Article • 12/16/2022

To ensure that your flows run as you expect, perform the trigger, and then review the
inputs and outputs that each step in your flow generates.

1. Create or update a cloud flow, and then leave the designer open after you select
Create flow or Update flow.

For example, create a cloud flow that sends email whenever someone tweets using
the #azure hashtag.

2. Perform the starting action for your flow.

For example, send a tweet that contains the #azure hashtag.

The starting action and each subsequent step indicates whether it succeeded and
how long it took.

3. Select the trigger or action to see its inputs and outputs.



4. Select Edit flow to make more changes or select Done if the flow works as you
expect.



Troubleshoot a cloud flow
Article • 04/01/2025

This article contains tips and tricks for troubleshooting cloud flows.

Identify specific flow runs
Once you build and deploy your flows, you might need to debug specific flow runs to
confirm that your flow ran as expected. By default, the flow owner can look at the Start,
Duration, and Status columns in the run history view in Power Automate to help them
identify the flow run they're interested in debugging. The owner can also expand the
troubleshooting section to identify the specific run in which they're interested, however,
for flows that run frequently, this can be time-consuming.

To make it more efficient to identify flow runs when debugging, Power Automate
provides the ability for flow owners to configure the list of columns that displays on the
run history page for each flow run. These columns map to the trigger outputs for your
flow. When you display the columns you want, you save time since you see the relevant
columns by default on the run history view.

Follow these steps to add one or more columns to your run history view.

1. Sign in to Power Automate .

2. On the left side of the screen, select My flows.

3. Select the flow for which you want to get more details.

4. On the flow details page, select Edit columns.

5. Select the columns that you want to add to your run history view for the flow that
you selected, and then select Save.

6. View the list of columns that displays on the run history view for the flow you
selected.

The hasAttachments and isHTML columns are now visible for the flow so that you
can quickly see those values to help you debug the flow.



 Tip

You can also configure the list of columns that displays with the All runs view.

Repair tips in email
Repair tips are sent to flow owners via email whenever a cloud flow fails. These repair
tips emails contain specific, actionable feedback about certain errors. For example, one
common error is setting up a cloud flow that attempts to get a person’s manager in
Office 365—but there's no manager configured in Microsoft Entra ID. If this or several
other conditions cause your flow to fail, you get a repair tips email.

The repair tips email contains the following sections:

ﾉ Expand table

Name Description

Time Displays the time the flow first failed.

What happened Provides a description of the problem that caused the failure in the flow.

How do I fix Provides tips for resolving the issue that caused the failure in the flow.

Troubleshooting Provides details including the number of times the flow failed, and a link to



Name Description

tips retry the flow with the same input data.

To fix the reported errors, select Fix my flow and follow the steps in the repair tips email.

Repair tips emails are optional. If you don't want to receive them, turn them off from the
properties menu for the specific flow.

If your flow fails, you can also troubleshoot it directly in Power Automate. Here are some
common failure scenarios and tips on how to fix them.

Identify the error
Follow these steps to find the error and learn how to fix it,

1. Select My flows.

2. Select the flow that failed.

3. In the 28-day run history section, select the date of the failed run.

Details about the flow appear, and at least one step shows a red exclamation icon.

4. Open that failed step, and then review the error message.

On the right pane, you can see the details of the error and how to fix it.



Authentication failures
In many cases, flows fail because of an authentication error. If you have this type of
error, the error message contains Unauthorized or an error code of 401 or 403 appears.
You can usually fix an authentication error by updating the connection:

1. On the right pane below How to fix, select View Connections.

2. Scroll to the connection for which you saw the Unauthorized error message.

3. Next to the connection, select the Fix connection link in the message about the
connection not being authenticated.

4. Verify your credentials by following the instructions that appear.

5. Return to your flow-run failure, and then select Resubmit.

The flow should now run as expected.

Troubleshoot in Copilot
The new troubleshoot in Copilot feature in Power Automate can assist you in identifying
and resolving errors that might occur during the testing of cloud flows or when



reviewing flow run history. You can use this Copilot feature when the new designer
experience is enabled.

Troubleshooting in Copilot provides a human-readable summary of the error and, when
possible, attempts to provide a solution to correct the error. This can greatly enhance
your experience by reducing the time and effort required to troubleshoot and resolve
issues.

７ Note

The troubleshooting in Copilot feature might not work in all scenarios. The good
news is, it’s continuously learning and improving over time, which means its ability
to assist users and resolve issues only gets better. This is a great example of how AI
and machine learning can be leveraged to improve your experience and
productivity.



Action configuration
Flows also fail if a setting in an action of the flow doesn't function as expected. In this
case, the error message contains Bad request or Not found, or an error code of 400 or
404 appears.

The error details should specify how to correct the failure. To update the configuration:

1. Select Edit and then correct the problem inside the flow definition.
2. Save the updated flow.
3. Select Resubmit to try the run again with the updated configuration.

Other failures
If the error code 500 or 502 appears, the failure is temporary or transient. To try the flow
again, select Resubmit.

Get help from support or the community
When you need help, you can use our Self Help options, or you can Ask for help from
others.

Self help
The Power Automate Support site offers you several self help options.

1. Go to Power Automate Support .
2. In the Self Help category, select Learn, Samples, or Documentation.

Ask for help from others
1. Go to Power Automate Support .

2. In the Ask for help section, select Contact support.

3. Type or select the environment to help identify the issue.

4. To search recommended solutions, complete the Tell us what you need help with
field, and then select the right arrow next to the field.

5. If you found your solution, select Yes in the Were these solutions helpful field.

6. If you don't find a solution, select Ask virtual agent.



7. In the Virtual Agent screen, type your message, and then select Send.

8. If you need more help from others, return to the Power Automate Support , and
select Community .

On the Microsoft Power Automate Community page, you can customize your
search and get answers and tips directly from other Power Automate users.

Related information
Training: Best practices for error handling in Power Automate flows (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Find and fix errors with Flow Checker
Article • 03/06/2025

Flow Checker in Power Automate promotes higher quality flows by ensuring you follow
best practices when you design flows. When you run the checker, you get insights into
questions like "which areas of my flow's implementation pose a performance or
reliability risk?"

For each issue the checker identifies, the checker points to specific occurrences within
the flow where you should consider making improvements. And, you learn how to
implement these improvements by following detailed guidance.

The checker is always active, appearing in the command bar in the designer.

Resolve errors and warnings
While designing your flow, you can select Flow Checker to open the checker to view
errors and warnings.

The checker also opens automatically when you save the flow if there are errors or
warnings. Once the checker opens, it shows all errors and warnings in your flow. In each
section, the checker calls out the actions where the error or warning occurs.

７ Note

Power Automate uses either the classic cloud flows designer or the new
modern designer with Copilot capabilities. To identify which designer you’re
using, go to the Note section in Explore the cloud flows designer.
When you switch between the classic and new designer, you're asked to save
your flow. You can't save and switch until all errors are resolved.

New designer

The Flow Checker shows you errors or warnings in your flow. It also provides help to
fix the errors and warnings in red on both the action panel and the flow card.

1. To run the checker, select Flow Checker.



The Flow Checker panel opens.

2. In the Flow Checker panel, select the error or warning and correct your error
with the help of the red text from the checker.

Alternatively, select the red error in the flow card to open the same window
where you correct the error.

3. Run the Flow Checker again. If there are no errors or warnings, you get a
message in the Flow Checker panel that says No errors found. We recommend
that you test your flow to ensure it works as expected.

More information
Get started with Power Automate

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create a cloud flow from a template in
Power Automate
Article • 09/05/2023

A good way to get started is to use a template that is suited to your organization's
scenario. You can choose from a collection of templates to find the one that best
matches your scenario. Search all templates  or browse by category to find your
scenario, and then follow the steps in the template to create a cloud flow from the
template.

The following video gives insights into using templates to create your flows.
https://www.microsoft.com/en-us/videoplayer/embed/RWKZQv?postJsllMsg=true

You can tweak templates by adding, editing, or removing triggers and actions to create
your own flows. You can copy paste actions in the same flow or across flows to speed up
the your tweaks.

Create a cloud flow from one of many built-in templates that can, for example, send you
a Slack message when your manager sends you an email in Microsoft 365.

 Tip

Create a cloud flow from scratch if you already have a process in mind and can't
find a template for it.

Here, we follow an example that uses a template to create a flow that sends you a Slack
message when your manager sends you an email in Microsoft 365.

Prerequisites
To complete this example, you need accounts with access to the following:

Power Automate
Slack
Microsoft 365

Choose a template
1. Sign in to Power Automate .



2. On the left-side navigation pane, select Templates.

3. Use the search bar to search for slack manager to find the Send a message on
Slack when my manager emails me template, and then select it.

4. If you aren't signed into Office or Slack, select Sign in, and then follow the
prompts.

5. After you confirm your connections, select Continue.

Your flow appears, showing each action with an orange title bar.

Customize your flow
1. Select the title bar for an event to expand it, and then customize it (for example, by

specifying a filter on the email that interests you).

2. Actions that require input from you are automatically be expanded.

For example, the Post message action is expanded because you need to enter a
channel, such as your @username. You can also customize the message content. By
default, the message contains just the subject, but you can include other
information.

3. Near the top of the screen, specify a name for your flow, and then select Create
flow.

4. If you're satisfied with your flow, select Save.

Now, when your manager sends you an email, you receive a Slack message that contains
the information that you specified.

See also
Watch your flow in action
Publish your own template
Use a template with Microsoft Dataverse
Get started with team flows and invite others to collaborate with you to design
flows



Create a cloud flow from a description
Article • 11/09/2024

When you build automation with Power Automate, it might take valuable time to learn
which actions and triggers you need, especially if you’re new to the Power Automate. If
you want to jump right in and get started, you can now just write a description of what
you want to automate in everyday language. Supporting most of the connectors, Power
Automate then uses OpenAI Codex to translate your description into code, and then
provides a corresponding flow that you can create instantly.

Prerequisites
A work or school account with access to a Power Automate environment that's
based in Europe or the United States.

７ Note
You can't create cloud flows from a description if you're logged in with a
Microsoft account.
If you don’t have access to an environment that's based Europe or the
United States, you can create a new environment and select Europe or
United States as the region.

Check current limitations for more information.

Create a flow from a description
In the following example, you build an automated cloud flow that sends a notification
through Teams and an email each time someone responds to a Microsoft Forms survey.

1. Sign in to Power Automate .

2. On the navigation menu to the left, select Create > Describe it to design it
(preview).



A screen opens where you can enter a description of what you want to automate.
You also get an example you can use for inspiration and try it out right away. As an
alternate, you can also go to Home and start describing your requirement. Learn
more in Create a flow using Copilot.

3. For this example, enter Every time someone responds to a Microsoft Forms
survey, post a message to Teams and send an email.

4. Select Confirm (the right arrow).

Power Automate returns a suggested flow that corresponds to what you entered.

７ Note

If the suggestion doesn't correspond to what you’re looking to automate,
select This isn't what I'm looking for. You get guidance on what you can do
next. This helps Microsoft to improve the AI behind this feature.



5. Select Next.

6. Set up the connections you need to run the flow.

7. Select Next.

8. Enter the information needed to run the flow. For example, which form to use and
to whom to send the Teams message and email. You can decide to fill in the
information on this step or do it later in the designer.

9. Select Create flow.

Your flow is now built. Congratulations! You can make modifications and edit the
flow, or save and test it.



Use natural language to flow in Teams
You can use natural language to flow in Teams. If the Workflows app doesn’t have a
template that fits your scenario, this feature helps you create a flow in Teams. To do this,
type a prompt describing what you want the flow to do, and then the feature generates
the flow for you. These steps eliminate the need to start from scratch.

７ Note

Natural language to flow in Teams is available only for select channels.

To use natural language to flow, follow these steps:

1. At the top of the Teams Chat menu, select Channels.

2. Find your channel, select the ellipsis (...), and then select Workflows.

3. At the bottom of the Workflows screen, select Workflow builder.



4. In the empty filed, type your prompt.

The AI suggests a list of flows based on your prompt.

If the examples don't quite match your scenario, scroll down and select View more
examples. If you're not satisfied with the examples, you can edit the prompt for
new examples.

5. Select an example that fits your scenario and then select Next.

6. Review the flow. If you're satisfied, select Next. If you're not satisfied, select This
isn't what I'm looking for and follow the instructions.

7. When the parameters for your flow are set, select Next.

8. If necessary, edit the flow and select Create flow.



9. When your get the message, Workflow added successfully, select Done.

Limitations
Power Automate supports descriptions written in the English language only.
Descriptions you write in other languages might work, but they aren't supported.
Cloud flows are the only type of flow that you can create from a description.
In the current version, the AI might not fill in some parameters automatically, even
if you provide them in the description.

Related information
Overview of cloud flows

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create a cloud flow in Power Automate
Article • 04/01/2025

Create a cloud flow that performs one or more tasks automatically after it's triggered by
an event. For example, create a cloud flow that notifies you by email when someone
sends a tweet that contains a keyword you specify. In this example, sending a tweet is
the event, and sending mail is the action.

Prerequisites
An account on Power Automate
A Twitter account
Office 365 credentials

７ Note

Power Automate uses either the classic cloud flows designer or the new
modern designer with Copilot capabilities. To identify which designer you’re
using, go to the Note section in Explore the cloud flows designer.
When you switch between the classic and new designer, you're asked to save
your flow. You can't save and switch until all errors are resolved.

New designer

Using Copilot, you can use natural language to create a flow.

1. Simply ask Copilot to create your flow by typing the following prompt:

when a new tweet is posted, send an email to eug@contoso.com with
Twitter username

Copilot suggests a flow based on your prompt:



2. Review and then provide the necessary connections to Twitter and Outlook.

3. Select Next and your flow appears on the designer.

4. Save the flow and it's ready to use.

Your flow will trigger when any new tweets that mention the key phrase
Contoso Company are posted. It will also send an email to the specified email
address in the Send an email action.

Test your flow
Send a tweet with the keyword that you indicated, or wait for someone else to post such
a tweet.

Within a minute after the tweet is posted, an email message notifies you of the new
tweet.

 Tip

Use the Send email (V2) action to format email in which you customize the font,
use bold, italic or underline, customize the color and highlight, and create lists or
links, and more.

Manage a cloud flow



You can have up to 600 flows in your account. If you already have 600 flows, delete one
before you create another flow.

1. Sign in to Power Automate .

2. In the navigation bar on the left, select My flows.

3. In the list of flows, do any of the following:

To pause a cloud flow, set its toggle to Off.

To resume a cloud flow, set its toggle to On.

To edit a cloud flow, select the pencil icon that corresponds to the flow you
want to edit.

To delete a cloud flow, select the ... icon, select Delete, and then select Delete
on the message box that appears.

To view the run history of a cloud flow, select the flow from the My flows
page, and then view the history under the 28 day run history section of the
page that opens.



Select a cloud flow run from the list of runs to see the inputs and outputs of
each step.

Related information
Add steps, such as different ways to be notified, to your flow.
Run tasks on a schedule, when you want an action to occur daily, on a certain date,
or after a certain number of minutes.
Add a cloud flow to an app
Get started with team flows and invite others to collaborate with you to design
flows.
Training: Get started with Power Automate (module)
Training: Enhance communication using Power Automate and the Office 365 Users
Connector (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create flows from the OneDrive for
Business launch panel
Article • 07/26/2024

Similar to the Power Automate Launch Panel in SharePoint , you can run flows on
specific files in OneDrive for Business.

This feature enables the person running the flow to use their own credentials, which is
especially applicable for flows that have been created by an IT department.

Users can also get prompts for runtime inputs like Approver or Message, which can be
of type text, file, email, Boolean, or number.

In this tutorial, we'll create a simple flow that uses one of the many OneDrive for
Business templates  to request approval of a file by the requestor's manager.

Create a cloud flow that requests manager
approval for a file in OneDrive for Business

1. Sign in to OneDrive for Business.

2. Find, and then select the file for which you want to create the flow.

3. Select the Show actions link (three dots).

4. Select Automate > Power Automate > Create a flow.



5. Select one of the available templates.

In this example, select the Request my manager's approval for the selected file
template.



6. Sign in to the required connectors, and then select Continue.



7. Make any changes you want to the template and then save your flow with a name
that you'll remember easily.

Run the flow
1. Sign in to OneDrive for Business.

2. Find, and then select the file for which you want to request manager approval.

3. Select the Show actions link (three dots).

4. Select Flow. You'll see the flow that you created earlier.

5. Select the flow you created earlier.



 Tip

While this tutorial shows how to create a cloud flow from a template, you can also
create a cloud flow from blank to use any of the hundreds of connectors available
in Power Automate.

Related information
Get started with Power Automate
Build multi-step flows

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Filter and copy data with Power
Automate
Article • 04/14/2023

This tutorial shows you how to create a cloud flow that monitors a source for new or
changed items and then copies those changes to a destination. You may create a cloud
flow like this one if your users enter data in one location, but your team needs it in a
different location or format.

While this tutorial copies data from a Microsoft SharePoint list  (the source) to an
Azure SQL Database table (the destination), you can copy data among any of the more
than 900 connectors  that Power Automate supports.

 Tip

For detailed information about using SharePoint with Power Automate, go to the
SharePoint documentation.

Prerequisites
Access to a data source and a destination. This tutorial doesn’t include steps to
create the source and destination.

Access to Power Automate .

A basic understanding of how your data is stored.

Familiarity with the basics of creating flows. You can review how to add actions,
triggers, and conditions. The following steps assume that you know how to
perform these actions.

 Tip

Every column name in the source and destination doesn't need to match. However,
you must provide data for all required columns when you insert or update an item.
Power Automate identifies the required fields for you.

Quick overview of the steps



If you're comfortable with Power Automate, use these quick steps to copy data from one
data source to another.

） Important

Changes you make in the destination aren't copied to the source because two-way
syncs aren't supported. If you attempt to set up a two-way sync, you'll create an
infinite loop where changes are sent endlessly between the source and destination.

1. Identify the source you'll monitor and the destination to which you'll copy changed
data. Confirm you've access to both.

2. Identify at least one column that uniquely identifies items in the source and
destination. In the example that follows, we use the Title column, but you could
use any column(s) you want.

3. Set up a trigger that monitors the source for changes.

4. Search the destination to determine if the changed item exists.

5. Use a Condition like this:

If the new or changed item doesn't exist in the destination, create it.
If the new or changed item exists in the destination, update it.

6. Trigger your flow, and then confirm that new or changed items are being copied
from the source to the destination.

If you haven't created a connection to SharePoint or Azure SQL Database previously,
follow the instructions when you're prompted to sign in.

Here are the detailed steps to create the flow.

Monitor the source for changes
1. Sign in to Power Automate .

2. Select My flows > Create from blank.

3. Search for SharePoint > select the SharePoint - When an item is created or
modified trigger from the list of triggers.

4. Enter the Site Address and then select the List Name on the When an item is
created or modified card.



5. Provide the Site Address and List Name for the SharePoint list your flow monitors
for new or updated items.

Search the destination for the new or changed
item
Use the SQL Server - Get rows action to search the destination for the new or changed
item.

1. Select New step > Add an action.

2. Search for Get rows, select SQL Server - Get rows, and then select the table you
want to monitor from the Table name list.

3. Select Show advanced options.

4. In the Filter Query box, enter Title eq ', select the Title token from the dynamic
content list, and then enter '.

The previous step assumes you're matching the titles of the rows in the source and
the destination.

The Get rows card should now look like the following screenshot:

Check if the new or changed item was found
We use the Condition action to check if the new or changed item was found.

1. Select New step > Add a condition to open the Condition card.



2. On the condition card:

a. Select the box on the left.

The Add dynamic content from the apps and connectors used in this flow list
opens.

b. Select value from the Get rows category.

 Tip

Confirm you've selected value from the Get rows category. Don't select value
from the When an item is created or modified category.

3. Select is equal to from the list in the center box.

4. Enter 0 (zero) in the box on the right side.

The Condition card now resembles this image:

5. Select Edit in advanced mode.

When advanced mode opens, you see @equals(body('Get_rows')?['value'], 0)
expression in the box. Edit this expression by adding length() around the
body('Get_items')?['value'] function. The entire expression now appears like this:
@equals(length(body('Get_rows')?['value']), 0)

The Condition card now resembles this image:

 Tip



Adding the length() function allows the flow to check the value list and
determine if it contains any items.

When your flow gets items from the destination, there are two possible outcomes.

Outcome Next step

The item exists Update the item

The item doesn't exist Create a new item

７ Note

The images of the Insert row and Update row cards shown next may differ from
yours because these cards show the names of the columns in the Azure SQL
Database table that's being used in the flow.

Create the item in the destination
If the item doesn't exist in the destination, create it using the SQL Server - Insert row
action.

On the If yes branch of the Condition:

1. Select Add an action, search for insert row, and then select SQL Server - Insert
row.

The Insert row card opens.

2. From the Table name list, select the table into which the new item will be inserted.

The Insert row card expands and displays all columns in the selected table. Fields
with an asterisk (*) are required and must be populated for the row to be valid.

3. Select each column that you want to populate and enter the data.

You can enter the data manually, select one or more tokens from the Dynamic
content, or enter any combination of text and tokens into the columns.

The Insert row card now resembles this screenshot:



Update the item in the destination
If the item exists in the destination, update it with the changes.

1. Add the SQL Server - Update row action to the If no branch of the Condition.

2. Follow the steps in the create the item section of this document to populate the
columns of the table.



3. At the top of the page, enter a name for your flow in the Flow name box, and then
select Create flow to save it.

Now, whenever an item in your SharePoint list (source) changes, your flow triggers and
either inserts a new item or updates an existing item in your Azure SQL Database
(destination).

７ Note

Your flow isn't triggered when an item is deleted from the source. If this is an
important scenario, consider adding a separate column that indicates when an item
is no longer needed.

See also
Use data operations



Run your flows with bttns from The
Button Corporation (preview)
Article • 06/13/2023

Trigger your flows by pressing a bttn (a physical button made by The Button
Corporation ). For example, you can press a bttn that triggers a cloud flow to perform
these tasks:

contacts your helpdesk with location information
sends an email to your team
blocks your calendar
reorders supplies

） Important

You must register  your bttn before you can use it in a cloud flow.

 Tip

Configure all bttn properties such as name, location, and email address on the bttn
website  before you create your flow.

Prerequisites
Access to Power Automate

At least one registered bttn

Create a cloud flow that's triggered from a bttn
In this walkthrough, we use a helpdesk template to create a cloud flow that you can
trigger with a single press of a bttn . When the flow runs, it generates a support
request and then sends it to the helpdesk. The support request provides the helpdesk
with the location of the room where help is needed. This walkthrough demonstrates
how to create this flow from a template, but you can use the blank template, which
gives you full control over all aspects of your flow.



You can use any of these templates to quickly create flows for your bttn and connect to
Zendesk, Google, and SharePoint, among others:

Tip: For the purposes of this walkthrough, give your bttn a name that represents a
conference room in a typical office building.

The settings for your bttn should resemble this example (from the bttn website):

Now that you've registered and configured your bttn, let's get started creating our flow.

Sign in and select a template
1. Sign into Power Automate .

Note: As an alternative, you can create flows in the Power Automate mobile app
for Android , iOS , or Windows Phone .

2. Enter bttn into the search box, and then select the search icon.



After you select the search icon, all templates that you can use with bttns appear.

3. Select the Use Bttn to call technical support for meeting room template.

Authorize Power Automate to connect to your bttn
1. If prompted, sign into the bttn and the Office 365 Outlook services, which will

enable the Continue button.



2. When you sign into the bttn service, authorize Power Automate to use your bttns.

Important: If you don't authorize Power Automate to use your bttns, you can't see
or connect to them from Power Automate.

3. After you sign into both services, select Continue.

Select the bttn that triggers the flow
1. In the When a bttn is pressed card, open the list of bttn IDs, and then select the

bttn that you want to use.



Your flow should now resemble this example.

2. Give your flow a name, and then select Create flow to save it.

Test your flow and confirm results
1. Press the button on your bttn.

2. View your flow's run history to confirm that it ran successfully.

You can check run history on the Power Automate website or on your mobile
device.

Note: The run status is set to running until someone selects Acknowledge in the
support-request email.

3. You can also confirm that the email was sent to the support team.

If you've followed along, the support email looks similar to this example:



Troubleshooting
If your flow wasn't triggered, sign into The Button Corporation's site and confirm
whether the button activity (presses) are being recorded.

You can also drill into the run activity on the Power Automate site and check for
error messages.



Run flows on a schedule
Article • 04/01/2025

Create a cloud flow that performs one or more tasks (such as sending a report in email).

Once a day, an hour, or a minute.
On a date that you specify.
After a number days, hours, or minutes that you specify.

Create a recurring flow
1. Sign in to Power Automate .

2. Select My flows > New flow > Scheduled cloud flow.

3. In the fields next to Starting, specify the date and time when your flow should
start.

4. In the fields next to Repeat every, specify the flow's recurrence.

5. Select Create.

７ Note



Power Automate uses either the classic cloud flows designer or the new
modern designer with Copilot capabilities. To identify which designer you’re
using, go to the Note section in Explore the cloud flows designer.
When you switch between the classic and new designer, you're asked to save
your flow. You can't save and switch until all errors are resolved.

Configure advanced options
New designer

The steps to configure an action in the cloud flows designer with Copilot are
identical to the classic cloud flows designer. However, if you have access to Copilot,
you can simply ask Copilot to create a scheduled flow. For example, you can ask by
typing the following prompt:

Create a flow that runs Monday every two weeks starting 09/25/2023 which
sends an email to contoso@gmail.com that their MPR doc is due

You can ask Copilot to create a scheduled flow using the same prompt in the
Copilot panel in the designer.



Copilot adds the following parameters to the flow it created for you in the action
configuration pane on the left:



Related information
Advanced options in Azure Logic Apps

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Use the Apply to each action to process
a list of items periodically
Article • 04/01/2025

Many triggers can immediately start a cloud flow based on an event such as when a new
email arrives in your inbox. These triggers are great, but sometimes you want to run a
cloud flow that queries a data source on a predefined schedule, taking certain actions
based on the properties of the items in the data source. To do this, your flow can be
started on a schedule (such as once per day) and use a loop action such as Apply to
each to process a list of items. For example, you could use Apply to each to update
records from a database or list of items from Microsoft SharePoint.

Watch this video for a demo of the Apply to each action.
https://learn-video.azurefd.net/vod/player?id=6b48b330-128d-4130-b093-
2f18edae65c3&locale=en-us&embedUrl=%2Fpower-automate%2Fapply-to-each

In this tutorial, we'll create a cloud flow that runs every 15 minutes and does the
following:

1. Gets the last 10 unread messages in your Microsoft 365 Outlook Inbox.

2. Checks each of the 10 messages to confirm if any has meet now in the subject.

3. Checks if the email is from your boss or was sent with high importance.

4. Sends a push notification and marks as read, any email that has meet now in the
subject and is either from your boss or was sent with high importance.

This diagram shows the details of the flow we'll create.



Prerequisites
Here are the requirements for successfully performing the steps in this tutorial.

An account that's registered to use Power Automate .
A Microsoft 365 Outlook account.
The Power Automate mobile app for Android , iOS , or Windows Phone .
Connections to Microsoft 365 Outlook and the push notification service.

For detailed information about using SharePoint with Power Automate, go to the
SharePoint documentation.

７ Note

Power Automate uses either the classic cloud flows designer or the new
modern designer with Copilot capabilities. To identify which designer you’re



using, go to the Note section in Explore the cloud flows designer.
When you switch between the classic and new designer, you're asked to save
your flow. You can't save and switch until all errors are resolved.

Create a cloud flow
New designer

[This topic is prerelease documentation and is subject to change.]

1. Try asking Copilot to create a flow by typing this prompt:

Every 15 minutes, Get top 10 unread emails and get my manager. If the
email is from my manager OR the email is Important and subject contains
'meet now', send me a push notification to my phone.

Copilot suggests a flow based on your prompt:

2. Select Next and review the connections.

3. Select Next and your flow appears on the designer.

The flow is preconfigured with all the required fields in the designer.



4. Save the flow and it's ready to use.

Add actions and conditions
1. Select + New step > Built-in > Apply to each action.

2. Select the field and then select value from the Dynamic content list to place it in
the Select an output from previous steps field on the Apply to each card. This
pulls in the body of the emails to be used in the Apply to each action.

3. Select + New step > Control > Condition.

4. Configure the Condition card to search the subject of each email for the words
"meet now".

Select the first field and then select Subject in the Dynamic content list.
In the dropdown list of operators in the second field, select contains.
In the third field, enter meet now.

5. In the If yes branch, select Add an action > Condition. This opens the Condition 2
card.



6. Configure the Condition 2 card to search each email with "meet now" in the
subject with high importance.

Select the first field and then select Importance in the Dynamic content list.
(If not already selected) In the dropdown list of operators in the second field,
select is equal to.
In the third field, enter high.

7. In the If yes branch, select Add an action. This opens the Choose an action card,
where you'll define what happens if the search condition (the meet now email was
sent with high importance) is true.

8. Search for notification, and then select the Send me a mobile notification action.

9. On the Send me a mobile notification card in the Text field, enter the details for
the push notification that will be sent if the subject of an email contains "meet
now" and the Importance is high.

10. Select the If no branch to select the recipients.

Select Add an action, and then type get manager in the search field.
In the Actions list, select Get manager (V2).
In the Get Manager (V2) card, select the User (UPN) field.
In the Dynamic content list, select To.

11. In the If no branch, select Add an action.



12. From the Actions list, select Condition. This opens the Condition 3 card.

13. Configure the card to check if the email sender's email address (the From token) is
the same as your boss' email address (the Email token).

Select the first field and then select From in the Dynamic content list.
In the dropdown list of operators in the second field, select contains.
In the third field, enter mail.

14. Under the If yes section of the Condition 3 card, select Add an action.

Next, you'll define what should happen if the search condition (the email was sent from
your boss) is true.

1. Search for notification, and then select the Send me a mobile notification action.

2. On the Send me a mobile notification 2 card, provide the details for the push
notification that will be sent if the email is from your boss.

3. Select Add an action.

4. Add the Mark as read or unread (V3) action.

5. Add the Message Id token to the Mark as read or unread (V3) card. The Message
Id is the Id of the message that will be marked as read.

6. Select Enter custom value from the Mark as list on the Mark as read or unread
(V3) card.

7. In the Dynamic content list, select Is Read.



8. On the toolbar at the top, select Save to save your flow.

Run the flow
1. Send yourself a high-importance email that includes meet now in the subject.

Alternatively, you can have someone in your organization send you such an email.

2. Confirm the email is in your inbox and it's unread.

3. Sign into Power Automate .

4. Select My flows. A list of your flows displays.

5. Place a check in the circle for the flow you just created to select it.

6. Select the Run icon to the right of the flow name.



7. On the panel to the right, select Run flow.

8. When the run flow has successfully started, select Done.

9. Select the flow run in which you're interested to view the results.

View results of the run
Now that you've run the flow successfully, you should receive the push notification on
your mobile device.

７ Note

If you don't receive the push notification, confirm that your mobile device has a
working data connection.

Related information
Training: Use Dataverse triggers and actions in Power Automate (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Power Automate mobile app overview
Article • 10/30/2023

This article provides an overview of the Microsoft Power Automate mobile app,
including installation, changing environments, and limitations of the app.

Experience the familiar look and feel of Power Automate on the go with the Power
Automate mobile app, where you can:

Create flows
Manage cloud flows
Create widgets
Manage approvals
Receive notifications

—all from your mobile device.

Install the Power Automate mobile app
If you haven't tried Power Automate yet, sign up for free. Then scan one of the QR codes
below with your mobile device. As an alternative, you can use the Google Play link or
the App store link to install the Power Automate mobile app.

Android iOS

７ Note

If you're installing the Power Automate mobile app, you'll need version 3.x.x or later
to get the functionality that's described in the articles in this section.



Change environments
You might have different environments to work in depending on the purpose of your
work (for example, testing, projects, and customers). You can easily change your
environment to access your flows, approvals, notifications, and more when you're
working on your mobile device.

1. Open the Power Automate mobile app and sign in with either Microsoft Entra ID or
your Microsoft account.

2. Select the environment icon, and then select the environment you want to access.
A check mark appears next to the selected environment.

Limitations



Power Automate mobile app doesn't support geofencing (using location-based
triggers).



Create flows from your phone
Article • 06/13/2023

There are many repetitive tasks that we all wish we could run with just a tap of a button.
For example, you may need to quickly email your team to remind them to join the daily
team sync. Or, you might want to start a new Visual Studio Codespaces build of your
code base after you've been notified that there are no more checkins planned for the
day. Flows allow you to accomplish these and many other tasks simply by tapping a
button on your mobile device.

The main difference between flows and instant flows is that you need to trigger instant
flows manually. To learn about the different types of flows, go to Cloud flows.

Prerequisites
To complete the example in this article, you'll need the following:

Access to Power Automate .
The generally available version of Power Automate mobile app for iOS  or
Android .
An account with permissions to use the connectors to create your flow. For
example, you'll need a Dropbox account in order to create a flow that accesses
Dropbox.

Create a flow
Create flows so that you can easily run repetitive tasks from any place, at any time from
your mobile device. Running flows saves you time and, since the tasks they perform are
automated, there will be fewer errors than if you manually did them.

1. Select the + (plus sign icon).

2. Select the Post MSN Weather updates to Yammer group everyday template.

3. Customize your flow by filling in these fields:

Recurrence
Interval: Enter a number. Frequency: Select the time occurrence.

Get forecast for today
Location: Select a valid input. Units: Select a measurement system.



Post message
Group ID: Aelect the group to post a message to.

4. (Optional) Enter a name for your flow.

If you don't enter a name, the flow will be saved using the same name as the
template you chose.



5. Select Save.

Congratulations, you've created a flow! You can now run this flow anytime, any place,
from the Power Automate mobile app. Simply press the flow and it will run!

Related information
Power Automate mobile app overview

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Manage cloud flows
Article • 07/26/2024

Use the Power Automate mobile app to do the following tasks:

View, edit, and run your flows.

Check the run history of flows.

Turn your flows on and off, or delete them.

You can manage your flows when you're away from your computer whether they're
solution-aware or non-solution–aware. Learn about solution-aware flows.

To learn about the different types of cloud flows, go to Cloud flows.

View a list of your cloud flows
By default, the Flows screen shows all the flows that you've created.



To show flows that others have shared with you, select Shared with me at the top of the
Flows screen.

Edit a cloud flow
You can edit your cloud flows on-the-go. Your available cloud flows are in one of the
lists in the Flows screen, as shown in the previous screenshot.

To edit a cloud flow:

1. On the Flows screen, select the flow that you want to edit.

The Flow details screen displays.

2. Select the pencil icon at the top of the screen.



Run, delete, and turn a flow on or off
Select the vertical ellipsis (⋮) next to a flow, and then select one of the options: Run flow,
Turn off (or if the flow is off, Turn on), or Delete.

You can also turn a flow on and off in the Details screen.

Run an instant flow
The main difference between flows and instant flows is that you need to trigger instant
flows manually to run them.

1. Launch Power Automate mobile app, tap Instant flows at the bottom of the page,
and tap the flow that you wish to run.

2. View the progress while the flow runs.

The page updates, indicating that the flow has completed.

View run history and details
Select the vertical ellipsis (⋮) next to a flow, and then select Details.

In addition to the flow's run history, you can view a description of the flow if one was
provided, how long ago it was modified, and its type.

You can also toggle Enable here to turn the flow on or off.



Related information
Power Automate mobile app overview

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create widgets for flows
Article • 07/26/2024

For quick and easy access to your flows, create a widget. Widgets make running flows
effortless. You can run a flow from the home screen of your mobile device, without
having to open the Power Automate app.

If your flow requires you to enter information, the widget will open the flow in the app.
The flow will continue after you fill in the information.

Widgets can only run flows that you created. They can't run flows that have been shared
with you. However, you can run solution-aware flows using a widget.

Create a widget on an iOS device
The widget will show only the top eight (8) flows on an iOS device.

1. Long-press the home screen where you want to place the widget and select the
plus icon (+).

2. Select the Power Automate app.

If you aren't signed in to the app, it will open to allow you to sign in.

3. Select Add a widget.

Create a widget on an Android device
1. Long-press the home screen where you want to place the widget and select

Widgets.

2. Select the Power Automate app.



If you aren't signed in to the app, it will open to allow you to sign in.

3. Tap the widget on your home screen.

Related information
Power Automate mobile app overview

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Manage approvals
Article • 07/26/2024

Manage your approval requests on your mobile device when you're away from your
desk.

You can quickly approve or reject approval requests in the Power Automate mobile app,
right from the Approvals screen.

1. In the Power Automate mobile app, select Approvals, and then select the arrow to
expand a request.

2. Select Approve or Reject.



If you want more information about a request before you approve or reject it, you can
view any comments and attachments on a separate screen.

1. On the Approvals screen, select the vertical ellipsis (⋮) next to a request, and then
select Details.

2. Read the comments and view the attachments, if any.

3. Select Approve or Reject.



When the Approval submitted successfully or Rejection submitted successfully
message appears at the top of the screen, your approval or rejection is complete:

Create custom responses
You can also create your own responses to approval requests. For example, you might
want to respond with Need more info before you either Accept or Reject a request.
Learn how to create custom responses.

Related information
Power Automate mobile app overview

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Receive notifications
Article • 06/05/2023

The Power Automate mobile app allows you to receive notifications on your mobile
device. You'll get a notification whenever you run a flow that uses either the Microsoft
Notifications connector or the Approvals connector. You'll also get a notification when a
flow encounters a run error.

The list of notifications you've received was previously called Activity Feed.

To view all notifications that correspond to your flows, select the bell icon at the top of
the screen.

Notifications that arrived since the last time you opened the app appear in the New list.
Other notifications appear in the Older list.

A timestamp indicates how long ago the notification arrived. For instance, 5 m means
the notification arrived five minutes ago. Notifications are removed from the Older list
after 14 days.



The Notifications screen shows notifications from the current environment only. To view
notifications from a different environment, select the environment.

Filter your notifications
By default, the Notifications screen shows all the notifications you've received.

To show only notifications that are related to push notifications sent from a flow, select
From flows at the top of the Notifications screen.

To show only notifications of errors that occurred when a flow ran, select Run status at
the top of the Notifications screen.

See also



Power Automate mobile app overview



Use the Power Automate plugin for
ChatGPT
Article • 04/01/2025

The Power Automate plugin for ChatGPT allows you to create, list, and run cloud flows
directly from ChatGPT conversations. You can use the plugin to create instant,
automated, or scheduled flows that run outside of ChatGPT, or use it to run flows that
have the Run from Copilot trigger from the Skills Plugins connector.

Prerequisites
OpenAI account with ChatGPT Plus  subscription.
Power Automate account with permission to create flows with standard connectors
(types of licenses). Personal Microsoft accounts and accounts in national and US
Government clouds aren't currently supported by the Power Automate plugin for
ChatGPT.

Get the plugin
1. Log in to ChatGPT .

2. If you haven't used Plugins before, go to Settings -> Beta features and enable the
Plugins toggle.

3. Start a new chat with ChatGPT and select GPT-4 using the model selector at the
top.

4. Hover over GPT-4 and select Plugins.

5. At the top of the chat, select No plugins enabled then Plugin store.

6. In the Plugin store window that opens, search Power Automate.

7. Select Install on the Power Automate plugin:



8. Log in with your Power Automate account.

9. Select Allow to authorize OpenAI to connect to your Microsoft account.

Use the plugin to create flows from a prompt
When you use a prompt that mentions creating a flow or automation, ChatGPT uses the
Power Automate plugin to respond with a link to preview and create a cloud flow. The
flow won't run until you have reviewed and saved it. Try some of the following example
prompts for creating automated and scheduled flows:

Set up an automation that emails me every morning with my open tasks in Planner
Help me create an automation where I get notified when my manager sends me a
high profile email
Create a flow that sends me an email when an item is added to a folder in
SharePoint



Create flows to run from ChatGPT
conversations
The Run from copilot trigger provides a way for you to create the equivalent of plugins
for ChatGPT that can use any of the 1000+ connectors in the Power Automate
ecosystem. To create a flow that can be used from a ChatGPT conversation use the
following steps:

1. Go to Power Automate .

2. Select Create from the left-pane, and then, select Instant cloud flow.

3. Select the Run from Copilot trigger and select Create. If you've added another
trigger to your flow, you can delete it and search for Run from Copilot to replace
it.

4. Add actions to your flow such as the Outlook connector's Send an email (V2).

5. Save the flow and test or run it at least once. The flow is now available from
ChatGPT. ChatGPT uses the title and description of the flow to determine which
flow you're referring to from a prompt. Ensure flows run as only tested flows show
up on ChatGPT.

The following screenshot shows an example flow that sends an email using the Outlook
connector:



Use the plugin to list and run flows
You can run flows that use the Run from Copilot trigger from ChatGPT with prompts
relevant to the title and description of your flows, such as send an email, post to Teams,
or add to Planner depending on your flows. ChatGPT replies with a link to run the flow
where you can enter and review any inputs to the flow before submitting the flow run.

To retrieve a list of all flows available to ChatGPT, use prompts such as List my flows,
Show my flows, or What are all my flows. ChatGPT returns a table of flows that use the
Run from copilot trigger and their details.

Control and privacy
The following considerations apply when invoking cloud flows from ChatGPT and other
Copilot experiences based on Large Language Models (LLMs):



1. ChatGPT doesn't immediately create the flow that the user wants. Instead, it
returns a link to a possible flow based on the provided prompt. The flow creation
happens on the Power Automate portal after human review. Users need to review
the flow and go through the creation steps to complete the process, including
confirming the actions and connections in the flow.

2. Only flows created by the user with the Run from Copilot trigger are discoverable
from ChatGPT. Shared flows aren't yet discoverable from ChatGPT.

3. ChatGPT can't directly invoke the flow run, as control is in the hands of the user to
review the run details and input parameters before submitting.

4. No user connections or data on which connectors are used are shared with
ChatGPT as part of the functioning of this plugin outside of the authorization
between the user's Microsoft and OpenAI accounts at plugin setup.

Environment support
Currently the flows that are created and run need to be in the tenants default
environment. We're working on a setup experience for the plugin that will allow users to
choose nondefault environments to associate the plugin with.

Frequently asked questions

What is the Skills Plugins connector?
The Skills Plugins connector is a new built-in connector that includes the Run from
Copilot trigger and Respond to Copilot action. It enables ChatGPT and Microsoft
Copilots to discover and run cloud flows separately from your other flows.

How can I manage what connectors and actions are
available to flows run from ChatGPT?
Power Platform data loss prevention (DLP) policies provide control over which
connectors and actions can be used by cloud flows, including flows with the Run from
Copilot trigger. Admins can manage these policies from the Power Platform Admin
Center .

Are all the flows in my tenant and Power Platform
environments shared with ChatGPT?



No, only flows that use the Run from Copilot trigger are visible to ChatGPT. Even with
those flows only the name and description of the flow are accessible in order for
ChatGPT to determine when to invoke the flow.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Use Power Automate flows as plugins in
Copilot for Microsoft 365 (preview)
Article • 01/29/2025

[This article is prerelease documentation and is subject to change.]

You can run Power Automate flows as plugins from Copilot for Microsoft 365.

） Important

This is a preview feature.
Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.

Prerequisites
To use flows as plugins in Microsoft 365 Copilot, you need a license and the ability to
enable plugins. To learn more, go to Licenses for Microsoft 365 Copilot.

Deploy the app
1. Sign in to the Microsoft 365 admin center  with your admin account.

2. On the navigation pane, expand Settings, and then select Integrated apps.

3. On the Available apps tab, search for Power Automate, and then select Deploy
App.

4. To open the Users tab, select Next.

5. Choose to deploy for all users, a specific set of users, or yourself.

6. To complete the remaining steps to deploy the app, select Next.

It might take up to 12 hours for the deployed app's plugin to show in Microsoft
365 Copilot.

Enable flow plugins



Create flows using the Run a flow from Copilot trigger from the Copilot Skills connector
in the default environment. Once created, these flows appear in the plugins menu in
Microsoft 365 Copilot. Currently, users can only see flow plugins that they created.

Run flows from Microsoft 365 Copilot
You can use the flow based plugins shipped by Microsoft in your Microsoft 365 Copilot
app in Microsoft Teams.

1. Sign in to Microsoft Teams .

2. Open the M365 Chat app.

If the Copilot app isn't on your menu, search for it in the Teams app store. A
plugins icon (four squares) shows on the text prompt.

3. Select the Plugins icon > Power Automate.

4. Enable the flow you want to use.



5. Enter a natural language prompt like Get my pending approvals, or Show me my
pending tasks from Microsoft Planner and To Do, to get the results.

Environment support
Currently, the flows that are created and run need to be in the tenant's default
environment. A setup experience for the plugin that allows users to choose nondefault
environments to associate the plugin with isn't available yet.

Related information
Build plugins using Microsoft business applications

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Get started with approvals
Article • 10/23/2024

Whether you need written acknowledgment from your manager or a formal
authorization from a diverse group of stakeholders, getting things approved is part of
almost every organization.

With the approvals capability in Power Automate, you can automate sign-off requests
and combine human decision-making for workflows. Some popular cases where
approvals can be used include:

Approving vacation time requests.

Approving documents that need sign-off.

Approving expense reports.

When you submit an approval in a flow, approvers are notified and can review and act
on the request.

Approvals actions
Actions are the events you want your flow to perform after the trigger starts the flow.
For example, when a new item is added to a list created with Microsoft Lists, trigger an
approval to have somebody review the new item.

The following image shows the full list of approval actions that you can use in your
flows.



If you want to quickly get started with approvals, use the Start and wait for an approval
action. This action lets you provide the information that should be in the approval
request and the approvers who will receive the request.

When you use the Start and wait for an approval action, the flow starts and then waits
for the approvers' response before it completes the run.

There are four approval types you can use.

ﾉ Expand table

Approval type Behavior

Approve/Reject - All approvers are given two options: Approve or Reject.
Everyone must A response is needed from each approver before the flow run is
approve completed. The actions that follow the Start and wait for an approval

action run after all the approvers respond, or when a single rejection
occurs.

Approve/Reject - First Assigned approvers are given two options: Approve or Reject.
to respond Approval or rejection by any approver completes the request. The actions

that follow the Start and wait for an approval action run after any one of
the approvers gives approval.



Approval type Behavior

Custom Responses - You define the options the assigned approvers can choose from.
Wait for all responses All approvers must respond to complete the process.

Custom Responses - You define the options the assigned approvers can choose from.
Wait for one A response from any approver completes the process.
response

Sequential approval Approvals are requested one at a time, in a specific order. Each approver
must respond before the request moves to the next approver in the
sequence. The actions that follow the Start and wait for an approval
action run after all the approvers in the sequence have responded.

Prerequisites
If it's the first time you're using approvals in your organization, ensure that you've met
the following prerequisites:

A Microsoft Dataverse database.
A valid license to create flows.

Permissions to create a Dataverse database
When you create approval flows, they're saved in Dataverse. Initially, when you use the
approvals connector in a cloud flow that's located in a non-default environment, the
system automatically provisions a database. To be successful, the user who runs the first
approval flow must have an administrator role in the environment.

It can take a few minutes for the database provisioning to be completed, and you'll
notice this delay the first time that you run the flow. Other users who create approval
flows don't need any elevated permissions in the environment.

７ Note

If you're using the default environment, you don't need to provision the Dataverse
database. If you create approval flows, the Dataverse database is created for you
automatically in the default environment.

License to create flows



Because the approvals connector is a standard connector, any license that grants access
to Power Automate and the ability to use standard connectors is sufficient to create
approval flows.

Here are the licenses that grant rights to use standard connectors:

Power Automate .
Office 365.
Dynamics 365 license with built-in Power Automate capabilities.

You can find a list of the Office 365 and Dynamics 365 licenses in the Microsoft Power
Apps and Power Automate licensing guide .

Get started
Use one of the following options to get started creating approval flows.

Use an existing template—You can search the list of approvals templates  for
your scenario, and then follow steps to create a flow that suits your needs. 

Tweak an existing template—If one of the existing templates is similar, but doesn't
fit your needs precisely, create a flow from that template and then tweak
the flow to your liking.

After you create a flow from a template, it's yours to modify or extend. Do this by
adding, editing, or removing triggers and actions. 

 Tip

You can copy and paste  actions in the same flow or across flows to speed
up the editing process.

Create an approval flow from scratch—If you can't find a suitable template, you
can create a flow from scratch and then connect it to the services and the
approvals you need by using the approvals actions. Learn how to create a flow
from scratch.  

Consult the community for inspiration and help—Power Automate has a thriving
community that can help if you're stuck or looking for some inspiration. Just head
over to the Power Automate forums  to ask specific questions and get answers.

Assign approvals to any user in your tenant



You can assign approvals to users—including guest users and Microsoft 365 groups—in
your current Dataverse environment or your Microsoft Entra tenant.

When you assign an approval to users who aren't in your environment, they're
automatically given the Approvals User Dataverse security role. Users need this role for
their responses to be processed and persisted in their approvals history.

The following tenant configurations don't allow this:

When the AllowAdHocSubscriptions setting in Microsoft Entra is disabled. In this
case, you can request your tenant administrator to enable it. You can find more
information about this in the self-service signup.
If a security group has been used to control which users have access to the
Dataverse environment.
Power Automate US Government plans.

After you assign an approval request to a user, they can respond directly from an
Outlook email, a Microsoft Teams adaptive card, or the Power Automate action center if
they have a Power Automate license or an Office 365 or a Dynamics 365 license with
built-in Power Automate capabilities. You can find a list of these Office 365 and
Dynamics 365 licenses in the Microsoft Power Apps and Power Automate licensing
guide.

Next step
Create approval flows

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Trigger approvals from lists created with
Microsoft Lists
Article • 02/10/2023

Imagine that you have a list created with Microsoft Lists in which employees store
requests for devices like monitors or headsets. You want to create an approval process
so that every time an employee adds a request to a list, somebody receives a request to
approve it.

To follow this guided tutorial, create a list with Micrsoft Lists. You can use the following
example of a list.

Once you have a list for which you want to create an approval process:

1. Go to the Start approval when a new item is added  template, which provides a
flow that's configured to create an approval process on a list.

2. Make sure all connections listed have a green check, and then select Continue.



3. Once the flow is created, configure these three items:

Site address: Select the site where you have your list from the dropdown list.

If the site doesn’t appear on the dropdown list, just enter your site URL.

List name: Once you have defined the Site Address, select the list you want
every new item added to trigger an approval.



Assigned to: This is the person in your company who should receive the
approval request. You can start by assigning yourself as the approver.

That’s it! The approval flow is now configured. If you look at the entire flow, the
steps are:

The flow is triggered every time a new item is added to the list you have
defined in step 3.

An approval request is sent to the person you've chosen.

If the approval is answered as Approve, the person who created the item on
the list gets an email with the approval confirmation. If the request was
answered as Reject, that person gets an email saying that the request was
rejected.



If for some reason the approval fails, you as the maker of this flow will get an
email informing you that the approval failed. In this case, you will need to
look at the run history of the flow to see why the approval failed.

4. Now let’s test this flow. first, select Save on the top right.

5. Once the flow has been successfully saved, select Test.

6. Select I’ll perform the trigger action.

7. Select Save and test.



8. Power Automate alerts you after the flow enters test mode. When it is in test
mode, create a new item on your list and then look at your flow to see it.

You'll see that once your flow starts, it runs to the approval action where it shows
an orange circle on the top right of the approval action step. This means that the
assigned approvers need to respond to the approval request for the flow to
continue.

Next step
Create approval flows



Trigger approvals from a SharePoint
document library
Article • 04/10/2025

This article shows you how to create an approval flow for new documents (invoices) when
they're added to a SharePoint document library. Once they're added, you can attach
documents to the approval request.

In the approval process, every time a new invoice is added to a SharePoint library, a request is
sent for someone to review its contents. If they approve the request, the invoice files are
moved to a folder.

To learn how to trigger approvals from a SharePoint document library, check out this short
video:
https://learn-video.azurefd.net/vod/player?id=551bee92-5535-4783-802e-
7d2ff9a808d9&locale=en-us&embedUrl=%2Fpower-automate%2Ftrigger-sharepoint-
library

For more detailed instructions, follow the procedures in this article.

Create a flow from a template
Before you start, you need to create some folders in Sharepoint. Then, you can create a flow
from a template in Power Automate.

1. On the navigation pane in SharePoint, select Documents.

2. Create two folders, such as Incoming Invoices and Reviewed Invoices.

3. On the navigation pane in Power Automate , select Templates.

4. In the Search templates field, begin typing Start an approval for new file to move it to a
different folder. When the template appears in the search results, select it.

This template provides us with a flow that is configured to set up an approval process for
a SharePoint document library.

5. Confirm that all the connections listed have a green checkmark, and then select Continue.
A cloud flow is created.

You might need to sign in or create to see the green checkmarks.



Update the trigger parameters
Continue by updating the trigger input parameters.

1. Select the trigger card.

2. In the Site Address field, select the SharePoint site that contains your list.

If the SharePoint site doesn’t appear on the list, type in your SharePoint site URL.

3. In the Library Name field, select the library in your SharePoint site where the folders
reside.

4. Under Advanced parameters, select Show all to display the Folder input parameter.

5. In the Folder field, select the folder icon, and then select the folder where you'll upload
the incoming files to be reviewed through an approval request.



6. Close the Parameters panel.

Add an action
Add an action that allows you to retrieve the content of the file.

1. Select the plus sign (+) below the trigger.
2. In the Search for an action or connector field, enter sharepoint get file content.
3. Scroll down to find and select the Get File Content action.

Configure your flow
1. In the Get File Content action screen, Parameters tab, update the following input

parameters:

a. In the Site Address field, select the same SharePoint site that contains your list.

If the SharePoint site doesn’t appear on the list, type in your SharePoint site URL.

b. In the File Identifier field, type a forward slash (/) and select the thunderbolt icon to
load the dynamic content picker.

c. In the dynamic content picker Search field, start typing identifier. When it appears in
the list, select Identifier.

2. In the designer, select the Start and wait for an approval action and update the following
input parameters:

a. In the Title field, enter a title for the approval request, such as A new file needs your
view and approval.

b. In the Assigned to field, select a user to be the approver of the approval request, such
as yourself.

c. In the Details field, enter details for the approval request for the approver, such as
Please approve this file - .

You can also include the file name including the extension by selecting the File name
with extension property from the trigger using the dynamic content picker.

d. In the Item link field, use the dynamic content picker to find and select the Link to
item property from the trigger.



e. In the Item link description field, use the dynamic content picker to find and select the
Name property from the trigger.

3. In the designer, select the Apply to each action. This action loops through each response
of the approvers for the approval request. In this example, only one approver was added,
so the flow processes only one response.

4. In the designer, select the Condition action. This action checks whether the Approver
Response value from the first responder equals Approve .

The condition action has two branches that represent a set of actions to be executed if
the condition is met (True) or not met (False). When the file is approved, the True branch
processes the two actions, which creates the file in the second folder, and deletes the
existing file in the original folder. Otherwise, if the file is rejected, the False branch
processes with no further automation.

5. In the designer, select the Create file action and update the following input parameters:
a. In the Site Address field, select the SharePoint site that contains your list. If the

SharePoint site doesn’t appear on the list, type your SharePoint site URL.
b. In the Folder Path field, select the folder where you plan to put the incoming files to

be reviewed with an approval.



c. In the File Name field, use the dynamic content picker to find and select the File name
with extension property from the trigger.

d. In the File Content field, use the dynamic content picker to find and select the File
Content property from the Get File Content action.

6. In the designer, select the Delete file action and update the following input parameters.
a. In the Site Address field, select the SharePoint site that contains your list. If the

SharePoint site doesn’t appear on the list, type in your SharePoint site URL.
b. In the File Identifier field, use the dynamic content picker to select the File Identifier

property from the trigger.

Test your flow
You're done configuring the flow. You can now test it.

1. On the menu bar, select Save. You might get a warning message from the Flow checker.
You can dismiss it.

2. Once the flow is saved, select Test.

3. Select Manually > Test.

Power Automate indicates to you when the flow is in test mode.

4. When it's in test mode, upload a new file to the Incoming Invoices folder in the
SharePoint document library that you specified earlier.

The flow continues to run the test.

Respond to the approval request
The person to whom you assigned the approval now receives the approval request in various
places where they can approve or reject it. The file to review is provided as a hyperlink for easy
reference.

By email
The email looks like the following screenshot with a hyperlink to the file in SharePoint.

If the email doesn't display correctly, make sure you have the latest updates in your Outlook
app, or use the web version of Outlook.



In Power Automate maker portal, in the Approvals section
The approver gets a list of their approval requests in the Received tab. When the request is
selected, the Respond panel appears where the approver can review the request, including
select the link which loads the SharePoint file to review in a new browser tab.

1. Scroll down the Respond panel and in the Choose your response dropdown list, select
Approve.

2. Select Confirm.



Once the request is approved or rejected, the flow test run continues. If the request was
approved, the True branch processes. Otherwise, the False branch processes.

Since the request in this example was approved, the file uploaded in the original folder
was deleted and created in the other folder.

Related information
Create and test an approval workflow with Power Automate



How to - Top scenarios with approval
flows
Article • 03/10/2023

Here are the top how to questions and answers about approvals in Power Automate.

Customize approval requests
There are two ways to customize approval requests.

Using custom options
Power Automate approvals provides two default options to approve or reject requests.

Your business might need other options beyond approve/reject. For example, you might
be reviewing a discount request and you may want the approver to be able to respond
from a list of possible discount limits, including:

Up to 5%
Up to 10%
Up to 15%
Denied.

You can customize the list of responses to approval requests by using Custom
Responses.

Here's an example.

Salespeople in an organization can request an approver to give customers a discount for
their purchases. These Salespeople enter the discount request into a SharePoint list,
which is the trigger of the flow. The flow then uses custom responses with the Start and
wait for an approval action.



Select as approval type Custom Responses – Wait for all responses or Custom
Responses – Wait for one response, depending on if you need multiple approvers or



just one.

Add as many response options as needed. In this case we are giving four mentioned
earlier.

Give a Title to the approval request, and then list the approvers in Assigned to.

After the approval request is answered, the flow sends an email to the salesperson who
requested the discount, informing them about the outcome of the request.

To get the response to the approval request, just use the Outcome output.



The approver sees the approval request like this.



Using markdown
Markdown is a language that's used to format text into Webpages like headers, tables,
or bold text. In an approval request, you can use markdown in the Details field to format
the information presented to approvers.

You can learn more about how to use markdown and the supported apps in the Use
Markdown in Power Automate approval requests article.

Here is an example of its usage.



And here's how the approvers see it in a nicely formatted email in Outlook.



Display approval date in my timezone
By default, approval emails display the Date Created field in GMT. There no way to
change this field.



You can work around this by displaying the date the flow was run, in your desired
timezone, in the Details field of the approval request. For example, to display the
approval request date in Paris time, add two time actions like this.



And the resulting approval email will look like this:



Reassign an approval to another person
If received an approval request, but you want somebody else to make the approval
decision, you can reassign the approval to somebody else:

1. Login to the Power Automate .

2. On the left navigation bar, select Approvals.

3. Hover your mouse over the approval you want to reassign, select the three dots >
Reassign.



On the other hand, if you are the requester, you cannot reassign the approval request.
However, you can Cancel the approval request, and then edit the flow to change the
Assigned to approver.

To cancel an approval:

1. Login to the Power Automate .

2. On the left navigation bar, select Approvals.

3. Select the Sent tab.

4. Select Cancel.



Get a confirmation email once an approval has
been answered
If you would like to be notified when an approver responds to an approval request, just
send yourself an email after the approval step in the flow. Send the email on the If yes
and on the If no branches of the approval outcome condition like this.



Cancel an approval
If you are the maker of a flow that requests approvals, and the approval requests
haven't been answered, you can cancel it by:

1. Login to the Power Automate .

2. On the left navigation bar, select Approvals.

3. Select the Sent tab.

4. Select Cancel.



Do sequential approvals
Some processes require pre-approval before the final approver is required to sign off.
For example, an organization may have a sequential approval policy that requires pre-
approval for invoices over $1,000.00 before they're approved by the Finance
department. This walkthrough guides you on how to manage sequential approvals with
Power Automate.

Post an approval request in Microsoft Teams
If you would like to notify the assigned approvers through a message in Microsoft
Teams instead of by email, start with the Request approval in Teams for a selected item
in SharePoint template  to do it.

Send an approval to multiple people
You can assign an approval request to multiple persons. Here are the two options.

1. When adding an approval action, there are two actions options for sending the
approval request to multiple persons. Select the appropriate option based on your
needs.

If only a response of one person from the group of people is enough to sign
off the approval and continue with the flow run, use the Approve/Reject –
First to respond or Custom Responses – Wait for one response action.



If Everybody must respond to the approval request to continue with the flow
run, select Approve/Reject – Everybody must approve or Custom Responses
– Wait for all responses.

2. In the Assigned to field, define the list of persons to whom the approval request
should be sent. Separate each person with a semicolon (;).

Next steps
Create approval flows



Manage approval requests in Power
Automate
Article • 04/14/2023

Power Automate makes it easy to automate approval workflow processes. In this
walkthrough, you learn how to view, approve, and reject approval requests sent from
Power Automate.

View pending approval requests
View all pending approval requests by following these steps:

1. Sign in to Power Automate .

2. On the left-side navigation pane, select Action items > Approvals.

Your pending approval requests appear on the Received tab.

Approve a request
If you're an approver in an approval flow, you receive an email whenever someone
creates a request. The approval request is also sent to the approvals center. You can
then approve or reject requests from the email, the approvals center, or the Power
Automate app.

To approve a request:

From email
1. Select Approve from the email you receive when an item is added to the

SharePoint Online list.

Note: If you're using a mobile device with the Power Automate app installed, the
Power Automate app launches, otherwise, the approvals center opens in your
browser.

2. Enter a comment, and then select the Confirm button.

From the approvals center



1. Sign in to Power Automate .

2. Select Approvals in the left-side navigation pane.

3. Select Approve on the request you want to approve.

4. Add any comments, and then select Confirm at the bottom of the screen.

From the Power Automate app
1. On your mobile phone with the Power Automate app installed, select Approve

from the request approval email.

2. Select Confirm in the upper right corner of the screen.

3. The success page shows, indicating that your approval has been recorded.

７ Note

The screens on Android, iOS and Windows Phone may differ slightly, however, the
functionality is the same on all devices.

Reject a request
You can reject a request via email, the approvals center, or the Power Automate app. To
reject a request, follow the steps for approving a request, but select Reject, instead of
Approve.

After you confirm your decision (rejection of the request), the flow runs the following
steps:

1. Sends an email to the person who requested vacation.
2. Updates the SharePoint Online list with the decision, and the comments from the

approver.

See also
Create approval flows
Create sequential approval flows
Create parallel approval flows
Install the Power Automate mobile app for Android , iOS  or Windows Phone



Create and test an approval workflow
with Power Automate
Article • 10/09/2024

With Power Automate, you can manage the approval of documents or processes across
several services, including SharePoint, Dynamics 365, Salesforce, OneDrive for Business,
Zendesk, or WordPress.

To create an approval workflow, add the Approvals - Start and wait for an approval
action to any flow. After you add this action, your flow can manage the approval of
documents or processes. For example, you can create document approval flows that
approve invoices, work orders, or sales quotations. You can also create process approval
flows that approve vacation requests, overtime work, or travel plans.

Approvers can respond to requests from their email inbox, the approvals center in
Power Automate , or the Power Automate app.

Create an approval flow
Here's an overview of the flow we'll create and test:

The flow performs the following steps:

1. Starts when someone creates a vacation request in a SharePoint Online list.



2. Adds the vacation request to the approval center, and then emails it to the
approver.

3. Sends an email with the approver's decision to the person who requested vacation.

4. Updates the SharePoint Online list with the approver's decision comments.

 Tip

For detailed information about using SharePoint with Power Automate, go to the
SharePoint documentation.

） Important

Always follow the best practices for SharePoint security and your organization's
best practices to ensure your environment is secure. Security is outside the scope of
this article.

Prerequisites
To complete this tutorial, you must have access to:

Power Automate .
A SharePoint Online list.
Office 365 Outlook and Office 365 Users account.

７ Note

While we use SharePoint Online and Office 365 Outlook in this walk-through, you
can use other services such as Zendesk, Salesforce, or Gmail. If you are using
SharePoint 2010, see SharePoint 2010 workflow retirement

Before you create the flow, create a SharePoint Online list . Later, we'll use this list to
request approval for vacations.

Create these columns in your SharePoint Online list:

ﾉ Expand table



Column Type

Title Single line of text

Start Date Date and Time

End Date Date and Time

Comments Single line of text

Approved Yes/No

Manager Comments Single line of text

Make note of the name and URL of the SharePoint Online list. You'll need these items
later when you configure the SharePoint - When an item is created trigger.

Create an automated cloud flow
1. Sign in to Power Automate .

2. Select My flows in the left-side navigation pane.

3. On the top-left menu, select New flow > Automated cloud flow.

Add a trigger
1. Give your flow a name.

2. Under Choose your flow's trigger, select When an item is created - SharePoint,
and then select Create.

3. On the When an item is created card, select the Site Address and the List Name
for the SharePoint list that you created earlier.

The Site Address and the List Name are the items you noted earlier in this walkthrough.



Add a profile action
1. Select New step, and then type profile into the Choose an action search box.

2. Select Office 365 Users.

3. Find, and then select the Get my profile (V2) action.

4. Select the fields from your profile that you want to include in your flow, and then
select Create to save the work you've done so far.

Add an approval action
1. Select New step.

2. Type approval into the Choose an action search box.

3. Select the Start and wait for an approval action.



4. Configure the Start and wait for an approval card to suit your needs.

７ Note

The Approval type, Title and Assigned To fields are required. You can use
Markdown to format the Details field.



７ Note

This action sends the approval request to the email address in the Assigned To box.

If your scenario requires it, you can attach files to your approval requests that use
Microsoft Dataverse.

Add an email action for approvals
Follow these steps to send an email if the vacation request is approved.

1. Select Add an action on the If yes branch of the condition.

2. Enter send email into the search box on the Choose an action card.

3. Select the Send an email (V2) action.



4. Configure the email card to suit your needs.

７ Note

To, Subject, and Body are required.

This card is a template for the email that is sent when the status of the vacation
request changes.

In the Body box on the Send an email (V2) card, use the Comments token from
the Approvals - Start an approval action.



Add an update action for approved requests
1. Select Add an action in the If yes branch.

2. Enter SharePoint in the search box on the Choose an action card, select the
SharePoint filter, and then select the Update item action.



3. Configure the Update item card to suit your needs.

７ Note

Site Address, List Name, Id, and Title are required.



Add an email action for rejections
1. Select Add an action on the If no branch.

2. Enter Send into the search box of the Choose an action card, select Office 365
Outlook to filter the actions, and then select the Send an email (V2) - Office 365
Outlook action.



3. Configure the email card to suit your needs.

This card represents the template for the email that's sent when the status of a
vacation request changes.

Add update action for rejected requests



1. Select Add an action.

2. Enter update into the search box on the Choose an action card, and then select
the Update item - SharePoint action.

3. Configure the card to suit your needs.

７ Note

Site Address, List Name, Id, and Title are required.



4. Select Save to save the work we've done.

If you've followed along, your flow should resemble this screenshot:



Now that we've created the flow, it's time to test it!

Request an approval to test your flow
Create a vacation request in the SharePoint Online list you created earlier.

After you save this request, the flow triggers, and then:

1. Creates a request in the approvals center.
2. Sends an approval request email to the approvers.

Create long-running approvals
If it's likely that your flow will run for more than 30 days, consider storing your approvals
in Microsoft Dataverse. This makes it possible for you to create flows that act on
responses to approval requests, even after the original flow run times out.

To do this, use two flows, one to send an approval request, and the other to run
business logic on the responses to the approval request, based on the Create an
approval (v2) action. Learn more about long running approvals.

 Tip

If you use modern email clients, you don't have to wonder if a request is still
required because Power Automate automatically updates the email to indicate that
the approval request is completed.

Cancel an approval request
Sometimes you might want to cancel an approval request that you've sent. Possibly you
made a mistake in the request, or it’s no longer relevant. In either case, the person who
sent the request can cancel it by following these steps:

1. Select the approval
2. Select Cancel approval in the side pane.

 Tip

You can always select the History tab to view the approval requests that you've
canceled.



７ Note

The cancel feature is supported on the Create an approval (v2) action.

Request approvals from guest users
You can send approvals requests to persons outside your organization. To do this, use
Microsoft Entra guest users by inviting users from other tenants as guests.

When you assign a role to a guest, this gives the guest the permission required to
participate in the approval process.

Now that you've created and tested your flow, be sure to let others know how to use it.

Related information
View and manage pending approval requests
Create sequential approval flows.
Create parallel approval flows.
Install the Power Automate mobile app for Android , iOS , or Windows Phone
Training: Build approval flows with Power Automate (module)
Training: Automate an approval process in Power Automate (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create approval flows with attachments
Article • 07/11/2023

Sometimes, you need to get a file approved for business purposes. Fortunately, you can
use Power Automate approvals to do this task. For example, let's say you are an
accountant and you want to get approval for an invoice. You could create an instant flow
that lets you send the file for approval by tapping a button and selecting the file to
send.

In this article, you learn how to create an approval flow that sends an attachment that
the approver needs to review before deciding if the request should be approved.

Create the flow
1. Sign in to Power Automate .

2. Select My flows > New > Instant-from blank.

3. Name your cloud flow > search for, and then select Manually trigger a cloud flow,
and then select Create.

4. Select the Manually trigger a cloud flow trigger > Add an input > File.

The previous steps configure your flow so that when it runs, it requests a file from
the user to trigger your flow.

5. Select New step.

6. Search for Approvals and then select Start and wait for an approval.

7. Select Approve/reject - First to respond in the Approval type list of the Start and
wait for an approval card.

8. Provide the following information on the Start and wait for an approval card:

Title - This is a short description that tells the approver what the request is
about.
Assigned to - The person to whom the request is sent.
Details - This text shows up in the approval request.

9. Select Show advanced options to reveal the fields in which you'll provide
information about the file attached to the request.

10. Provide a file name in Attachments Name - 1



Include the file extension that matches the file type that's uploaded.

11. in the Attachments Content - 1 field, provide the contents for the file that will be
sent to the approver.

７ Note

The file content needs to be binary encoded. In most cases, this is handled
correctly within the flow. However, if the attachement appears to be corrupted
in the email, check to make sure the file content is binary encoded.

An easy way to do this is to use the File Content item from the list of dynamic
content that appears when you select the Attachments Content - 1 field.

12. Select Save to save your flow.

Test your flow
You can test your flow by selecting Test and then uploading an .xlsx file.



1. Select Test.

2. Select I'll perform the trigger action.

3. To start the test, select Test > Continue.

4. Select Import.

5. Find the file, select it, and then select Open to upload the file or image you're
sending for approval.

6. Select Run flow.

The test run starts.

7. To monitor the status of the test, select Flow Runs Page.

Approve the request
The person to whom you send the approval request receives an email where they can
view the attachment and then approve or reject the request.

Approvers can also review requests in the approvals center.

Add a condition to an approval flow
In most approval flows, you'd want to notify the person who requests the approval of
the decision. To learn how to add a condition to an approval flow to take specific actions
based on the outcome of the request, go to Create and test an approval workflow.



Set up sequential approvals
Article • 10/23/2024

Some workflows require pre-approval before the final approver can sign off. For
example, a company might have a sequential approval policy that requires pre-approval
for invoices over $1,000.00 before the Finance department can approve them.

In this example, you set up a sequential approval for vacation requests. The requestor’s
manager and the manager of the requestor’s manager must approve the vacation
requests.

Create your flow
Create a flow that triggers when a new response is submitted to a form.

1. Sign in to Power Automate .
2. On the navigation pane to the left, select My flows.
3. On the menu at the top, select New flow > Automated cloud flow.
4. Give your flow a name.
5. Under Choose your flow's trigger, select When a new response is submitted, and

then select Create.
6. Select the When a new response is submitted card to open the action

configuration pane, and then select the Form Id of a form you previously created.
7. Insert a step and then select the Get response details action.
8. In the same action, place the same Form Id from the previous action.
9. In the Response Id field, select the response ID from the previous Get response

details action.

Get the manager for the person who created
the vacation request
After you create the flow, you need to get the manager for the person who created the
vacation request.

７ Note

It's a good idea to periodically save changes to your flow while you work.

1. Select New step.



2. In the Choose an action search field, type get manager.
3. Find and select the Get manager (V2) - Office 365 Users action.
4. Select the Get manager (V2) card to open the action configuration pane, and then

insert the Responder’s Email token into the User (UPN) field.
5. Rename the action to Get level 1 manager.

Get the manager of the requestor’s manager
After you get the manager for the person who created the vacation request, you need to
get the manager of the requestor’s manager.

1. Select New step.
2. In the Choose an action search field, type get manager.
3. Find and select the Get manager (V2) - Office 365 Users action.
4. From the Get level 1 manager action, insert the Id token into the User (UPN) field

on the Get manager card.
5. Rename the action to Get level 2 manager.

Add an approval action for pre-approvals
1. Select New step.

2. In the Choose an action search field, type approval.

3. Select the Start and wait for an approval action.

4. Select the Sequential Approval type.

5. Give the approval a title.

In this example, you add two (2) steps.

6. In Assigned To – 1, enter the Mail token from the Get level 1 manager approval
action.

7. To add an approval step, select Add new item.

8. Configure the Start and wait for an approval card to suit your needs.



Now, when the flow runs, it first goes to the level 1 manager. If that person approves it,
then it goes to the level 2 manager for approval.

You can rename actions as you wish. You can also add other actions and subsequent
actions after the approval, such as an email that sends the approval decision to the
requestor. The following screenshot shows what your flow might look like with renamed
actions and an email action at the end.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Manage sequential approvals with
Power Automate
Article • 10/21/2024

Some workflows require pre-approval before the final approver is required to sign off.
For example, a company may have a sequential approval policy that requires pre-
approval for invoices over $1000.00 before they're approved by the Finance department.

Learn how to quickly and easily set up sequential approvals in Set up sequential
approvals.

In this tutorial, you manually create a sequential approval flow that manages employee
vacation requests. For detailed information about using SharePoint with Power
Automate, go to the SharePoint documentation.

Learn more about using SharePoint with Power Automate in SharePoint documentation.

７ Note

SharePoint is used here only as an example. It isn't required to create approval
flows. You can use any of the more than 200 services with which Power Automate
integrates to drive your flows. If you're using SharePoint 2010, go to SharePoint
2010 workflow retirement .

Detailed steps in the flow
The flow:

1. Starts when an employee creates vacation request in a SharePoint Online list .
2. Adds the vacation request to the approval center and then emails the request to

the pre-approver.
3. Emails the pre-approval decision to the employee.
4. Updates the SharePoint Online list with the pre-approver's decision and comments.

Note: If the request is pre-approved, the flow continues with these steps:
5. Sends the request to the final approver.
6. Emails the final decision to the employee.
7. Updates the SharePoint list with the final decision.

This image summarizes the preceding steps:



Prerequisites
Power Automate .
A SharePoint Online list.
Office 365 Outlook and Office 365 Users account.

７ Note

While we use SharePoint Online and Office 365 Outlook in this walk-through, you
can use other services such as Zendesk, Salesforce, or Gmail. If you are using
SharePoint 2010, see SharePoint 2010 workflow retirement

Before you create the flow, create a SharePoint Online list . Later, we'll use this list to
request approval for vacations.

For the purposes of this walkthrough, the SharePoint Online list that you create must
include the following columns:

The SharePoint Online list you create must include the following columns:

ﾉ Expand table

Title Single line of text

Vacation start date Date and time



Title Single line of text

Vacation end date Date and time

Comments Single line Of text

Approved Yes/No

Manager comments Multiple lines Of text

Modified Date and time

Created Date and time

Pre-approved Yes/No

Created By Person or group

Modified By Person or group

Make note of the name and URL of the SharePoint Online list. We use these items later
when you configure the SharePoint - When a new item is created trigger.

Create your flow
1. Sign in to Power Automate .

2. Select My flows in the left-side navigation pane.

3. On the top-left menu, select New flow > Automated cloud flow.

1. Give your flow a name.

2. Under Choose your flow's trigger, select When an item is created - SharePoint,
and then select Create.

3. On the When an item is created card, select the Site Address and the List Name
for the SharePoint list that you created earlier.

1. On the When an item is created card, select the Site Address and the List Name
for the SharePoint list that you created earlier.

Get the manager for the person who created
the vacation request



1. Select +New step, and then type get manager into the Choose an action search
box.

2. Find, and then select the Get manager (V2) - Office 365 Users action.

3. Insert the Created By Email token into the User (UPN) box on the Get manager
card.

This action gets the manager for the person who created the vacation request in
SharePoint.

７ Note

It's a good idea to periodically save changes to your flow as you go.

Add an approval action for pre-approvals
1. Select New step.

2. Type approval into the Choose an action search box.

3. Select the Start and wait for an approval action.



4. Configure the Start and wait for an approval card to suit your needs.

７ Note

The Approval type, Title and Assigned To fields are required. You can use
Markdown to format the Details field.



This action sends the pre-approval request to the email address in the Assigned To box.

Add a condition
1. Select New step, and then select Condition in the list of actions.

2. On the Condition card, select Choose a value on the left.

A list of dynamic values display.

3. Select Responses Approver response from the list of dynamic values.



4. Select the Choose a value box on the right, and then enter Approve into the box.

７ Note

The valid responses to the Approvals - Start an approval action are
"Approve" and "Reject". These responses are case-sensitive.

5. Your Condition card should now show:

７ Note



This condition checks the response from the Start and wait for an approval action.

Add an email action for pre-approvals
1. Select Add an action on the If yes branch of the condition.

2. Enter send email into the search box on the Choose an action card.

3. Select the Send an email (V2) action.



4. Configure the email card to suit your needs.

７ Note

To, Subject, and Body are required.

This card is a template for the email that is sent when the status of the vacation
request changes.

In the Body box on the Send an email (V2) card, use the Comments token from
the Approvals - Start an approval action.



Add an update action for pre-approved
requests

1. Select Add an action in the If yes branch.

2. Enter SharePoint in the search box on the Choose an action card, select the
SharePoint filter, and then select the Update item action.



3. Configure the Update item card to suit your needs.



Get the pre-approver's manager
1. Use the Get the manager for the person who created the vacation request steps

we did earlier to add, and then configure another Get manager action. This time
we get the pre-approver's manager.

2. The Get manager 2 card should resemble this image when you're finished. Be sure
to use the Email token from the Get manager category on the Add dynamic
content from the apps and services used in this flow card.

Add the final approval action
1. Use the add an approval action for pre-approvals steps we did earlier to add, and

then configure another Start and wait for an approval action. This action sends an
email request for final approval.



2. When you're done, the card should resemble this image:

Add the final approval condition
Repeat the steps from add a condition to add, and then configure a Condition that
checks the final approver's decision.

Send email with final approval
1. Use the steps from Add an email action for pre-approvals to add, and then

configure an action that sends an email when vacation requests are approved.

2. When you're finished, your card should resemble this image:



Update SharePoint with approval
1. Use the steps from Add an update action for pre-approved requests to add, and

then configure an action that updates SharePoint when the vacation request is
approved.

2. When you're finished, the card should resemble this image:

Send email with pre-approval rejection
1. Select Add an action on the If no branch.



2. Enter Send into the search box of the Choose an action card, select Office 365
Outlook to filter the actions, and then select the Send an email (V2) - Office 365
Outlook action.

3. Configure the email card to suit your needs.

This card represents the template for the email that's sent when the status of a
vacation request changes.



This action must be added to the IF NO, DO NOTHING branch below the Condition
card.

Update SharePoint with pre-approval rejection
1. Select Add an action.

2. Enter update into the search box on the Choose an action card, and then select
the Update item - SharePoint action.



3. Configure the card to suit your needs.

Send email with final rejection



1. Use the steps from Send email with pre-approval rejection to add, and then
configure an action that sends an email when the vacation request is rejected by
the final approver.

This action must be added to the IF NO, DO NOTHING branch below the
Condition 2 card.

2. When you're finished, the card should resemble this image:

Update SharePoint with final rejection
1. Use the steps from Update SharePoint with pre-approval rejection to add, and then

configure an action that updates SharePoint if the final approver rejects the
vacation request.

2. When you're finished, the card should resemble this image:



3. Select Update flow to save the work we've done.

If you've followed along, your flow should resemble this image:



Now that you've created the flow, let's see it in action.

Request an approval
Create a vacation request in the SharePoint Online list you created earlier.

After you save this request, the flow triggers, and then:

1. Creates a request in the approvals center.
2. Sends an approval request email to the approvers.

Your request should resemble this image:

View pending approval requests
View all pending approval requests by following these steps:

1. Sign in to Power Automate .



2. On the left-side navigation pane, select Action items > Approvals.

Your pending approval requests appear on the Received tab.

Pre-approve a request
If you're an approver in an approval flow, you receive an email whenever someone
creates a request. The approval request is also sent to the approvals center. You can
then approve or reject requests from the email, the approvals center, or the Power
Automate app.

To approve a request:

From email
1. Select Approve from the email you receive when an item is added to the

SharePoint Online list.

Note: If you're using a mobile device with the Power Automate app installed, the
Power Automate app launches, otherwise, the approvals center opens in your
browser.

2. Enter a comment, and then select the Confirm button.

From the approvals center
1. Sign in to Power Automate .

2. Select Approvals in the left-side navigation pane.

3. Select Approve on the request you want to approve.

4. Add any comments, and then select Confirm at the bottom of the screen.

From the Power Automate app
1. On your mobile phone with the Power Automate app installed, select Approve

from the request approval email.

2. Select Confirm in the upper right corner of the screen.

3. The success page shows, indicating that your approval has been recorded.



７ Note

The screens on Android, iOS and Windows Phone may differ slightly, however, the
functionality is the same on all devices.

Approve the request
The steps to approve a request are identical to the steps to pre-approve a request

The final approver gets the vacation request only after the request has been pre-
approved.

Reject a request
You can reject a request via email, the approvals center, or the Power Automate app. To
reject a request, follow the steps for approving a request, but select Reject, instead of
Approve.

After you confirm your decision (rejection of the request), the flow runs the following
steps:

1. Sends an email to the person who requested vacation.
2. Updates the SharePoint Online list with the decision, and the comments from the

approver.

Related information
Single approver modern approvals walkthrough

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create parallel approval workflows with
Power Automate
Article • 12/16/2022

In a parallel approval workflow, multiple persons are required to approve items such as
invoices, purchase orders, vacation requests, etc. Each person's approval is independent
of all other approvers.

In this walkthrough, we use Power Automate to create a cloud flow that automates a
parallel approval workflow. This flow automates an employee vacation request process
that requires approval from all persons (or teams) that the employee supports regularly.
Employees use a SharePoint list  to request vacation. Vacation approvals are required
from the employee's direct manager, the Sales team, and the Human Resources team.
Each vacation request is routed to each approver for a decision. The flow sends email
with status changes and then updates SharePoint with the decisions.

 Tip

For detailed information about using SharePoint with Power Automate, go to the
SharePoint documentation.

Prerequisites
Power Automate .
A SharePoint Online list.
Office 365 Outlook and Office 365 Users account.

７ Note

While we use SharePoint Online and Office 365 Outlook in this walk-through, you
can use other services such as Zendesk, Salesforce, or Gmail. If you are using
SharePoint 2010, see SharePoint 2010 workflow retirement

Before you create the flow, create a SharePoint Online list . Later, we'll use this list to
request approval for vacations.

The SharePoint Online list you create must include the following columns:



Title Single line of text

Employee comments Single line Of text

Direct manager comments Multiple lines Of text

Sales team comments Multiple lines of text

HR team comments Multiple lines of text

Direct manager approved Yes/No

Sales team approved Yes/No

HR team approved Yes/No

Vacation start date Date and time

Vacation end date Date and time

Make note of the name and URL of the SharePoint Online list. We use these items later
to configure the SharePoint - When an item is created trigger.

Create your flow from the blank template
1. Sign in to Power Automate .

2. Select My flows in the left-side navigation pane.

3. On the top-left menu, select New flow > Automated cloud flow.

Add a trigger
1. Give your flow a name.

2. Under Choose your flow's trigger, select When an item is created - SharePoint,
and then select Create.

3. On the When an item is created card, select the Site Address and the List Name
for the SharePoint list that you created earlier.



Get the manager for the person who created
the vacation request

1. Select +New step, and then type get manager into the Choose an action search
box.

2. Find, and then select the Get manager (V2) - Office 365 Users action.

3. Insert the Created By Email token into the User (UPN) box on the Get manager
card.

This action gets the manager for the person who created the vacation request in
SharePoint.



Name and save your flow
Provide a name for your flow, and then select Save to save the work we've done so far.

７ Note

Select the Save icon periodically to save the changes to your flow.

Add an approval action for immediate manager
1. Select New step.

2. Type approval into the Choose an action search box.

3. Select the Start and wait for an approval action.



4. Configure the Start and wait for an approval card to suit your needs.

７ Note

The Approval type, Title and Assigned To fields are required.
You can use
Markdown to format the Details field.



） Important

This action sends the vacation request to the email address in the Assigned To box,
so insert the Email token from the Get manager (v2) list.

Insert a parallel branch approval action for the
sales team

1. Select the down arrow that's located between the Get manager (v2) and the Start
and wait for an approval cards.

2. Select the plus sign that shows up on the down arrow after you select it.

3. Select Add a parallel branch.



4. Search for, select, and then configure a Start and wait for an approval action that
sends the vacation request to the sales team. See the steps used to Add an
approval action for immediate manager if you're not sure how to add the Start
and wait for an approval action.

） Important

Use the sales team's email address in the Assigned To box of the Start an
approval 2 action.

Insert a parallel branch approval action for the
human resources team
Repeat the steps to insert a parallel branch for the sales team to add, and then configure
a Start an approval action to send vacation requests to human resources.

） Important

Use the human resources team's email address in the Assigned To box of the Start
an approval 3 action.

If you've followed along, your flow should resemble this example:



Options after adding parallel branches
After you've added actions to parallel branches, there are two ways to add steps to your
flow:

Insert a step within a branch: Use the Insert a new step (+) button above or below
the card. This button that appears when you select a branch or hover over the
connector arrow). This button adds a step to that specific branch. This button is
shown here:




Add a step to the flow: Use the larger +New step button at the bottom of the
entire workflow. Steps you add with this button run after all previous branches
complete. This button is shown here:


In the following sections, we add steps within each branch:

Add a condition that checks if the vacation request was approved or rejected.
Send an email that informs the employee of the decision.
Update the vacation request in SharePoint with the approval decision.

Then, we use the +New step button to send an email that summarizes all decisions
made on the vacation request.

Let's continue:

Add a condition to each branch
1. Select the first Start and wait for an approval branch.

2. Select the small Insert a new step (+) button below the card (the circular plus
button that appears when you hover over the connector arrow).

3. Select Add an action from the menu that appears, and then select Condition in the
list of actions.

4. Select the first box on the Condition card, and then select the Response token
from the Start and wait for an approval category in the dynamic content list.



5. Confirm the list (in the middle of the Condition card) is set to is equal to.

6. Enter Approve (this text is case-sensitive) into the last box.

7. Your condition card should now resemble this example:

７ Note

This condition checks the response from the Start an approval action that
goes to the employee's manager.

8. Repeat the preceding steps on the Start an approval 2 (the approval request to
sales) and Start an approval 3 (the approval request to human resources)
branches.

Add email actions to each branch
Perform the following steps on the IF YES side of the Condition branch.

Note: Your flow uses these steps to send an email when the request is approved:

1. Select Add an action on the If yes branch of the condition.



2. Enter send email into the search box on the Choose an action card.

3. Select the Send an email (V2) action.

4. Configure the email card to suit your needs.



７ Note

To, Subject, and Body are required.

This card is a template for the email that is sent when the status of the vacation
request changes.

In the Body box on the Send an email (V2) card, use the Comments token from
the Approvals - Start an approval action.

To send an email when a request is rejected, use the IF NO side of the Condition branch,
and then repeat the preceding steps to add a template for the rejection email.

Repeat the preceding steps on the Start and wait for an approval 2 (the approval
request to sales) and Start and wait for an approval 3 (the approval request to human
resources) branches.

Update the vacation request with the decision
Perform the following steps to update SharePoint when decisions are made.

Note: Be sure perform these steps on both the IF YES and the IF NO sides of the branch.

1. Select Add an action in the If yes branch.

2. Enter SharePoint in the search box on the Choose an action card, select the
SharePoint filter, and then select the Update item action.



3. Configure the Update item card to suit your needs.



Repeat the preceding steps on the Start an approval 2 and Start an approval 3
branches.

Complete the flow
1. Select +New step

2. Use the steps provided previously to send an email that summarizes the results of
each approval. Send this email to the employee who requested vacation. Your card
may resemble this example:



Learn more about modern approvals
Introduction to modern approvals



Create an approval flow that requires
everyone to approve
Article • 04/14/2023

This tutorial shows you how to create an approval workflow that requires everyone (all
assigned approvers) to agree for a vacation request to be approved, but any approver
can reject the entire request.

This type of approval workflow is useful in an organization that requires a person's
manager and the manager's manager, to both agree to a vacation request for it to be
approved. However, either manager can decline the request without the other person's
input.

７ Note

While this tutorial highlights a vacation approval scenario, you can use this type of
approval flow in any situation where multiple approvers are required to approve a
request.

Here's a quick video tutorial about approvals.
https://www.microsoft.com/en-us/videoplayer/embed/RWKXdq?postJsllMsg=true

Prerequisites
Access to Power Automate , Microsoft Office 365 Outlook, and Microsoft Office
365 Users.

A SharePoint list .

This tutorial assumes you've created a SharePoint list that's used to request
vacations. See the parallel approvals walkthrough for an in-depth example that
details what your SharePoint list might look like.

 Tip

For detailed information about using SharePoint with Power Automate, go to
the SharePoint documentation.

Familiarity with the basics of creating flows.



You can review how to add actions, triggers, and conditions. The following steps
assume that you know how to perform these actions.

７ Note

While we use SharePoint and Office 365 Outlook in this walkthrough, you can use
other services such as Zendesk, Salesforce, Gmail, or any of the more than 200
services  that Power Automate supports.

Create the flow
This tutorial uses tokens. To display the list of tokens, select any input control, and then
search for the token in the Dynamic content list that opens.

７ Note

If you haven't created a connection to SharePoint or Office 365 previously, follow
the instructions when you're prompted to sign in.

1. Sign in to Power Automate .

2. On the top left of the screen, select My flows > New > Automated-from blank.

3. Name your flow, and then add the SharePoint - When an item is created or
modified trigger.

4. Enter the Site Address for the SharePoint site that hosts your vacation request list,
and then select a list from List Name.

5. Select New step, add another Office 365 Get manager (V2) action, and then add
the Mail token to the User (UPN) box.

The Mail token is located under the Get manager (V2) category of the Dynamic
content list. This token dynamically provides access to the email address for the
manager's manager.

You can also rename the Get manager (V2) 2 card to something meaningful like
"Skip level manager".

6. Select New step, add the Start and wait for an approval action, and then select
Approve/Reject - Everyone must approve from the Approval type list.



） Important

If any approver rejects, the approval request is considered rejected for all
approvers.

7. Use the following table as a guide to complete the Start and wait for an approval
card.

Field Description

Approval type See the approval types.

Title The title of the approval request.

Assigned to The email addresses of the approvers.

Details Any additional information that you want sent to the approvers listed in
the Assigned to field.

Item link A URL to the approval item. In this example, this is a link to the item in
SharePoint.

Item link A text description for the Item link.
description

 Tip

The Start and wait for an approval action provides several tokens, including
Responses and Outcome. Use these tokens in your flow to provide rich
reporting of the results from a run of an approval request flow.

The Start and wait for an approval card is a template for the approval request
that's sent to approvers. Configure it in a way that's useful for your organization.
Here's an example.



When a cloud flow with the Start and wait for an approval action is configured
with Approve/Reject - Everyone must approve, it waits until all Assigned to
approve or at least one Assigned to rejects the approval request.

 Tip

Add a Condition step if you want your flow to check the response of the
approval request and perform different actions based on the Outcome. The
Outcome is an array of Approve or Reject elements, based on the number of
responses to the request.

Let's continue with the flow and send an email when a decision is made on the
approval request.

8. Select New Step, search for "send an email", add the Office 365 Outlook Send an
email (V2) action, and then configure the action to send an email with the results
of the request to the person who wants to go on vacation.

Here's an example of what the Send an email (V2) card might look like.



７ Note

Any action that follows the Start and wait for an approval action runs based on
your selection in the Approval type list on the Start and wait for an approval card.
The following table lists the behavior based on your selection.

Approval types and their behaviors
Approval type Behavior

Approve/Reject - Approval or rejection is needed by all approvers to complete the request.
Everyone must
approve The actions that follow the Start and wait for an approval action run after

all of the approvers approve, or when a single rejection is done.

Approve/Reject - Approval or rejection by any approver completes the request.
First to respond The actions that follow the Start and wait for an approval action run after

any one of the approvers decides.

Custom responses - All approvers must respond to complete the process.
Wait for all responses

Custom responses - A response from any approver completes the process.
Wait for one
response

At the top of the screen, select Save to save your flow.

Congratulations, your flow is complete! If you followed along, your flow resembles this
image.



Now, whenever an item is added to your SharePoint list, or if an item changes, your flow
triggers and sends approval requests to all approvers whom are listed in the Assigned
to box of the Start and wait for an approval card. Your flow sends approval requests via
the Power Automate mobile app and via email. The person who creates the item in
SharePoint gets an email that summarizes the results, clearly indicating if the request
was approved or rejected.

Here's an example of the approval request that's sent to each approver.

Here's an example of what a response and a response summary may look like after your
flow runs.



See also
Single approver modern approvals
Sequential modern approvals
Parallel modern approvals
Approvals and Dataverse
Approve requests on the go



Wait for approval in Power Automate
Article • 04/14/2023

Create a cloud flow that, if you create an item in SharePoint, sends approval email and
then notifies you whether the item was approved or rejected. To follow this tutorial,
create a SharePoint list as a trigger action. You can alternatively use another data source
such as Dropbox or OneDrive.

Prerequisites
Create a SharePoint list that's named Project Tracker, add a column named Title, and
then add a person or group column named Assigned To.

 Tip

For detailed information about using SharePoint with Power Automate, go to the
SharePoint documentation.

Add an event to trigger the flow
1. Sign in to Power Automate .

2. Select My flows in the top navigation bar, and then select Create from blank.

3. Select the Search hundreds of connectors and triggers box, enter new item, and
then navigate to SharePoint - when an item is created.

4. If prompted, sign into SharePoint.

5. Under Site Address, enter the URL of the SharePoint site that contains your list.



6. Under List Name, select the list you created earlier. If you're following along, the
name is Project Tracker.

Add the resulting action
1. Select the New step button, and then select Add an action.

2. In the Search all connectors and actions box, type or paste send email, and then
select Office 365 Outlook - Send email with options.

3. If prompted, sign into Office 365 Outlook.

4. Select the To field, and then select the Assigned to Email token.

The user in the Assigned To column receives the email to approve or reject items.
When you create an item to test the flow, specify yourself in this field. That way,
you not only approve or reject the item, but also receive the notification email.

You can customize the Subject and User Options fields to suit your needs.

Add a condition
1. Select the New step button, and then select Add a condition.

2. Select the first box, and then select the SelectedOption token.

3. Select the last box, and then type Approve.



4. In the If yes area, select Add an action.

5. In the Search all connectors and actions box, type or paste send email, and then
select Office 365 Outlook - Send an email.

6. In the To field, enter a recipient such as Created by Email.

7. In the Subject box, specify a subject.

For example, select Assigned To DisplayName, type has approved with a space on
each side, and then select Title.

8. In the Body box, specify an email body such as Ready to proceed with the next
phase of the project.

The person who created the item in the SharePoint list will be notified whether the
project was approved or rejected.

9. In the If no area, repeat the previous steps, except change the Subject and Body to
reflect that the project was rejected.

Finish and test your flow
Give your flow a name, and then select Create flow.

An approval email is sent to the recipient that you specified. When the recipient selects
Approve or Reject in that email, you receive email that indicates the response.

See also
Single approver modern approvals walkthrough
Create sequential approvals
Create parallel approvals
Approve requests on the go



Approve requests on your mobile device
by using Power Automate
Article • 12/16/2022

If a cloud flow identifies you as an approver and you've installed the mobile app for
Power Automate, you receive a push notification whenever your approval is requested.

This article walks you through a few common scenarios that you’re likely to encounter
while you manage approval requests in the mobile app for Power Automate.

７ Note

The images in this topic are from an Android device; however, the experience on
iOS is similar.

Prerequisites
To complete this walkthrough, you need:

An Android  or iOS  device running the mobile app for Power Automate.
To be designated as the approver in an approval flow.
Pending requests for approval.

View pending requests
1. Open the mobile app for Power Automate.



2. Select APPROVALS in the upper-right corner.



3. View all pending approvals:



If you don't have any pending approval requests, create an approval flow, set yourself as
an approver, and then trigger the flow. Approval requests appear in the approval center
a few seconds after the flow triggers and sends a request for approval.

Approve requests and leave an optional
comment

1. If you haven't done so, follow the preceding steps to view pending requests.

2. Select APPROVE on the request that you want to approve.



3. (Optional) select Add comment (optional).



Enter a comment on the Add comment screen.



4. Select CONFIRM in the upper-right corner.

The success screen displays after the flow records your decision.



Reject requests and leave an optional comment
Follow the steps to approve a request, but select REJECT in the second step.

Learn more
Create modern approval flows.



Request approvals from Microsoft 365
groups
Article • 04/14/2023

You can send approvals to Microsoft 365 groups and to individuals. It's useful to send
approvals to groups in scenarios where you need an approval from any one person in
the group. For instance:

You need the approval of a representative of the leadership team for a project.

You want the copy of the new marketing material to be approved by someone on
the social media team.

 Tip

Only a single user from the group needs to respond to the approval. That user's
response is used to represent the entire group.

Send an approval to a Microsoft 365 group
Approvals to groups behave exactly like approvals to users, it's just the entity that the
approval is being sent to that's different. Let's look at a simple example.

７ Note

This example uses the First to respond action, but you can combine this action with
other types of approvals as well.

Create the flow
1. Sign in to Power Automate .

2. Select My flows > New > Instant — from blank.

3. Give your flow a name.

4. Search for and then select Manually trigger a flow.

5. Select Create.



6. Select the Manually trigger a flow trigger > Add an input > File.

This step configures your flow so that when it runs, it requests a file from the user
to trigger your flow.

7. Select New step.

8. Search for Approvals, and then select Start and wait for an approval.

9. On the Start and wait for an approval card, for Approval type, select
Approve/reject - First to respond.

10. Enter the following:

Title: This is a short description that gives the approver some details about
the approval request.
Details: This text shows up in the approval request.

11. In the Assigned to field, start entering the name of the group to which you want to
send the approval. The Assigned to field accepts both user and Microsoft 365
group inputs. If you know the email ID associated with the group, you can include
that as well.

 Tip

You can include multiple groups and users in the Assigned to field.

12. Select Save to save your flow.



Test your flow
1. Select Test.

2. Select I'll perform the trigger action.

3. Select Test > Continue.

4. Select Run flow.

You'll see that the test run starts.

5. Select Flow Runs Page to monitor the status of the test.

Approve the request
For mail-enabled groups, the group to which the approval is sent receives a notification
to respond to the approval. Members of the group can also view the approval in the
Approvals action center on the Power Automate portal and in the Approvals app in
Microsoft Teams.

What to expect when you send approval
requests to groups and users
You can choose to send an approval to multiple groups, or even a combination of
groups and users. Here are a few examples of such scenarios and their expected
outcome:

The First to respond approval sent to group 1 and group 2: At least one user from
either group 1 or group 2 needs to approve.

The Everyone must respond approval sent to group 1 and group 2: At least one
user from both group 1 and group 2 needs to approve.

The First to respond approval sent to group 1 and user 1: At least user 1 or one
member from group 1 needs to approve.

The Everyone must respond approval sent to user 1 and group 1: Both user 1 and
at least one member from group 1 needs to approve.

Known issues and limitations
1. Only mail-enabled Microsoft 365 groups and security groups are supported.



2. Teams notifications aren't supported with group approvals. Teams notifications are
sent only for approvals that are assigned to individual users.

3. The group must allow email from external senders to receive email notifications.

4. When you create an approval for a newly created Microsoft 365 group, there maay
be a small time period where Outlook actionable emails can present an error.

Add a condition to an approval flow
In most approval flows, you'd want to notify the person who requests the approval of
the decision. To learn how to add a condition to an approval flow to take specific actions
based on the outcome of the request, go to Add an email action for approvals.



Build an approval loop by using Power
Automate and Dataverse
Article • 04/14/2023

Dataverse can give you a way to build flows that have information stored in a database
independent of a cloud flow. The best example of this is with approvals. If you store the
status of the approval in a table, your flow can work on top of it.

In this example, you'll create an approval process that starts when a user adds a file to
Dropbox. When the file is added, information about it appears in an app, where a
reviewer can approve or reject the change. When the reviewer approves or rejects the
change, notification mail is sent, and rejected files are deleted from Dropbox.

By following the steps in this section, you'll build:

a custom table that will contain information about each file added to Dropbox and
whether the file's status is approved, rejected, or pending.
a flow that adds information to the custom table when a file is added to Dropbox,
sends mail when the file is approved or rejected, and deletes rejected files. These
steps demonstrate how to build such a cloud flow from scratch, but you can create
a similar flow from a template.
an app in which a reviewer can approve or reject files added to Dropbox. You'll use
Power Apps to generate this app automatically based on the columns in the
custom table.

Prerequisites
Sign up for Power Automate and Power Apps.

Create connections to Dropbox and Office 365 Outlook, as Manage your
connections.

Build the table
1. Sign in to Power Apps .

2. On the left navigation bar, select Tables.

3. Select New table and then New table.



4. Specify a display name and a plural name for the new table. In this example, both
names are ReviewDropboxFiles. Optionally, you can add a description.

5. Select Save to save the table.

Add columns to the table
1. Select the ReviewDropboxFiles table in the Tables page, and then select New >

Column.



2. Create a new column named Approver with the following properties:

Set Display Name to Approver.
Set Data type to Single line of text.
Set Format to Email.
Set Required to Business required.

3. Create a new column named Status with the following properties:

Set Display Name to Status.
Set Data type to Single line of text.
Set Format to Text.
Set Required to Business required.

4. Create a new column named File identifier with the following properties:

Set Display Name to File identifier.
Set Data type to Single line of text.
Set Format to Text.
Set Required to Business required.

Sign in and create a cloud flow
1. Sign in to Power Automate .

2. On the top right menu, select the environment in which you created the database.
If you don't select the same environment, you won't see your table.

3. Go to My flows and select New flow > Automated cloud flow.

Start when a file is added
1. In the Build an automated cloud flow dialog, enter a name for the flow and search

for the When a file is created Dropbox trigger.

2. Under Folder, select the folder icon, and then browse to the folder where files will
be added.

Add data to the table
1. In the designer, select New step and search for the Add a new row Dataverse

action.



2. Configure the action as presented in the following screenshot:

a. In the Table name drop-down menu, select the ReviewDropboxFiles table.

b. In the Approver field, enter the email address of the person who will review the
files.

c. In the File identifier field, select File identifier from the Dynamic content list.

d. In the Name field, select File name from the Dynamic content list.

e. In the Status field, enter Pending.

Check whether the file has been reviewed
1. Under the Add a new row action, select New step and search for the Do until

action.

2. Configure the Do until action as presented in the following screenshot:

a. Select the left box in the action and select Status from the Dynamic content list.

b. In the middle drop-down menu, select is not equal to.

c. In the right box, enter Pending.

3. Inside the Do until action, select Add an action and search for the Get a row by ID
Dataverse action.

4. Configure the Get a row by ID action as presented in the following screenshot:

a. In the Table name drop-down menu, select the ReviewDropboxFiles table.



b. In the Row ID field, select File identifier from the Dynamic content list.

Check whether the item has been approved
1. Under the Do until action, select New step and search for the Condition action.

2. Configure the Condition action as presented in the following screenshot:

a. Select the left box in the action and select Status from the Dynamic content list.

b. In the middle drop-down menu, select is equal to.

c. In the box on the right, enter Approved.

Send notification mail
1. Under the If yes action, select Add an action and search for the Send an email

(V2) Office 365 Outlook action.

2. Configure the Send an email (V2) action as presented in the following screenshot:

a. In the To field, enter the email address of the person whom you want to notify
when an item is accepted.

 Tip

To make testing the flow easier, specify your own address. You can change
it when the flow is ready for actual use.

b. In the Subject field, select File name from the Dynamic content list.

c. In the Body field, enter The item has been approved..

3. Under the If no action, repeat the step 2, but specify the body of the email
message as The item has been rejected.

Delete rejected files
1. Under the Send an email (V2) action for the rejection mail, select Add an action

and search for the Delete file Dropbox action.

2. In the File field, select File identifier from the Dynamic content list.



Save the flow
1. At the top of the screen, enter a name for the created cloud flow, and select Save.

2. In Dropbox, add at least two files to the folder that you specified: one to test
approval and one to test rejection.

Build the app
1. Sign in to Power Apps .

2. Go to the Create page and then select Dataverse.

3. Select your Dataverse connection, and then the ReviewDropboxFiles table.

If this is your first time, you're prompted to create a connection to Dataverse.

4. If the Welcome to Power Apps Studio dialog box appears, you can follow it or skip
it.

Customize the app
At this step, the app should contain three screens to browse, see the details and edit the
entries, respectively.

To add or remove fields from a screen:

1. Select the desired screen on the Tree view.

2. Select the root element of the screen.

3. Select Edit in the right pane.



The current example contains the following fields for each screen:

In the browse screen, there are fields for the Name and Status columns of the
Dataverse table.
In the details screen, there are fields for the Name, Status, File identifier, and
Approver columns of the Dataverse table.
In the edit screen, there's a field for the Name column and an edit text field for the
Status column of the Dataverse table.

Test the overall solution
1. In Power Apps, open the preview mode selecting the play button on the toolbar.

2. Select the arrow next to the first file in the list to see the details about it.

3. Select the pencil icon to change the details of the file.

4. In the Status box, enter Approved and select the checkmark icon to save your
changes. In a few minutes, you'll receive an email stating that the file was
approved.

5. Repeat the previous steps but enter Rejected (or anything except Approved) in the
Status field. In a few minutes, you'll receive an email stating that the file was
rejected, and the file will be deleted from Dropbox.



Use Markdown language in Power
Automate approval requests
Article • 07/11/2023

This article shows you how to use [Markdown]
(https://en.wikipedia.org/wiki/Markdown  syntax to add rich formatting to your
approval requests.

） Important

Approval request emails are actionable messages. If your Microsoft Outlook
client doesn't support actionable messages, it displays approval requests in
HTML format.
All markdown renderers have implementation differences. For details, review
the Client Support section.
Markdown isn't currently supported for the Approvals app on Microsoft
Teams.

Client Support
Markdown support among clients is inconsistent. The Power Automate team works to
address these inconsistencies, however, inconsistencies remain. The following table lays
out the known limitations among the supported clients.

Feature Power Power Outlook Outlook Teams Teams Approvals
Automate Automate Web mobile Teams

mobile app App
app

Headers Yes Yes Yes Yes No No No

Numbered Yes Yes No Yes Yes Yes No
Lists

Nested Yes Yes No Yes Yes Yes Yes
Numbered
Lists

Tables Yes Yes Yes Yes No No No

Images No No No No No No No



Feature Power Power Outlook Outlook Teams Teams Approvals
Automate Automate Web mobile Teams

mobile app App
app

Forced Line Yes* Yes* No (use a Yes* Yes* Yes* No
Breaks blank line

instead)

Blank Lines No No Yes Yes No Yes No

Emphasis Yes Yes Yes Yes No No No

*Forced line breaks within table cells aren't supported for Power Automate, the Power
Automate mobile app, Outlook Web, Teams, and the Teams mobile app.

７ Note

For Outlook Mobile, the previous parameters can vary depending on the Outlook
client app and version that you're using.

Headers
Structure your comments using headers. Headers segment longer comments, making
them easier to read.

Start a line with a hash character #  to set a heading. Organize your remarks with
subheadings by starting a line with additional hash characters, for example #### . Up to
six levels of headings are supported.

Example:

Markdown

# This is a H1 header
## This is a H2 header
### This is a H3 header
#### This is a H4 header
##### This is a H5 header



Result:

Paragraphs and line breaks
Make your text easier to read by breaking it up with paragraphs or line breaks. Enter two
spaces prior to the line break to force most clients to start a new line.

Example:

Markdown

This is line 1.(space)
Now text will appear on the next line.

Result: This is line 1.
Now text will appear on the next line.

Example 2

Markdown

This is line 1.(space, space)  

Line 2 has extra space before it.

Result:
This is line 1.

Line 2 has extra space before it.

Lists
Organize related items with lists. You can add ordered lists with numbers, or unordered
lists with just bullets.



Ordered lists start with a number followed by a period for each list item. Unordered lists
start with a * . Begin each list item on a new line. In a Markdown file or widget, enter
two spaces prior to the line break to begin a new paragraph, or enter two line breaks
consecutively to begin a new paragraph.

Ordered or numbered lists
Example:

Markdown

1. First item.
1. Second item.
1. Third item.

Result:

1. First item.
2. Second item.
3. Third item.

Bullet lists
Example:

Markdown

- Item 1
- Item 2
- Item 3

Result:

Item 1
Item 2
Item 3

Nested lists
Example:

Markdown



1. First item.
   - Item 1
   - Item 2
   - Item 3
1. Second item.
   - Nested item 1
   - Nested item 2
   - Nested item 3

Result:

1. First item.

Item 1
Item 2
Item 3

2. Second item.

Nested item 1
Nested item 2
Nested item 3

Links
Use HTTPS links, which are rendered as links in all clients. Non-HTTPS links (for example,
FTP, HTTP, and mail) can be rendered as regular text.

You can set text hyperlinks for your URL using the standard markdown link syntax:

Markdown

[Link Text](Link URL)

Example:

Markdown

[Power Automate](https://make.powerautomate.com)

Result:
Power Automate



Tables
Organize structured data with tables.

Place each table row on its own line
Separate table cells using the pipe character |
The first two lines of a table set the column headers and the alignment of elements
in the table
Make sure to end each row with a CR or LF.
Aligning text within a table element is currently not supported.

Example:

Markdown

| Heading 1 | Heading 2 | Heading 3 |
|-----------|-----------|-----------|
| Cell A1 | Cell A2 | Cell A3 |
| Cell B1 | Cell B2 | Cell B3 |

Result:

Heading 1 Heading 2 Heading 3

Cell A1 Cell A2 Cell A3

Cell B1 Cell B2 Cell B3

Emphasis (bold, italics, strikethrough)
You can emphasize text by applying bold, italics, or strikethrough to characters.

To apply italics: surround the text with an asterisk *  or underscore _
To apply bold: surround the text with double asterisks ** .
To apply strikethrough: surround the text with double tilde characters ~~ .

Combine these elements to apply multiple emphases to text.

Example:

Markdown

Use _emphasis_ in comments to express **strong** opinions and point out 
~~corrections~~ 



**_Bold, italicized text_**  
**~~Bold, strike-through text~~**

Result:
Use emphasis in comments to express strong opinions and point out corrections
Bold, italicized text
Bold, strike-through text

Special characters
Syntax Example/notes

To insert one of the following characters, Some examples on inserting special characters
prefix with a backslash: Enter ```\\``` to get \\

\ backslash Enter ```\_``` to get \_

` backtick Enter ```\#``` to get \#

_ underscore Enter ```\(``` to get \(

{} curly braces Enter ```\.``` to get \.

[] square brackets Enter ```\!``` to get \!

() parentheses

# hash mark

+ plus sign

- minus sign (hyphen)

. dot

! exclamation mark



Create custom response options for
approval flows
Article • 04/14/2023

Let’s say you want to send an approval request each time an employee uploads an
expense report to SharePoint and then allow the approver to respond with one of three
options: Accept, Need more info, or Reject.

Prerequisites
A Power Automate account.
A SharePoint list for employees to enter their expense reports.

 Tip

For detailed information about using SharePoint with Power Automate, go to the
SharePoint documentation.

Create approval flow
1. Sign in to Power Automate .

2. On the left navigation bar, select My flows.

3. Select New > Automated-from blank.

4. On the screen that opens, provide a name for your flow in Flow name.

5. In Choose your flow's trigger field, search for SharePoint.

6. From the list of triggers, select When an item is created.

7. Select Create.



8. Provide the SharePoint Site Address and List Name.

 Tip

Select Enter custom value from the Site Address field before you enter text
into Site Address.

9. Select New step, search for Approval, and then select Start and wait for an
approval.

10. On the Start and wait for an approval card, select the Approval type list.

11. Select Custom Responses - Wait for one response.

Next, you'll create the custom responses that your approvers will use when they
respond to an approval request for an employee expense.

12. In the Response options Item box, enter Accept and then select Add new item.



13. In the Response options Item box, enter Reject and then select Add new item.

14. In the Response options Item box, enter Need more info.

15. Enter a Title, Assigned to (email for the approver), and Details (the details to be
contained in the approval request).

Here's an example of what you might include for your organization.

Now that you've created your custom responses, you might want to do different things
in your flow, depending on the response from the approver.



Use approval responses
If the response to the request is Accept, you might want to send an email to the
accounting department, asking them to reimburse the employee for the expense.

If the response is Reject, you might want to send an email to the employee, letting them
know that the request was rejected.

And finally, if the response from the approver is Need more info, you might want to
send an email to the employee, requesting the employee to provide more information.

To do any of these in the flow, add a Condition or a Switch action to your flow, and then
select the Outcome field of the approval request from the dynamic content picker. Be
sure to confirm whether the value is Accept, Need more info, or Reject.

Respond to approval requests with a custom
response
Approvers receive approval requests in email. The requests are also displayed in the
approval center on Power Automate.

Limitations
Outlook and Outlook Web Access (OWA) actionable messages have a limit of five
custom responses. This means that only the first five responses that are defined within
the flow will be visible in the actionable section of Power Automate approval emails. You
can submit the remaining options via a non-actionable HTML email, the Power
Automate approval center, the Power Automate mobile application, or Teams.



Approvals that rely on custom responses can fail if they're sent to many users with the
type set to Everyone must approve. This failure is due to the data size limitations of the
results field.

７ Note

For approvals using a single custom response, Outlook and OWA expand the
response field so users do not need to select a button before they can respond like
they do when there are multiple approval options.

Related information
Create single approver flows
Create sequential approver flows

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Known issues
Article • 01/30/2024

Work with guest users
If you assign a guest user to an approval, that user can't view or act on the approval by
default. The guest user must be assigned a valid Power Automate license (per user
license or Microsoft 365-based user license) to view or respond to the approval.

Adaptive cards mismatch in Microsoft Teams
There are multiple ways in which you can notify an approver when a flow runs. By
default, all flows that handle approvals send an email notification. You can also send an
adaptive card with the approval to users in Microsoft Teams. If the approver responds
through the email notification or through the approval action center, the card in
Microsoft Teams won't auto-update. This can lead to situations where there's a
mismatch between the status shown on the adaptive card and that of the flow.

To avoid this, you can disable the default notification email sent to the user as part of
approval creation.



Abandoned approvals in the approval action
center
As part of the flow, you can send an approval request to a user and wait for a response.
An approval flow can wait for 28 days. If the wait time exceeds 28 days, that flow fails.
This only impacts the flow itself, meaning that the approval continues to exist in the
action center. This can lead to cases where there are abandoned approvals in the



approval action center that have no flow waiting on them. The requestor or environment
admin then needs to manually delete these approvals from the action center.

Anchors
Anchor links aren't supported. Unexpected results occur if you use anchors.

Data templating
Data templating isn't fully supported for adaptive cards in Power Automate. As a
workaround, use actions like compose, filter, select, and apply to each to manually
construct the card within your flows.

Approvals with custom responses set to
Everyone must approve
Approvals that rely on custom responses can fail if they're sent to many users with the
type set to Everyone must approve. This failure is due to data size limitations of the
results field.

Update a Power Apps (V2) trigger to invoker
connection
The Power Apps (V2) trigger supports both embedded and invoker connections. When
you update the connections in your Power Apps (V2) trigger to invoker connections, you
must refresh or remove and re-add the flow in the app and save the app.

To learn more, go to Known issues with Power Apps (V2) trigger.

Split create and wait actions
It's possible to create flows with the approval connector where you use the Create an
approval and Wait for an approval as independent actions. If a user immediately
responds to an approval request before the flow reaches the wait action, it's possible for
the flow to become stuck in the wait stage. To avoid getting the flow stuck, ensure that
the create and wait actions are called close together within the flow. Alternately, change
the status of the approval in Dataverse before you call the wait action.



Use approval outcomes in loops
When you use approvals with do until loops, users need to account for all possible
outcomes of a flow. If not, the flows could be stuck in infinite loops. For basic and await
all approvals, the final states can be Approved, Rejected, or Canceled. Custom approvals
are based on what the user chooses to have as the options for the approval. Use a
condition or switch statement with approval flow instead of do until loops.

View details of an approval
To view details of an approval, select an individual approval to open it. Formerly, you
could also view the details in the Details column on the Received tab of the Approvals
list view, but this column is now removed.

Issues with email notifications
Here's an explanation of the process for sending an approval email notification, and a
description of the possible email notification statuses and troubleshooting.

Sending approval email notifications is a two-step process:

1. Power Automate places a request for the email to be sent.
2. The email goes into a queue.

Reply to an approval email
When you reply to an approval email notification, you must add your intended
recipient(s) to the To: line. Previously, the person who sent you the approval request
would be automatically added to the To: line when you selected Reply, but now it must
be done manually.

Email status definitions
ﾉ Expand table

Status Description

Pending Power Automate is requesting that the notification is sent.

Requested Power Automate successfully placed the request for the notification to be sent, but
the request is still being processed.



Status Description

Sent The email notification was correctly sent.

Failed The email notification was correctly placed in the queue, but there was an error
sending it.

Missing emails
If the status of your email notification is Sent but you don't see the email notification,
try the following options:

Refresh your inbox and verify that you have an active Internet connection.
Confirm that the email address is correct for the intended recipient.
Review your email settings and verify if there are any filters or blocked addresses
that may prevent you from seeing the notification.
Check your spam or promotions folder.

Troubleshoot failed requests
If the status of your email notification is Failed, you can try the following options:

Make another request to the same recipients.
Raise a ticket to Microsoft Support, detailing the issue.



Overview of using Outlook and Power
Automate
Article • 02/01/2025

Connectors represent the service to which you want to connect. For example, you can
use the OneDrive, SharePoint, or Twitter connectors to use those services. Two of the
most popular connectors used in flows to send or receive email are the Outlook.com
connector and the Office 365 Outlook connector. Both connectors offer similar
operations that you can use to manage your mail, calendars, and contacts. You can
perform actions such as send mail, schedule meetings, add contacts, and more with
either of these connectors.

Outlook.com or Office 365 Outlook: Which
connector should I use?
If you're using a work or school email account, use the Office 365 Outlook connector. If
you're using a personal account (Microsoft account), use the Outlook.com connector. In
this article, we refer only to the Office 365 Outlook triggers and actions. You can also use
the same techniques for the Outlook.com connector.

Triggers
A trigger is an event that starts a cloud flow. For example, When a new email arrives
(V3) is a trigger that starts a cloud flow when an email arrives into an inbox. You can also
trigger flows based on the properties of an email. More information: Trigger a cloud
flow based on email properties.

The following screenshot shows a partial list of the Office 365 Outlook triggers. For the
full list of triggers you can use to start flows, go to Office 365 Outlook triggers.



Actions
Actions are the events you want the flow to do after the trigger event takes place. An
example of an action is, "when someone sends me an email, save it to OneDrive."

The following screenshot shows a partial list of Office 365 Outlook actions. For the full
list of actions you can use in your flows, go to Office 365 Outlook actions.



Related information
Create flows for popular email scenarios
Create flows to manage email
Customize email in flows
Training: Enhance productivity with Power Automate and the Office 365 Outlook
Connector (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create flows to manage email
Article • 10/09/2024

Here are some of the most frequently used ways to create flows to manage your email.

Power Automate offers many templates for you to create flows. You can use these
templates "as is" or you can make any adjustments that your scenario needs. If you
don't find a template that matches your scenario, you can create a cloud flow without a
template. You can also create a flow from connectors.

1. Use a template: Most likely, there's already a template  that accomplishes your
scenario. Search for your scenario among the templates, and then follow the steps
to create a cloud flow from the template.

2. Tweak a template: If you find a template that's similar to your scenario, but it
doesn't do exactly what you want, you can create a cloud flow from that template
and then tweak the flow to your liking. You can extend a cloud flow that you
created from a template by adding, editing, or removing triggers and actions.

 Tip

You can copy and paste actions in the same flow or across flows to speed up
the process.

3. Create a cloud flow from scratch: If you can't find a template that's similar to your
scenario, you can create a cloud flow from scratch and then connect the services
you want.

4. Create a cloud flow from a connector: In Power Automate, select Connectors
from the left side of the screen, search for the connector you want, and then select
it to create your flow. For example, search for outlook to find connectors for
Outlook for Microsoft 365.

Related information
Overview of using Outlook and Power Automate
Customize email in flows
Create flows for popular email scenarios
Training: Create flows to manage email (module)



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create flows for popular email scenarios
Article • 10/09/2024

Here are some of the top scenarios in which you can use Power Automate to manage
your email.

Send an email from your account.
Send an email from a distribution list or shared mailbox.
Send an email with voting options.
Build an approval process and notify colleagues via email.
Send a reminder email to approvers.
Send a daily digest email with a summary table.

Send email from your account
To send email from your account, use the Send an email (V2) action.

You can send the email to one or more recipients. You can use the rich text editor to
make text bold, add color, and format the email similar to the way you do in Outlook.
You can add static text or values from previous actions by using dynamic content. You
can use the send as option to send email as someone else, or on behalf of someone
else. To use this option, you'll need the permissions in Outlook to send on another
person's behalf. You can find all email you send in your Sent items folder in Outlook.

For example, if you have a cloud flow that sends you an email as soon as your item is
approved, you can add the link of the approved item as an attachment.



Send email with voting options
Use the Send email with options action to send an email with voting options using
actionable email. Provide voting options in the User Options field.

The recipients receive an email similar to the following screenshot.



In your flow, you must capture that response and save it somewhere. You might email it
to yourself, save it to Excel, or post it to Microsoft Teams. Don't forget to save it,
otherwise you won't know how people voted.

Send an email from a distribution list or shared
mailbox
Use the Send an email from a shared mailbox (V2) action, and specify the shared
mailbox address to send email from a shared mailbox.

The distribution list admin must first give you permissions to the shared mailbox. When
you use this action, email appears in the Sent folder of your shared mailbox because
you're sending it from that account directly.

Build an approval process and send
notifications via email



You can use Power Automate to build an approval process that notifies users via
email .

Send reminder email to approvers
You can also send reminder emails for approval requests .

Send a daily digest email with a table
Here are three ways you can send a daily digest email with a table.

Use the Data Operation – Select action to create a table with the column names
and data you'd like to appear in the email. You can further format the data by
using expressions. In following example, the flow gets calendar events within a
certain timeframe, converts the time zones, and then creates a table with the
events.

Add the Create HTML Table action, and then add the output from the select action
to the HTML action.

Add the Send an email (V2) action, and then add the output from an HTML table
into the body of the email.

Related information
Overview of using Outlook and Power Automate
Create flows to manage email
Customize email in flows
Training: Create flows to manage email (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Trigger a cloud flow based on email
properties
Article • 04/01/2025

Use the When a new email arrives (V3) trigger to create a cloud flow that runs when
one or more of the following email properties match criteria that you provide.

ﾉ Expand table

Property When to use

Folder Trigger a cloud flow whenever emails arrive in a specific folder. This property can
be useful if you have rules that route emails to different folders.

To Trigger a cloud flow based on the address to which an email was sent. This
property can be useful if you receive email that was sent to different email
addresses in the same inbox.

CC Trigger a cloud flow based on the CC address to which an email was sent. This
property can be useful if you receive email that was sent to different email
addresses in the same inbox.

From Trigger a cloud flow based on the sender's email address.

Importance Trigger a cloud flow based on the importance with which emails were sent. Emails
can be sent with high, normal, or low importance.

Has Trigger a cloud flow based on the presence of attachments in incoming emails.
Attachment

Subject Filter Search for the presence of specific words in the subject of an email. Your flow
then runs actions that are based on the results of your search.

） Important

Each Power Automate plan  includes a run quota. Always check properties in the
flow's trigger when possible. Doing so avoids using your run quota unnecessarily. If
you check a property in a condition, each run counts against your plan's run quota,
even if the filter condition that you defined isn't met.

For example, if you check an email's From address in a condition, each run counts
against your plan's run quota, even if it's not from the address that interests you.



In the following tutorials, we check all properties in the when a new email arrives (V3)
trigger. Learn more by visiting the frequently asked billing questions and the pricing
page.

Prerequisites
An account with access to Power Automate .

An email account with Outlook for Microsoft 365 or Outlook.com.

The Power Automate mobile app for Android , iOS , or Windows Phone .

Connections to Office, Outlook, and the push notification service.

Trigger a cloud flow based on an email's
subject
In this tutorial, we create a cloud flow that sends a push notification to your mobile
phone if the subject of any new email has the word "lottery" in it. Your flow then marks
any such email as read.

Although this tutorial sends a push notification, you're free to use any other action that
suits your workflow needs. For example, you might store the email contents in another
repository such as Google Sheets or a Microsoft Excel workbook stored on Dropbox.

1. Sign in to Power Automate .

2. On the left pane, select My flows.

3. Select New flow > Automated cloud flow.

4. In the Flow name field, enter a name for your flow.

5. In the Choose your flow's trigger field, enter new email.

6. Select When a new email arrives (V3) from the list of triggers. This trigger runs
each time an email arrives.

7. Select Create.

8. Select the folder that you'd like the flow to monitor for incoming emails, and then
select Show advanced options.



To display all your email folders, select the Show Picker icon, which is located on
the right side of the Folder box on the When a new email arrives (V3) card.

７ Note

Power Automate uses either the classic cloud flows designer or the new
modern designer with Copilot capabilities. To identify which designer you’re
using, go to the Note section in Explore the cloud flows designer.
When you switch between the classic and new designer, you're asked to save
your flow. You can't save and switch until all errors are resolved.

New designer

1. Simply ask Copilot to create your flow by typing the following prompt:

When I receive an email that contains the word 'lottery' in the subject, send
me a push notification and mark the email as Read.

2. Review the connections and parameters on the designer.

3. Save the flow.

Trigger a cloud flow based on an email's sender
In this tutorial, you create a cloud flow that sends a push notification to your mobile
phone if any new email arrives from a specific sender (email address). The flow also
marks any such email as Read.



New designer

1. Simply ask Copilot to create your flow by typing the following prompt:

When I receive an email from jake@contoso.com, send me a push
notification and mark the email as Read.

2. Review the connections and parameters on the designer.

3. Save the flow.

Trigger a cloud flow when emails arrive in a
specific folder
If you have rules that route emails to different folders based on certain properties, such
as the address, you might want this type of flow.

７ Note

If you don't already have a rule that routes email to a folder other than your inbox,
create such a rule and confirm it works by sending a test email.

New designer

1. Simply ask Copilot to create your flow by typing :



When I receive an email in Sync Issues folder, send me a push notification
and mark the email as Read.

2. Make sure the folder is selected in email trigger, if it isn't already applied by
Copilot.

3. Your flow is ready to be used. Simply save the flow and your automation is
running.

4. Test your flow by sending an email to the folder you specified.



Related information
Training: Create flows to manage email (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Customize email in flows
Article • 03/28/2025

Here are the top how-to scenarios for email in Microsoft Power Automate, with
examples of how to achieve them.

1. Send a beautifully formatted email.
2. Add an image to your email (includes video).
3. Send email to a distribution list.
4. Send automatic replies from a shared mailbox.
5. Change the date and time format of an email.

Send a beautifully formatted email
You can use HTML to beautify your email. Following are two options that you can use to
beautify your messages with HTML.

７ Note

Power Automate uses either the classic cloud flows designer or the new
modern designer with Copilot capabilities. To identify which designer you’re
using, go to the Note section in Explore the cloud flows designer.
When you switch between the classic and new designer, you're asked to save
your flow. You can't save and switch until all errors are resolved.

New designer

[This topic is prerelease documentation and is subject to change.]

In the Edit with Copilot designer, you can simply format the email body with rich
controls like bold, italics, headers, and more.



Add an image to your email
Outlook takes the image you included in your email and converts it to plain text. Instead
of copying/pasting the plain text into Power Automate, follow these steps:

1. Upload the image to cloud-based storage, such as Google Drive or OneDrive for
Business.

2. Get the anonymous visitor URL to the image.

3. In the Power Automate Send an email action, do the following:

a. Go to the HTML section of the rich text editor.

b. Look for <image src= in the HTML.

c. Change the value of the src property to the URL of the image from the cloud-
based storage provider where you uploaded the image.



Your src should be similar to: <image src="https://url/to/your/images.png"/>.

） Important

Inline images are limited to a size of 100 KB. This might affect the quality of
the image.

Learn more about how to include an image from OneDrive in this quick video:

https://learn-video.azurefd.net/vod/player?id=b5c93ea2-c39a-4903-bba8-
65ad22fa390d&locale=en-us&embedUrl=%2Fpower-automate%2Femail-customization

Send email to a distribution list
The Send an email action can send messages to an email-enabled security group or
distribution list. Each member of the email-enabled security group or distribution list
receives the email in their group mailbox rather than their own mailbox.

Alternatively, follow these steps if you want users to receive the email in their mailbox.

1. Add the Get group members action from the Microsoft Entra ID connector, and
then select the distribution list.

2. Under the action Microsoft Entra ID-Get group members, add an Apply to each
action.

3. Inside the Apply to each action, add the Send an email action, and then add the
group members from the Get group members action as dynamic content in the To
field.



Send automatic replies from a shared mailbox
You can do this in the web version of Outlook.

1. Sign in to the web version of Outlook at https://outlook.office365.com  with your
Office 365 credentials.

2. Select your profile image (or placeholder image) in the upper-right corner.
3. Select Open another mailbox.
4. Enter the name or email address of the shared mailbox, and then select it.
5. Select Settings in the upper-right corner, and then select Automatic replies.
6. Configure your automatic reply.

Change the date and time format of an email
By default, the email you receive shows the Coordinated Universal Time (UTC) time zone.
However, your users might want to change it to their local time zone. For instructions,
go to Converting time zone in Microsoft Power Automate  to convert the time zone.

Related information



Overview of using email with flows
Create flows to manage email
Create flows for popular email scenarios
Training: Create flows to manage email (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Troubleshoot common issues with email
in flows
Article • 10/09/2024

Known limitations
For known limitations of the Send an email action, go to Office 365 Outlook: Known
issues and limitations.

Frequently asked questions
I didn't get an email. Why?

1. Confirm that your IT department has approved all Power Automate endpoints to
allow it to send email to your email servers. These endpoints include IP addresses
and domains .

2. Double-check whether you have any Outlook rules that are moving the email to a
different folder.

3. Check whether you're using the Focused inbox feature. Check whether the email
landed in another folder.

I didn't get an email, and the send an email action looks stuck in my flow.

If you're using the Mail connector, note that it has a limit of 100 API calls per 24 hours.
Try the Office 365 Outlook connector, which has a limit of 300 API calls per 60 seconds
instead, so you'll be less likely to hit the limit.

I have a cloud flow that is triggered when an email arrives in a folder. Will my flow
trigger if I move email from one folder to another folder?

No. Your flow will be triggered only when a new email arrives.

I'm trying to send an email to all the approvers. I see an Apply to each action around
the Send an email action, causing separate emails. I want to send an email to all of
them.

Apply to each is added because there are multiple approvers. You can create a string
variable (as opposed to an array) and store email addresses, separated by semicolons, in
it.



I don't get an attachment for some of my approvals.

The Approval action attaches files to a notification email until the size of the email
reaches 5 MB. If the attachments exceed 5 MB, the approval email directs the approver
to check the attachments in the Power Automate approval center.

How do I increase the email attachment size limit for Power Automate?

A Microsoft Dataverse administrator can change the limit by going into Microsoft
Dataverse > Email Configuration settings, and then setting the file
size limit for attachments.

Power Automate stopped working - I get "Item ID doesn't belong to current mailbox"
error in Power Automate when using actions with shared mailbox.

As of May 6, 2020, shared mailbox support was added for certain operations with an
optional Mailbox address parameter, allowing you to specify a shared mailbox address
for your operations to access. If you were using this operation prior to May 6, 2020,
you'll need to explicitly update your operations to specify the shared mailbox address.

I see this error: "REST API is not yet supported for this mailbox".

This error can occur for accounts that are on a dedicated (on-premises) mail server
when:

1. The mailbox is on a dedicated Microsoft Exchange Server, or it isn't a valid
Microsoft 365 mailbox.

2. The mailbox is an Outlook.com account that isn't enabled.

3. The mailbox isn't part of a Microsoft 365 plan that includes Power Automate.

To resolve the issue, go to "REST API is not yet supported for this mailbox" error for
request to a mailbox .

Unable to send email with attachment error: "Parameter 'Attachment Content' cannot
be null or empty."

Use expressions to encode the attachment with base64. The attachment will be
recognized after you're done.

Related information
Overview of using Outlook with Power Automate
Create flows to manage email



Customize email in flows
Create flows for popular email scenarios
Training: Create flows to manage email (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Use flows with Excel
Article • 02/26/2025

Integrate Power Automate with Excel for the web and desktop to automate repetitive
tasks, reduce errors, and improve productivity. For example, you can track customer
feedback, manage projects, or analyze data. By connecting Excel to apps and services
such as SharePoint, Teams, and Planner, Power Automate can make collaboration and
data sharing across different platforms seem effortless.

With this feature, you can easily create Power Automate workflows in Excel. To get
started, select a Power Automate prebuilt template that closely meets your needs. Then,
customize it to fit your Excel workbook.

Here are some of the prebuilt templates that you can use in Excel:

Monitor incoming emails to an alias in an Excel worksheet
Track Planner tasks in Excel
Categorize Excel rows with GPT

Build a flow in Excel
To get started using Power Automate in Excel, follow these steps.

1. Open your Excel workbook in Excel.

2. On the ribbon, on the Automate tab, select Automate Work.

3. Browse the prebuilt templates, and select one.



4. Follow the prompts to connect to the app or service that you want to integrate
with Excel.

5. Select Create flow.

） Important

All flows are created in the default environment.

Manage your flow
After you create a flow, you can manage it from Excel. Management includes the ability
to delete your flow, turn it off, edit it, and view details about it.

To manage your flow, select the ellipsis (…) for it in the Power Automate pane, and then
select an option on the menu.



Limitations
Here are some limitations to be aware of when using Power Automate in Excel:

The Power Automate pane is currently available only in Excel for the web and
desktop, but not on Mac.
If your flow uses the Excel Online (Business) connector, you might experience
issues. Learn about the issues and limitations in Excel Online (Business).
Only flows created in the default environment are listed and available to be run in
Excel.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Use SharePoint and Power Automate to
build workflows
Article • 11/25/2024

Power Automate is deeply integrated with SharePoint. You can start with any of the
more than 100 SharePoint templates , or create your own flow that integrates with
SharePoint from scratch.

Learn more about how to use Power Automate with SharePoint in the following video.
https://www.microsoft.com/en-us/videoplayer/embed/RWL7D9?postJsllMsg=true

Top SharePoint workflow scenarios
Here are some of the top scenarios in which you can use Power Automate with
SharePoint:

Manage approval flows.
Work with files and lists created with Microsoft Lists.
Migrate from workflows to Power Automate.

Manage approval flows
Customize SharePoint page approvals to meet your needs.
Require approval of documents in SharePoint by using Power Automate.
Route finished documents to a team for approval.

Work with files and lists
Manage list item and file permissions.
Move files to different folders after they're approved in SharePoint.
Create an item in SharePoint when a new order is added in Salesforce.
Get items from lists, or get files from libraries.
Create a flow for a list or library in SharePoint or OneDrive .
Edit a cloud flow .

Other top scenarios
Use HTTP requests to manage lists and libraries.
Create SharePoint reminder flows.



SharePoint triggers and actions
You can use SharePoint triggers to start flows that monitor changes made to a list or
library. For a full list, go to SharePoint triggers.

As soon as your flow starts, you can use any of the more than 40 actions to manipulate
your lists.



Migrate from workflows to Power Automate
Migrate from classic workflows to Power Automate flows in SharePoint.

Related information
Get started with Power Automate and SharePoint
Get started with approvals
Create modern approval flows in conditions in advanced mode
Training: Integrate SharePoint and Power Automate (learning path)

Feedback



Was this page helpful?  Yes  No

Provide product feedback



SharePoint remind me
Article • 11/26/2024

Lists created with Microsoft Lists and SharePoint libraries allow you to define custom
metadata columns to track dates. With Power Automate's integration with SharePoint,
you can easily create reminder flows, based on DateTime columns in SharePoint. With
reminder flows, you receive a personal email alert a predetermined number of days in
advance of a date on any document or item in SharePoint.

Prerequisites
Access to Microsoft SharePoint Online.
A list, or library with a DateTime column.
Access to Power Automate.

７ Note

This feature isn't available for GCC, GCC High, DOD, or other sovereign clouds.

 Tip

For detailed information about using SharePoint with Power Automate, go to the
SharePoint documentation.

Create a reminder flow
1. Create a list in Microsoft Lists  with at least one DateTime column in the current

view.

2. Select Automate > Set a reminder > Date deactivated (this is the column with the
DateTime for the reminder).



3. Optionally, you might need to sign into the services that this Power Automate
template uses.

4. Select Continue.

5. Provide a Flow name and the number of days prior to the DateTime column entry
when you want to receive the reminder alert on the Set a reminder card.

6. On the Set a reminder card, select Create.

7. You receive the following message, indicating that the flow was created.

Confirm reminders received



You receive a reminder via email, based on the Remind me this many day(s) in advance
entry you made on the Set a reminder flow you created earlier.

Edit your flow
The reminder flow is like any other flow, so you can access and edit it through Power
Automate .

Related information
Getting started with Power Automate .
Set a reminder flow  in SharePoint.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Manage SharePoint page approvals with
Power Automate
Article • 11/25/2024

SharePoint site admins can use Power Automate to require new or updated site pages
to be approved before being published.

In this article, you learn how to configure your SharePoint site to use a cloud flow to
require changes to the site to be approved before they go live.

７ Note

SharePoint approvals isn't available in government cloud environments.

Configure SharePoint for page approvals

Prerequisites
You must be a SharePoint site admin to perform the activities in this article.

 Tip

For detailed information about using SharePoint with Power Automate, go to the
SharePoint documentation.

1. Sign in to SharePoint as a site admin.

2. Select Pages from the navigation bar.



3. Select Automate > Power Automate > Configure page approval flow.

4. Select Create flow.

5. Optionally, you might need to sign in to the services that this Power Automate
template uses.

6. Select Continue.

7. Provide a Flow name, at least one name in the Approvers box, and then select
Create.



Your flow is complete. Now, each time a page is added or modified, an approval request
goes to the Approvers you listed in the flow.

The page approval flow is just like any other flow, so it is listed in the My flows tab.

Submit a page for approval



Now that you created a page approval flow, anyone who adds or changes a page needs
to do the following steps.

1. Make a change to the site (add a new page, for example) and then save the
change.

2. Wait for someone to approve the change.

Approve a page
Approvers receive an email whenever there's a page approval request. They can approve
the requests directly in the email if their email client supports actionable messages.
Alternatively, they can open the page from the email to review, and then approve the
page in SharePoint.

Customize page approval flows
Because page approvals use Power Automate behind the scenes, the page approval flow
is available for site owners to modify and add any custom business logic in the flow. To
modify the flow, the site owner can select Flows and then select See your flows in the
pages library to find the page approval flow.

Limitations
Only the specific triggers and actions that are used by a page approval flow are
supported for use on a Pages library. All other SharePoint triggers and actions aren't
supported.

Related information
Page approval flow



Configure page approval

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Use flows in Microsoft Teams
Article • 02/27/2025

Power Automate flows can be used in three scenarios with Teams.

ﾉ Expand table

Scenario Description

Trigger flows from In this scenario, you can create flows that are triggered when someone
Teams messages. selects a Teams message. The flow can then run as any other flow you

create.

Use flows with Here, adaptive cards can be used as the trigger for flows. The full set of
adaptive cards. rich adaptive cards is available to you.

Create flows from Use the Power Apps app in Teams to create flows that use Dataverse for
within the Power Teams. Dataverse for Teams is a built-in, low-code data platform for Teams
Apps app in Teams. that empowers users to build custom apps and workflows within Teams by

using Power Apps and Power Automate.

７ Note

Department of Defense (DoD) cloud environments support the following
capabilities:

Create and trigger the When a new chat message is added flow
Create and trigger the When keywords are mentioned flow
Create and trigger the When a new team member is added flow
Create and trigger the Post a feed notification flow
Create and trigger the When I am @mentioned flow

Licensing
There are no additional licensing requirements when you use Power Automate with
Microsoft Teams.

For detailed licensing information about Dataverse for Teams, see licensing and
restrictions in the Microsoft Power Platform admin guide.

Related information



Power Apps and Teams
Microsoft Copilot Studio overview

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Install the Workflows app in Microsoft
Teams
Article • 11/04/2023

The Workflows app lets you automate your Microsoft Teams activities or and connect
Microsoft Teams to other apps and services.

７ Note

The Power Automate app in Teams is now called Workflows. If you still see the
Power Automate app, you might need to update the app manually to get the latest
changes. To learn how to do this, go to Update an app in Microsoft Teams .

1. Sign in to Microsoft Teams .

2. Select View more apps (...), and then search for the workflows app.

3. In the search results list, select the Workflows app.

After a few moments, the Workflows app installs.

You can also install the Workflows app from the Microsoft Teams app store .

７ Note

The Workflows app isn't available in Microsoft 365 Government tenants.

Get started with the Workflows app
You can access the Workflows app in Microsoft Teams from the left pane.

From the Home tab, you can create and manage your flows.



Pin the Workflows app
To allow you to access the Workflows app easily at a later time, you can pin it in
Microsoft Teams.

To pin the Workflows app in Microsoft Teams:

1. On the left pane, right-click on Workflows.

2. Select Pin.

Known issues
The Workflows app in Microsoft Teams shows flows only from your organization's
default environment. Any flow that you create from the Workflows app is located in the
default environment.

See also
Create flows in Microsoft Teams
Manage your flows in Microsoft Teams



Create flows in Microsoft Teams
Article • 10/09/2024

There are multiple ways in which you can create flows within Microsoft Teams.

Power Automate flow templates: The Microsoft Teams store has templates directly
integrated, making it easy for you to get flow templates to get started quickly.
Team overflow messages: You can create flows from the overflow menu of Teams
message.
Workflows app: You can use the Workflows app to create flows from a template or
from scratch.

You can manage all flows you create from any of these entry points directly within Power
Automate or from within the Workflows app in Teams.

Prerequisites
To use the Workflows app, you need an account with access to Microsoft Teams .

Create a cloud flow from the Microsoft Teams
store
Follow these steps to create a flow from the Microsoft Teams store.

1. Sign in to Microsoft Teams .

2. On the left pane in Teams, select Apps.

3. At the bottom of the left pane, select Workflows.

You see a list of templates that are relevant to Microsoft Teams.

4. Select any of the templates to build your flow.

When you select a template, a new dialog opens. Name the flow, and then sign
into the apps and services the flow uses (if you aren't already signed into them).

5. After all the connections are setup, select Next.

6. Provide the parameters that the flow requires, and then select Add workflow to
create the flow.

A confirmation page that states that your flow was created successfully appears.



7. To complete flow creation, select Done.

8. You can manage your flows from the Workflows app in Teams or in Power
Automate. To open the Workflows app in Teams to manage your flows, select
Manage workflows in the Save time with Workflows section.

Create a flow from the message menu in
Microsoft Teams
You can create manually triggered flows from the overflow menu of a Microsoft Teams
message.

Follow these steps to create a manually triggered flow from the Microsoft Teams store.

1. Sign in to Microsoft Teams .

2. On any message in Teams, select the ellipses (...) in the menu.

3. Select More actions > Create new action.

You see list of templates that use the For a selected message manual trigger.

4. Select any template to set up the connections you need.

5. Select Next to setup the parameters that the template needs.

A confirmation page appears once your flow is created successfully.



Create a cloud flow from a template in the
Workflows app
By default, the Workflows app shows you templates that have been created for
Microsoft Teams. You can switch filters on the top right to view all Power Automate
templates.

Follow these steps to create a cloud flow from a Microsoft Teams template.

1. Sign in to Microsoft Teams .

You can also use the Microsoft Teams app.

2. On the left panel, select Apps.

3. Search for workflows.

4. In the Search results for "workflows" panel, select Open next to Workflows.

5. Select the Create tab, and then select the template on which you'd like to base
your flow.

If the template that you selected is optimized for Microsoft Teams, a dialog that
lets you rename the flow and authenticate with the apps necessary for the flow
displays.

７ Note



You must login to all connectors so that your flow can run successfully. A
green check indicates that you've authenticated.

6. Set up the connections as needed.

7. Select Continue to get a list of parameters that are necessary for the flow to run
successfully. Provide the parameters that are needed.

8. You're all set! You'll get a confirmation that your flow was successfully created.
After you create your flow, you can find it on the Home tab.

） Important

When you create flows from within the Workflows app in Microsoft Teams,
they're always created in your organization's default environment. You can
also access these flows from Power Automate .

Create a cloud flow from scratch
If you want full control over the flow that you create, select Create a flow from the top
right side of the screen, instead of using a template.

This opens the full Power Automate designer experience within Microsoft Teams where
you can create a fully customized flow.



Known issues
All flows that you create from within the Workflows app are located in your
organization's default environment.
The Workflows app must be enabled in the Microsoft Teams admin center  in
order for this functionality to work.

Related information
Manage your flows in Microsoft Teams
Microsoft Teams connector documentation
Training: Build your first workflow with Power Automate and Dataverse for Teams
(module)
Training: Get started with Microsoft Dataverse for Teams (module)
Training: Create apps, copilots, flows, and more with Microsoft Dataverse and
Teams (learning path)

Feedback
Was this page helpful?



 Yes  No

Provide product feedback



Use flows in teams created from
templates
Article • 11/09/2024

Microsoft Teams templates are prebuilt definitions of a team's structure that are
designed around a specific business need or project.

Power Automate templates and team templates are meant to address similar business
scenarios. When you create a team with a Microsoft-provided team template, you get a
curated selection of flow templates that are specific to your team scenario.

Here are the five team templates that support scenario-specific flow templates.

Manage a Project
Manage an Event
Organize a Help Desk
Incident Response
Onboard Employees

For example, if you create a team from the Manage a Project template, the
recommended flow templates on the Power Automate tab in the General channel is
filtered to your Manage a Project scenario.

For example, follow these steps to use the Manage a Project template from within
Microsoft Teams.

1. Open Microsoft Teams.

2. Select Teams from the top of the panel on the left.

3. Select Join or create a team from the bottom of the Teams panel on the left.

4. Select Create team from the Join or create a team screen.



5. Select the Manage a Project template.

6. On the Manage a Project screen, select Next after you review the summary and
details of the template.

7. Select the Sensitivity and Privacy levels for your team.

8. Give your team a name, a description, and then select Create.

9. Wait while the team is created.

10. After you create the team, select the Power Automate tab in the General channel,
and then select Set up tab.

11. On the Power Automate screen, check the Post to the channel about this tab
checknox, and then select Save .



12. Scroll down the Power Automate tab to view the list of suggested Power
Automate flow templates that are relevant to your team's scenario.



You can now select any of the flow templates listed to customize your team.

 Tip

You can use any of the five team templates listed earlier in the article to create a
team that's right for your organization.

Related information
Create a cloud flow from a description
Use team templates in the admin center
Create a team with a Teams templates

Feedback
Was this page helpful?  Yes  No



Provide product feedback



Manage flows in Microsoft Teams
Article • 11/04/2023

The Home tab provides an overview of your flows from your organization's default
environment.

By default, the Home tab is filtered to display flows that use Microsoft Teams triggers
and actions. You can select Microsoft Teams flows to change the filter to display all your
flows.

On the Home tab, you can view the information that's displayed in each of the following
six columns to get an overview of your flows.

Column Description

Flow name Represents the name that you provided for the flow.

Status Displays the status of the flow. For example, is the flow enabled or disabled? You
can change the status of your flows directly from this list.

Modified Displays the amount of time that's passed since the flow was last changed.

Owners Provides a list of the users who own the flow.

Type Shows the type of flow. Flows can be Automated, Instant, or Scheduled.

Team and If your flow reads from or writes to any team or channel, that information is
channel provided here so you can get a quick glance of the teams your flow touches.

 Tip

You can select any flow to view more details about it.



Known issue
The Workflows app in Microsoft Teams shows your flows that are located only in your
organization's default environment.

See also
Create flows in Microsoft Teams
Microsoft Teams connector documentation



Send a message in Teams using Power
Automate
Article • 10/15/2024

This article covers different ways in which you can send a message in Teams.

You can use Power Automate to set up a flow that sends messages to a Teams Channel
or group chat using the Microsoft Teams connector. Messages can be posted either as
the user who is signed into the connector in the flow or by using the Flow bot.

Flow setup
For the purposes of this document, we're using a scenario where a flow is used to notify
a Channel or a Group chat, but the same principles can be used to apply to any flow
where the Post a message in a chat or channel is used.

1. Sign in to Power Automate .
2. Select My flows > New > Automated cloud flow.
3. Enter a name for your flow.
4. Select the When a file is created (properties only) trigger.
5. Select Create.
6. Set up your trigger by choosing a SharePoint site and Folder ID that you want to

monitor.
7. to add an action to this flow, select + New Step.
8. Search for and select the Post a message in a chat or channel action.

Message sender options
The Post a message in a chat or channel action can send a message in the following
two ways:

As the Flow bot: In this method, the message gets sent as the Flow bot instead of
any individual users. Use this sender option if you didn't want to tie the message
to any specific user and just want to use a generic sender instead.

As a User: In this method, the message gets sent as the user who is signed in to
the Teams connector in the Flow (generally the Flow owner). This method can be
used when the message needs to get sent as a regular user.



The Post as and Post in options within the action control all the different combinations
of how messages can be posted in Teams.

Post a message as the Flow bot in a Teams
channel
To send a message as the Flow bot in a Teams Channel select the Post as option as Flow
bot and the Post in option as Channel. Once you do two more dynamic inputs show up,
which allows you to specify the Team and Channel in which to send the message and
add your message in the message field.

Post a message as the Flow bot in an existing
named group chat
To send a message as the Flow bot in a group chat:

1. Select the Post as option as Flow bot and the Post in option as Group chat.



2. Another option shows up that lets you select the group chat to post in. Choose a
group chat to post the message in and add your message in the message field.

By default, Teams lists only the 50 most recent named group chats in the
dropdown menu. If you want to send a message to a new group chat, use the
option in the following section.

Create a new group chat and post a message to
it as the Flow bot
The Post message in a chat or channel action can be combined with the Create a chat
action to create a new group chat and post a message to it. This is useful in scenarios
where a chat might not already exist for this topic and one needs to be created.

1. To create a new group chat, add the Create a chat action before the Post message
in a chat or channel action. Add the members who need to be in the chat using
their emails. Separate multiple emails with a semi-colon and enter the title for the
chat if needed.

2. To send a message as the Flow bot in the new created group chat, select the Post
as option as Flow bot and the Post in option as Group chat. Once you do, another
option that lets you select the group chat to post in appears.

3. In the Group chat field, choose Enter custom value and select the Conversation id
from the Create a chat action in the dynamic token picker.



Post a message as the Flow bot directly to a
user
When you send a message as the Flow bot, you have the added option of posting
directly to a user. This is useful in notification scenarios where you want to reach out to
an individual user using the Flow bot.

For this, select the Chat with Flow bot option and specify the user you want to message
and the specific message you want to send.

Post a message as the user in a Teams Channel



To send a message as the user in a Teams Channel, select the Post as option as User and
the Post in option as Channel. Once you do, two dynamic inputs appear, which allows
you to specify the Team and Channel in which to send the message and add your
message in the message field.

Post a message as the user in an existing
named group chat
To send a message as the user in a Group chat, select the Post as option as User and the
Post in option as Group chat. After you do, an another option that lets you select the
Group chat to post in appears. Choose a group chat to post the message in and add
your message in the message field.



By default, Teams only lists the 50 most recent named group chats in the drop-down. If
you want to send a message to a new group chat, use the option in the following
section.

Create a new group chat and post a message
The Post message in a chat or channel action can be combined with the Create a chat
action to create a new group chat and post a message to it. This is useful in scenarios
where a chat might not already exist for this topic and one needs to be created.

1. To create a new group chat, add the Create a chat action before the Post message
in a chat or channel action. Add the members who need to be in the chat using
their emails. Separate multiple emails with a semi-colon and enter the title for the
chat if needed.

2. To send a message as the Flow bot in the new created group chat, select the Post
as option as User and the Post in option as Group chat. Once you do, another
option that lets you select the Group chat to post in appears. In the Group chat
field, choose Enter custom value and select the Conversation id from the Create a
chat action in the dynamic token picker.



Mention a user in any message
Mentions are a great way to get the attention of a user in Teams. You can combine any
of the above actions and add a mention in the message of to a user or channel.

1. To mention a user, use the Get @mention token for a user action and specify the
email of the user you want to mention in the User field.

The User field only accepts a single user input. If you want to mention multiple
users, you need to add multiple instances of this action within the flow.

2. Add the mention token generated from that action in any of the previous Post a
message in chat or channel action scenarios.



The Get @mention token for a user action only supports mentioning users and
not channels or Teams at the moment.

Known issues and limitations
By default Teams only lists the 50 most recent named group chats in the drop-
down list. If you want to send a message to a new group chat, use the following
option.

The Get @mention token for a user can only be used for mentioning users,
mentioning channels/teams is currently not supported.

Sending a message in private channels isn't supported.

Related information
Training: Use the Teams connector in Power Automate (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Trigger a cloud flow from any message
in Microsoft Teams
Article • 04/14/2023

You can use messages to trigger processes in Teams. For example, you might use a
Teams message as a starting point to create a work item in Azure DevOps or create a
sales opportunity in Dynamics 365.

Use the For a selected message trigger in the Teams connector to trigger a cloud flow
directly from within Teams.

Create the flow
1. Sign in to Power Automate .

2. Enter a name for your flow.

3. Select the For a selected message trigger.

4. Select Create. You must sign in to Teams if you aren't already signed in.

The For a selected message trigger has an optional input in the form of an adaptive
card. Use an adaptive card to construct a form to collect information from the user who
triggers the flow. For instance, if the flow creates a task, you can use an adaptive card to
collect information like the title of the task and the description.

Collect information from the user
To collect information from the user by using a form, users can select Create Adaptive
Card in the trigger.

This displays an inline adaptive card editor, where you can drag card elements to
construct your own form.



Each input within the adaptive card form has an ID. You can use the ID later in the flow
through dynamic tokens to reference inputs that a user might have entered as part of
running the flow.

Use the message details within the flow
Several message elements are available as a trigger output for use within the flow.
Here's an overview of some of the properties:

Message content: The full HTML content of the Teams message.

Plain text message output: The plain text variation of the Teams message.

Link to message: A direct URL to reference the message.

Sender display name, Sender ID: The details about the user who sent the
message.

Originating user display name, originating user ID: The details about the user
who invoked the flow.

For more information, go to the full list of trigger outputs.

Trigger the flow
You must create these flows within the default environment for them to appear in
Teams.



If you don't see the flows you create with the For selected message in Teams trigger,
ask your admin to confirm whether the Power Automate Actions app is enabled in the
Teams admin center https://admin.teams.microsoft.com/policies/manage-apps .

Any flow that uses the For a selected message trigger shows up as a message action in
the Teams message in the More actions menu for the flow.

） Important

The name of the flow is used to reference the flow within Teams, so be sure to
provide a descriptive name for it.

Best practices
Be sure to include a form of a confirmation to the user after the flow is completed. We
recommend using Post a message as the flow bot to a user or Post a message as the
flow bot to a channel to notify the user in Teams when a triggered flow has been
completed.

Here's an example of a cloud flow that creates a work item in Azure DevOps and then
posts a confirmation to the originating user.



Known issues and limitations
You must create these flows within the default environment to ensure they get
listed in Teams.

Only the flow author can trigger the flow. The flow will only be available to other
members of the channel/chat if the author explicitly shares it with them.



Create flows using the Power Apps app
in Microsoft Teams
Article • 11/04/2023

You can build flows to customize and add further value to Teams from within the new
Power Apps app in Teams. You can create instant, scheduled, and automated flows, with
access to over 350 connectors. This includes a connector to work with Microsoft
Dataverse for Teams tables within Teams.

７ Note

You need a Power Automate license  to access all Power Automate connectors,
including the premium connectors. Users with a Microsoft 365 license can use all
standard connectors.

Prerequisites
The Power Apps app must be installed before you can create flows in Teams. More
information: Install the Power Apps personal app in Microsoft Teams

Before you can use the Power Apps app in Teams to create a cloud flow, a
Dataverse for Teams environment must already exist for that team. A Dataverse for
Teams environment is automatically provisioned when you create your first app in
Teams.

Create a cloud flow in Teams
1. Go to the Build tab in your Power Apps app, and then select See all.

2. Select New, select Flow, and then select the type of flow you want to create. You
can create only the following types of flows: instant, scheduled, and automated.



3. If this is your first time creating a cloud flow, you'll have to select your
country/region, and then select Get started.

4. The Build an automated flow screen appears, where you can select a trigger, and
create and save your flow.

７ Note

The screen that appears here will be different depending on whether you
selected Instant or Scheduled in step 2 earlier.



Work with your flows
To find your saved flows:

1. Sign in to Teams.

2. On the left pane, select Power Apps.



3. On the Build tab, select the team in which you created your flow, and then select
See all in the tree view.



Customize a cloud flow
In Teams, you might have acquired flows from an installed app or you might have
created them yourself. You can update or customize either of these types of flows.

1. To update a cloud flow, select the Build tab, and then select See all to see all the
apps and flows in this team.

2. Select the flow that you want to edit, and then select Edit.

View details and run history
1. To view the details and run history for a cloud flow, select the Build tab, and then

select See all.



2. Select the flow for which you want to view the details, and then select Details.

See also
Use the new Power Apps app in Microsoft Teams
What is Dataverse for Teams?
About the Dataverse for Teams environment



Create your first adaptive card
Article • 11/04/2023

Adaptive cards within Power Automate may either share blocks of information or collect
data via a form for a given data source.

In either case, you'll need to sketch out which datasets you'll share, and/or what data
the form will need to collect.

 Tip

Use simple blocks of data rather than complex table arrays.

Prerequisites
Microsoft Teams with the Workflows app installed.

Add an action
In this procedure, you’ll add an action that will use the data from previous actions in the
flow to post information to a Microsoft Teams channel.

1. Sign in to Power Automate .

2. Select My flows in the top navigation bar.

3. Select New flow > Instant cloud flow.

4. Name your flow.

5. Select Manually trigger a flow as the trigger.

6. Select Create.

7. In the designer, select New Step.

8. Search for Microsoft Teams, and then select Post an adaptive card to a Teams
channel and wait for a response as the action.

9. Select the Team and the Channel to which you'd like to post the card.

10. Paste this JSON into the Message box.



JSON

{
    "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",
    "type": "AdaptiveCard",
    "version": "1.0",
    "body": [
        {
            "type": "TextBlock",
            "text": "Poll Request",
            "id": "Title",
            "spacing": "Medium",
            "horizontalAlignment": "Center",
            "size": "ExtraLarge",
            "weight": "Bolder",
            "color": "Accent"
        },
        {
            "type": "TextBlock",
            "text": "Header Tagline Text",
            "id": "acHeaderTagLine",
            "separator": true
        },
        {
            "type": "TextBlock",
            "text": "Poll Header",
            "weight": "Bolder",
            "size": "ExtraLarge",
            "spacing": "None",
            "id": "acHeader"
        },
        {
            "type": "TextBlock",
            "text": "Lorem ipsum dolor sit amet, consectetur adipiscing
 elit. Integer vestibulum lorem eget neque sollicitudin, quis malesuada
 felis ultrices. ",
            "id": "acInstructions",
            "wrap": true
        },
        {
            "type": "TextBlock",
            "text": "Poll Question",
            "id": "acPollQuestion"
        },
        {
            "type": "Input.ChoiceSet",
            "placeholder": "Select from these choices",
            "choices": [
                {
                    "title": "Choice 1",
                    "value": "Choice 1"
                },
                {
                    "title": "Choice 2",



                    "value": "Choice 2"
                },
                {
                    "title": "Choice 3",
                    "value": "Choice 3"
                }
            ],
            "id": "acPollChoices",
            "style": "expanded"
        }
    ],
    "actions": [
        {
            "type": "Action.Submit",
            "title": "Submit",
            "id": "btnSubmit"
        }
    ]
}

11. Make the following replacements in the JSON.

） Important

Do not remove any quotation marks when you do the replacements. You can
revise the car choices to suit your needs:

Text to change New text

Header Tagline Text Power Automate Poll

Poll Header Preferred Car Model

Poll Question Please vote on your preferred car model from the
choices listed here.

Replace the latin text with a reason, or We are polling our employees in order to
business context, related to why you determine if we should provide personalized
are conducting the poll. parking places that are sized for the most popular

cars.

Choice 1 (replace in both places) Tesla

Choice 2 (replace in both places) Lexus

Choice 3 (replace in both places) Honda

12. Select New Step, and then search for and select one of the Send an email actions
to which you have access.



13. Provide the email recipient as the person who selected the instant button (use the
Email tag from the dynamic content from the trigger).

14. Configure the Body of the email as follows. Replace the words in curly parentheses
"{}" with dynamic tokens:
Your poll response was {acPollChoices} (acPollChoices is dynamic content from
the wait for a response action). It was submitted by {User Name} (User Name is
dynamic content from the trigger)

Test your adaptive card
To test your work, run the flow you created earlier and confirm the following:

The flow run has no errors, and waits for the response, showing the wait indicator
for the Adaptive Card action on the run screen.

The Teams channel has the new adaptive card posted.

When you respond to the card by selecting a car model, and then selecting the
Submit button on the bottom section of the adaptive card:

No errors should occur on the adaptive card.

The flow run completes successfully.

Card replacement is relevant after submission if you have configured the Update
message area at the bottom of the wait for a response actions (shown next with
the corresponding replacement card). Otherwise, all submissions will simply reset
the form.

The email notification contains the body that shows who submitted the response
and which car was selected.

Congratulations! you’ve just made your first interactive adaptive card!



Troubleshooting tips for adaptive cards
The most common problems that you will encounter when creating adaptive cards are:

Flow run errors are often caused by one of the following factors:
The Workflows app isn't installed in Microsoft Teams – Install the Workflows app
in Microsoft Teams.

In this case the error may resemble this screenshot:

Improperly formatted JSON – This is not usually as complex as one might
expect. These are most often just situations where:



There are curly quotes, or missing quotes, around values within the JSON.
Always check the JSON to ensure all text values are enclosed within double
quotes, and that numbers are enclosed in quotation marks. All quotation
marks should be straight and not curly.

You can validate the format of your JSON by pasting the JSON into the Card
Payload Editor .

Missing Image URLs – All image values within Adaptive Cards must refer to a
valid URL. Full image content is not be directly supported in an Adaptive Card.
Test your image links by pasting the URL into the browser to see if an image is
displayed.

Adaptive Cards may not look like what’s expected during to styling and schema
constraints:

Check that placeholder values, text styles, and any markup language align with
Adaptive Card schema requirements (review Adaptive Card schema best
practices here )

Leverage the Visual Studio Code Adaptive Card validator. To install it from the
Visual Studio Code application, open the Extensions Marketplace, and search for
Adaptive Card Viewer.

Truncated screenshot of the Adaptive Card Viewer extension installed in Visual Studio
Code (shortcut: Ctrl+V+A once enabled).

Errors following Adaptive Card submission are often due to:

Using an action, which does not include ‘wait for response’ in the name



Attempting to submit the card more than once. Each Adaptive Card can be
submitted only once, after which all further submissions will be ignored.



Overview of adaptive cards for
Microsoft Teams
Article • 09/08/2023

Adaptive cards are a platform-agnostic method of sharing and displaying blocks of
information without the complexity of customizing CSS or HTML to render them. You
author adaptive cards in JSON format, with integrations that cloud apps and services
can openly exchange. When delivered to a specific host, such as Microsoft Teams, the
JSON file is transformed into native UI that automatically adapts to its host. Therefore,
process designers can now offer consistent UI patterns whenever they need to show
information as part of a business process/automation.

Since adaptive cards adapt to their host, they're perfect vehicles for sharing information
between Microsoft Teams and other services.

Currently available actions for flows
The following actions enable makers to create adaptive cards for Microsoft Teams. As
integration scenarios evolve, other hosts will also be supported by Power Automate,
which will extend your opportunities to leverage adaptive cards throughout Microsoft
cloud subscriptions.



７ Note

Adaptive cards aren't available within the DoD (Department of Defense)
environment.

Directing content to Teams members or AAD
users

Post your own adaptive card as the Flow bot to a user
This action posts an adaptive card as a flow bot to a specific user. In this case, you need
to provide a recipient email address. Then, the card shows up in that recipient's chat
and/or activity feeds during the flow run. There's no requirement for the user to be part
of a Teams instance to receive these types of adaptive cards. In this case, only the URL
buttons function by redirecting to the URL that's configured within the flow.

Post an adaptive card as the Flow bot to a Teams user,
and wait for a response
This action posts an adaptive card as a Flow bot to a specific user, like the case
presented earlier in this article. However, in this case the flow run will not continue after
the post until the recipient responds to inputs that are required within the card. The flow
continues after the recipient responds. The flow returns dynamic content for one (1)
response per recipient and per card.

Directing content to Teams channels
Post your own adaptive card as the flow bot to a channel
This action posts an adaptive card as a flow bot to a specific Teams channel. In this
case, you're prompted for Teams instance, and a channel where the card is posted.
The flow maker has to have access to the Teams instance in order to post an
adaptive card there. In this case, only URL buttons function by redirecting to the
URL configured within the flow.

Post an adaptive card as the flow bot to a Teams channel, and wait for a
response
This action posts an adaptive card as a flow bot to a specific Teams channel as in
the case above. In this case, the flow doesn't continue until someone on the



channel responds to inputs required within the card. The flow continues once
anyone in the Teams channel responds but only returns dynamic content for one
(1) response per responder and per card. When you use this card, the flow waits
for a response from any Teams member.

Known issues
It isn't possible to collect data from adaptive cards unless they're created using
one of the wait for a response actions. Adaptive cards that don't wait return an
error for all button actions except OpenURL. Learn more about OpenURL
buttons .

Selecting Action.Submit buttons on a card that doesn't include the wait for a
response suffix show an error.

Adaptive cards created using the wait for response actions can only be submitted
once per card. The flow run continues after the first response, and any further
submissions are ignored.

Only the information within the Update message input box show on the
replacement card after consumers submit the card.

Additional details, such as the user id of the person submitting the card, are
available within the dynamic content in actions following the wait for a response
action. However, it might be necessary to include the Office 365 Users connector in
order to complete desired profile information for the user who submitted the card.

Once the wait for a response adaptive cards are submitted, the card resets and
then appears exactly the same, unless the replacement/update message area is
configured. Update messages are a best practice. They're recommended in order
to update others and prevent consumers from attempting to submit the card more
than once.

The Update Message and the Should update card inputs must be configured if a
replacement card is desired.

Power Automate uses Microsoft adaptive cards' unique features and services to
handle the cards within any host. This article is intended to clarify any specifics



related to flow actions. You can also use the full documentation for building
adaptive cards.

See also
Create your first adaptive card
Microsoft Teams connector
Adaptive cards IO



Create your first adaptive card
Article • 11/04/2023

Adaptive cards within Power Automate may either share blocks of information or collect
data via a form for a given data source.

In either case, you'll need to sketch out which datasets you'll share, and/or what data
the form will need to collect.

 Tip

Use simple blocks of data rather than complex table arrays.

Prerequisites
Microsoft Teams with the Workflows app installed.

Add an action
In this procedure, you’ll add an action that will use the data from previous actions in the
flow to post information to a Microsoft Teams channel.

1. Sign in to Power Automate .

2. Select My flows in the top navigation bar.

3. Select New flow > Instant cloud flow.

4. Name your flow.

5. Select Manually trigger a flow as the trigger.

6. Select Create.

7. In the designer, select New Step.

8. Search for Microsoft Teams, and then select Post an adaptive card to a Teams
channel and wait for a response as the action.

9. Select the Team and the Channel to which you'd like to post the card.

10. Paste this JSON into the Message box.



JSON

{
    "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",
    "type": "AdaptiveCard",
    "version": "1.0",
    "body": [
        {
            "type": "TextBlock",
            "text": "Poll Request",
            "id": "Title",
            "spacing": "Medium",
            "horizontalAlignment": "Center",
            "size": "ExtraLarge",
            "weight": "Bolder",
            "color": "Accent"
        },
        {
            "type": "TextBlock",
            "text": "Header Tagline Text",
            "id": "acHeaderTagLine",
            "separator": true
        },
        {
            "type": "TextBlock",
            "text": "Poll Header",
            "weight": "Bolder",
            "size": "ExtraLarge",
            "spacing": "None",
            "id": "acHeader"
        },
        {
            "type": "TextBlock",
            "text": "Lorem ipsum dolor sit amet, consectetur adipiscing
 elit. Integer vestibulum lorem eget neque sollicitudin, quis malesuada
 felis ultrices. ",
            "id": "acInstructions",
            "wrap": true
        },
        {
            "type": "TextBlock",
            "text": "Poll Question",
            "id": "acPollQuestion"
        },
        {
            "type": "Input.ChoiceSet",
            "placeholder": "Select from these choices",
            "choices": [
                {
                    "title": "Choice 1",
                    "value": "Choice 1"
                },
                {
                    "title": "Choice 2",



                    "value": "Choice 2"
                },
                {
                    "title": "Choice 3",
                    "value": "Choice 3"
                }
            ],
            "id": "acPollChoices",
            "style": "expanded"
        }
    ],
    "actions": [
        {
            "type": "Action.Submit",
            "title": "Submit",
            "id": "btnSubmit"
        }
    ]
}

11. Make the following replacements in the JSON.

） Important

Do not remove any quotation marks when you do the replacements. You can
revise the car choices to suit your needs:

Text to change New text

Header Tagline Text Power Automate Poll

Poll Header Preferred Car Model

Poll Question Please vote on your preferred car model from the
choices listed here.

Replace the latin text with a reason, or We are polling our employees in order to
business context, related to why you determine if we should provide personalized
are conducting the poll. parking places that are sized for the most popular

cars.

Choice 1 (replace in both places) Tesla

Choice 2 (replace in both places) Lexus

Choice 3 (replace in both places) Honda

12. Select New Step, and then search for and select one of the Send an email actions
to which you have access.



13. Provide the email recipient as the person who selected the instant button (use the
Email tag from the dynamic content from the trigger).

14. Configure the Body of the email as follows. Replace the words in curly parentheses
"{}" with dynamic tokens:
Your poll response was {acPollChoices} (acPollChoices is dynamic content from
the wait for a response action). It was submitted by {User Name} (User Name is
dynamic content from the trigger)

Test your adaptive card
To test your work, run the flow you created earlier and confirm the following:

The flow run has no errors, and waits for the response, showing the wait indicator
for the Adaptive Card action on the run screen.

The Teams channel has the new adaptive card posted.

When you respond to the card by selecting a car model, and then selecting the
Submit button on the bottom section of the adaptive card:

No errors should occur on the adaptive card.

The flow run completes successfully.

Card replacement is relevant after submission if you have configured the Update
message area at the bottom of the wait for a response actions (shown next with
the corresponding replacement card). Otherwise, all submissions will simply reset
the form.

The email notification contains the body that shows who submitted the response
and which car was selected.

Congratulations! you’ve just made your first interactive adaptive card!



Troubleshooting tips for adaptive cards
The most common problems that you will encounter when creating adaptive cards are:

Flow run errors are often caused by one of the following factors:
The Workflows app isn't installed in Microsoft Teams – Install the Workflows app
in Microsoft Teams.

In this case the error may resemble this screenshot:

Improperly formatted JSON – This is not usually as complex as one might
expect. These are most often just situations where:



There are curly quotes, or missing quotes, around values within the JSON.
Always check the JSON to ensure all text values are enclosed within double
quotes, and that numbers are enclosed in quotation marks. All quotation
marks should be straight and not curly.

You can validate the format of your JSON by pasting the JSON into the Card
Payload Editor .

Missing Image URLs – All image values within Adaptive Cards must refer to a
valid URL. Full image content is not be directly supported in an Adaptive Card.
Test your image links by pasting the URL into the browser to see if an image is
displayed.

Adaptive Cards may not look like what’s expected during to styling and schema
constraints:

Check that placeholder values, text styles, and any markup language align with
Adaptive Card schema requirements (review Adaptive Card schema best
practices here )

Leverage the Visual Studio Code Adaptive Card validator. To install it from the
Visual Studio Code application, open the Extensions Marketplace, and search for
Adaptive Card Viewer.

Truncated screenshot of the Adaptive Card Viewer extension installed in Visual Studio
Code (shortcut: Ctrl+V+A once enabled).

Errors following Adaptive Card submission are often due to:

Using an action, which does not include ‘wait for response’ in the name



Attempting to submit the card more than once. Each Adaptive Card can be
submitted only once, after which all further submissions will be ignored.



Candidate feedback sample
Article • 12/16/2022

The candidate feedback form sample is an Adaptive Card input form that's designed for
collecting feedback during an interview loop. We recommend using this with a shared
instant flow button to enable anyone on the team to provide feedback on candidates
during an interview loop. Extend this by recording responses in a database or other
desired data sources to support these additional opportunities:

Facilitate the review of follow-up suggestions before the next session with the
candidate.

Facilitate aggregated data review after all responses are recorded.

Notify the human resources representative with the hire/no hire vote count at the
end of the process



Inputs/Outputs and notes

Dynamic Token Name Placeholder Text Notes:

{acFullName} {acFullName} Display text

{acComments} {acComments} Display text

{acDecision} Response output

{acFollowUp} Response output

JSON

{

  "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",




  "type": "AdaptiveCard",

  "version": "1.0",

  "body": [

    {

      "type": "TextBlock",

      "size": "Medium",
      "weight": "Bolder",

      "id": "Title",

      "text": "CANDIDATE FEEDBACK FORM",

      "horizontalAlignment": "Left"

    },

    {

      "type": "Input.Text",

      "placeholder": "{acFullName}",

      "style": "text",

      "isMultiline": false,

      "maxLength": 75,

      "id": "acFullName"

    },

    {

      "type": "Input.Text",

      "placeholder": "{acComments}",

      "style": "text",

      "isMultiline": true,

      "maxLength": 200,

      "id": "acComments"

    },

    {

      "type": "TextBlock",

      "size": "Medium",
      "weight": "Bolder",

      "text": "Decision",

      "horizontalAlignment": "Left",

      "separator": true
    },

    {

      "type": "Input.ChoiceSet",

      "id": "acDecision",

      "value": "1",

      "choices": [

        {

          "title": "Hire",

          "value": "Hire"

        },

        {

          "title": "No Hire",

          "value": "No Hire"

        }

      ],

      "style": "expanded"

    },

    {

      "type": "TextBlock",

      "text": "Suggest follow-up discussion regarding:",
      "weight": "Bolder"




    },

    {

      "type": "Input.ChoiceSet",

      "id": "acFollowUp",

      "isMultiSelect": true,

      "value": "",

      "choices": [

        {

          "title": "Past experience in the topic area",

          "value": "Experience"

        },

        {

          "title": "Inclusive behaviors and work ethics",

          "value": "Inclusivity"

        },

        {

          "title": "Ability to work without supervision",

          "value": "Independent"

        }

      ]

    }

  ],

  "actions": [

    {

      "type": "Action.Submit",

      "title": "Submit"

    }

  ]

}




Image share sample
Article • 12/16/2022

The Image Share Form sample is an Adaptive Card designed for sharing photos that
have been posted to SharePoint and which may be a dependency for a process to
complete (such as processes related to inspection, compliance, and audits). This is a
display only adaptive card.

Inputs/Outputs and notes

Dynamic Token Name (inputs) Placeholder Text Notes

acphotoTitle {acphotoTitle} Display text

acTimestamp {acTimestamp} Display date/time

acImageThumbnail {acImageThumbnail} Display image 

This must be replaced with a valid URL

acAltText {acAltText} Accessibility alternative text

JSON

{

    "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",

    "type": "AdaptiveCard",

    "version": "1.0",

    "body": [

        {

            "type": "TextBlock",




            "text": "{acphotoTitle}",

            "id": "Title",

            "size": "Large"

        },

        {

            "type": "TextBlock",

            "text": "{acTimestamp}",

            "size": "Medium",

            "weight": "Lighter"

        },

        {

            "type": "Image",

            "altText": "{acAltText}",

            "url": "{acImageThumbnail}"

        }

    ],

    "spacing": "None"

}




Lead collection sample
Article • 12/16/2022

The lead collection sample is an Adaptive Card input form designed for collecting leads
from anyone that may come into contact with individuals interested in a set of products.
Feel free to change the choices for the products, remembering that each choice can
have display text, as well as an internal value which will be output after someone
submits the card (they can also be the same as we show in the sample code block).



Inputs/Outputs and notes:

Dynamic Token Placeholder Text Notes
Name

Title Display text

acInstructions Display text

acLeadFName {firstName} Response output

acLeadLName {lastName} Response output

acLeadEmail {emailAddress} Response output

acLeadPrimaryPhone {primaryPhone10digits} Response output

acLeadProductInterest {productInterests} Response output 
As multi-select values, where each selection
will be separated by a comma.

JSON

{

    "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",

    "type": "AdaptiveCard",

    "version": "1.0",

    "body": [

        {

            "type": "ColumnSet",

            "columns": [

                {

                    "type": "Column",

                    "width": 2,

                    "items": [

                        {

                            "type": "TextBlock",

                            "text": "Lead Notification",
                            "weight": "Bolder",

                            "id": "Title",

                            "size": "ExtraLarge"

                        },

                        {

                            "type": "TextBlock",

                            "text": "Please fill out a single form for each 
individual expressing interest in our products. ",

                            "isSubtle": true,

                            "wrap": true,

                            "id": "acInstructions",

                            "size": "Large"

                        }

                    ]

                }




            ]

        },

        {

            "type": "Container",

            "items": [

                {

                    "type": "TextBlock",

                    "text": "Potential Customer FIRST NAME",

                    "wrap": true,

                    "size": "Medium"

                }

            ]

        },

        {

            "type": "Input.Text",

            "id": "acLeadFName",

            "placeholder": "{firstName}"

        },

        {

            "type": "TextBlock",

            "text": "Potential Customer LAST NAME",

            "wrap": true

        },

        {

            "type": "Input.Text",

            "id": "acLeadLName",

            "placeholder": "{lastName}"

        },

        {

            "type": "TextBlock",

            "text": "Corporate email",

            "wrap": true

        },

        {

            "type": "Input.Text",

            "id": "acLeadEmail",

            "placeholder": "{emailAddress}",

            "style": "Email"

        },

        {

            "type": "TextBlock",

            "text": "Business Phone Number"

        },

        {

            "type": "Input.Text",

            "id": "acLeadPrimaryPhone",

            "placeholder": "{primaryPhone10digits}",

            "style": "Tel"

        },

        {

            "type": "RichTextBlock",

            "inlines": [

                {

                    "type": "TextRun",

                    "text": "{productInterests}"




                }

            ]

        },

        {

            "type": "Input.ChoiceSet",

            "placeholder": "Placeholder text",

            "choices": [

                {

                    "title": "Office 365",

                    "value": "Office 365"

                },

                {

                    "title": "Dynamics 365",

                    "value": "Dynamics 365"

                },

                {

                    "title": "Azure Services",

                    "value": "Azure Services"

                },

                {

                    "title": "Power Platform",

                    "value": "Power Platform"

                }

            ],

            "style": "expanded",

            "id": "acLeadProductInterest",

            "isMultiSelect": true

        }

    ],

    "actions": [

        {

            "type": "Action.Submit",

            "title": "Submit"

        }

    ]

}




Create a poll sample
Article • 01/27/2023

The create a poll sample is an Adaptive Card input form that's designed for submitting
polls to Microsoft Teams. Replace the display text in this card to customize for the poll.
This adaptive card enables you to take different decision paths based on the responses
given in the poll values, or voting counts, of card consumers.

Inputs/Outputs and notes

Dynamic Token Name Placeholder Text Notes:

Title Display text

acHeaderTagLine Display text

acHeader Display text



Dynamic Token Name Placeholder Text Notes:

acPollQuestion Display text

acPollChoices Response output 
Single select as radio buttons

JSON

{

    "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",

    "type": "AdaptiveCard",

    "version": "1.0",

    "body": [

        {

            "type": "TextBlock",

            "text": "Poll Request",

            "id": "Title",

            "spacing": "Medium",

            "horizontalAlignment": "Center",

            "size": "ExtraLarge",

            "weight": "Bolder",

            "color": "Accent"

        },

        {

            "type": "TextBlock",

            "text": "Header Tagline Text",

            "id": "acHeaderTagLine",

            "separator": true

        },

        {

            "type": "TextBlock",

            "text": "Poll Header",

            "weight": "Bolder",

            "size": "ExtraLarge",

            "spacing": "None",

            "id": "acHeader"

        },

        {

            "type": "TextBlock",

            "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit
. Integer vestibulum lorem eget neque sollicitudin, quis malesuada felis ult
rices. ",

            "id": "acInstructions",

            "wrap": true

        },

        {

            "type": "TextBlock",

            "text": "Poll Question",

            "id": "acPollQuestion"

        },

        {

            "type": "Input.ChoiceSet",




            "placeholder": "Select from these choices",

            "choices": [

                {

                    "title": "Choice 1",

                    "value": "Choice 1"

                },

                {

                    "title": "Choice 2",

                    "value": "Choice 2"

                },

                {

                    "title": "Choice 3",

                    "value": "Choice 3"

                }

            ],

            "id": "acPollChoices",

            "style": "expanded"

        }

    ],

    "actions": [

        {

            "type": "Action.Submit",

            "title": "Submit",

            "id": "btnSubmit"

        }

    ]

}




Metadata update card sample
Article • 01/27/2023

The Metadata Update sample is an adaptive card designed to enable flow makers to
notify or update Teams members or channels with metadata related to a record, file, or
topic. This card is a display only adaptive card. However, input fields may be added if
one of the wait for response actions are used to create it.

This card is comprised of three sections:

1. The topic header area with header, sub-header, and description.
2. The fact list area for relevant row metadata.
3. A column set which supports a table array of data

Inputs/Outputs and notes

Dynamic Token Name (inputs) Placeholder Text Notes

acHeader {Header} Display text

acSubHeader {SubHeader} Display text

acDescription Latin Text Display text

acFact1 {acFact1} Display text

acFact2 {acFact2} Display text



Dynamic Token Name (inputs) Placeholder Text Notes

acFact3 {acFact3} Display text

acColumnSetHeader Headers 1 through 3 Display text 

Column set header display tex

acColumnSet Columns 1 through 3 Replace with array or column values.

JSON

{

    "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",

    "type": "AdaptiveCard",

    "version": "1.0",

    "body": [

        {

            "type": "TextBlock",

            "text": "Metadata Update Card",

            "weight": "bolder",

            "size": "large",

            "id": "acTitle"

        },

        {

            "type": "ColumnSet",

            "columns": [

                {

                    "type": "Column",

                    "width": "auto",

                    "items": [

                        {

                            "type": "TextBlock",

                            "text": "Sub Header Tag Line",

                            "weight": "Bolder",

                            "wrap": true,

                            "id": "acSubHeader"

                        }

                    ]

                }

            ]

        },

        {

            "type": "TextBlock",

            "text": "Lorem ipsum dolor sit amet, consectetur adipiscing 
elit. In condimentum leo lorem, at facilisis augue hendrerit eget. Praesent 
ut malesuada ipsum. Vivamus semper faucibus felis quis sagittis. Nunc 
pellentesque metus at nunc gravida, vitae volutpat sapien vehicula. Nulla 
lorem nibh, porttitor vel semper ut, ornare nec erat.",

            "wrap": true,

            "id": "acDescriptionArea"

        },

        {

            "type": "FactSet",




            "facts": [

                {

                    "title": "Fact 1:",

                    "value": "{acFact1}"

                },

                {

                    "title": "Fact 2:",

                    "value": "{acFact2}"

                },

                {

                    "title": "Fact 3:",

                    "value": "{acFact3}"

                }

            ],

            "id": "acFactSet"

        },

        {

            "type": "Container",

            "spacing": "Large",

            "items": [

                {

                    "type": "ColumnSet",

                    "columns": [

                        {

                            "type": "Column",

                            "items": [

                                {
                                    "type": "TextBlock",
                                    "weight": "Bolder",

                                    "text": "HEADER 1"

                                }
                            ],

                            "width": "stretch"

                        },

                        {

                            "type": "Column",

                            "items": [

                                {
                                    "type": "TextBlock",
                                    "weight": "Bolder",

                                    "text": "HEADER 2"

                                }
                            ],

                            "width": "stretch"

                        },

                        {

                            "type": "Column",

                            "items": [

                                {
                                    "type": "TextBlock",
                                    "weight": "Bolder",

                                    "text": "HEADER 3"

                                }
                            ],

                            "width": "stretch"




                        }

                    ]

                }

            ],

            "bleed": true

        },

        {

            "type": "ColumnSet",

            "columns": [

                {

                    "type": "Column",

                    "items": [

                        {

                            "type": "TextBlock",

                            "text": "Column 1",

                            "wrap": true,

                            "id": "acCol1"

                        }

                    ],

                    "width": "stretch"

                },

                {

                    "type": "Column",

                    "items": [

                        {

                            "type": "TextBlock",

                            "text": "Column 2",

                            "wrap": true,

                            "id": "acCol2"

                        }

                    ],

                    "width": "stretch"

                },

                {

                    "type": "Column",

                    "items": [

                        {

                            "type": "TextBlock",

                            "text": "Column 3",

                            "wrap": true,

                            "id": "acCol4"

                        }

                    ],

                    "width": "stretch"

                }

            ],

            "$data": "acDataContext"

        }

    ],

    "bleed": true


}




Daily weather report sample
Article • 01/27/2023

The daily weather report sample is an Adaptive Card designed to be used with MSN
weather to post a daily weather update to a Teams channel.

Inputs/Outputs and notes

Dynamic Token Name Placeholder Notes
Text

{acCityState} See template Display text 

A variable can be used to hold the City, State, or Zip
Code values

{acDailySummary} See template Display text

{acCurrentDateTime} See template Display text

{acUrlConditionsImage} See template Display text 
See template comments This must be replaced with a
valid URL

{acCurrentTemperature} See template Display text

{actempHi} See template Display text

{actempLow} See template Display text

JSON



{

    "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",

    "type": "AdaptiveCard",

    "version": "1.0",

    "body": [

        {

            "type": "TextBlock",

            "text": "{acCity}, {acState}",

            "size": "Large",

            "isSubtle": true

        },

        {

            "type": "TextBlock",

            "text": "{acCurrentDateTime}",

            "spacing": "None"

        },

        {

            "type": "TextBlock",

            "text": "{acDailySummary}",

            "spacing": "None"

        },

        {

            "type": "ColumnSet",

            "columns": [

                {

                    "type": "Column",

                    "width": "auto",

                    "items": [

                        {

                            "type": "Image",

                            "url": "{acUrlConditionsImage}",

                            "size": "Large"

                        }

                    ]

                },

                {

                    "type": "Column",

                    "width": "auto",

                    "items": [

                        {

                            "type": "TextBlock",

                            "text": "{acCurrentTemperature}",

                            "size": "ExtraLarge",

                            "spacing": "None"

                        }

                    ]

                },

                {

                    "type": "Column",

                    "width": "stretch",

                    "items": [

                        {

                            "type": "TextBlock",

                            "text": "°F",




                            "weight": "Bolder",

                            "spacing": "Small"

                        }

                    ]

                },

                {

                    "type": "Column",

                    "width": "stretch",

                    "items": [

                        {

                            "type": "TextBlock",

                            "text": "Hi {actempHi}",

                            "horizontalAlignment": "Left"

                        },

                        {

                            "type": "TextBlock",

                            "text": "Lo {actempLow}",

                            "horizontalAlignment": "Left",

                            "spacing": "None"

                        }

                    ]

                }

            ]

        }

    ]

}




Acronyms form sample
Article • 12/16/2022

The acronym form sample is an Adaptive Card input form that's designed to collect
acronyms and storing them in Dataverse. These acronyms could be queried from
anywhere due to this ongoing data collection.

Inputs/Outputs and notes

Dynamic Token Name Placeholder Text Notes:

{acAcronym} Enter the abbreviation for the acronym Response output

{acDefinition} Enter a definition of the acronym above Response output



JSON

{

    "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",

    "type": "AdaptiveCard",

    "version": "1.0",

    "body": [

        {

            "type": "TextBlock",

            "text": "Acronym Logger",

            "id": "Title",

            "spacing": "Medium",

            "horizontalAlignment": "Center",

            "size": "ExtraLarge",

            "weight": "Bolder",

            "color": "Accent"

        },

        {

            "type": "Container",

            "items": [

                {

                    "type": "TextBlock",

                    "text": "Acronym",

                    "wrap": true,

                    "spacing": "Medium"

                },

                {

                    "type": "Input.Text",

                    "id": "acAcronym",

                    "placeholder": "Enter the abbreviation for the acronym"

                },

                {

                    "type": "TextBlock",

                    "text": "Definition",

                    "wrap": true

                },

                {

                    "type": "Input.Text",

                    "placeholder": "Enter a definition of the acronym above"
,

                    "id": "acDefinition",

                    "isMultiline": true

                }

            ]

        }

    ],

    "actions": [

        {

            "type": "Action.Submit",

            "title": "Submit",            "id": "btnSubmit"

        }

    ]

}







Lead collection sample
Article • 12/16/2022

The lead collection sample is an Adaptive Card input form designed for collecting leads
from anyone that may come into contact with individuals interested in a set of products.
Feel free to change the choices for the products, remembering that each choice can
have display text, as well as an internal value which will be output after someone
submits the card (they can also be the same as we show in the sample code block).



Inputs/Outputs and notes:

Dynamic Token Placeholder Text Notes
Name

Title Display text

acInstructions Display text

acLeadFName {firstName} Response output

acLeadLName {lastName} Response output

acLeadEmail {emailAddress} Response output

acLeadPrimaryPhone {primaryPhone10digits} Response output

acLeadProductInterest {productInterests} Response output 
As multi-select values, where each selection
will be separated by a comma.

JSON

{

    "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",

    "type": "AdaptiveCard",

    "version": "1.0",

    "body": [

        {

            "type": "ColumnSet",

            "columns": [

                {

                    "type": "Column",

                    "width": 2,

                    "items": [

                        {

                            "type": "TextBlock",

                            "text": "Lead Notification",
                            "weight": "Bolder",

                            "id": "Title",

                            "size": "ExtraLarge"

                        },

                        {

                            "type": "TextBlock",

                            "text": "Please fill out a single form for each 
individual expressing interest in our products. ",

                            "isSubtle": true,

                            "wrap": true,

                            "id": "acInstructions",

                            "size": "Large"

                        }

                    ]

                }




            ]

        },

        {

            "type": "Container",

            "items": [

                {

                    "type": "TextBlock",

                    "text": "Potential Customer FIRST NAME",

                    "wrap": true,

                    "size": "Medium"

                }

            ]

        },

        {

            "type": "Input.Text",

            "id": "acLeadFName",

            "placeholder": "{firstName}"

        },

        {

            "type": "TextBlock",

            "text": "Potential Customer LAST NAME",

            "wrap": true

        },

        {

            "type": "Input.Text",

            "id": "acLeadLName",

            "placeholder": "{lastName}"

        },

        {

            "type": "TextBlock",

            "text": "Corporate email",

            "wrap": true

        },

        {

            "type": "Input.Text",

            "id": "acLeadEmail",

            "placeholder": "{emailAddress}",

            "style": "Email"

        },

        {

            "type": "TextBlock",

            "text": "Business Phone Number"

        },

        {

            "type": "Input.Text",

            "id": "acLeadPrimaryPhone",

            "placeholder": "{primaryPhone10digits}",

            "style": "Tel"

        },

        {

            "type": "RichTextBlock",

            "inlines": [

                {

                    "type": "TextRun",

                    "text": "{productInterests}"




                }

            ]

        },

        {

            "type": "Input.ChoiceSet",

            "placeholder": "Placeholder text",

            "choices": [

                {

                    "title": "Office 365",

                    "value": "Office 365"

                },

                {

                    "title": "Dynamics 365",

                    "value": "Dynamics 365"

                },

                {

                    "title": "Azure Services",

                    "value": "Azure Services"

                },

                {

                    "title": "Power Platform",

                    "value": "Power Platform"

                }

            ],

            "style": "expanded",

            "id": "acLeadProductInterest",

            "isMultiSelect": true

        }

    ],

    "actions": [

        {

            "type": "Action.Submit",

            "title": "Submit"

        }

    ]

}




Approvals in Microsoft Teams
Article • 11/04/2023

Approvals in Microsoft Teams is a native Teams application that lets you easily create,
manage, and share approvals from your hub for teamwork.

You can quickly start an approval flow from the same place you send a chat, a channel
conversation, or from the approvals app itself. Just select an approval type, add details,
attach files, and choose approvers. Once submitted, approvers are notified and can
review and act on the request.

These approvals are triggered directly with the Power Automate infrastructure and don't
require a flow with an approvals action. Though, if you wish to modify your approvals,
by creating custom pre-approval or post-approvals actions, you can create a flow for
your approval.

Learn more about how to use approvals in Teams in the following video.
https://www.microsoft.com/en-us/videoplayer/embed/RWL2mp?postJsllMsg=true

Use the approvals app in Teams
1. Sign into Microsoft Teams

2. Select More added apps (...), search for Approvals, and then select the approvals
app



 Tip

If you do not see the approvals app in the more apps menu, it is likely that your
Teams Administrator has disabled the app in your tenant. Contact your Teams
administrator to enable the approvals app from the Teams admin center.

Known issues
Currently, all the approvals are created in your organization's default environment.



Create an approval from a chat or
channel
Article • 11/04/2023

With the new approvals experience in Teams, you can create an approval from any chat
or channel from the compose box.

Start an approval in a chat or channel
Follow these steps to create an approval in a chat or channel in Teams.

1. Sign into Microsoft Teams .

2. Navigate to the chat or channel in which you want to send the approval.

3. Select the approvals icon under the compose box.

4. When you select the icon, a modal dialog appears for you to enter the details of
the approval.



5. Enter the details of the approval you want to send, along with who you need the
approval from.

 Tip

By default, the approvers' input is restricted to the roster of the team or chat in
which you are sending the approval.

1. Optional: You can also include a file with your approval. To do so, select Add
attachment in the Approval form. Any files you upload are automatically stored in
your OneDrive/SharePoint folder, just like other files shared on Teams.



2. Select Send.

A card is created and sent in the chat or channel.



Custom responses for approvals
If you want to customize the actions for an approval, use the Custom responses option
to change the action to anything you want. To do so, follow the same steps mentioned
earlier and then toggle the custom responses option in the approvals form.

 Tip

If you want to add more than two custom responses, you will need to use a cloud
flow to send the approval. Learn more about custom responses in approvals.

Known issue



Currently, all the approvals created using this native Teams experience are created in
your organization's default environment.



Create an approval from the approvals
app
Article • 11/04/2023

You can trigger an approval at any time from the approvals app in Teams.

Start an approval from the approvals app
Follow these steps to create an approval from the approvals app in Teams.

1. Sign into Microsoft Teams .

2. Select More added apps (...), search for approvals, and then select the approvals
app.



3. Select New Approval request on the top right of the app.



4. Enter the details of the approval.



 Tip

If you are sending an approval to multiple users and you need everyone to
respond, ensure that select the Require a response from all approvers option.
If you only need one of the approvers to approve turn the option off.

5. Select Send.

The approval shows up in the Sent tab in the app.



Known issues
Currently, all the approvals created using this native Teams experience are created in
your organization's default environment.



Respond to an approval from a chat or
channel
Article • 11/04/2023

If a user sends you an approval in a chat or channel message or from the approvals app,
you can respond to it directly from within the Teams chat or channel or from the
approvals app.

The approvals app also shows you any approvals that were sent using a flow in the same
environment. So, you can use the approvals app in Teams to manage all your approvals.

Approve or reject a request in Teams
Follow these steps to respond to an approval in a chat or channel in Microsoft Teams.

1. Sign into Microsoft Teams .

2. Go to the chat or channel in which you were sent the approval.

You should see a card with the approval.

Alternately, you can open the approvals app in Teams and go to the Received tab.



3. Select View details on the card or select the approval to open the approval form.



4. From here, you can approve or reject the approval. You can also include comments
with your decision. Once approved, the state is updated in the card or the app.

 Tip

If the approver has chosen to send an approval with custom responses, the actions
at the bottom can differ. For example:






Manage your approvals from the
approvals app in Teams
Article • 11/04/2023

The approvals app in Teams gives you an overview of all the approvals that you have
sent or received in your organization's default tenant. This includes approvals you might
have received through chat or channel messages, direct approvals, and even approvals
that come in through a flow.

From here you can either approve or reject an approval you have received, or cancel an
approval you have sent out.

View approvals
From the main approvals app in Teams, you can get a view of all the approvals you have
sent or received.



Cancel an approval request
From the Sent tab, you can choose to cancel an approval that is still in progress. To do
so, select the approval you want to cancel and then select the Cancel approval option.



７ Note

You can only cancel approvals that are in progress.



Customizing approvals in Teams
Article • 11/04/2023

By default, the approvals app only lets you modify custom responses in the app.

If you want to create a custom process with pre and post approval actions that are
automatically triggered using an event, you will need to create an approval flow in the
Power Automate.

Visit the approvals documentation section to get started with approval flows



Microsoft Teams approvals with custom
connectors
Article • 04/14/2023

You can use the approvals hub in Microsoft Teams to quickly integrate approvals
workflows into existing line of business apps that do not have their own approvals
system. You achieve this by using a custom connector to 'connect' to the existing line of
business apps.

 Tip

When you use the approvals hub, you get to manage all your approvals in a central
location.

This article shows you how to:

Create a custom connector.
Add a trigger and actions to a custom connector.
Create an approval flow.
Use the approvals hub in Teams to manage approvals that you created with the
flow.

Prerequisites
One of the following subscriptions:

Power Automate

Power Apps

Basic experience building flows and custom connectors.

Create a custom connector
1. Sign in to Power Automate .

2. Expand Data, and then select Custom connectors.

3. Select New custom connector, and then Create from blank from the dropdown
list.



4. In the Connector name field, enter a name for the custom connector, and then
select Continue.

5. In General Information, enter a Description and a Host.

6. At the bottom of the screen, select Security.

7. Select the authentication type that your API uses.

8. At the bottom of the screen, select Definition.

Add a trigger
You need a trigger to serve as the first step in the approval flow that you'll create.

Some common approval triggers are:

When a new row is created.
Wen a row is updated.

 Tip

Both Webhook and polling triggers work with approval flows.

1. Continuing from the earlier steps, select New Trigger in the Triggers list.

2. Enter a Summary, Description, Operation ID, and select a Trigger type.

3. Select either important or advanced for the visibility the trigger to make the
trigger available when you create the approval flow.

4. Below the Request heading, select Import from sample.



5. Define the Verb, URL, Headers, and Body for your trigger.

6. Add a response.

The response configuration depends on your trigger type (Webhook or polling).
Webhook triggers require a callback URL parameter and a location header that
contains a value that's used to delete the Webhook registration.

7. Configure the Webhook Response and Trigger configuration.

8. Configure the polling response to meet your needs.

9. Configure the trigger to meet your needs.

Create an approval flow
Now that you've created your custom connector, it's time to create your approval flow
that uses the custom connector.

1. Sign in to Power Automate .



2. Select New flow, and then select Automated cloud flow.

3. Select Skip on the Build an automated cloud flow screen.

4. Select the Custom tab, and then select your new custom connector.

5. Select a trigger from your custom connector.

6. Select New step.

7. Search for "approvals", and then select Start and wait for an approval.

8. Select the Approval type, and then populate the required fields on the Start and
wait for an approval card.

9. Select New step > Control > Condition.

10. Select the Choose a value text box, and then search the dynamic content for
"Responses Approver response".

11. Update the condition with the desired result.

） Important

The "Approve" or "Reject" approval responses are case sensitive.

12. Add an action in both condition result sections.



Manage approvals generated by the approval
flow

1. Sign in to Microsoft Teams .

2. Search for the approvals app, and then select it.

3. View your received and sent approvals.

4. Take an action that activates your custom connector’s trigger.

5. View the new approval request in flow run history.

6. View the new approval request in the approvals app.

7. Select the approval request, review the details, and then select Reject or Approve.



8. View the completed approval request in flow run history.

9. View the completed approval request in approvals app.

10. Confirm in the target system the approval completion update steps were executed
successfully.

See also
Create a custom connector from scratch
Use a Webhook as a trigger for Azure Logic Apps and Power Automate
Use a polling trigger for Microsoft Power Automate



Create a Power Automate visual for
Power BI
Article • 05/14/2024

APPLIES TO:  Power BI Desktop  Power BI service

When you create a Power Automate visual in a Power BI report, your end-users can run
an automated flow, just by clicking a button in your report. Furthermore, the flow can be
data contextual, meaning that the flow inputs can be dynamic, based on the filters the
end-users set.

Add the Power Automate visual
Power BI Desktop

1. Select the Power Automate icon from the Visualizations pane.



In Power BI Desktop, you can also add the visual from the ribbon. On the
Insert tab, select Power Automate in the Power Platform section.

Once you select the visual, it automatically gets added to your current report
page, with getting started instructions.

2. Scroll, resize the visual, or select the Focus mode icon to see all the instructions.



3. After you’ve reviewed the instructions, resize the button and place it where you’d
like on the report.

Change the environment in which your flow is
created
To select your preferred environment for creating your flow, use the environment picker
in the Power Automate visual. This includes environments where you have any built-in
security role, as well as any environments where you are an owner of one or more flows.
If you cannot find your preferred environment, see the article Troubleshoot missing
environments to learn more about the requirements.

Edit the flow



Power BI Desktop

1. With the flow selected, add any data fields to the Power Automate Data
region, to be used as dynamic inputs to the flow.

2. Select More options (...) > Edit to configure the button.

3. In edit mode of the visual, either select an existing flow to apply to the button, or
create a new flow to be applied to the button.



4. You can start from scratch or start with one of the built-in templates as an
example. To start from scratch, select New > Instant cloud flow.

5. Select New step.

6. Here, you can choose a subsequent action or specify a Control if you want to
specify additional logic to determine the subsequent action.



7. Optionally, you can reference the data field(s) as dynamic content if you want the
flow to be data contextual. This example uses the Region data field to create an
item in a SharePoint list. Based on the end-user’s selection, Region could have
multiple values or just one.



8. After you’ve configured your flow logic, name the flow, and select Save.

9. Select the arrow button to go to the Details page of the flow you just created.

Here's the Details page for a saved flow.



10. Select the Apply button  to attach the flow you’ve created to your button.

Format the flow
Optionally, you can change the button text, font color, font size, or fill color of the
button. These options along with other settings are available in the Format pane:



Test the flow
After you've applied a flow to the button, we recommend testing it before you share the
flow with others. These Power BI flows can only run in the context of a Power BI report.
You can't run these flows in a Power Automate web app or elsewhere.

If your flow is data contextual, make sure you test how the filter selections in the report
impact the flow outcome.

1. To test the flow in edit mode of the report, select Back to report, then press Ctrl
while you select the button to run the flow.



The button text indicates that the flow has been triggered.

2. To check if the flow has run successfully, select the More commands (...) menu >
Details in the flow that has been triggered:

3. On the Details page, you can see the run history and status for the flow:

） Important

You can only run these Power BI flows within the context of a Power BI report. You
can't start flows from the Power Automate portal. To test the flow in edit mode of
the report, select Back to report, and then press Ctrl + click on the button to run
the flow in the context of the report. You can also navigate to edit mode or to



Power Automate to view the run history of the flow and ensure it is running
successfully.

Share the flow
When the flow is running successfully, you can share it with your report readers.

1. Select Edit in the Run only users section:

2. Specify which users or groups you want to give run access to:



Give users edit access
Alternatively, you can give any users edit access to the flow, not just run permissions.

Select Share  , and specify the users or groups that you want to add as an
owner:



Considerations and limitations
Additional manual inputs to the button aren't supported.
The visual isn't supported for embedded analytics.
The visual doesn't work in Publish to Web (public) scenarios, because
unauthenticated scenarios aren't supported by Power Automate.
The visual doesn't support export scenarios.
The Power Automate visual is limited to process a maximum of 1000 records.
The user running the flow within the Power BI report needs to have permissions to
run the flow. Grant these permissions through direct sharing by the user or by
sharing to a Microsoft Entra group.
Create flows that you will use with the Power BI button trigger directly within the
Power BI report. Avoid going directly to Power Automate to create these flows, as
the trigger will not have access to the data fields necessary for creating the flow.
Power BI data is sent to, and processed in, a geography where the flow is
deployed.

Related content
For more information about Power Automate, take a look at the following articles:

Integrate Power BI data alerts with Power Automate
Export and email a Power BI report with Power Automate
Get started with Power Automate
More questions? Try the Power BI Community

Feedback



Was this page helpful?  Yes  No

Provide product feedback | Ask the community



Configure Power Automate cloud flows
in Power Pages
Article • 01/16/2025

Power Automate cloud flow allows users to create automated workflows between
different applications and services. You can use a Power Automate cloud flow to create
logic that performs one or more tasks when an event occurs. For example, configure a
button so that when a user selects it, send an email or meeting request, update a record,
collect data, synchronize files, and other tasks.

Now, you can securely invoke Power Automate cloud flows from Power Pages to interact
with 1000+ external data sources and integrate it into your business site.

７ Note

Your Power Pages site version must be 9.5.4.xx or later for this feature to work.
Your starter site package version must be 9.3.2304.x or higher.

Prerequisites
To integrate with Power Pages, a Power Automate license is required. It's recommended
to use a Power Automate Process license in the production instance.

Steps to integrate cloud flow
1. Create a cloud flow.

2. Add the flow to your site.

3. Invoke a flow from your website.

Create a flow
1. Sign into Power Pages .

2. Select site + Edit.

3. Navigate to the Set up workspace, then select Cloud flows under Integrations.



4. Select + Create new flow.

5. Search for Power Pages Select When Power Pages calls a flow trigger.

6. Define your flow steps and return values and select Save.

７ Note

Only solution-aware flows can be attached to the Power Pages site.

Add a flow to your Site
After you create an instant cloud flow, it needs to be associated with the Power Pages
site and secured with a web role.

1. Sign into Power Pages .

2. Select site + Edit.

3. Navigate to the Set up workspace, then select Cloud flows under Integrations.

4. Select + Add cloud flow.

5. Search for the recently created flow.

6. Select + Add roles under Roles.

7. Select roles that should have access to the flow.

8. Select Save.



７ Note

When you add a flow to your site, a unique URL is generated that allows you to
invoke the cloud from your site.

Invoke a flow from web page
Use Power Pages cloud flow API to interact with Power Automate to perform external
service integration. Cloud flow API operations consist of HTTP requests and responses.

ﾉ Expand table

Operation Method URI

Invoke cloud flow POST [Site URI]_/api/cloudflow/v1.0/trigger/<guid>

Example:

Request

HTML

POST 
https://contoso.powerappsportals.com/_api/cloudflow/v1.0/trigger/4d22a1a2-
8a67-e681-9985-3f36acfb8ed4
{
    "Location":"Seattle"
}



Response

Cloud flow without response action

HTML

HTTP/1.1 Accepted
Content-Type: application/json

Cloud flow with response action

HTML

HTTP/1.1 200 OK
Content-Type: application/json
Body
{
    "conditions":"Rain",
    "humidity":"93",
    "latitude":"47.60620880126953",
    "longitude":"-122.33206939697266"
}

Authenticating cloud flow API requests
You don't need to include an authentication code, because the application session
manages authentication and authorization. All API calls must include a Cross-Site
Request Forgery (CSRF) token.

Passing parameter to cloud flow
In a cloud flow, you can define input parameters of type Text, Boolean, File, and
Number. The parameter name you define in the request body should match the
parameter name defined in the cloud flow trigger.

） Important

You must pass the request parameters name as defined in the cloud flow.
Support for passing a parameter to a flow configured with secure inputs isn't
available.

Sample JavaScript to call a flow



This sample demonstrates how to call a flow using Asynchronous JavaScript and XML
(AJAX).

    shell.ajaxSafePost({
        type: "POST",
        url: "/_api/cloudflow/v1.0/trigger/44a4b2f2-0d1a-4820-bf93-
9376278d49c4",
        data: {"eventData":JSON.stringify({"Email": "abc@contoso.com", 
"File":{"name":"Report.pdf", "contentBytes":"base 64 encoded string"} })}
    })
    .done(function (response) {
    
    })
    .fail(function(){
    
    });

７ Note

If no input parameter is defined in the trigger, pass an empty payload in the
request.
For information on cloud flow limitations, see Limits of automated,
scheduled, and instant flows.

Application Lifecycle Management (ALM) for
Cloud flows
When you move Power Pages site components that include cloud flows from one
environment to another, the cloud flows must be registered in the target environment. If
you don't register the cloud flows, invoking them from the website results in a forbidden
error.

To register the flow with the target environment, follow these steps:

1. Sign into Power Pages  and select the target environment.

2. Locate the site and select Edit.

3. Go to the Set up workspace, then select Cloud flows under Integrations.

4. Within the Cloud flows in this site list, look for the register button.



5. To register the flow, select the icon.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Overview of flows with Microsoft Forms
Article • 04/11/2023

Use the Microsoft Forms connector in Power Automate to add a form to a flow. Do you
need to record a purchase in your sales system when you receive an order form? Maybe
you'd like to get an emailed notification when a customer submits a survey or a student
turns in a quiz. These are a few examples of how using forms with Power Automate
flows can eliminate manual data entry, simplify record keeping, and help you stay on
top of your day.

Watch the following video to see how you can use a form in Power Automate.
https://www.microsoft.com/en-us/videoplayer/embed/RWKXdv?postJsllMsg=true

Triggering a form action in a flow
In Power Automate, a trigger is an event that starts a run of a flow. Actions are the steps
a flow takes in response to the trigger.

Forms has one trigger. "When a new response is submitted," and one action, "Get
response details." The action pulls in the details of the form response as dynamic
content that you can use elsewhere in the flow.






Get started using flows with Microsoft
Forms
Article • 02/09/2023

The easiest way to add a form to a flow is to start with a template. Search the template
gallery  for "Microsoft Forms," or browse by category, to find a template that meets
your needs. Follow the steps in the template to create your flow.

If you find a template that's similar to what you want to do but it isn't exactly right for
your scenario, you can still create a flow from the template and then customize it. You
can add, edit, and remove triggers and actions. You can even copy and paste actions in
the same flow or across flows to speed up the process.

If you can't find a template that you like, Create a flow from scratch, connect the services
you want to use, and then add the triggers and actions that your scenario requires.

If you need inspiration, check out the list of the most common ways to use forms in a
flow.

More information
Create a cloud flow from a template in Power Automate
Submit a template to the Power Automate gallery



Common ways to use a form in a flow
Article • 04/01/2025

If you're not sure where to start, these are some of the most common ways people use
Microsoft Forms with Power Automate:

Send an email when there's a new form response
Send an email to the form responder
Send an approval request with the form details
Add form responses to an Excel worksheet
Get an attachment from a form and send it in an email

Send an email when there's a new form
response
You can turn on email notifications for the form's owners in your form settings. If you
want someone else to be notified when a response is submitted, create a custom email
notification with Power Automate.

７ Note

Power Automate uses either the classic cloud flows designer or the new
modern designer with Copilot capabilities. To identify which designer you’re
using, go to the Note section in Explore the cloud flows designer.
When you switch between the classic and new designer, you're asked to save
your flow. You can't save and switch until all errors are resolved.

New designer

1. Ask Copilot to create your flow by typing the following prompt:

when a new MS Forms response is submitted, send an email

Power Automate returns a suggested flow that corresponds to what you've
entered.



2. Select Next.

3. Review the connections and select Create flow to land on the designer.

4. On the designer, provide the missing fields in the Send an email* action if
Copilot didn't automatically populate it for you.

Send an email to the form responder



You can turn on email receipts for respondents in your form settings. If you want to
customize the email they receive, use Power Automate.

New designer

1. Ask Copilot to create your flow by typing the following prompt:

Send email to the responder along with their response

Copilot tries configuring most of the parameters in the email action, as in the
following example:

2. Fill in the rest of the parameters in the email action (Email body).



3. Save the flow.

Send an approval request with the form details
In this example, we'll start with another prebuilt template and customize it to create a
vacation approval request.

New designer

[This topic is prerelease documentation and is subject to change.]

1. Search for Microsoft Forms in the Power Automate template gallery  and
select the template named Send form responses for approval.

2. Sign in to or create the connectors, as needed, and select Continue.

3. Ask Copilot to create your flow by typing the following prompt:

when a new response is submitted, start an approval with
megan@contoso.com and if it succeeds, send email to the responder

Power Automate returns a suggested flow that corresponds to what you've
entered.



4. Select Next.

5. Review the connections and select Create flow to land on the designer.

6. On the designer, provide the forms ID, approver's email, and configure the
email action.

7. Save your flow.

Add form responses to an Excel worksheet
In this example, you create a flow from blank. Continuing with the scenario from our
earlier examples, we'll use the flow to record employees' names and vacation dates in an
Excel table when they submit their summer vacation form.

New designer

1. Create an Excel sheet if it doesn't already exist.

2. From within the designer, simply ask copilot to create your flow by typing the
the following prompt:

If approved, add the forms response to excel sheet



Power Automate returns a suggested flow that corresponds to what you've
entered.

3. Choose the Excel sheet of your choice.

4. In the respective column fields, choose the response token from MS forms
trigger.

For example, choose the vacation start token in the Vacation start field of the
Excel action.

Get an attachment from a form and send it in
an email
In this example, we'll create another flow from blank. We'll use the flow to create a share
link for a file that's uploaded on our summer vacation form, and then email the link.



Select your form
1. In Power Automate, create an automated cloud flow from blank.

2. Select the Microsoft Forms When a new response is submitted trigger.

3. In the first step in the flow, When a new response is submitted, select your form in
the Form Id box.

4. Add a step to your flow:

Search for forms, and then select Microsoft Forms.
Select Get response details.
Select your form in the Form Id box.

Use a JSON schema to find the uploaded file
1. Save and test your flow. Be sure to upload a file to your form.

This step allows Power Automate to use the test run to generate a sample JSON
schema for the uploaded file.

2. On your flow's information page, under 28-day run history, select the test run.

3. Expand the Get response details step and copy the contents of the file upload
output.



4. In the upper-right corner of the window, select the Edit pencil icon to open the
flow canvas.

5. Add a step to your flow:

Search for "parse" and select Parse JSON.

In the Content box, select the dynamic content that corresponds to the file
upload option on the form.



6. Select Generate from sample.

7. Under Insert a sample JSON payload, select the box and paste the file upload
output you copied earlier, and then select Done.

The Parse JSON action should look something like this after you select Done:



Create a share link and email the URL
1. Add a step to your flow:

Search for "create share link" and select the OneDrive for Business action
Create share link.

Select the File box. The dynamic content panel opens. Select the Expression
tab.

Type the following expression: first(body('Parse_JSON'))?['id']

Select the Link type and Link scope.

Select OK.

2. Add a step to your flow:

Search for "send email" and select the Office 365 Outlook action Send an
email (V2).

Enter the recipients, subject, and body of the email. Select dynamic content
to include details from the form response in your email.

Convert the URL to a clickable link



To make the URL of the shared file a clickable link in the email, you'll need to use the
HTML editor and an anchor tag:

1. In the email body toolbar, select the HTML view icon (</>).
2. Enclose the dynamic content Web URL and name in an anchor tag to turn them

into a link and the link title, respectively.

In this example, you entered the following HTML in the email body, where text in curly
brackets indicates the dynamic content:

HTML

<a href="{WebURL}">{name}</a>

Here's an example:

You can combine getting an attachment from a form and creating an approval flow.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



How to do more with forms in Power
Automate
Article • 02/09/2023

Here are some less-common things you can do with a form in your automated flows:

Change the format of dates in a flow
Change the response submission time zone
Add a group form to a flow
Send an email based on a conditional form response
Convert an attachment on a form to PDF or other file type
Upload form responses to a Power BI dataset
Create a lead from a form response

Change the format of dates in a flow
Learn how to customize date formats in a flow .

Change the response submission time zone
By default, the form shows the response submission timestamp in the UTC time zone.
Learn how to convert the time zone .

Add a group form to a flow
If a group is the owner of the form you want to add to a flow, Power Automate doesn't
list it in the Form Id.

Go to the form. Copy the Form Id from the URL of the form, and then add it as a custom
value.

Send an email based on a conditional form
response
When you use a form in a flow, you can add a condition that's based on how a user
responds to a question in the form. The condition can test a text value or a numerical
value. The condition creates two parallel branches, If yes and If no, to which you can add
actions.



For example, you can use a condition to email details about a specific event or a general
calendar of events, depending on how customers respond on an interest form. To learn
more, follow the step-by-step instructions in Create an automated workflow for
Microsoft Forms .

Convert an attachment on a form to PDF or
another file type
Add your form to a flow, and then add the following actions.

Data Operation - Select
Data Operation - Create HTML table
OneDrive for Business - Create file
OneDrive for Business - Convert file

Upload form responses to a Power BI dataset
Learn how to turn Forms surveys into insights with Power Automate and Power BI .

More information
Troubleshoot common issues
Microsoft Forms - known issues and limitations



Troubleshoot known issues with forms
in flows
Article • 12/16/2022

Review the following troubleshooting tips in your form in a flow isn't working as you
expect.

Limitations
Make sure you aren't trying to make a form do something it can't. For information about
the limitations of forms, go to Microsoft Forms - known issues and limitations.

Known issues

My flow doesn’t work or has stopped working
Make sure that your form still exists in the same location.

You might have reached a limit for the connector or for the product. For the Microsoft
Forms connector, you're limited to 300 API calls per connection within 60 seconds and
one trigger poll every 86,400 seconds. Also check the response limits  for Microsoft
Forms.

I'm getting an invalid connection error
Verify the throttling limits for all connectors in your flow. You can find the throttling
limits for each connector in the reference documentation for that connector. For
example, the reference documentation for the SharePoint connector is available.

Temporarily turn off your browser plug-ins, such as the Privacy Badger, that may block
the cookies that Power Automate uses.

When the email sends form responses, the files are
corrupt
Make sure you aren't using a base64()  function, since it might corrupt the files.

Flows with forms only work sometimes



One common reason this happens is that a user entered more than 255 characters in a
single-line text field in the form. Try using a multi-line text field instead.

Form created by another team isn’t listed as an option in
Form Id
Check whether the form is listed in the Microsoft Forms Shared with me tab.

You can also check the transfer ownership of the form , especially if members of the
team will leave the company.

The Form Id field lists duplicate form names
The Form Id list picks up forms that you have deleted but which are still in the Recycle
Bin. In Microsoft Forms, delete forms you no longer need, and then empty the recycle
bin.

Unable to find the correct Form Id
Go to your form. copy the Form Id from the URL of the form, and then add it as a
custom value.

I don’t get an attachment for some of my approvals
The approval action limits the size of file attachments in email to 5 MB. For attachments
that are larger than 5 MB, the approval action redirects approvers to check for the
attachment on the Power Automate Action items > Approvals page.

Send email action looks stuck in my flow
If you're using the Mail connector in your flow, try using the Office 365 Outlook
connector instead. The Mail connector has a limit of 100 API calls per 24 hours. The
Outlook connector has a limit of 300 API calls per 60 seconds, which means that you're
much less likely to reach the limit.



Overview of how to integrate Power
Automate flows with Dataverse
Article • 04/09/2025

With Microsoft Dataverse , you can store and manage data for business applications and
integrate natively with other Microsoft Power Platform services like Power Apps, Power Pages,
and Microsoft Copilot Studio from your cloud flows.

The Microsoft Dataverse connector provides several triggers to start your flows and many
actions that you can use to create or update data in Dataverse while your flows run. You can
use Dataverse actions even if your flows don't use a trigger from the Dataverse connector.

Use the Microsoft Dataverse connector to create cloud flows that start when data changes in
Dataverse tables and custom messages. For example, you can send an email whenever a row
gets updated in Dataverse.

Overview of triggers



The Microsoft Dataverse connector provides the following triggers to help you define when
your flows start:

When a row is created, updated, or deleted
When a row is selected
When an action is performed

Overview of actions
The Microsoft Dataverse connector provides the following actions to help you manage data in
your flows:

Create a new row
Update a row
Search rows with relevance search
Get a row
List rows
Delete a row
Relate rows
Unrelate rows
Execute a changeset request
Download file or image content
Upload file or image content
Perform a bound action
Perform an unbound action



Trigger flows when a row is added,
modified, or deleted
Article • 04/01/2025

The When a row is added, modified or deleted trigger runs a flow whenever a row of a
selected table and scope changes or is created.

Prerequisites
To create a flow that triggers when you create, modify, or delete a row, you must
have user-level permissions for create, read, write, and delete on the Callback
Registration table.

Additionally, depending on the scopes defined in the flow, you might need at least
that level of read on the same table. You can get more information about
Environment security.

The following information is required to use the When a row is added, modified or
deleted trigger.

Trigger condition
Table name
Scope

７ Note

Power Automate uses either the classic cloud flows designer or the new
modern designer with Copilot capabilities. To identify which designer you’re
using, go to the Note section in Explore the cloud flows designer.
When you switch between the classic and new designer, you're asked to save
your flow. You can't save and switch until all errors are resolved.

New designer

In your flow, select the card for the When a row is added, modified or deleted
trigger. A pane opens on the left with the Parameters tab selected.



Trigger condition
The trigger condition, Change type, precisely defines which combination of changes to
a row would run the flow.

When the flow is triggered by the creation, update, or deletion of a row, the value of
triggerOutputs()['body/SdkMessage']  will be Create , Update , or Delete , respectively.

If there are multiple updates to a single row in a table, Power Automate evaluates the
trigger for each update, even if the values that are being updated on the row are the
same as the previous value. These updates could lead to multiple flow runs.

Table name
The Table name list filters the rows to indicate precisely which kind of rows should
change before the flow triggers. See Tables in Dataverse.

The When a row is added, modified or deleted trigger doesn't support triggering flows
on relationships of type 1:N or N:N.

Scope
The Scope list indicates those rows should be monitored to determine if the flow should
be run.



Here’s what each scope means:

ﾉ Expand table

Scope Row ownership level

Business Unit Actions are taken on rows owned by anyone in your business unit.

Organization Actions are taken by anyone within the environment.

Parent: Child business Actions are taken on rows that are owned by anyone in your business
unit unit or a child business unit.

User Actions are taken on rows owned by you.

Advanced options
You can set additional properties to define more granularly when the flow runs and the
user profile under which it runs.

New designer

[This topic is prerelease documentation and is subject to change.]

1. To access the advanced options, select the List rows card.

2. In the Parameters tab, select Add new parameters from the dropdown menu.

Filter conditions
Use filter conditions to set conditions for when to trigger flows.



Filter columns
Use the Select columns box to define the specific columns of the row that should cause
the flow to run when included in the request, as a comma-separated list of unique
column names. Only include columns with changed values in update requests. The flow
will run when the values included are the same as existing values.

This property applies to the Update condition only. Create and Delete apply to all
columns of a row.

This property isn't supported on virtual tables.

Filter expression
The filter expression provides a way for you to define an OData style filter expression to
help you to define the trigger conditions even more precisely. The flow runs only when
the expression evaluates to true after the change is saved in Dataverse. In the following
examples, the flow triggers when firstname  is updated to "John".

Examples for Filter rows:

firstname eq 'John'

contains(firstname,'John')

To learn how to construct these filter expressions, go to the examples in standard filter
operators and query functions.

Unlike the examples in the reference links, your expression must not contain the string
$filter=. This string applies only when you use the APIs directly.

Wait condition using delay until
Use an OData-style time stamp in the Delay until property to delay the flow trigger until
a specific UTC time.

The key benefit of using the Dataverse Delay until property instead of the standard
Delay until action is the Dataverse Delay until property never expires, allowing the flow
run to wait for long periods of time.

User impersonation using Run As



The flow owner must have the Microsoft Dataverse privilege Act on Behalf of Another
User (prvActOnBehalfOfAnotherUser). The Delegate security role includes this privilege
by default. You can enable it on any security role. For more details, go to Impersonate
another user.

When you create flows with the When a row is added, modified or deleted trigger, you
can set each Microsoft Dataverse action in the flow to be performed using the context
of a user, other than the flow owner.

Follow these steps to impersonate a user.

New designer

For each Dataverse action that you want to run as a different user, select an option
in the Run as dropdown menu.

For the steps in which it isn't selected, the default user is assumed. This calls the
underlying APIs as per the selected user, and not as the flow owner. If nothing is
specified, it defaults to the flow owner who created the flow—essentially, the
author.

Here are the other options:

Flow owner: The user who created the flow.

Row owner: The user who owns the Microsoft Dataverse row that underwent a
change, causing the flow to be triggered. If a row is owned by a team, then this
option falls back to run as the flow owner.

Modifying user: The user that took the action on the Microsoft Dataverse row,
causing the flow to get triggered or modified.

Additionally, instant flows allow running the steps of any other connector such as
Microsoft Teams, Microsoft 365 Outlook, or SharePoint in the same flow using the
invoker’s connection. To do so, follow these steps:

1. Go to the flow overview page.

2. Select Edit on the Run only users settings.

3. In the Manage run-only permissions pane, go to the User and groups tab, and
then select Provided by run-only user under the Connections Used list.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Trigger flows with actions
Article • 10/09/2024

You can create flows that trigger based on a Dataverse action that's included in both a
Catalog and a Category.

Additionally, your role needs permissions to read it, which may require read access to
the sdkmessage, customapi, or workflows tables in Dataverse.

As the name suggests, this trigger runs the flow whenever a specific Dataverse action is
performed. A Dataverse action is distinct from a Power Automate action. In Dataverse,
custom process actions, or simply actions, are a way of extending out of the box
operations on data. You can use them to define reusable custom business logic. To learn
more, see Work with actions and Use Custom Process Actions with code. To learn how to
run Dataverse actions from Power Automate, see Perform bound or unbound actions.

Here are the input fields for the trigger.

Catalog – used to organize and manage Dataverse actions, similar to the way you
use folders to organize files.

Category – used as a sub-classification within a catalog.

Table name – used to filter the available actions by their associated table (bound
actions), or to filter global actions (unbound actions). For unbound actions, select
(none).

Action name – used to identify the action that triggers the flow each time it runs
successfully. The list of available actions is filtered by the catalog, category, and
table name.



Using dynamic content and action inputs /
outputs
A Dataverse custom action is meant for custom business logic, it accepts input
parameters and returns output parameters. When this trigger runs, these parameters are
available as dynamic content in the flow and can be used in subsequent steps.

Here's the naming scheme for the parameters.

The prefixes ActionInputs and ActionOutputs specify whether it is an input or
output parameter.



The next literal is the name of the parameter.

For complex data types such as an entity object, the last literal is the column name,
for example, donotfax.

Related information
Training: Use Dataverse triggers and actions in Power Automate (module)
Training: Integrate Power Automate with SharePoint HTTP actions (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Use a flow to add a row in Dataverse
Article • 02/09/2023

Use the Add a new row action to add a new row in Microsoft Dataverse.

Follow these steps to add a new account in Dataverse when you receive an email to your
sign-up address, as shown in the following image:

1. Create a flow with the When a new email arrives (V3) trigger to your flow.

2. Select New step to add an action to your flow.

3. Enter new row into the Search connectors and actions search box on the Choose
an operation card.

4. Select Microsoft Dataverse.

5. Select Add a new row action.

6. Select the Accounts table in the Add a new row card.



After you select a table, the card expands, displaying both optional and required
items. All mandatory items display an asterisk (*).

7. Optional: If you don't see a column that you need, select Show advanced options
at the bottom of the card to view all columns.

 Tip



You can use outputs from previous triggers and actions in the Dynamic content
selector, as shown in the following image, or modify them by building an
expression as outlined in Use expressions in flow actions .



Use a flow to update a row
Article • 12/16/2022

Use the Update a row action to make changes to a row in Microsoft Dataverse.

For example, you can create a flow that updates an Account in Dataverse when you
receive an email, as shown in the following image.

Update a row
After you select a table, the action card displays a list of inputs for the row Id that's
related to the columns in the table to update. An asterisk (*) indicates the mandatory
columns. The Row Id column is the unique Id for the row that's being updated. If you



provide a row Id that doesn't exist or generated with the guid() expression, the action
performs an update or insert (upsert) operation, creating a new row with the Id you
provide.

If you don't see a column, select Show advanced options at the bottom of the card. The
update doesn't include columns left blank, unless a null value is provided explicitly.



Get a row by ID from Dataverse
Article • 12/16/2022

Use the Get a row by ID action to retrieve data from Microsoft Dataverse. This action
helps you retrieve the columns of a specific row when its unique ID is known.

 Tip

After you get a row by ID, you can use the columns from that row in all steps that
come later in your flow.

Follow these steps to use Row ID to get a row from the Accounts table.

1. Select New step to add an action to your flow.

2. Enter get row into the Search connectors and actions search box on the Choose
an operation card.

3. Select Microsoft Dataverse.



4. Select the Get a row by ID action.

5. Select the Accounts table from the Table name list, and then enter the row ID in
the Row ID box for the row that you want to get from the Accounts table.



７ Note

The Row ID column is the unique ID of the row that you are retrieving, as
shown in the following image. You can get the row Id by using a query in the
actions in your flow before you need to use the row id.

Advanced options
Select Show advanced options to set more properties that further define the
information that should be returned.

The advanced options are:

Select columns
Expand Query
Partition Id



Select columns
Sometimes it's necessary to optimize the amount of data retrieved in a flow, especially if
you're performing this step inside a loop. Instead of retrieving all columns, you can
specify which ones you want to retrieve by entering unique names of those columns.
Separate columns with a comma.

Expand Query
Use Expand Query to specify an OData-style expression that defines which data from
related tables is returned. There are two types of navigation properties:

Single-valued navigation properties correspond to Lookup columns that
support
many-to-one relationships and allow you to set a reference to another table.

Collection-valued navigation properties correspond to one-to-many or
many-to-
many relationships.

If you include only the name of the navigation property, you’ll receive all the properties
for the related rows. To learn more, see Retrieve related table rows with a query.

To use the Expand Query box in a flow step, enter an Odata expression as shown in the
following image. This example shows how to get the contactid and fullname columns for
the primarycontactid of the account.






Use a flow to delete a row from
Dataverse
Article • 12/16/2022

Follow these steps to delete a row from Dataverse.

1. Create a flow with the When a new email arrives (V3) trigger to your flow.

2. Select New step to add an action to your flow.

3. Enter delete row into the Search connectors and actions search box on the
Choose an operation card.

4. Select Microsoft Dataverse.

5. Select Delete a new row action.



6. Select the table name, and then enter an ID in Row ID.

The Row ID column is the unique ID of the row that you are deleting.

 Tip

You can retrieve the Row ID by using the dynamic content that's generated from
earlier steps in your flow.



Use lists of rows in flows
Article • 04/01/2025

Use the List rows action to retrieve multiple rows at once from Microsoft Dataverse with
a structured query.

Get a list of rows
Follow these steps to add the List rows action to your flow to return up to 5,000
accounts from the Accounts table in Dataverse.

７ Note

Power Automate uses either the classic cloud flows designer or the new
modern designer with Copilot capabilities. To identify which designer you’re
using, go to the Note section in Explore the cloud flows designer.
When you switch between the classic and new designer, you're asked to save
your flow. You can't save and switch until all errors are resolved.

New designer

1. Select the plus sign (+) > Add an action.
2. On the Add an action sceen, enter list rows in the Search field.
3. Under Microsoft Dataverse, select List rows (Preview).
4. On the Parameters tab to the left, select Accounts in the Table Name

dropdown menu.
5. Close the screen by selecting (<<).

Turn on pagination to request more than 5,000
rows
To get more than 5,000 rows from a query automatically, turn on the Pagination feature
from Settings.

When pagination is set and the amount of rows exceeds that number of the threshold
configured, the response won't include the @odata.nextLink parameter to request the



next set of rows. Turn pagination off so that the response includes the @odata.nextLink
parameter that can be used to request the next set of rows. Go to Skip token to learn
how to use it.

Content throughput limits and message size limits apply to ensure general service
guarantees.

New designer

1. Select the List rows card.

2. On the pane to the left, select the Settings tab > Networking.

3. Move the Pagination slider to the On position if it's not already turned on.

4. In Threshold, enter the maximum number of rows requested. The maximum
configurable threshold is 100,000.

Internally, this number is rounded off in increments of the default page size.
For example, if that page size is 5,000, and you enter 7,000, the number of
rows returned is 10,000.

Advanced options
The advanced options for the List Rows action allow you to sort, filter, arrange, and
extend the results of a query.

New designer

You can set options inthe action configuration pane.

1. To see the options, select the List rows card.

2. In the Parameters tab, select an advanced option in the Add new parameters
dropdown menu.



Select columns
Enter a comma-separated list of columns to return, such as
"name,createdon,preferredcontactmethodcode,emailaddress1,telephone1" for the
Account table.

Filter rows
Use to define an OData-style filter expression to narrow down the set of rows that
Dataverse returns, such as "createdon ge 2021-01-01T00:00:00-00:00" for rows with
createdon greater than or equal to the year 2021.

Learn how to use standard filter operators and query functions to construct Filter Query
expressions.

Certain characters, such as &, #, and + need to be replaced with their URL-encoded
equivalent. More information: URL encode special characters



） Important

Filter expressions can't contain this string, $filter=, because it only applies when
you use the APIs directly.

Sort by
Use to define an OData-style expression that defines the order in which items are
returned, such as "name desc". Use the asc or desc suffix to indicate ascending or
descending order, respectively. The default order is ascending.

Expand query
Use to specify an OData-style expression that defines the data that Dataverse returns
from the related tables, such as primarycontactid($select=contactid,fullname)  to use
the account's primarycontactid to retrieve the fullname column from the related
contact with ID contactid in the response.

There are two types of navigation properties that you can use in Expand Query:

1. Single-valued navigation properties correspond to lookup columns that support
many-to-one relationships and allow you to set a reference to another table.

2. Collection-valued navigation properties correspond to one-to-many or many-to-
many relationships.

If you include only the name of the navigation property, you’ll receive all the properties
for the related rows. To learn more, see Retrieve related table rows with a query.

To use it in a flow step, enter this Odata expression in the Expand Query field:
primarycontactid(contactid,fullname) . This is how to get the contactid and fullname
columns for the primarycontactid of each account.

Row count
Use to indicate the specific number of rows for Dataverse to return. Here's an example
that shows how to request 10 rows.

Fetch Xml Query



Aggregation queries aren't currently supported when using the List rows action with
FetchXML queries. However, the distinct operator is supported.

New designer

Use a Dataverse-style FetchXML query, which allows more flexibility in building
custom queries. These queries can be useful when you work with a table that has
multiple related tables, or handling pagination. The following screenshot shows
how to use FetchXML.

Example FetchXML query for the Account table:

XML

<fetch count="10">
<entity name="account">

<attribute name="name" />
<attribute name="preferredcontactmethodcode" />
<attribute name="emailaddress1" />
<attribute name="telephone1" />

   <link-entity name="contact" to="primarycontactid" 
from="contactid">
      <attribute name="fullname" />

</link-entity>
<filter> 

<condition attribute="createdon" operator="ge" value="2021-
01-01T00:00:00-00:00" />

</filter>
<order attribute="name" descending="true" />

</entity>
</fetch>

As the distinct operator isn't currently supported directly in FetchXML queries from
the List rows action, the union function can be used to remove duplicate rows. For
example, you can use the Select action to transform the response of the List rows
connection to the specific array format you need, then create a variable with the
expression union(body(‘Select’),body(‘Select’)) to get an array with distinct rows.

Skip token
Because Power Automate applies content throughput limits and message size limits to
ensure general service guarantees, it's often useful to use pagination to return a smaller
number of rows in a batch, rather than the default limits on number of table rows
returned.



The default page limit of 5,000 rows applies if you don't use pagination.

To use it, implement a loop to parse the @odata.nextLink value in the JSON response,
extract the skip token, and then send another request until you've listed the number of
rows that you need.

JSON

HTTP/1.1 200 OK  
Content-Type: application/json; odata.metadata=minimal  
OData-Version: 4.0  
Content-Length: 402  
Preference-Applied: odata.maxpagesize=3  
  
{  
   "@odata.context":"[Organization 
URI]/api/data/v9.1/$metadata#accounts(name)",
   "value":[  
      {  
         "@odata.etag":"W/\"437194\"",
         "name":"Fourth Coffee (sample)",
         "accountid":"7d51925c-cde2-e411-80db-00155d2a68cb"
      },
      {  
         "@odata.etag":"W/\"437195\"",
         "name":"Litware, Inc. (sample)",
         "accountid":"7f51925c-cde2-e411-80db-00155d2a68cb"
      },
      {  
         "@odata.etag":"W/\"468026\"",
         "name":"Adventure Works (sample)",
         "accountid":"8151925c-cde2-e411-80db-00155d2a68cb"
      }
   ],
   "@odata.nextLink":"[Organization URI]/api/data/v9.1/accounts?
$select=name&$skiptoken=%3Ccookie%20pagenumber=%222%22%20pagingcookie=%22%25
3ccookie%2520page%253d%25221%2522%253e%253caccountid%2520last%253d%2522%257b
8151925C-CDE2-E411-80DB-
00155D2A68CB%257d%2522%2520first%253d%2522%257b7D51925C-CDE2-E411-80DB-
00155D2A68CB%257d%2522%2520%252f%253e%253c%252fcookie%253e%22%20/%3E"
}

Partition ID
An option to specify the partitionId while retrieving data for NoSQL tables. To learn
more, see Improve performance using storage partitions when accessing table data.

Related information



Training: Use Dataverse triggers and actions in Power Automate (module)
Training: Integrate Power Automate flows and Dataverse (learning path)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Connect to other environments using the
Microsoft Dataverse connector
Article • 04/09/2025

You can automate apps, data, and processes across Dataverse databases in different Power
Platform environments through supported actions in the Microsoft Dataverse connector.

Dataverse connector operations with the Environment parameter allow you to choose between
using the current environment where the flow is located or selecting another environment.

Actions with names ending in selected environment are now generally available to use in
cloud flows, with an Environment parameter that allows you to choose between the current
environment where the flow is located or another environment. Support for triggering flows
based on Dataverse changes from other environments isn't yet available.

The following diagram shows a Power Automate cloud flow being triggered when a row
changes in the Contoso Support environment. It takes actions in other Contoso Services and
Contoso Field Service environments to list rows, add a row, and perform an action in the
example Contoso Corporation's Microsoft Entra tenant.

Add actions that connect to other environments
1. Sign in to Power Automate .

2. Create a new cloud flow such as an instant flow with the Manually trigger a flow trigger.

Alternatively, you can open an existing flow.

3. In the flow designer, select the plus sign (+) to add a new action.



4. Search for dataverse, and then select See more on the Microsoft Dataverse connector to
see all available actions.

5. Add one of actions that ends in selected environment, such as List rows from selected
environment.

6. Use the Environment parameter in the action card to choose the environment to connect
to. The connection you use for the action must have permissions to perform the
operation in the other environment.



7. To connect to Dataverse in the same environment as the flow, select (Current) in the
Environment parameter.

Actions and triggers that can connect to other
environments
The following actions now support connecting to other environments, and appear in the flow
designer with names ending in selected environment:

Add a new row
Update a row
Delete a row
List rows
Get a row by ID
Perform a bound action
Perform an unbound action
Relate rows
Unrelate rows
Upload a file or image
Download a file or image



The actions to search rows and perform a changeset request don't support the Environment
parameter yet.

Support for the following triggers is coming soon:

When a row is added, modified or deleted
When an action is performed

The When a row is selected trigger doesn't have the Environment parameter because it's only
supported within the same environment as the related Dataverse table.

Features supported by operations with the
Environment parameter

Connect to the same environment the flow is located when (Current) is selected as the
environment.
Connect to other environments in the same tenant or other tenants based on the
connection used. The connection must have permissions.

To restrict connections to other tenants from the Microsoft Dataverse connector and
other connectors, Power Platform administrators can enable tenant isolation policies.

Connect to an environment specified dynamically.
Use of user and service principal connections.

Add actions that connect to other environments
dynamically
To set the Environment parameter dynamically, select Enter custom value at the end of the
Environment parameter selector and provide the base URL of a Power Platform environment.
The URL should be in the format https://<yourenvironmentid>.crm.dynamics.com/  and can be
provided as a string, expression, environment variable, or dynamic content.

To get the base URL of an environment, open the details page of the environment from the
Power Platform admin center , or use the output of the List user environments action in the
Power Automate Management connector.

For actions like Add a row that depend on the specific table schema from one environment,
the schema isn't automatically retrieved when specifying the environment dynamically, and the
request payload needs to be manually constructed. To use these actions, set the Table
parameter to the LogicalCollectionName  of the table, and the Body parameter to the contents
of the equivalent Dataverse Web API request in JSON format. For example, to create a new
account, enter the table name as accounts and the body as {"name": "Contoso Marketing"}.



Best practices
For best performance, deploy flows using the Microsoft Dataverse connector to the same
Power Platform environment as the data and apps they're connecting to.

The Microsoft Dataverse connector in Power Automate is optimized to directly connect
to Dataverse through a native integration when the Environment parameter is set to
(Current) .
When connecting to other environments, it connects through the Power Platform
connectors platform.

Review recommended admin and governance practices around your Power Platform
environment strategy when planning solutions that connect to other environments,
including staging flows in separate development, test, and production environments for
specific business groups and applications.

Limitations
Dataverse connector operations connecting to other environments require the
connection to remain active and the related user to have sufficient permissions in
Dataverse. Actions and triggers in the current environment can continue to run as long as
the related user is still active and has sufficient permissions in Dataverse, even if the
connection is expired. Learn more about maintaining Dataverse connector connections.
Using instant flows with the Dataverse connection set to Provided by run-only user isn't
supported outside of the current environment yet.
The triggers When a row is added, modified or deleted and When an action is
performed don't support the Environment parameter yet.
The Environment  parameter isn't supported for the actions Search rows (preview) and
Perform a changeset.



Use wait conditions to delay flows
Article • 06/20/2024

The Microsoft Dataverse connector provides four ways to add wait conditions. Use these
wait conditions when you need to delay processing in your flows until a particular
condition is met.

Postpone triggering the flow and the first action until a specific time. To learn
more, go to Wait condition using Postpone Until.

Add a fixed delay before the next step.

Delay an action until a specific timestamp.

Delay an action until a specific event occurs. You can use this action from the
Microsoft Dataverse connector or any other connector as a step in the middle of
the flow to delay subsequent steps until a specific event occurs. For example, you
can define a flow that’s similar to the one in the following image to check for
updates to Account rows in Dataverse, and then waits for an email confirmation
from the Account manager before updating the change.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Perform bound actions or unbound
actions
Article • 10/09/2024

） Important

In this acticle, the term action means a Dataverse action. Dataverse actions aren't
the same as Power Automate actions. In Dataverse, you use actions to extend out
of the box operations on data. You can use these actions to define reusable custom
business logic.

Flows can call Dataverse actions that are available in the Microsoft Dataverse connector.
These actions include everything from fulfilling a sales order to exporting a solution.

Actions represent operations that might have side effects in the database, such as
creating or updating rows.

There are two types of Dataverse actions that you can use in flows.

Bound actions
Unbound actions

Bound actions
Bound actions target a single table or a set of rows from a single table.

To perform a bound action, add Perform a bound action to your flow.

Follow these steps to edit one of your flows to perform a bound action.

1. After any step in your flow, select Add new step.

2. Enter bound in the search box, select Microsoft Dataverse from the list of
connectors, and then select Perform a bound action.



3. In Table name, select the name of a table you want to use.

4. In Action name, select the action you'll perform.

5. In Row ID, enter the row in the table on which you want to perform the bound
action.



6. Save, and then run your flow.

7. Confirm that the bound action completes successfully on the table that you
selected.

Unbound actions
Unbound actions aren’t bound to a table and are called as static operations. Unbound
actions are performed on the entire environment, not on specific tables or rows.

To perform an unbound action in your flow, add Perform an unbound action to your
flow.

To edit one of your flows to perform an unbound action, follow these steps.

1. After any step in your flow, select Add new step.

2. Enter unbound in the search box, select Microsoft Dataverse from the list of
connectors, and then select Perform an unbound action.



3. In Action name, select an action.

4. Enter or select any of the optional details on the Perform an unbound action card.

5. Save, and then run your flow.

6. Confirm that the unbound action completes successfully.

Related information
Training: Use Dataverse triggers and actions in Power Automate (module)
Training: Integrate Power Automate with SharePoint HTTP actions (module)

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Use relationships to modify rows
Article • 12/16/2022

Relationships are an important concept in the Microsoft Dataverse. Power Automate
allows you to work with these relationships in a few ways.

Modify or add rows directly with relationships
When you create or modify rows, there are columns that hold relationships. For
example, when you create an account, there is a Primary Contact column.

When you want to create or modify a relationship, use standard OData notation. For
example, while creating an account row, you should set the Primary contact column to
the OData ID of a contact row like this: contacts(c96be312-4ac1-4358-99b6-
1e14e2957b15) .

） Important



If you try to pass only the GUID from previous step, you’ll get an error like
this: Resource not found for the segment <segmentname>. The Microsoft Dataverse
connector expects the full OData ID of the target row, including the type of the
row.

If the lookup column is polymorphic (meaning it can have more than one possible target
type), then the target row OData ID must be provided in the correct column. For
example, the Company name column for Contacts is polymorphic and can take either
an account or contact, but not both.

Activity party relationships
Activity parties are
a special type of relationship in Dataverse. For example, when you
create an appointment, the values for Required Attendees and Optional Attendees are
related to the System users table.



Select Add new item, and then enter the required data to add multiple values for an
activity party. As shown earlier in the article, you must use the OData ID syntax for
systemusers(<ID of the user>) .

You can also pass in a list of different activity parties by toggling from item mode to
array mode by using the “T” button in the upper-right corner. When you do that, you
can use expressions to pass in data from a previous action, as shown in the following
array:



Use Dataverse search to retrieve rows
Article • 12/16/2022

Use the Search rows action in flows to retrieve data from Microsoft Dataverse by using
keywords and Dataverse search, which delivers fast, intelligent, and comprehensive
results across tables in Dataverse.

Prerequisites
Your admin must configure Dataverse search on your environment before you can use
the search action on Microsoft Dataverse.

You can add the Search rows action to your flows, and then provide a keyword in
Search term to search for that keyword across all the indexed rows in Dataverse.

You can use dynamic content from a previous step in the flow to parameterize the
Search term box. For example, you can use a keyword that's entered in a Power Virtual
Agent bot and set the following options to initiate an automated search:



７ Note

It can take a few hours for newly added rows to be included in the search results.

Search type
Use the Search type option to provide the syntax for the search query. Use simple to
indicate that you want to use the simple query syntax. Or, use full if you prefer to use
the Lucene query syntax. The default query syntax is simple.

Take a look at the following examples or review the full list of features at Search across
table data using Dataverse search.

The simple query syntax supports the following functionality:

Operator Description

Boolean AND operator; denoted by + 

operators OR operator; denoted by |


NOT operator; denoted by -



Operator Description

Precedence A search term "hotel+(wifi | luxury)" will search for results containing the term
operators "hotel" and either "wifi" or "luxury" (or both).

Wildcards Trailing wildcards are supported; for example, "Alp*" searches for "alpine".

Exact A query enclosed in quotation marks " ".
matches

The Lucene query syntax supports the following functionality:

Operator Description

Boolean Provides an expanded set compared to simple query syntax. 

operators AND operator; denoted by AND, &&, + 


OR operator; denoted by OR, ||

NOT operator; denoted by NOT, !, –

Precedence The same functionality as simple query syntax.
operators

Wildcards In addition to a trailing wildcard, also supports a leading wildcard.

Trailing wildcard – "alp*"

Leading wildcard - “/.*pine/”

Fuzzy search Supports queries misspelled by up to two characters. 

"Uniersty~" will return "University"

"Blue~1" will return "glue", "blues"

Term Weighs specific terms in a query differently. 

boosting "Rock^2 electronic" will return results where the matches to "rock" are more

important than matches to "electronic".

Proximity Returns results where terms are within x words of each other, for more contextual
search results. 


For example, "airport hotel"~5" returns results where "airport" and "hotel" are
within five words of each other, thus boosting the chances of finding a hotel
located close to an airport.

Regular For example, /[mh]otel/ matches "motel" or "hotel".
expression
(regex)
search

To use any of the search operators as part of the search text, escape the character by
prefixing it with a single backslash (\). Special characters that
be escaped include the
following characters: + - & | ! ( ) { } [ ] ^ " ~ * ? : \
/



Search mode
You can specify whether any or all the search terms must be matched to count the
document as a match. The default is any. It controls whether a term with the NOT
operator is AND'ed or OR'ed with other terms in the query (assuming there is no + or |
operator on the other terms).

Using any for Search mode increases the recall of queries by including more
results. By default, it is interpreted as "OR NOT". For example, "wifi -luxury" will
match documents that either contain the term "wifi" or those that don't contain
the term "luxury".

Using all for Search mode increases the precision of queries by including fewer
results. By default, it is interpreted as "AND NOT". For example, "wifi -luxury" will
match documents that contain the term "wifi" and don't contain the term "luxury".

Go to Search across table data using Dataverse search for more details.

Advanced Options
You can optimize your search by using other advanced options as described is this
section.
See Search across table data using Dataverse search for more examples.

Row filter: You can narrow your search by specifying filters as shown in the
following image.

Table filter: You can restrict your search to specified tables as shown in the
following image.

Sort by: Use this option to sort by specifying a column name and adding asc or
desc as the suffix, as shown in the following image.



Using dynamic content and Dataverse rows
You can use the outputs of the action directly from Dynamic content. Here's the
meaning of each of the parameters.

Parameter Description
name



Parameter Description
name

Body The object that represents the entire response. It contains the list of rows, total row
count, and facet results.

List of rows An object that represents all the rows returned.

List of rows An individual row in the list of rows, when used inside a loop.
item

Row search The Dataverse score of a row. This score indicates how closely it matched the
score search keywords and conditions.

Row search Highlights the specific keywords that matched the search keywords in the row.
highlights

Row table The name of the table for a single row. This action aggregates rows from all
name searchable tables in the environment.

Row object This is an identifier for each row. Use this identifier in conjunction with the table
id name in the Get rows action to read all the columns in a row.

Row object The table name identifier for the row.
type code

When you are building your flow, the dynamic content might appear like this image:



The Search rows action returns many other columns for the matched rows in a variable
schema, depending on your Dataverse search configuration.
To use these columns,
parse the JSON response, and then use the dynamic outputs generated from it as shown
in the following image.






Relate or unrelate rows in Dataverse
Article • 12/16/2022

） Important

You can associate two Microsoft Dataverse rows only if they have a one-to-many or
many-to-many relationship.

Relate rows
Follow these steps to associate two rows while editing your flow:

1. Select New step to add an action to your flow.

2. Enter relate rows into the Search connectors and actions search box on the
Choose an operation card.

3. Select Microsoft Dataverse.

4. Select the Relate rows action.



Like other actions in this connector, a list of supported tables is available.

5. Select the table to which you want to relate or enter a custom value for the table
name.

6. You will need to enter the identifier of the row you want to relate.



The list of supported one-to-many and many-to-many relationships based on the
table type selected is populated in the format <Related Table Type> –
<Relationship Schema Name>. You can select the relationship to which you want
to relate your row.

7. Enter the full resource URL of the row to which you want to add the relationship.

This URL is the full OData identifier of the resource, as shown in the following
image:

 Tip

You can get the row identifier URL from a previous step from the available
dynamic content.



Unrelate rows
1. Select New step to add an action to your flow.

2. Enter unrelate rows into the Search connectors and actions search box on the
Choose an operation card.

3. Select Microsoft Dataverse.

4. Select unrelate rows action.

Your flow uses this action to disassociate two Dataverse rows if they are linked by a
one-to-many or many-to-many relationship.

5. Select the type of table you want to unrelate from or enter a custom value for the
table name.

6. Enter the identifier of the row that you want to unrelate from.



The list of supported one-to-many and many-to-many relationships based on the
table type you selected will be populated in the format <Related Table Type> –
<Relationship Schema Name>. Select the relationship you want to unrelate the
related table from or enter your custom value for the relationship schema name.

7. Enter the full resource URL of the related table you want to unrelate. This URL will
be the full OData identifier of the resource.

 Tip

You can usually copy the row identifier from a previous step by using dynamic
content.






Use a flow to perform a changeset
request in Dataverse
Article • 04/04/2024

Change sets provide a way to bundle several operations that either succeed or fail as a
group. When multiple operations are contained in a changeset, all the operations are
considered atomic, which means that if any one of the operations fails, any completed
operations are rolled back.

Follow these steps to get started with change sets.

1. In your flow, select New step.

2. Enter changeset into the search box of the Choose an operation card.

Notice that the operations list now only displays operations with the word
"changeset" in its name.

3. Select the Perform a changeset request to add its scope to your flow.

4. Select Add an action.



You’ll notice that this approach is different from any other action you’ve added in
the following ways:

Instead of inputs and outputs, this is a container to which you can add
actions.

When you select Add an action, you’ll see just the following three actions:
Add a new row
Delete a row
Update a row



You can't have additional built-in actions in a changeset scope because all actions
are evaluated together in Dataverse. You see that there are no arrows between
each of the actions, indicating that there aren't dependencies between these
actions (they all run at once).

5. Add all of the actions that you want to perform.

Limitations
The only supported actions in a changeset scope are Add a new row, Delete a
row, and Update a row. For example, the Apply to each action isn't supported in a
changeset.
You can't reference an output of a previous action in the changeset scope.
Perform a changeset request action (Dataverse) isn't supported yet in the AI-
powered cloud flows designer.



Upload or download image and file
content
Article • 12/16/2022

You can use flows to upload or download images and files in Microsoft Dataverse. There
are two column data types for handling images and file content in Dataverse.

File: You can have a column that stores arbitrary file data for your table.

Image: In addition to a column that stores the full size of an image as a file, the
Image datatype can also include thumbnail information.

You can use the Microsoft Dataverse connector to work with these data types in Power
Automate.

Download file or image content
Follow these steps to add the Download a file or an image action to your flow. You can
use the downloaded file contents in suitable actions later in the flow.

1. Select New step to add an action to your flow.

2. Enter download a file into the Search connectors and actions search box on the
Choose an operation card.

3. Select Microsoft Dataverse.

4. Select the Download a file or an image action.



5. Select the table from which you want to download the file or image content or
enter your own custom value for the table name.

6. In Row ID, enter the row ID of the row in the table that you just selected.

 Tip

You can normally copy the row identifier from a previous request by using
dynamic content.

The list of supported file and image columns for the table you selected earlier will
be populated in the Column name list.

7. From Column name, select the column that holds the file or image content that
you want to download.



You now can access the file or image content by using the File or image content
variable in the Dynamic content list.

With the content output of the action, you can pass it to any action later in the
flow. In the following example, the file contents are being passed to the Create file
action.



Upload file or image content
Follow these steps to add the Upload a file or an image action to your flow. This way,
you can upload content to a corresponding file or image column in Microsoft Dataverse.

1. In Table name, select the table to which you want to upload the file or image
content or enter a custom value.

2. Enter the identifier in Row ID for the row to which you want to upload the file or
image content.

 Tip

You can normally copy the row identifier from a previous request by using
dynamic content.

The list of available file and image columns in the table that you selected is
populated.

3. From Column name, select the column to which you want to upload the image or
enter a custom value.



Your Upload a file or an image action card might look like this now.

4. Enter the content you want to upload.

In this example, the files to upload are the attachments content from an email
captured earlier in the flow. You can select Attachments Content in the list of
dynamic content that's displayed when you select Add dynamic content on the
Upload a file or an image card.



Troubleshoot known issues with
Dataverse
Article • 12/16/2022

Here's a list of known issues with Microsoft Dataverse and Microsoft Power Automate.

Localization of metadata – When you change the Power Automate language and
regional locale settings, there's no change to metadata like table and column
names. There is no change in the metadata because they display in the language
and regional locale settings of your Microsoft Dataverse
environment. See Languages to view your Dataverse settings.

Working with lookup fields – When working with the Add a new row and Update
a row actions, you must enter lookup fields in the following syntax –
 entity_unique_name(Item_ID).

Working with multi-select fields – When working with the [Add a new
row and Update a row actions, the user interface allows you to select only one
option. To select multiple options, you must switch the input method to custom,
and then enter a unique name for each option, separating each name with a
comma.

Adding a row with attachments to the Notes table– When you use
an attachment from the dynamic output of a non-Dataverse step, you must use an
expression to convert it to a string. For example, when you add a row inside
an Apply to each loop over the output from the When a new email arrives trigger,
use string(triggerOutputs()?['body/attachments']) instead of items('Apply_to_each')?
['contentBytes'], as shown in the following image.



SharePoint and OneDrive document tables don't display inputs when you create
a flow - When you create a flow that triggers on the Dataverse SharePoint
documents table or the OneDrive documents table, no data from these tables is
passed to the editor and the flow inputs array is empty. This behavior occurs
because these tables are virtual and their data isn't stored in Dataverse.



Use Dataverse-based flows
in Power Apps  
Article • 12/16/2022

Power Apps is a suite of apps, services, connectors, and data platform that provides a
rapid application development environment to build custom apps for your business
needs. Use Power Apps, to quickly build custom business apps that connect to your
business data that’s stored either in the underlying data
platform Microsoft
Dataverse or in various cloud and on-premises data sources, such as SharePoint,
Microsoft 365,
Dynamics 365, SQL Server, and so on. 

 

Apps built using Power Apps provide rich business logic and workflow capabilities to
transform your manual business processes to digital, automated processes. Further,
apps built using Power Apps have a responsive design, and can run seamlessly in Web
browsers or on mobile devices (phone or tablet). 

With Power Apps, you can create Canvas apps and Model-driven apps, and both types
of apps support using data stored in Microsoft Dataverse. You can use the Microsoft
Dataverse connector in Power Automate to integrate your apps with an
automated flow, setting them off whenever users tap the associated button.

Get started with Power Apps: 

Watch Power Apps demos  

Watch videos on the Power Apps channel  on YouTube. 



 

Canvas apps 
You can associate any button in a canvas app with a cloud flow that uses the Microsoft
Dataverse. Each time the canvas app user hits the button, the associated flow runs in the
background. 

1. Edit an existing canvas app, or create one by following the steps in Create a canvas
app from Microsoft Dataverse in Power Apps. Then go to the Insert menu and
then add a Button as shown here. 

 

2. Select the button you just added.

3. Select the Action menu.

4. Add a Power Automate flow by choosing an existing flow or creating a
new one from the panel that appears on the right. If the flow requires any
parameters, this step prompts you to provide them in the formula bar. 



5. Be sure to use the Power Apps trigger as shown here. 

6. Create the flow as shown here. 






Create a cloud flow that uses Microsoft
Dataverse
Article • 04/14/2023

Improve operational efficiency with a unified view of business data by creating flows
that use Dataverse .

For example, you can use Dataverse within Power Automate in these key ways:

Create a cloud flow to import data, export data, or take action (such as sending a
notification) when data changes. For detailed steps, see the procedures later in this
topic.
Instead of creating an approval loop through email, create a cloud flow that stores
approval state in a table, and then build a custom app in which users can approve
or reject items. For detailed steps, see Build an approval loop with Dataverse.

In this article, you will create a cloud flow that sends an email notification when a
Qualified Lead Process creates a new Opportunity in Dataverse. The notification includes
the Notes from the Lead.

Prerequisites
Sign up for Power Automate  and Power Apps .

If you have trouble, verify whether Power Automate and Power Apps support the
type of account that you have and your organization hasn't blocked signup.

If you haven't used Dataverse before, create a Dataverse environment with a
database in the Power Platform admin center.

Sign in to your environment
1. Sign in to Power Automate .

2. On the top right menu, select the environment where you created the Dataverse
table.

） Important



If you don't select the same environment, you won't see your Dataverse
tables.

Use a template
1. On the navigation pane to the left, select Templates, and then search for Copy

Notes from Lead to Opportunity.

You could use any template that performs a task in Dataverse that you want to
automate. In this example, you'll use the Copy Notes from Lead to Opportunity in
Dataverse template.

2. (If you haven't already created a connection) Select Sign in, and then provide your
credentials as needed.

3. Select Continue.

You'll now see the template and its connections. In the following steps, you'll
customize this template.

Customize your flow template
1. On the When an Opportunity is created card, select the Environment, Table

Name, and Scope that you want to use.

For more information on scope, go to Trigger flows—scope.

2. Complete the Get Opportunity row card, per your requirements.

3. Configure the Originate from a Lead card.

4. Complete the Get Lead and the List Notes for the Lead cards on the If yes side of
the decision branch.



5. Expand the Apply to each card, and then delete the Copy Lead Note to New Note
card.

6. Select Add an action, search for notification, and then select Send me an email
notification.



7. Configure the notification card to send you an email notification with the details of
the notes for the lead.

 Tip

If you can't find a template that does what you need, you can build a cloud flow
from scratch that operates on top of Dataverse.



Create a cloud flow to view Dataverse
long term retained data
Article • 09/25/2024

Microsoft Dataverse supports custom retention policies to securely retain unlimited data
long term in a cost-efficient way. While Dataverse can support your business growth
with no limit on active data, you might want to consider moving inactive data to the
Dataverse long term retention store. After doing so, you can create a cloud flow to view
read-only rows in long term data retention in Microsoft Dataverse.

The cloud flow described here creates and sends an email that includes an Excel file
containing the retained data. If there are retained attachments associated with rows
from Dataverse, they're also included as links in the Excel file. For more about the
privileges required to run this flow, go to View long term retained data in Microsoft
Dataverse

Creating the flow requires the following high level steps:

1. Pass query parameters in FetchXML to create an Excel file with retained data, using
a Dataverse action named Create Excel from RetainedData.

2. Set a condition to determine if the Excel file has been created. Download the Excel
file. Pass the required retrieval criteria parameters (table and FetchXML).

3. When the Excel file has been created:

Set an action to download the Excel file.
Set an action to send an email to recipients with the Excel file attached.
Set an action to delete the Excel file from the Dataverse system table. This
step is recommended to avoid Excel documents consuming database
storage.

 Tip

If you don’t see an email after running a flow successfully, check your junk mail
folder.

Create the query and download FetchXML
1. Sign into Power Apps , and then select Settings > Advanced settings.



2. On the Dynamics 365 Settings page, select Advanced Find (filter icon) on the
command bar.

3. At the top of the Advanced Find pane, select Change to retained data.
4. Create the query you want to retrieve the retained data. More information:

Advanced find in model-driven apps
5. In Advanced Find on the Advanced Find tab, select Download Fetch XML.

Create the flow
The following steps show you how to use an instant flow to create the Excel file and
send it as an attachment to someone in email. You can also use similar steps to create a
scheduled cloud flow.

1. On the Power Apps  home page, select Flows on the left navigation pane.

2. Select New flow, and then select Instant cloud flow.

3. Enter a name for the flow, and then select Manually trigger a flow.

4. Select Create.

5. Select New step, and then on the Choose an operation step, select Microsoft
Dataverse.

6. For the action, select Perform a background operation.

7. Enter the following information:

Catalog: Microsoft Dataverse Common
Category: Retained Data
Table name: (none)



Action name: Select Enter custom value and then enter Create Excel from
RetainedData

FetchXml: Paste in the FetchXML created earlier from the advanced find
query.
LayoutXML: Leave blank

8. Select New step.

9. For Choose an operation, select Condition, and then select the Expression tab.

10. Add the following expression:

outputs('Perform_a_background_operation_(preview)')?

['body/backgroundOperationStatusCode’]

is equal to: 30

11. In the If yes box, select Add an action.

12. On the Actions tab, select Download a file or an image.



13. Select the following values:

Table name: RetainedData Excels
Row ID: Select Add dynamic content, and then select
ExportRetainedDataResponse ExportedExcelID
Column name: ExcelContent

14. Select Add action to add another action that sends an email with the Excel file
attachment.

15. For Choose an operation, select Office 365 Outlook, and the for the action select
Send an email (V2).

16. Enter the following required values for the email.

To: Enter a valid email address for the email recipient.
Subject: Enter the email subject, such as Retained Accounts from 2020.
Body: Enter text for the email body, such as Attached are the retained
accounts from 2020.
Attachments Name -1: Enter a name for the attachment, such as
accountsretained2020.xls.
Attachments content: On the Add dynamic content tab, select File or image
content.



17. Select add an action to delete the Excel file created and saved in the Dataverse
table RetainedData excels:

Select an operation> Microsoft Dataverse.
Under Actions, select Delete a row.
Choose the following values:

Table name: RetainedData Excels
Row ID: Select Add dynamic content, and then select
ExportRetainedDataResponse ExportedExcelID.

18. Select Save

19. Run the flow.

The email recipients receive an email with the attached Excel worksheet containing the
retained data rows.

See also
Dataverse long term data retention overview

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create a cloud flow with Microsoft
Dataverse (legacy)
Article • 04/25/2024

With the Microsoft Dataverse connector, you can create flows that are initiated by create
and update events within Dataverse. You can also perform create, update, retrieve, and
delete actions on rows in Dataverse.

） Important

Flows that are created with the Dataverse (legacy) connector will no longer work
after a date that is announced during 2024. To automatically migrate from the
Dataverse (legacy) connector to the Microsoft Dataverse connector, use the
migration tool in Power Automate.

Initiate a cloud flow from Dataverse
You can use any of the following triggers to initiate your flow.

When a flow step is run from a business process flow.
When a row is added, modified, or deleted.
When an action is performed.

If the selected trigger requires an environment to be selected, then you can choose
(Current) , which always uses the database in the environment in which Power



Automate runs. If you want your flow to always trigger based on an event in a specific
environment, select that environment.

You can use scopes to determine if your flow runs in any of the following scenarios:

If you add row.
If a user within your business unit adds a new row.
If any user in your organization adds a new row.

ﾉ Expand table



Scope Trigger timing

Business Unit Action is taken on a row owned by your business unit

Organization Action is taken by anyone within the organization or database

Parent: Child business Action is taken on a row owned by your business unit or a child
unit business unit

User Action is taken on a row owned by you

Triggers that run when a row is modified can also use filtering columns. This ensures
that the flow only runs when any of the defined columns are modified.

） Important

To prevent your flow from unnecessarily running, use filter columns.

This flow triggers anytime the first or last name of a contact that the flow user owns is
modified.

Trigger privileges
To create a cloud flow that triggers based on create, update, or delete on a row, the user
needs to have user level permissions for create, read, write, and delete on the Callback



Registration table. Additionally, depending on the scopes defined, the user might need
at least that level of read on the same table. Learn more about environment security.

Write data into Dataverse
Use any of the following actions to write data into Dataverse:

Create a new row
Update a row

Here's an example of creating a follow-up task when the given user creates a new
account row.



Advanced concepts

Write data into customer, owner, and regarding columns
To write data into customer, owner, and regarding columns, two columns must be
populated.

ﾉ Expand table



Column Example settings
category

Regarding Regarding = ID of the row (for example, account ID) and Regarding Type as
selected from the list.

Customer Represents the ID of the row and the customer type as selected from the list.

Owner Represents the ID of the system user or team, and owner type as selected from
the list.

Enable upsert behavior
You can use the update a row command to provide upsert actions. This command
updates the row if it already exists, or creates a new row. To invoke upsert, provide the
table and a GUID key. If the row with the specified type and key exists, an update occurs.
Otherwise, a row with the specified key is created.

Trigger behavior
If you have a trigger registered on the update of a row, the flow runs for every
committed update to the given row. The service invokes your flow asynchronously, and
with the payload that it captures at the time the invocation occurs.

Flow runs might be delayed if there's a backlog of system jobs in your environment. If
this delay occurs, your flow is triggered when the system job to invoke the flow runs.

See also
Add canvas apps and cloud flows to a solution by default



Manage cloud flow run history in
Dataverse
Article • 03/28/2025

With cloud flow run history in Dataverse, you can apply the extensibility of Dataverse to
track the results of your cloud flow executions at scale. With this feature, you can use
the power of Dataverse’s common data architecture, including Role-Based Access
Control (RBAC), to manage the FlowRun data. Only solution cloud flows, with their
definitions in Dataverse, can have their run history stored in Dataverse.

As part of this feature, each cloud flow execution has an entry in the table FlowRun. This
feature is using Dataverse’s nonrelational database, elastic tables, to store the cloud flow
run history.

Cloud flow run history in Dataverse is used by the automation center to provide
comprehensive monitoring and troubleshooting experiences for automation processes
across Power Automate.

Cloud flow run elements
The FlowRun table contains key elements of a cloud flow run, including the following:

ﾉ Expand table

Element Description

Name Primary key and the logic app Id of the flow run.

Start time When the cloud flow execution was triggered.

End time When the cloud execution was finished.

Run duration Time, in seconds, for the cloud flow to finish the run.

Status End result of the flow execution (Success, Failed, or Cancelled).

Trigger type The trigger type of this flow run (Automated, Scheduled, or Manual).

Error code Error code returned from the flow execution.

Error message Detailed error message, if applicable, returned from the flow execution.

Owner Owner of the flow.



Element Description

Workflow Display name of the cloud flow.
name

Workflow Id WorkflowID of the specific cloud flow,

IsPrimary Binary value to denote whether this flow run has any parent cloud flow
triggering it.

Parent Run Id Name of the parent cloud flow run instance, if this record is for a child flow.

Partition Id Partition Id of this user in the elastic table instance.

Time to live Time in seconds of when this run record is automatically deleted.

You can view and update the details through standard Dataverse APIs, the Dataverse
connector, or directly from the Tables view in the maker portal.

Since this feature is built on elastic tables, we store the cloud run history data in specific
logical partitions for optimized performance. The run history data is partitioned based
on users, so each user in an organization has a dedicated partition.

FlowRun data uses Dataverse database storage capacity. Storage use across
environments can be monitored in the Power Platform admin center.

Storage use for FlowRun records
By default, flow run data is stored for 28 days (2,419,200 seconds). If you want to modify
the duration of how long the executions can be stored, you can update the Time to live
(in seconds) for the flow run in the Organization table in an environment backed with
Dataverse. Depending on your environment’s storage capacity, you can adjust the
length of storage for these run records.

The FlowRunTimeToLiveInSeconds value on the Organization table can be changed in
the PowerApps table browser or using the Dataverse Web API .

Turn on or reduce storage of cloud flow run
history
If the FlowRunTimeToLiveInSeconds value in the Organization table is changed, then the
lifetime of any new FlowRun records is retained for that length of time. Lowering the
value can reduce the number of FlowRun records, and storage used, over time.



Set FlowRun time to live in Dataverse
Setting the FlowRunTimeToLiveInSeconds value in the Organization table to zero stops
all ingestion of new FlowRun records.

Set FlowRun time to live in Power Platform admin center
The FlowRunTimeToLiveInSeconds value in the Organization table can be set in the
Power Platform admin center environments experience. To choose the FlowRun entity
time to live that's used in an environment:

1. Sign in to Power Platform admin center.
2. Navigate to Environments.
3. For the desired environment, open the Settings page.
4. Select Product > Features.
5. Under Cloud flow run history in Dataverse, set the FlowRun entity time to live

retention value to 28 days (the default), 14 days, 7 days, or Disabled.

Set custom TTL values to store a longer or more specific
amount of cloud flow run history
If you want a specific Time To Live (TTL) value that isn't available through the Power
Platform admin center experience, then you can set that value directly as the
FlowRunTimeToLiveInSeconds value in the Organization table.

Reduce number of FlowRun records
immediately
If the environment is running short on storage, then customers can choose to clean up
database space by setting the TTLInSeconds value for a set of FlowRun records. The
records are then automatically cleaned up and permanently deleted within a minute or
two. Ensure that the records are no longer needed, because they can't be recovered
once deleted.

Time To Live (TTL) value calculations
Time to live (TTL) values for Organization.FlowRunTimeToLiveInSeconds and
FlowRun.TTLInSeconds are specified in seconds. The following table contains common
values that can be used in the Organization and FlowRun tables.



ﾉ Expand table

Days Seconds

1 day 86,400 seconds

3 days 259,200 seconds

7 day 604,800 seconds

14 days 1,209,600 seconds

28 days 2,419,200 seconds

60 days 5,184,000 seconds

Use FlowEvent data to get visibility into
FlowRun data completeness
FlowRun records might be incomplete for many reasons. The FlowEvent table is used to
provide signals that runs were skipped and the data set is incomplete. The lack of
signals doesn't mean that the data set is complete.

You can view the FlowEvent records in the PowerApps table browser or using the
Dataverse Web API . All of the relevant records have a FlowEvent.EventType value of
"FlowRunIngestion" and then the FlowEvent.EventCode value explains the event.

The following table contains a list of FlowEvent.EventCode values that might be used to
signal that FlowRun data isn't complete:

ﾉ Expand table

EventCode Reason

isFlowRunIngestionECSDisabled Cloud flow run history isn't being saved in Dataverse due
to service configuration, so no cloud flow data can be
shown. The ECS service configuration is set automatically
and there's no way for an admin to change the ingestion
behavior in this state.

TtlSettingEqual0 Your current environment's TTL (time-to-live) configuration
for cloud flow runs is set to not retain data. As a result,
some cloud flow run history might be missing. This state
occurs when Organization.FlowRunTimeToLiveInSeconds is
set to zero.



EventCode Reason

IngestionDisabledByOrgSettings Cloud flow run history isn't being saved in Dataverse due
to environments settings, so some of the run history for
cloud flows might be missing. This occurrence happens
when Organization.FlowRunTimeToLiveInSeconds was set
to zero in the past.

ElasticTableStorageCapacityReached You reached your Dataverse storage capacity limit, causing
a pause in cloud flow run data synchronization.

ElasticTablePartitionLimitReached You reached your Dataverse storage partition limit, causing
a pause in cloud flow run data synchronization.

IngestionRateDataLoss Some of the run history for cloud flows might be missing
due to high volume of runs in this environment.

FlowRunsEventLoadingFailed Unable to load the events for cloud flow runs in your
current environment. As a result, some historical cloud flow
run data might not be available.

FlowRunsTTlSettingFailedMessage Unable to retrieve your environment's TTL (time-to-live)
setting for cloud flow runs. As a result, some historical
cloud flow run data might not be available.

ElasticTableNoRoleForUser A user who owns one or more flows doesn't have read
permissions to the FlowRun table in Dataverse, so some
cloud flow run history isn't saved in Dataverse. The reason
is because that user can't be set as the owner.

Known limitations
FlowRun records are assigned to a specific owner when they're written into the
table, so the concept of shared FlowRun records for shared flows currently isn't
supported.
Flow owners need at least read access to the FlowRun table to store their run
records in Dataverse. The system writes FlowRun records into the table and then
ownership is assigned to the primary owner of the flow. If the primary owner of the
flow doesn't have read permission to the FlowRun table then the FlowRun record
isn't stored and a FlowEvent.EventCode of ElasticTableNoRoleForUser is seen in the
FlowEvent table. To fix this situation, ensure that flow owners have FlowRun table
read permission.
Currently, there's a limit of 20 GB per partition within elastic tables. Further run
record insertions, only for that specific user, would fail once the limit is reached.
FlowRun records might be throttled and skipped if a user has many flows with high
run rates. When throttling occurs, an entry is created in the FlowEvent table to



signal that runs were skipped and the data set is incomplete.

７ Note

The underlying data stream used for powering the cloud flow run record insertions
isn't transactional, and hence isn't 100 percent lossless. Small data losses on this
data stream might happen due to temporary, non-repeating service issues. Those
missing records aren't represented by FlowEvent. Flow execution history within flow
details in the Power Automate portal is transactional, and therefore provides a
lossless view of runs.

FAQ

Why do all of my environments have a
FlowRunTimeToLiveInSeconds value of zero?
If all of your environments have a FlowRunTimeToLiveInSeconds value in the
Organization table of zero, then it could be one of these situations:

1. If FlowRun data isn't available, then your environments might not be automatically
enabled for FlowRun ingestion because there wasn't enough Dataverse database
storage capacity available.

2. If FlowRun data was previously available, then an administrator might have turned
off ingestion of new records.

Does writing cloud flow run history into Dataverse use
Power Platform request quota?
Writing cloud flow run history into Dataverse as FlowRun data doesn't count towards
the Power Platform Request limits. APIs executed to read that FlowRun data do count
towards Power Platform Request limits.

How does this data compare to the data available in
Application Insights?
Admins can set up Application Insights to provide monitoring data from Power
Automate flow executions. The Application Insights data is:

More complete because of data pipeline issues obtaining the FlowRun data.



Deeper because it has information about triggers and actions executed.
Able to be correlated with Power Apps and Dataverse Application Insights data
through correlation identifiers.

Related information
Automation center

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Introduction to desktop flows
Article • 06/20/2024

Desktop flows broaden the existing robotic process automation (RPA) capabilities in
Power Automate and enable you to automate all repetitive desktop processes.
Automating is quicker and easier than ever with the new intuitive Power Automate
desktop flow designer using the prebuilt drag-and-drop actions or recording your own
desktop flows to run later.

Desktop flows are addressed to essentially everyone who is performing simple or
complex rule-based tasks on their workstations. Users at home, small businesses,
enterprises, or larger companies can leverage automation capabilities in Power
Automate to create flows, interact with everyday tools like email and Excel, or work with
modern and legacy applications. Examples of simple and complex tasks you can
automate are:

Quickly organize your documents using dedicated files and folders actions
Accurately extract data from websites and store them in Excel files using web and
Excel automation
Apply desktop automation capabilities to put your work on autopilot

If you're a home user who is accessing a weather website to see tomorrow's forecast or
a self-employed businessperson extracting information from vendors' invoices or even
an employee of a large enterprise who automates data entry on an ERP system, Power
Automate is designed for you.

It allows you to automate both legacy applications, such as terminal emulators, modern
web and desktop applications, Excel files, and folders. You can interact with the machine
using application UI elements, images, or coordinates.

Sign in to Power Automate Windows application using one of the following accounts
and automate your tedious tasks:

Getting started with a Microsoft account
Getting started with a work or school account
Getting started with an Organization premium account

A full comparison of the features included in each account can be found at Sign-in
account comparison.

Here's a list of Known issues and limitations for Power Automate.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Get started with Power Automate in
Windows 11
Article • 02/24/2023

Windows 11 allow users to create automations through the preinstalled Power
Automate app. Power Automate is a low-code platform that enables home and business
users to optimize their workflows and automate repetitive and time-consuming tasks.

Any Windows user can build flows with little-to-no coding experience. A collection of
more than 400 premade actions and a recorder that captures mouse and keyboard
functions make robotic process automation (RPA) intuitive for both regular and power
users.

Using the available actions, you can automate virtually any Microsoft and third-party
application on Windows and exchange data between different applications and
webpages.

For example, you can extract prices from shopping websites, compare them, and store
them to Excel spreadsheets by deploying some easy-to-configure actions.

Using Power Automate, you can populate any form and reduce the time needed to
enter data on regularly used applications. Performing repetitive online orders, tracking
price changes, populating fields on web pages and desktop applications, creating
backups, and converting files are all tasks that can be fully automated with desktop
flows.

https://www.microsoft.com/en-us/videoplayer/embed/RWLTqj?postJsllMsg=true



Apart from the premade actions, Power Automate enables you to record your activity
and automatically convert these steps into actions. The recording feature makes RPA
friendly to all non-technical users and allows you to develop simple flows effortlessly.

To start your journey with desktop flows, follow our getting started guide. More
technical starting guides are available for users with a work or school account and
organization premium account. Check the Sign-in account comparison to view what
each version offers.



Use copilot to analyze desktop flow
activity
Article • 01/21/2025

[This article is prerelease documentation and is subject to change.]

Understanding automation performance is key to achieving operational excellence and
reliability goals, regardless of the size of the automation estate, team, or role within the
organization. To reach those goals requires advanced and dynamic monitoring
capabilities that provide you with valuable insights that highlight areas of success and
identify potential bottlenecks, trends and areas for improvement. Having more detailed
insights allows you to make informed decisions that optimize your automation
processes, leading to increased efficiency and effectiveness.



The latest advancements in AI provide us with unprecedented opportunities to explore
new automation health monitoring use-cases that could include anything from simple
data exploration to anomaly detection, smart recommendations, and even self-healing
bots.

With copilot now able to analyze desktop flow activity we're taking the first step in a
new direction, allowing you to democratize access to insights by asking copilot desktop



flow activity-specific questions using natural language.

） Important

This capability is powered by Azure OpenAI Service.
Copilot is a new technology that is still being developed. It's optimized for use
with English language and has limited support with other languages. As such,
parts of it might appear in English rather than your preferred language.
Read the responsible AI FAQs for copilot in desktop flow activity to learn
more about this new copilot experience.
More FAQs: Responsible AI FAQs for Power Automate,FAQ for copilot data
security and privacy in Microsoft Power Platform

Prerequisites
A work or school account with access to a Power Automate environment that's
based in the United States.
Check known limitations for more information.

How does it work?
This copilot experience is powered by the Azure OpenAI service and is capable of
translating user prompts into valid Dataverse FetchXML queries. Initially, these queries
are focused on and optimized for desktop flow activity, such as runs, flows, errors, and
machines.

High-level process
1. Once the user inputs a valid prompt, copilot generates a valid FetchXML query

based on the input.
2. If the generated FetchXML is valid, the query is then executed against the

Dataverse backend under the current user's security context to retrieve matching
data. This ensures that users only see data that they're already authorized to
access.

3. Copilot then determines the most suitable output visualization, such as a table, pie
chart, bar chart, or line chart, to effectively present the insights and data to the
user.



What are FetchXML queries?
Microsoft Dataverse FetchXML is a language used for retrieving data from a Dataverse
database. It's designed to be easy to create, use, and understand. For example, you
might want to ask Dataverse to give you a list of all flow runs for a specific flow. The
FetchXML query is the way you phrase that question so the database understands it and
can give you the right results.

Prompting best-practices
Be specific: The more specific you are with your prompt, the better the AI will
understand and respond. If the AI isn't producing the desired output, don't worry,
try again by adjusting your prompt.
Experiment with prompts: If you're not getting the results you were expecting, try
rephrasing your prompt or provide more context.
Provide feedback: If the AI produced great or unsatisfactory responses, let us know
by selecting the thumbs up or down with an option to provide more feedback via
the Tell Microsoft what you liked about this feature link that appears underneath.

Prompt examples
Examples of prompts that can be used as starter prompt for your own use-cases are
explained in this section. Some of these prompts might not be applicable or return
incorrect results, since the accuracy might be influenced by model understanding or the
actual prompt and the data available to you based on your permissions. We recommend
that you review and validate the returned results and FetchXML query. More
information: Validate FetchXML query results generated by copilot.

Runs
Which flows ran the most last week?
What were yesterday’s top five flows by number of completed runs?
What was the average run duration of the '[insert your flow name here]' flow during
last semester?

Errors
Show me the most frequent run errors during last month.
Show me a distribution of successful versus failed flows during last quarter.
What were the number of failed runs during the week prior to the last one?



Machines
Which bots had the most run failures today?
Which machines are in maintenance mode?
What are the machines with the most run failures?

Makers
Show me the top flows by number of runs together with their owner info.
Who were the top 10 users running flows during last month?
When and by whom were desktop flows modified last week?

Multi-turn prompts
In the context of AI, multi-turn prompts allow you to have an ongoing conversation with
the copilot, where it remembers the context of the previous messages in the
conversation. It's not just answering one-off questions; it's engaging in a dialogue with
you, where each response is based on what's been said before.

７ Note

When engaging in a multi-turn conversation, copilot keeps track of the five most
recent questions only. This means that copilot starts clearing the prompts that were
entered first and only keeps the latest five. To improve response quality, we suggest
limiting your follow-up questions to four and then restart the chat. More
information: Clearing previous prompt context to start over.

Example

ﾉ Expand table

Turn Prompt and reply

User: show me a distribution of successful vs failed flows during last quarter

Copilot: Here's the distribution of successful vs failed flows during the last quarter.

User: what was the top error of those that failed?

Copilot: Here's the top error of those that failed.



Turn Prompt and reply

User: on which machine names did they fail the most?

Copilot: Here are the machine names where the most failures occurred.

User: of those that succeeded what were their average run duration?

Copilot: Here's the average run duration of the flows that succeeded.



Influencing the output format
You can influence copilot's output format by asking for explicit output types like "show
me failed vs. succeeded flow run distribution as a bar chart." This likely produces the
following outcome:





Clearing previous prompt context to start over
If you wish to reset the conversation with copilot you can select the three dots ...  next
to the copilot name, and then select New chat.



Validate FetchXML query results generated by
copilot
The following steps guide you through the process to validate (and potentially reuse)
FetchXML queries in Power Automate cloud flows.

Step 1: Make a copy of the FetchXML query
After submitting your query to the copilot, you get a reply that includes a link labeled
Show code. Select this link and then select the copy icon located in the upper right
corner of the FetchXML  box to copy the code.

Step 2: Create cloud flow and test FetchXML query
1. Navigate to the Power Automate portal  and select My flows from the left-

navigation menu.
2. Continue by selecting + New flow on the command bar, and then select Instant

cloud flow from the dropdown menu.
3. Enter a flow name, select Manually trigger a flow, and then select Create.
4. The cloud flow designer appears. Find and then select the + New Step button.
5. On the search bar that appears, enter Dataverse, and then select the Dataverse

connector from the results.
6. Various actions are displayed. Scroll through until you find and select the List rows

action.
7. Within the List rows action, select the Show advanced options link.
8. A FetchXML query field appears. This is where you input the copied FetchXML

query that copilot previously generated.
9. After pasting in your FetchXML, select Save.



10. Test your flow by selecting Test.
11. Follow the prompts on your screen to start your flow manually to review its results.

Step 3: Understanding the results
Let's assume you asked the copilot 'how many failed vs succeeded flows did we have last
month?' This produces a FetchXML query similar to the following:

XML

<fetch version="1.0" mapping="logical" aggregate="true" count="3" page="1">
    <entity name="flowsession">
        <attribute name="flowsessionid" alias="flowsession_count" 
aggregate="count" />
        <attribute name="statuscode" alias="flowsession_statuscode" 
groupby="true" />
        <filter type="and">
            <condition attribute="completedon" operator="last-x-months" 
value="1" />
        </filter>
    </entity>
</fetch>

If data matches the given FetchXML query, the List rows Dataverse action configured in
step 2 returns data in a format called JSON  (JavaScript Object Notation), which is
essentially a method used to present data in a well-organized manner, making it easy to
read and write digitally.

For distribution-based questions like previously mentioned, data is grouped by one or
more fields ( statuscode ), together with an aggregation ( count ) that returns the number
for each group (that is, failed , succeeded , and so on).

Each of the returned records contains fields such as:

flowsession_count : The number of times the workflow ran.
flowsession_regardingobjectid : The unique identifier for the flow run.
flowsession_statuscode : The status of the flow run (for example, Failed).
workflow_name : The name of the flow.

If you want to know how many times a specific flow ran, look at the flowsession_count
column of the record where workflow_name  is your flow name.



Understanding copilot replies on problematic
prompts
This table shows default responses that are returned when the copilot is unable to
understand your question, intent, or generate a valid answer.

ﾉ Expand table

Copilot reply Details

Sorry, something went wrong. Please try again. Indicates that an unexpected error
occurred. Rephrase your question and try
again.

Sorry, I couldn’t understand your question. Please Indicates that your question couldn't be
rephrase it and try again. I’m able to answer translated into a valid FetchXML query.
questions that are about the data on this page. For Rephrase your question and try again.
more examples of prompts that you can ask the
copilot, you can visit the prompt example section on
our documentation page.

Sorry, Copilot is at capacity and temporarily Indicates there are resource constraints on
unavailable — please try again in a little while. the backend. Retry your question after a

short time.

Sorry, your message contains potentially harmful Indicates that your question might include
content. Please ensure your input is appropriate and potentially harmful content and has been
try again. blocked by the backend service. Remove

any potentially harmful content from your
question and try again.

Sorry, I was not able to generate a valid answer based Indicates that the generated FetchXML is
on your question. Please rephrase it and try again. I’m invalid or that the query failed when
able to answer questions that are about the data on copilot tried to execute it. Rephrase your
this page. For more examples of prompts that you can question and try again.
ask the copilot, you can visit the prompt example
section on our documentation page.

Sorry, your search includes too many results. Please Indicates that the filter(s) applied to your
refine your query and try again. For examples on how query exceed current aggregation limits in
to limit search results returned by the copilot, visit our FetchXML. Add more appropriate filters
documentation page. such as asking for yesterday's or last

month's data to your query to ensure that
it returns data within those limits.

Known issues and limitations



The following list contains known limitations of the copilot in desktop flow activity.

Copilot is a new technology that is still being developed. It's optimized for use with
English language and has limited support with other languages. As such, parts of it
might appear in English rather than your preferred language.
Copilot is currently only available in Dataverse environments based in the United
States.
Copilot might return wrong or incomplete data and FetchXML queries.
Copilot is initially only capable to answer questions about desktop flow activity
such as errors, machines, and past and current runs.
In multi-turn conversations, copilot keeps context of the last five question only. If
you encounter wrong or incomplete results, consider resetting the conversation.
More information: Clearing previous prompt context to start over.
For queries that return large result-sets, copilot might not be able return or render
these.

Related information
Get started with Copilot in cloud flows (preview)
FAQ for Copilot in desktop flow activity
FAQ for Copilot in cloud flows
FAQ for Copilot in Power Automate Process Mining
FAQ for Copilot data security and privacy in Microsoft Power Platform

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Power Automate for desktop
architecture
Article • 06/20/2024

） Important

Gateways for desktop flows are no longer supported. Switch to our machine-
management capabilities. Learn more about switching from gateways to
direct connectivity.

There are two different methods that Power Automate can use to connect to the cloud
services in order to receive flow execution jobs. The first option is direct connectivity,
while the second option requires the on-premises data gateway to be installed.

The data flow between the desktop and the cloud is the same in both options; only the
application and user account that initiates the web requests are different.

Attended/Unattended desktop direct
connectivity to the cloud service
The UIFlowService is a Windows service that is installed with Power Automate on the
desktop machine. By default, it's set to start automatically and runs as the new user NT
SERVICE\UIFlowService. This user is created during installation.

Azure Relay is a service that facilitates communication channels that are established
entirely by making outgoing requests to the service. It achieves this functionality either
by establishing a WebSocket connection or using HTTP long-polling, if necessary.

７ Note



The Azure Relay and Power Automate cloud services are both cloud resources in
Azure. You can find more information about Azure Relay in What is Azure Relay.

The outgoing web requests from the UIFlowService on the desktop machine to Azure
Relay in the cloud use HTTPS to make requests to FQDN *.servicebus.windows.net over
port 443.

Destination IP addresses for Azure Relay can be found at Azure IP Ranges and Service
Tags  for the public cloud under the name ServiceBus. Similar documents are available
for the other Azure national clouds. No inbound ports are required to be open on the
desktop machine.

Attended/Unattended desktop connectivity to
the cloud service using the on-premises data
gateway
７ Note

Power Automate now offers direct connectivity to the cloud without the use of on-
premises data gateways. You can find more information in Attended/Unattended
desktop direct connectivity to the cloud service.

The UIFlowService is a Windows service that is installed with Power Automate on the
desktop machine. The on-premises data gateway Windows service is a separately
installed component that acts as a communications gateway between the UIFlowService
and Azure Relay.

By default, the data gateway service is set to start automatically and run as the new user
NT SERVICE\PBIEgwService. This user is created during installation.

Azure Relay is a service that facilitates communication channels that are established
entirely by making outgoing requests to the service. It achieves this functionality either
by establishing a WebSocket connection or using HTTP long-polling, if necessary.



７ Note

The Azure Relay and Power Automate cloud services are both cloud resources in
Azure. You can find more information about Azure Relay in What is Azure Relay.

The details about this data flow are documented in Adjust communication settings. The
firewall requirements for execution are exactly the same as the direct connectivity
option, but a different service and user account will be making the outgoing requests.

Other Power Automate outgoing web requests
Power Automate makes some additional outgoing web requests at runtime, which are
documented in Desktop flows services required for runtime.

The CRL endpoints are only required if you use the on-premises data gateway. They use
HTTP over port 80 and are initiated by the UIFlowService.

Session credential lifecycle
1. A desktop machine is registered by signing in to the on-premises data gateway or

registering inside Power Automate using the direct connectivity feature. This
process generates a public and private key to be used for secure communication
with this machine.

2. The machine registration request is sent by the desktop application to the Power
Automate cloud services. The request contains the newly generated machine's
public key. This key is stored along with the machine registration in the cloud.

3. When the request completes, the machine is successfully registered and appears in
the Power Automate web portal as a resource that can be managed. However, the
machine cannot be used by a flow until a connection to it is established.

4. To establish a Power Automate connection in the web portal, users must select an
available machine and provide the username and password credentials of the
account to use to run the desktop flow.

Users can select any previously registered machine, including machines that have
been shared with them. When a connection is saved, the credentials are encrypted
using the public key associated with the machine and stored in this encrypted
form.



The cloud service is storing the encrypted user credentials for the machine.
However, it can't decrypt the credentials because the private key only exists on the
desktop machine. The user can delete this connection at any point, and the stored
encrypted credentials will also be deleted.

5. When a desktop flow is run from the cloud, it uses a previously established
connection selected in the Run a flow built with Power Automate for desktop
action.

6. When the desktop flow job is sent from the cloud to the desktop, it includes the
encrypted credentials stored in the connection. These credentials are then
decrypted on the desktop using the secret private key, and they're used to sign in
as the given user account.

Although the logical data flow is from the cloud to the desktop, the connection is
established from the desktop to the cloud. It uses Azure Relay to connect to the cloud
using an outgoing web request.

If a gateway cluster is created using the on-premises data gateway, the private key used
to decrypt credentials is generated on all machines in the cluster. The private key is
generated using the recovery key that is requested during machine registration. The
recovery key is never sent to the cloud.

If a machine group is created using direct connectivity, the group's private key is
encrypted using a user-defined group password. Then, it's sent to the cloud for storage
as part of the register machine request.

The encrypted private key is shared with other machines that join the group. However,
as the user must first provide the password to decrypt this private key, the service can't
read any stored credentials in the connection.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Premium RPA features
Article • 02/20/2025

This article lists the premium robotic process automation (RPA) features and benefits
that are included in the Power Automate Premium plan (previously Power Automate per
user with attended RPA) and are available to organization premium accounts.

Premium feature list
ﾉ Expand table

Feature/Benefit Description Additional
information

Automatic Trigger/schedule attended or Learn how to trigger
triggering/scheduling and unattended desktop flow runs from desktop flows from
integration with cloud flows cloud flows. Integrate with cloud flows cloud flows

and connect to hundreds of cloud apps
and services.

Flow triggering via desktop Trigger local attended desktop flows Learn how to trigger a
shortcut through their desktop shortcuts. desktop flow via

shortcut

Flow triggering via URL Trigger local attended desktop flows Learn how to trigger a
through their run URLs from anywhere desktop flow via URL
on your machine.

Flow triggering in Picture-in- Trigger attended desktop flows within a Learn how to trigger a
Picture virtual window. desktop in Picture-in-

Picture

Access to premium and Access all premium cloud connectors Learn about premium
custom connectors and create custom connectors. connectors

Learn about custom
connectors

AI Builder capacity Infuse AI into your cloud flows through Learn about AI Builder
custom or prebuilt models with AI
Builder.

Access to process mining Visualize and analyze your business Learn about process
processes with process mining. mining

Access to cloud connectors Use cloud connectors directly in Learn how to invoke
from desktop flows desktop flows. the SharePoint cloud



Feature/Benefit Description Additional
information

connector from
desktop flows

Custom actions Ability to use custom developed Learn how to create
automation actions in desktop flows and use custom actions

in desktop flows

UI elements collections Ability to create, share, and use groups Learn how to create
of predefined UI elements in multiple and use UI elements
desktop flows collections in desktop

flows

Sharing and collaboration Share flows between team members Learn how to share
and select access levels such as co- desktop flows
owner or user. View and manage the
flows shared with you.

Access to multiple Organize, store, and manage flows Learn about
environments across multiple environments, and environments

benefit from environment isolation and
role-based access.

Centralized flow Manage desktop flows and view their Learn how to manage
management and reporting detailed run logs centrally from the desktop flows

Power Automate portal.

Flow monitoring Monitor all your desktop flow runs Learn about
centrally from the Power Automate monitoring
portal.

Flow queues management Monitor, manage, and visualize all your Learn about queues
queued desktop flow runs and set
priorities.

Centralized bot Manage the machines and machine Learn about machine
orchestration and groups that host your desktop flows management
management and run unattended automation at scale

with hosted RPA bots.

Desktop flow analytics Access analytics for desktop flows in the Learn about analytics
Microsoft Power Platform admin center.

Customer support Receive prompt technical assistance Power Automate
from a Microsoft support professional. support

Work queues Use work queues to store, prioritize, Learn more about work
distribute, and process work items. queues



） Important

Unattended desktop flow executions require the Power Automate Process
plan (previously named Power Automate per flow).
AI Builder is licensed as an add-on for existing subscription plans. A certain
number of AI Builder credits are included in the Power Automate Premium
plan (previously Power Automate per user with attended RPA).

Plans that provide entitlements for the
premium RPA features

Trial plan
The Power Automate for desktop free trial plan is available for 90 days. Free users in an
organization can sign up for this trial through the Start trial option found within the Go
premium section of Power Automate for desktop or the desktop flows sections of the
Power Automate portal. Free users are also prompted to start a trial while they attempt
to add the Run a flow built with Power Automate for desktop action in a cloud flow.

Standalone plan
The Power Automate Premium plan (paid or trial, previously Power Automate per user
with attended RPA) gives full access to all RPA premium features and benefits. Both
Power Platform admins and individual users and makers can purchase licenses for Power
Automate. You can find more information about purchasing Power Automate licenses in
Buy Power Automate licenses.

Pay-as-you-go plan
Pay-as-you-go is a new way to pay for Power Automate using an Azure subscription.
This allows you to get started building and sharing flows without any license
commitment or upfront purchasing. Desktop flow users in a pay-as-you-go-enabled
environment have access to most of the premium features listed above in the scope of
that specific environment. You can find more information regarding the pay-as-you-go
plan in Pay-as-you-go plan.



More information about Power Automate
licensing

Power Automate pricing
Overview of Power Automate licensing

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Prerequisites and limitations
Article • 01/03/2025

This article presents all the prerequisites and limitations you should consider before
installing and using Power Automate on your desktop.

Prerequisites
An account with administrator privileges to install Power Automate using the MSI
installer

If you install it from the Microsoft Store, a standard Windows account is
acceptable.

An account to sign in to Power Automate
Learn what features are available for each account type.

A device with the following hardware (these requirements don't include the
resources required for the applications involved in your desktop flows):

７ Note

The following hardware requirements apply only to single-user sessions with
Power Automate for desktop open.

Minimum hardware:
Processor: 1.00 GHz or faster with two or more cores. For unattended mode,
four or more cores are needed.
Storage: 1 GB
RAM: 2 GB

Recommended hardware:
Processor: 1.60 GHz or faster with two or more cores. For unattended mode,
four or more cores are needed.
Storage: 2 GB
RAM: 4 GB
GPU acceleration
.NET Framework 4.7.2 or later

A device that runs Windows 10 (Home, Pro, Enterprise), Windows 11 (Home, Pro,
Enterprise), Windows Server 2016, Windows Server 2019, or Windows Server 2022
(devices with ARM processors aren't supported)



If your device runs Windows 10 Home or Windows 11 Home, you can use Power
Automate to create desktop flows and monitor them on the Power Automate
portal . However, you can't trigger desktop flows from the cloud.

ﾉ Expand table

Activity Description Windows Windows
Home Enterprise/Pro/Server

Authoring Create with Power Automate Yes Yes
for desktop

Runtime Local runtime (attended) Yes Yes

Runtime Cloud runtime No Yes
(attended/unattended)

Monitoring Manage desktop flows Yes Yes

Monitoring View run logs Yes Yes

Access as described in IP Address configuration

TLS 1.2

A browser: Microsoft Edge (version 80 or later), Google Chrome, or Mozilla Firefox

An environment with a Microsoft Dataverse database (applicable only for work or
school accounts)

A supported keyboard attached

An active connection to the Internet

Prerequisites for multi-user session enabled Windows
operating system (high density)
For high-density workloads on multi-session enabled Windows operation systems, each
bot creates a separate user session. Therefore, the computer's hardware must support
these concurrent Windows sessions. At a high level, we recommend the following
configuration:

Basic requirements for the first user session:
CPU: 4 cores
RAM: 4 GB
Storage: 2 GB



Per additional user session:
CPU: 2 cores
RAM: 4 GB

７ Note

These recommendations can vary significantly based on background
processes that are running, the type of workload being executed, and the
specifications of the CPU cores. Hardware adjustments may be required
depending on these factors.
You need a DSL-range internet (not LAN) bandwidth to function properly.

To monitor the performance of individual user sessions:

1. Open Task Manager.
2. Select the Users tab.
3. Review the RAM and CPU usage for each session.

Considerations when setting up Power
Automate for desktop using VM images
When setting up Power Automate for desktop in your organization, don't preinstall
Power Automate for desktop as a part of a base VM image. This approach can lead to
unexpected behavior due to the machine registration information that might still be
retained in the cloned VM image.

Instead, install Power Automate for desktop individually on each machine after the
imaging process. This method ensures that the installation is tailored to the specific
environment.

For automated deployments, use deployment tools and scripts to install and configure
Power Automate for desktop post-imaging. This method provides greater flexibility and
control over the installation process, allowing for a more consistent and error-free
deployment.

Supported languages
Power Automate for desktop uses the display language selected in Windows. Learn how
to manage display language settings in Windows .



The following table shows all the languages that Power Automate for desktop supports
in addition to English.

ﾉ Expand table

A - E F - J K - Q R - T U - Z

Basque Finnish Kazakh Romanian Ukrainian

Bulgarian French Korean Russian Vietnamese

Catalan Galician Latvian Serbian (Cyrillic,
Serbia)

Chinese (Simplified) German Lithuanian Serbian (Latin, Serbia)

Chinese Greek Malay Slovak
(Traditional)

Croatian Hindi Norwegian Slovenian

Czech Hungarian Polish Spanish

Danish Indonesian Portuguese (Brazil) Swedish

Dutch Italian Portuguese Thai
(Portugal)

Estonian Japanese Turkish

Sign-in account comparison
The following table describes what features are available for different account types. You
can find more information regarding accounts in the Power Platform license guide .

ﾉ Expand table

Microsoft Work or Organization
account school premium

account account

Storage OneDrive Dataverse of Dataverse
Personal default across
account environment environments

Accessible recorder: Add different actions and Yes Yes Yes
record desktop apps and web apps in a single
desktop flow.



Microsoft Work or Organization
account school premium

account account

Easy-to-use designer: Use the drag-and-drop Yes Yes Yes
visual designer to organize your flow logically,
while using desktop and web recorders to
capture core logic of your automation in a
single desktop flow.

Robust browser support: Use intelligent data Yes Yes Yes
extraction across all major web browsers
(Microsoft Edge, Internet Explorer, Google
Chrome, Mozilla Firefox)

Pre-built actions: Apply a diverse set of 400+ Yes Yes Yes
prebuilt actions that connect to many different
systems.

Access to new actions: Automate more non- Yes Yes Yes
API systems with new support for SAP, legacy
terminals such as mainframes and AS/400,
Java apps, Citrix, etc.

Exception handling: Take advantage of Yes Yes Yes
exception handling to enable automation of
complex cases that require validation and
proactively manage flow settings to ensure a
flow is completed without the need for human
interaction.

Connectivity with cloud flows No No Yes
(triggering/scheduling flows)

Dataverse storage: Save new desktop flows No No Yes
built with Power Automate centrally in
Dataverse, benefiting from environment
isolation and role-based access.

Sharing and collaboration: Share flows with No No Yes
team members and select access level such as
codevelopment or run-only.

Centralized management and reporting: New No No Yes
flows and any execution logs are automatically
saved to the Power Automate service to
provide centralized management and
reporting.

Additional capabilities such as AI Builder, No No Yes
integration with cloud flows, use of more than



Microsoft Work or Organization
account school premium

account account

400 premium and custom connectors,
unattended RPA (with unattended add-on),
and much more.

Known issues and limitations
Desktop flows in v1 schema environments can't exceed 100 MB in size. If a desktop
flow exceeds the size limit, separate its logic into smaller desktop flows.

Only work or school account users with a Dataverse database provisioned in their
default environment can create Power Automate desktop flows. Power Automate
desktop flows are stored in the default environment with the Dataverse database.

If the Dataverse database doesn't exist in the default environment, the user isn't
able to create desktop flows, and is prompted to create a database. There's no
connectivity of Power Automate desktop flows with cloud flows. 

After users create the Dataverse in the Power platform admin center, they might be
prompted to create it again. In this scenario, exit Power Automate for desktop
from the system tray icon and restart it.

If users sign in with trial or paid accounts and want to connect their free Microsoft
accounts, they must use Power Automate for desktop version 2.6.48.21069 or
above. Otherwise, they encounter the following error:

Power Automate applies the proxy configuration specified in Windows proxy
settings. If the proxy server requires authentication, the administrator must exclude



Power Automate from using it or use another server that doesn't require
authentication. Learn more about configuring Power Automate to bypass a
corporate proxy server.

The number of actions that can be logged in a single desktop flow run is limited to
10,000. Extra actions are performed but aren't logged.

Power Automate for desktop is fully backwards compatible. However, forward
compatibility isn't guaranteed. Each update might introduce action upgrades that
change their signature (properties or values of an action) and/or a change in the
engine powering runtime and authoring. Attempting to run or edit a desktop flow
created with a newer version of Power Automate for desktop might result in the
following error message:

"This flow has been generated by a newer Power Automate version than the one
currently installed. Download and install the latest version of Power Automate and try
again."

To resolve this issue, edit and run the flow with the version that was used to create or
edit it, or use a newer version of Power Automate for desktop.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Install Power Automate
Article • 03/25/2025

Before you install Power Automate on your device, make sure that it meets the system
requirements.

Download and install Power Automate using an MSI installer or from Microsoft Store.
The Microsoft Store installation doesn't require you to have admin rights on your device
and is updated automatically regularly. The MSI installer requires admin rights and
requires manual updates. However it also includes an option to install the machine
runtime application, which allows you to manage machines from the Power Automate
portal. You can use the Power Automate for desktop store installation in conjunction
with the runtime application, which you can install from the MSI.

７ Note

Having both versions of Power Automate on your machine isn't supported. You
must choose between Power Automate MSI installer or Microsoft Store (MSIX).

By default, Power Automate for desktop honors the proxy settings specified in Windows.
To learn how to override this configuration for the Power Automate console, go to
Power Automate for desktop using a proxy server. To learn how to configure proxy
settings for the machine runtime, go to override them after install .

Install Power Automate using the MSI installer
７ Note

Admin permissions on your local computer are required to install Power Automate
for desktop using the MSI installer.

1. Download the Power Automate installer . Save the file to your desktop or
Downloads folder.

2. Run the Setup.Microsoft.PowerAutomate.exe file.

3. Follow the instructions in the Power Automate for desktop setup installer.

4. Make your selections for each feature:



Power Automate for desktop is the app you use to build, edit, and run
desktop flows.

Machine-runtime app allows you to connect your machine to the Power
Automate cloud and harness the full power of robotic process automation
(RPA). Learn more about machine management.

Install required files for UI automation in Java applets. Close all Java-related
processes before you install these files.

5. Select the check box to agree to the terms of use, and then select Install.

If the installation fails, go to the troubleshooting guide for help.

７ Note

There's only one Power Automate installer for both 32-bit and 64-bit computers. It
automatically identifies the architecture of your operating system and proceeds to
install the suitable version of the files accordingly.

.NET 8 requirement
Starting with version 2.55, Power Automate for desktop requires the .NET 8 runtime. The
Power Automate MSI installer downloads and installs the .NET 8 runtime if it isn't
already on the machine. Without .NET 8, computers need internet access to these URLs:

https://aka.ms/dotnet/8.0/windowsdesktop-runtime-win-x64.exe

https://aka.ms/dotnet/8.0/windowsdesktop-runtime-win-x86.exe

Power Automate for desktop uses the .NET 8 runtime to bring you the best and latest UI
experience. The x86 package is required even on x64 operating systems because some
automation modules within Power Automate are only available in 32-bit mode.

If you receive an error indicating that the .NET 8 runtime failed to install, it might be
because your computer can't connect to these URLs or one of the packages didn't
install. To fix this issue, install these runtime packages manually on the machine. After
installation, future versions of Power Automate don't download the .NET 8 runtime.

Install Power Automate from Microsoft Store
1. Find Power Automate in Microsoft Store:



Launch Microsoft Store and search for Power Automate for desktop.

Open a browser and go to this Microsoft Store page . Then, select Get in
Store app to launch Microsoft Store on your device.

Go to the Power Automate product page  and select the appropriate option
for installing.

2. After Microsoft Store is open, select Get to download and install Power Automate.

Update Power Automate
New versions of Power Automate MSI installer are served from a URL beginning with
https://download.microsoft.com .

Update manually
By default, Power Automate for desktop notifies you when a new version is available.
Select Update to automatically download and open the latest installer for your region.
You must have admin permissions on your local computer to perform the update.
Updating to the latest version is recommended to have the latest features and bug fixes.

Update automatically
Starting with the April 2025 (2.54) release, automatic updates are available for the MSI
installation of Power Automate for desktop. Learn more at Automatic update capability.

To learn about managing Power Automate for desktop using System Center
Configuration Manager, go to Manage Power Automate for desktop on Windows.

Determining which install you have on your
computer
If you already have Power Automate installed on your machine and you didn't install it,
check whether it's the Microsoft Store version or the MSI version. To do this, go to Start
Menu > Add or remove programs. Then search for "Power Automate". If Power
Automate for desktop is in the list, it's the MSI version. Power Automate is the
Microsoft Store version.

Uninstall Power Automate



1. Open the Start menu > Settings > Apps.

2. Search for Power Automate, and then select it.

3. Select Uninstall.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Install Power Automate silently
Article • 01/30/2024

You can use the same installer for both manual and silent installation of Power
Automate. Silent installation means that no user intervention is required during
installation.

1. Download Power Automate for desktop . Save the file to your desktop or
Downloads folder.

2. Open the Start menu, search for Command Prompt, and then run it as
administrator.

3. Navigate to the directory to which you downloaded the Power Automate installer;
for example:

CMD



 cd C:\Users\Admin\Downloads\

4. Run the following command to run the installer silently:

CMD

Setup.Microsoft.PowerAutomate.exe -Silent -Install -ACCEPTEULA

） Important

You must include the "-ACCEPTEULA" argument to indicate that you accept
the terms and conditions for Power Automate.

Command line arguments
You can use more arguments in the command line to customize the installation. Use the
help menu to view command line arguments you can use.

CMD

Setup.Microsoft.PowerAutomate.exe -HELP

ﾉ Expand table

Command Description

-INSTALLPATH:Value Specify the full path of the installation folder that will be
created. Default: %PROGRAMFILES(X86)%\Power Automate

- Enables sending optional usage data to Microsoft.
ALLOWOPTIONALDATACOLLECTION

-DISABLEPADSHORTCUT Doesn't create a shortcut for Power Automate for desktop.

-DISABLETURNONRDP Doesn't turn on Remote Desktop on the machine.

-ACCEPTEULA Accepts the end user license agreement needed for the
installation.

-RESTOREDEFAULTCONFIG Restores to the default installation settings during an
upgrade.

-DONOTINSTALLPAD Doesn't install Power Automate for desktop.



Command Description

-DONOTINSTALLMACHINERUNTIME Doesn't install Power Automate machine-runtime app.

-SKIPINSTALLINGJAVAAUTOMATION Doesn't install files that are required for enabling UI
automation in Java applets.

-SKIPENABLEPIPMODE Doesn't enable Picture-in-Picture run mode on the
machine.

-SKIPGATEWAYSUPPORT Doesn't install certificates or start the http server required
for use with the on-premises data gateway.

-ADDGATEWAYSUPPORT Re-enables on-premises data gateway support after it has
been disabled with the SKIPGATEWAYSUPPORT parameter.

Here's an example of a command that installs Power Automate silently in the folder My
Programs\foo on the D: drive:

CMD

Setup.Microsoft.PowerAutomate.exe -Silent -Install -ACCEPTEULA -INSTALLPATH: 
D:\My Programs\foo

Update Power Automate silently
To update Power Automate silently, use the same command line arguments that you use
to install it.

７ Note

All your data and settings, including telemetry, shortcuts, and more, are retained
when you update Power Automate. Therefore, if you want to change the settings
that were enabled or disabled on installation, you need to uninstall and reinstall
Power Automate.

Uninstall Power Automate silently
Use the following command to silently uninstall Power Automate:

CMD

Setup.Microsoft.PowerAutomate.exe -Silent -Uninstall



Install an on-premises data gateway with
PowerShell cmdlets
） Important

Gateways for desktop flows are deprecated except for China region. Switch to our
machine-management capabilities. Learn more about switching from gateways to
direct connectivity.

To find information about how to install, configure, and manage a gateway using
PowerShell cmdlets, go to PowerShell Cmdlets for On-premises data gateway
management. To use the cmdlets, you must run them from PowerShell 7.0.0 or higher
with elevated permissions.



Configure automatic updates for Power
Automate for desktop
Article • 02/20/2025

Starting with the April 2025 (2.54) release of Power Automate for desktop, machines
upgrade automatically to new versions in the background without requiring user
interaction.

） Important

This article only applies to the MSI version of Power Automate for desktop.
The store version's updates are managed by the Windows Store.

There are two automatic update modes: regular and emergency.

７ Note

Automatic updates are gradually enabled on a per-tenant basis. Expect some delay
between enabling automatic updates and your tenant's machines starting to
update. If you want your tenant to be enabled early, contact support.

Regular automatic updates
When a new Power Automate for desktop release is available, the Power Automate
update service  downloads and installs it automatically in the background when the
machine is idle.

Automatic updates are disabled by default. Enable them using the registry. Learn more
in Configuring automatic updates.

Emergency automatic updates
Use this update mode to receive critical security patches and major regression fixes to
Power Automate for desktop machines.

When a patch is available, machines upgrade to the patched minor version (2.XX.Y to
2.XX.Z) or to the latest version with the patch, but only when not in use.



Emergency automatic updates are enabled by default but can be disabled using the
registry. Learn more in configuring automatic updates.

Configuring automatic updates
By default, regular automatic updates are disabled, but emergency automatic updates
are enabled.

To change the default behavior, create the following registry values. You need admin
rights.

ﾉ Expand table

Key Name Type Value

SOFTWARE\WOW6432Node\Microsoft\Power EnableRegularAutoUpdates DWORD If set to 1 ,
Automate Desktop\Global regular

automatic
updates
are
enabled.

SOFTWARE\WOW6432Node\Microsoft\Power DisableEmergencyAutoUpdates DWORD If set to 1 ,
Automate Desktop\Global emergency

automatic
updates
are
disabled.

Automatic updates limitations
Automatic updates don't run when:

The Power Automate service is running as a custom account. Learn more in change
the on-premises service account.
A local or cloud-orchestrated desktop flow run is executing on the machine.
The Power Automate for desktop designer, runtime application, installer, or
troubleshooter is running.
There's custom configuration in the *.exe.config  files of the Power Automate
install folder.

If you need custom proxy configuration, set it in the *.Proxy.config  files
instead of the *.exe.config  files. Learn more in configure Power Automate for
desktop proxy settings.



If you need custom screen settings, define them in the registry instead of in the
config files. Learn more in set screen resolution for unattended mode.

The machine belongs to a hosted machine group.
Power Automate for desktop was installed by extracting the MSI installer from the
.exe bundle installer.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Install Power Automate browser
extensions
Article • 02/02/2023

To automate web-related tasks, Power Automate provides a built-in Automation
browser that's set up for you and works out of the box.

Power Automate also supports the four most popular browsers: Microsoft Edge, Internet
Explorer, Google Chrome, and Mozilla Firefox. These browsers need extra setup and
extensions to work with Power Automate.

Install browser extensions
When installation of Power Automate for desktop is complete, the installer prompts you
to install the Power Automate extension for your browser. The links in the installer send
you to the appropriate extension store.

If you skip the automatic installation of the browser extension, you can do it yourself
later. Use the following links or go through the Tools > Browser extensions options in
the flow designer.



For Power Automate for desktop v2.27 or later:

Microsoft Edge
Google Chrome
Mozilla Firefox

For Power Automate for desktop v2.26 or earlier (legacy):

Microsoft Edge
Google Chrome

Alternative ways to install browser extensions
After Power Automate for desktop version 2.27, the Microsoft Edge, Google Chrome,
and Mozilla Firefox browser extensions are part of the installation. Find the extension
files in the following path: C:\Program Files (x86)\Power Automate
Desktop\BrowserExtensions.

Install extension for Microsoft Edge
1. Go to Edge extensions through the browser's settings or enter edge://extensions/

in the address bar.

2. Make sure that Developer mode is turned on.

3. While you are on the Edge extension page, drag and drop the extension file in the
area.

Install extension for Google Chrome
1. Go to Chrome extensions through the browser's settings or enter

chrome://extensions/ in the address bar.

2. Make sure that Developer mode is turned on.

3. While you are on the Chrome extension page. drag and drop the extension file in
the area.

Install extension for Mozilla Firefox
1. Go to the Firefox Add-ons Manager through the browser's settings or enter

about:addons in the address bar.



2. Select the gear icon, and then select Install Add-on From File….

3. Browse to the browser extension folder of your Power Automate installation.

4. Select Open, and then select Add.

Alternatively, you can launch Mozilla Firefox and drag the extension file to the browser
window.

Set up browsers
To make sure that your browser works as expected with Power Automate, you'll need to
turn off a couple of features.

Microsoft Edge: Go to Settings > System and turn off Continue running
background apps when Microsoft Edge is closed.

Google Chrome: Go to Settings > Advanced > System and turn off Continue
running background apps when Google Chrome is closed.

Mozilla Firefox: Firefox alerts that freeze the browser and prevent users from
switching to other tabs or windows may affect your desktop flows. Turn off this
feature.

1. Enter about:config in the address bar.
2. Search for the prompts.tab_modal.enabled preference in the list and change

it to false.

Internet Explorer: By default, Internet Explorer works in protected mode to prevent
any external application from controlling it. While Power Automate can still work
with this setting turned on, it won't be able to clear the browser's cache or cookies.
Turn off protected mode.

1. Select the gear icon, and then select Internet options.

2. Navigate to Security > Internet and turn off Enable Protected Mode. Repeat
the same step for the Local intranet and Trusted sites zones.



3. Select OK.

Internet Explorer for servers: To use Internet Explorer in Windows Servers, you must
turn off Internet Explorer Enhanced Security Configuration. This feature prohibits
all desktop flows from properly launching an Internet Explorer or Automation
browser instance through the Launch new Internet Explorer action. Additionally, it
prevents web helpers from working as expected.

1. Launch Server Manager and select the Local Server tab.

2. Select Internet Explorer Enhanced Security Configuration.

3. Turn off IEESC for both administrators and users.



4. Select OK.



Migration to Manifest V3
Article • 02/13/2023

After a certain date that the respective products will announce, Google Chrome and
Microsoft Edge browsers will no longer run Manifest V2 extensions. Until December
2022, the Power Automate browser extensions for both browsers were based on
Manifest V2. Therefore, the web extensions must be migrated to Manifest V3 to be
functional after the deprecation date (TBD).

A manifest file is the blueprint of an extension. It includes information such as the
version number and the title of the extension and permissions it needs to run. Migrating
from Manifest V2 to V3 will bring several structural changes to how browsers handle the
extensions. Manifest V3 extensions enjoy enhancements in security, privacy, and
performance. They can also use more contemporary open web technologies such as
service workers and promises.

Manifest V2 deprecation plan
Timeframe Microsoft Partner Center Microsoft Edge and Google

and Chrome Web Store Chrome changes
changes

July 2022 No longer accepts new No change
Manifest V2 extensions with
visibility set as Hidden or
Public.

TBD No longer accepts updates to Both browsers will stop
Google Chrome, TBD 
 existing Manifest V2 running Manifest V2
Microsoft Edge extensions. Developers can extensions. Enterprises can

submit updates for migrating a allow Manifest V2 extensions
V2 extension to V3. to run on both browsers using

Enterprise policies.

TBD No change Manifest V2 extensions will no
Google Chrome, TBD 
 longer function in both
Microsoft Edge browsers even with the use of

Enterprise policy.

Chromium has revised the timelines for Manifest V2 sunset. We'll independently decide
on Manifest V3 migration timelines for Microsoft Edge add-ons and share an update in
this article. We continue to analyze the concerns raised by the extension developers and



explore the optimal path for the Microsoft Edge add-ons ecosystem. Meanwhile, refer to
the Chromium timelines  for planning your extension's migration.

For more information, go to:

Manifest V2 support timeline
Overview and timelines for migrating to Manifest V3

Power Automate plan for deprecating Manifest
V2 and migrating to V3
A new browser extension, Microsoft Power Automate, was released in December 2022.
The extension follows the Manifest V3 standard, taking advantage of its benefits. The
extension is compatible with Power Automate for desktop v2.27 (December 2022
release) or later. After the deprecation date (TBD), you should upgrade to Power
Automate for desktop v2.27 (or later) and install the new extension.

The old web extension will continue to exist after the release of the new one. It will be
renamed to Microsoft Power Automate (Legacy) and continue using Manifest V2. If you
want to keep Power Automate for desktop v2.26 or earlier installed, use the legacy web
extension until the deprecation date (TBD).

After then, enterprise users have two options:

Upgrade to Power Automate for desktop v2.27 or later and use the new browser
extension.

(Only for enterprises) Use Enterprise policies to allow Manifest V2 extensions to
run on Microsoft Edge/Google Chrome. By enabling it, you may use Power
Automate for desktop v2.26 or earlier and the legacy web extension until a date
that will be announced by the respective products and will be a few months after
the deprecation date (end of extension date). After the end of extension date
(TBD), everyone must upgrade to Power Automate for desktop v2.27 or later.

After the deprecation date (TBD), users without the Enterprise policy applied must
upgrade to Power Automate for desktop v2.27 or later and use the new browser
extension.

Run JavaScript function on web page action
） Important



Due to security limitations issued by Mozilla Firefox, you can't use the Run
JavaScript function on web page action with an instance of it. For this action, use
one of the other browser options in your desktop flow.

Due to limitations in the way Manifest V3 works, injecting JavaScript on a web page is
impossible when Developer tools are disabled by Group Policy, making the action not
functional.

If you upgrade to Power Automate for desktop v2.27 or later and use the new browser
extension, the Run JavaScript function on web page action will be functional with the
use of its debugger capability.

The action won't be impacted if you use the legacy browser extension and Power
Automate for desktop v2.26 or earlier.

When the action runs, you'll see a "Microsoft Power Automate" started debugging this
browser message with no real effect on the execution.

７ Note

The new version of the browser extension requires the browser's Developer tools to
be enabled. The extension uses its debugger capabilities to run the JavaScript code
of the respective action.

To ensure that Developer tools aren't disabled in Microsoft Edge, go to Microsoft Edge -
Policies.

To ensure that Developer tools aren't disabled in Google Chrome, go to Chrome
Enterprise policy .

Upgrade to Power Automate for desktop v2.27
(or later) and the new browser extension
With the December 2022 release of Power Automate for desktop, you're able to
download and upgrade as usual.

The new browser extensions will be installed automatically during Power Automate
installation. If you want to install them manually, go to Install Power Automate browser
extensions.



Extend the usage of Manifest V2 extensions
If you want to wait to install the new version of the browser extension, you can extend
the use of the Manifest V2 extensions until the end of extension date (TBD). You can
extend the use through an enterprise group policy. However, by the end of the
extension date (TBD), you'll have to upgrade to the new version of the extension.

Google hasn't yet officially announced the way to enable the enterprise policy.



Power Automate v2 schema
Article • 03/05/2025

７ Note

The Power Automate and Dataverse feature described in this article is applicable to
users who sign in with work, or school accounts, or organization premium
accounts.

Power Automate stores desktop flows in Microsoft Dataverse, which lets you securely
store and manage data used by business applications.

This functionality enables you to use features like solutions for Application Lifecycle
Management (ALM). However, handling data stored in this way might be challenging.

Thus, a new storage schema for desktop flows in Dataverse (v2) is available. It makes
working with Dataverse APIs easier and enables future product enhancements with
desktop flows. The new storage schema is publicly available along with Power Automate
for desktop (v2.29).

Enable the v2 schema
The v2 schema effectively reduces Dataverse database consumption for paid license
users. Also, it offloads components of your desktop flows into your Dataverse for Apps
File Capacity, which is part of your current subscription.

There's no immediate need to act, although we recommend you to enable future
product enhancements. Before enabling the new schema, ensure that users and
unattended runtime machines have been updated to the appropriate Power Automate
for desktop version.

Power Platform administrators can choose when to enable the v2 storage schema. To
enable it, go to the Power Platform Admin Center  > Environments > Settings >
Product > Features > Enable storage of desktop flow files into v2 schema. This setting
applies at the environment level.



Convert desktop flows stored in the v1 schema to the v2 schema by end of 2024, as
then the v1 schema will be deprecated. You need Power Automate for desktop v2.29 or
later to author and run desktop flows using environments where the v2 schema is
enabled. This requirement ensures desktop flow makers and attended and unattended
users can take advantage of the new functionality.

Schema v2 enabled by default
Starting January 2024, v2 schema is automatically enabled for all environments.
Although not recommended, the option to opt-out of the autoenablement is available
in the Power Platform admin center. Turning on the opt-out delays the enablement of
v2 schema on this particular environment.

Later in 2024, v2 schema will be turned on for all environments without the option to
disable the feature and the option won't be visible in Power Platform admin center. As a



best practice, we recommend that you enable the feature in advance so users can
benefit from the product enhancements, which come with it.

As of October 1st, 2024, the v2 schema is enabled by default in all Public regions of the
Power Platform.

Manage desktop flows in environments with
the v2 schema enabled
Power Automate desktop flows currently stored in the v1 schema continues functioning
as intended in environments where the v2 schema is enabled. New, modified, and
resaved desktop flows are stored in the v2 schema.

If a desktop flow belongs to a solution in a v2-enabled environment, follow these
additional steps to ensure the solution package contains all the binaries required for the
flow to function correctly.

Roll back converted desktop flows
Power Automate for desktop version 2.29 or later allows organizations that moved
ahead with the v2 schema to roll back until the v1 schema becomes deprecated.

You can roll back a desktop flow converted to the v2 schema by resaving the desktop
flow to an environment where the Power Platform administrator has the feature
disabled.

For most scenarios, there's no need to downgrade your version of Power Automate for
desktop. However, desktop flows that use v2-related features that aren't supported by
the v1 schema can't roll back.

A rollback from v2 to v1 can result in some screenshots associated with UI elements not
being saved. Although those screenshots aren't necessary for the desktop flow to run,
you can save them:

1. Go to the UI Elements right panel in Power Automate desktop.
2. Select each UI element in the list.

This ensures that the screenshots are saved when you rollback to v1.

Limitations of v2 schema desktop flows



Desktop flows stored in the v2 schema only function in environments with the v2
schema feature enabled.

V1 schema desktop flows in a managed solution might operate in an environment
where the v2 schema is enabled, but first you should resave them into another
environment where the v2 schema is enabled.

Then, you can import the updated v2 schema version of the same process to the
managed environment where it's intended to run. The active layer can be replaced by
the v2 schema version of the automated process.

ﾉ Expand table

Scenario Power Automate for Power Automate for
desktop prior to desktop after to February
February 2023 release 2023 release

Can run v1 schema desktop flows in Yes Yes
environments with the v2 schema
enabled?

Can run v2 schema desktop flows in No (user notified of error) Yes
environments with the v2 schema
enabled?

Can run v2 schema desktop flows in No (user notified of error) Yes
environments with the v2 schema
disabled?

Can edit/save v1 desktop flows into Yes Yes
v1 schema in environments with the
v2 schema disabled?

Can edit/save v1 desktop flows into Yes No (flows are upconverted
v1 schema in environments with the and saved in the v2
v2 schema enabled? schema)

Can edit/save v2 desktop flows into No (user notified of error) Yes (flows are downgraded
z1 schema in environments with the to and saved in the v1
v2 schema disabled? schema)

Can edit/save v2 desktop flows into No (user notified of error) Yes
v2 schema in environments with the
v2 schema enabled?

Exceeded size limit



When you save a desktop flow in v2 schema, you might see the following error:

"The flow can't be saved as it has exceeded the allowed size limit."

The limit applies to the definition of the desktop flow saved in Dataverse, which can't
exceed 16M characters. The issue can occur with a large desktop flow, such as when
actions have large property values or variables have large default values. For example,
an image saved as base64 and set as a default variable value.

We recommend to not store a large payload in the action properties or in the variable
default value. Instead retrieve the value from other actions or pass the value as an input
variable. You can also split your desktop flow into multiple child desktop flows.

Dataverse schema
With v2 schema, we change the data model stored in Dataverse. In addition to the
workflow entity, we use the desktop flow binary entity to store data related to the
desktop flow including images and metadata.



） Important

The desktop flow binary objects are required components of the desktop flow as
they store required data for the desktop flow to be able to open or run. Don't
delete these binary objects. Deleting them results in permanent data loss for the
desktop flow, which makes the respective flow non-editable.

The number of desktop flow binaries might vary depending on the size of the desktop
flow.

Roles and privileges
With the v2 schema, the desktop flow binary table is used. For desktop flows to work as
expected, you need additional privileges. If you're using the default security roles
Environment Maker  and Basic User , there's no change needed.

If you use custom security roles to manage the access to your desktop flow, Power
Platform admins need to add the following list of privileges to the role:

prvCreatedesktopflowbinary

prvReaddesktopflowbinary

prvWritedesktopflowbinary

prvDeletedesktopflowbinary



prvSharedesktopflowbinary

prvAssigndesktopflowbinary

prvAppenddesktopflowbinary

prvAppendTodesktopflowbinary

prvReadSolution

The minimum access level for each privilege is basic (user). More information: Security
roles and privileges

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Desktop flow action logs configuration
Article • 04/01/2025

This page provides configuration guidance for desktop flow logs, located under the
environment's feature section in the Power Platform admin center .

） Important

This feature is only applicable to desktop flows that are launched from a cloud
flow and isn't available yet for local attended runs from Power Automate
desktop.

The Activation status of run action logs setting defines when desktop flow run action
logs should be captured and even allows you to turn them off completely.



ﾉ Expand table

Activation Details
status

Enabled This option is the default for both existing and new environments where logs are



Activation Details
status

(default) captured as usual.

On run This option only captures desktop flow actions logs when there's a runtime error.
failure This means that logs aren't available for every single run, but only when an error

occurs. However, if an error does occur, all logs for that particular run are available,
including both successful and failed actions.

Disabled This option effectively disables desktop flow run action logs completely.

Ｕ Caution

Changing any of these settings can have a significant impact on features such as
run failure troubleshooting and auditing. Consider the implications of changing
these settings before proceeding.

Prerequisites
Premium Power Automate license and administrative privileges to configure log
settings
Power Automate URL and IP address configurations

Public cloud
Government cloud

Configure desktop flow action log version
The Action logs version allows you to choose V1, V2, or both.





ﾉ Expand table

Logs version Explanation

V1 - Stored in the This option is the default. Logs are stored in the AdditionalContext
AdditionalContext field of field of the Flow Session table, which is a file attribute stored as a
the FlowSession entity blob in Microsoft Dataverse. Logs V1 consumes Dataverse file

capacity.

V2 - Stored in the This option allows you to store logs in the Flow Logs table, which is
FlowLogs entity stored in Elastic Tables. Logs V2 consumes Dataverse log capacity.

Both This setting allows logs to be stored in both the traditional
AdditionalContext field of the Flow Session table and the Flow Logs
table. This feature consumes both Dataverse file and log capacity.
This setting is intended for debugging or testing purposes as it
consumes both Dataverse log and file capacity.

The FlowLogs entity time to live in minutes value determines how long action logs
should be retained in the Flow Logs elastic table. Dataverse automatically deletes
records that are older than the specified time-frame. Here are some example values for
your convenience.

ﾉ Expand table



Days Minutes

One day 1,440 minutes

Three days 4,320 minutes

Seven days 10,080 minutes

14 days 20,160 minutes

28 days 40,320 minutes

60 days 86,400 minutes

90 days 129,600 minutes

180 days 259,200 minutes

365 days 525,600 minutes

Forever 0 (zero) minutes

７ Note

Before enabling logs V2, make sure you have sufficient Dataverse log capacity that
would support the data retention settings and aligns with your capacity planning,
entitlement and adjust as necessary. See the Sample Dataverse capacity demand
calculations for logs V2 following section for some sizing examples.

Key differences of desktop flow logs V1 and V2
The following table describes the differences between desktop flow logs V1 and V2:

ﾉ Expand table

Feature Logs V1 Logs V2 Details

Automatic Data Not Available Available V2 uses Elastic Tables, which are
Retention powered by Azure Cosmos DB and

comes with a built-in time-to-live
feature for automatic data
retention.

Support for Roughly up to Minimum 100K V2 can theoretically scale up to
large log sizes 50,000 to actions, can go up to gigabytes worth of action logs per

80,000 action 10M actions run in the future, whereas V1 can
depending on the



Feature Logs V1 Logs V2 Details

logs actions generated only scale to the volume specified
(maximum) and the duration of in this table.

execution

Support for Not Available Available In V1, the AdditionalContext
advanced attribute is a file type, stored as a
reporting and blob in Dataverse, making it
governance challenging to parse for reporting

and governance controls. Logs are
much more accessible in V2.

Support for Not Available Available In V1, the AdditionalContext
Azure Synapse attribute is a file type, stored as a
Link for blob in Dataverse, which isn't
Dataverse supported for synchronization to
integration Azure Synapse.

Support for Not Available Available In V1, the AdditionalContext
Dataverse attribute is a file type, stored as a
auditing blob in Dataverse, which isn't

supported in Dataverse auditing.

Support for Not Available Planned In V1, the AdditionalContext
Dataverse long- attribute is a file type, stored as a
term retention blob in Dataverse, which isn't

supported in Dataverse long-term
retention.

Based on Available Available Both versions use Dataverse RBAC,
Dataverse Role- inheriting action log permissions
Based Access from their parent flow session
Control (RBAC) record.

Logs V2 offers significant enhancements over the previous version, V1. V2 uses the
elastic tables feature, which is great for handling large data volumes, like action log
scenarios, and has built-in data retention (TTL). Ideal for organizations needing to access
significant amount of data for reporting, governance, and integration with automatic
data retention control.

Dataverse capacity demand calculations for
logs V2
The following table shows sample Dataverse log storage consumption estimates per
desktop flow run when using logs V2. It outlines the approximate storage demand for
different numbers of actions, assuming an average of 3 KB of storage per action.



ﾉ Expand table

Number of actions Storage demand per action (KB) Total storage consumption (MB)

1,000 3 2.93

10,000 3 29.3

30,000 3 87.9

60,000 3 175.8

100,000 3 293

160,000 3 480

） Important

The figures shown in the above table are just estimates and the actual storage
consumption can vary significantly. The exact storage demand depends on the
specific details and complexity of each action log. Therefore, these numbers should
be used as a rough guide for understanding the potential storage demand and
planning your storage requirements accordingly.

Querying logs V2 data
Accessing desktop flow action logs data can be achieved by making an API call to the
Dataverse backend, either using the traditional API call syntax or using the new
ExecuteCosmosSqlQuery method. This method allows you to execute a SQL query
against Dataverse, enabling the retrieval and filtering of data.

The data model of logs V2 is based on a parent-child relationship between the Flow
Session and Flow Log tables. Every record inherits permissions from its parent flow
session record. In order to query action logs of a specific desktop flow run, you can use
the following query syntax.

Traditional Dataverse API call syntax
The following API call retrieves a specific flow session by its ID (aaaaaaaa-0000-1111-
2222-bbbbbbbbbbbb) and then accesses the associated action logs using the
flowsession_flowlog_parentobjectid  relationship.

HTTP



[Organization URI]/api/data/v9.0/flowsessions(aaaaaaaa-0000-1111-2222-
bbbbbbbbbbbb)/flowsession_flowlog_parentobjectid  

New ExecuteCosmosSqlQuery API call syntax using
FlowLogs table

HTTP

    [Organization URI]/api/data/v9.2/ExecuteCosmosSqlQuery(
    QueryText=@p1,EntityLogicalName=@p2,QueryParameters=@p3,PageSize=@p4)?
    @p1: 'SELECT c.props.flowlogid as flowlogid, c.props.createdon as 
createdon, c.props.data as data, c.props.level as level, c.props.type as 
type, c.ttl as ttlinseconds, c.props.cloudflowid as cloudflowid, 
c.props.cloudflowrunid as cloudflowrunid, c.props.desktopflowid as 
desktopflowid, c.props.flowmachineid as flowmachineid, 
c.props.flowmachinegroupid as flowmachinegroupid, c.props.flowsessionid as 
flowsessionid, c.props.workqueueid as workqueueid, c.props.workqueueitemid 
as workqueueitemid FROM c WHERE c.props.type IN (100000001) ORDER BY 
c.props.data.startTime DESC'
    @p2: 'flowlog'
    @p3: {"Keys":
["@referencingParentId","@referencingParentLogicalName"],"Values":
[{"Type":"System.Guid","Value":"40590757-a9c0-4f4c-abfc-e2f389049d90"},
{"Type":"System.String","Value":"flowsession"}]}
    @p4: 50

Learn more about querying JSON columns in elastic tables.

Breaking down the call into individual pieces
The base URL (https://[my org].api.crm[my region].dynamics.com/api/data/v9.2/) is
the endpoint for the Dataverse Web API.
ExecuteCosmosSqlQuery is the method being called. This method allows the
execution of a SQL query against Dataverse.
The parameters for the ExecuteCosmosSqlQuery method are provided in
parentheses following the method name:

QueryText=@p1 : The SQL query to be executed. In this case, the query selects
various properties from a table where the type is 100000001 (desktop flow
action log type) and orders the results by the startTime property in descending
order.
EntityLogicalName=@p2 : This section is the logical name of the table ( flowlog )
that stores the action logs.



QueryParameters=@p3 : This section is a JSON object specifying parameters for
the query. In the previous example, it's specifying a key-value pair where the
keys are @referencingParentId  and @referencingParentLogicalName  with values
of flowsessionid  (GUID) and type of the table flowsession .
PageSize=p4 : This section is the query page size.

Known limitations
Logs V2 are only available for desktop flow runs that are launched from a cloud
flow through the desktop flow connector action.
Bulk-delete jobs aren't currently supported for the Flow Log table.
Flow log records can't yet be viewed in the Table section of the maker portal
(make.powerapps.com).
Changing action log version doesn't migrate previous desktop flow action logs to
the new log storage type.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Application lifecycle management
(ALM) for Power Automate v2 schema
Article • 05/25/2024

In the Dataverse data model, desktop flows stored in the v2 schema consist of multiple
binaries. This article explains how to update a desktop flow within a solution that resides
in an environment with the v2 schema enabled.

Update a v2 desktop flow and export the
solution
To update a desktop flow with v2 schema and export the solution, follow these steps:

７ Note

Importing a managed solution into the same environment as the originating
unmanaged solution isn't possible.
New binaries are automatically added to the solution in which the desktop
flow is located, we still recommend to use the following procedure before
exporting to ensure all binaries are added to the solution.
You can use solution checker to validate that your solution is not missing any
dependencies.

1. Go to Power Automate  and select Solutions.

2. Select the solution you want to modify.

3. Select the ellipses next to the flow display name, and then Advanced > Add
required objects.



4. In the Add Required Objects dialog, select OK.

5. Some new Desktop Flow Binary items should appear in the solution.

6. Go back to the solution summary and export the solution as a managed solution.

7. Import the solution into the required environment. This environment must have
the v2 schema enabled.

Manage v1 and v2 schema migrations with
solutions
When using solution to manage the lifecycle of your desktop flows, it's important to
note the following considerations for importing v2 desktop flows into an environment
that contains both v1 and v2 desktop flows.

Managed solutions

７ Note

As a best practice, you shouldn't update a managed desktop flow directly. Instead,
import a new version of the solution. Updating a managed desktop flow in v2
schema is now blocked.

If you meet all of the following criteria, you first need to remove the managed solution
from the target environment before importing it again:

You use a managed solution to export desktop flows from your test environment
to production environment.
You have a desktop flow that was updated from v1 to v2 in your target
environment.



You want to import a new version in v2 from another environment.

If you can't remove the solution because you have other dependencies on this solution,
you need to remove any unmanaged layer on the desktop flow, including related data.
To see the related data, in the desktop flow in the solution, select Dependencies and
then select the Used by tab. The list of unmanaged binaries associated with this desktop
flow are shown and you can delete them.

If the desktop flows on the target environment are still v1, you can safely import the
solution containing the v2 desktop flow.

Unmanaged solutions

７ Note

An unmanaged solution should only be used for sharing a desktop flow with other
makers and shouldn't be use to import into production. Instead, a managed
solution is recommended to have a proper ALM.

If you meet all of the following criteria, you need to first delete the desktop flows from
the target environment using an unmanaged solution:

You use an unmanaged solution to share desktop flows.
You have a desktop flow that was updated from v1 to v2 in your target
environment.
You want to import a new version in v2 from another environment.

If the desktop flows in the target environment are still v1, you can safely import the
solution containing the v2 desktop flow.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create a Microsoft Dataverse database
Article • 02/24/2023

All the flows you create in Power Automate for desktop are stored in a Microsoft
Dataverse database. There are several ways to create a Dataverse database. Environment
administrators can create them in the Power Platform admin center and in Power Apps
and in Power Automate for desktop. Non-admins can create a Dataverse database in
Teams.

Create a Dataverse database in Power
Automate for desktop
Users with administrative rights on their device can create a Dataverse database in
Power Automate for desktop.

If you're using a free work or school account, a database is created automatically the
first time you sign in with your account after you install Power Automate.

If your account is a premium account, select Create database the first time you sign in
to Power Automate to create a Microsoft Dataverse database.

Create a Dataverse database in Teams
You can use the approvals workflow in Teams to automatically create a Dataverse
database that Power Automate can use to store flows. You need to follow this process
only once per tenant, and even non-admins can do it.

1. Sign in to Microsoft Teams .

2. Select More added apps (...).

3. Search for and install the Approvals app.



4. In the upper-right corner of the Approvals page, select New approval request.

5. Name your request; for example, Test .

6. Search for and select your username in the Approvers list.



7. Select Send.

Sending the approval request starts the creation of a Dataverse database. It may
take a few minutes to complete. When it's done, you'll receive a notification in
Teams that you have a request for approval.



8. Approve the request. Your Dataverse database is now added to the default
environment.

9. Exit Power Automate for desktop from the system tray icon to restart it.



Governance in Power Automate for desktop
Article • 04/01/2025

You can use the Windows registry to control who can do what with Power Automate for desktop.

Ｕ Caution

Modifying Windows registry settings incorrectly can cause serious problems that may prevent your
computer from booting properly. Microsoft cannot guarantee that any problems resulting from the
configuring of registry settings can be solved. Modification of these settings is at your own risk. We
strongly recommend that you back up your Windows registry  before proceeding.

７ Note

If a registry key doesn't exist in the Windows registry, first create the key and then add the registry value.

Prevent users manually updating Power Automate for
desktop
You can use the following registry entry to keep users from manually updating Power Automate for desktop
and receiving update notifications.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop DisableOptionalUpdates DWORD

Value

1: Users can't manually update Power Automate for desktop.

Prevent users from manually configuring Power
Automate for desktop to start automatically
Use the following registry entry to prevent users from manually configuring Power Automate for desktop to
start automatically. This key only applies to installer (MSI) versions.

ﾉ Expand table

Hive Key Name Type

HKEY_CURRENT_USER SOFTWARE\Microsoft\Power Automate Desktop DisableAutoStartConfiguration DWORD

Value

1: Users can't manually select to automatically start Power Automate for desktop.



Prevent users accessing Power Automate for desktop
using certain kinds of accounts
７ Note

Setting any value other than 1, or not setting a value at all, in the following registry keys will allow users
to sign in to Power Automate for desktop. If all the following registry keys are set to 1, users can't sign in
to Power Automate for desktop using any type of account.

Prevent users accessing Power Automate for desktop using their
Microsoft accounts
You can use the following registry entry to keep users from signing in to Power Automate for desktop using a
Microsoft account.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop RestrictMSAAccountsSignIns DWORD

Value

1: Users can't sign in to Power Automate using their Microsoft account.

Prevent users accessing Power Automate for desktop using their
work or school accounts
You can use the following registry entry to keep users from signing in to Power Automate for desktop using
their work or school account without a per-user plan with attended RPA license.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate RestrictNoLicenseOrgIDAccountsSignIns DWORD
Desktop

Value

1: Users can't sign in to Power Automate using their work or school account without a per-user plan with
attended RPA license.

Prevent users accessing Power Automate for desktop using their
work or school accounts or organization premium accounts
You can use the following registry entry to keep users from logging into Power Automate for desktop using
their work or school accounts or organization premium accounts.



ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop RestrictOrgIDAccountsSignIns DWORD

Value

1: Users can't sign in to Power Automate using their work or school account or organization premium
account.

Restrict access to Power Automate for desktop
To restrict access to Power Automate for desktop on a workstation with Windows 10 or Windows 11, use App
locker.

Configure Power Automate for desktop to use the Web
Account Manager (WAM) as a fallback sign in method
By default, Power Automate for desktop uses the Web Account Manager (WAM) for user authentication. If any
sign in errors occur, it uses an Internet Explorer client as a fallback method.

You can use the following registry entry to set Power Automate for desktop to sign in with the Windows Web
Account Manager (WAM) as a fallback sign in method.

７ Note

For older versions of Power Automate for desktop prior to version 2.41, this registry entry configures
Power Automate for desktop to sign in with the Web Account Manager (WAM) as the primary sign in
method.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop UseMsalWindowsBroker DWORD

Values

1: Power Automate for desktop authenticates users using the WAM functionality as a fallback sign in
method.

Configure Power Automate for desktop to check for
revoked certificates
Certificates ensure the security of your connections to online data sources. You can use the following registry
entry to configure the level of certificate check, based on the certificates’ revocation information status.

７ Note



The default configuration when no registry entry is set is Basic check.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop\Global CertificateRevocationCheck DWORD

Values

0: No check - Power Automate for desktop doesn't check the revocation information. All valid
certificates are allowed through.
1: Basic check (default) - Power Automate for desktop rejects only certificates that are revoked.
Certificates without revocation information are allowed through. This is important for some
organizations with corporate proxy services.
2: Comprehensive check – Power Automate for desktop rejects both certificates that are revoked and
certificates without revocation information.

Allow users to select an organization in Power
Automate for desktop
You can use the following registry entry to allow users to select the organization of their preference in Power
Automate for desktop.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop EnableOrganizationPicker String

Values

"isEnabled":1: Signed-in users can select the organization of their preference through the Switch
organization option in the Power Automate for desktop console.

"isEnabled":0: Signed-in users can't select the organization of their preference and the Switch
organization option is disabled.

"organizationList":[OrgID(s)] (for example, organizationList:["10z677m8-l4v6-9cm5-c6n6-
r1747rp5338k","86d487j7-y1t2-9gk7-k7n2-x5079jq4619r"] ): The organizations with the specified IDs are
available to connect during sign-in.

"selectOrganizationFromListIsEnabled":1: Power Automate for desktop tries to connect to each of the
organizations specified in the organizationList value, in order, during sign-in.

"selectOrganizationFromListIsEnabled":0: The specified list in the organizationList value isn't taken into
consideration during sign-in.

７ Note



The "isEnabled" values aren't related to the organizationList and selectOrganizationFromListIsEnabled
values. The isEnabled values define whether the Switch organization option is available to signed-in
users, whereas the organizationList and selectOrganizationFromListIsEnabled values define the
organizations that Power Automate for desktop tries to connect to automatically during sign-in.

Configure Power Automate for desktop to connect to a
region
You can use the following registry entry to set the region where users connect to by default during sign-in.

７ Note

Values 0 and 1 apply to older versions of Power Automate for desktop, prior to version 2.41.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop Cloud DWORD

Value

0: The user can select the region to connect to through another option in the sign-in screen.
1: The user is automatically connected to the first available region they're registered to.
2: The user connects to the global public region.
3: The user connects to the US Government GCC region.
4: The user connects to the US Government GCC High region.
5: The user connects to the US Government DoD region.
6: The user connects to the China (operated by 21Vianet) region.

Configure Power Automate for desktop to interact with
a corporate proxy server
IT administrators can set the following registry key to configure how Power Automate interacts with a
corporate proxy server.

） Important

From Power Automate for desktop version 2.45, all proxy settings can be configured through the Power
Automate proxy configuration files. Learn more at Configure Power Automate for desktop proxy
settings.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop ProxyServer String



Value

ProxyAddress:Port (for example, https://myproxy.com:3128 ): The proxy server and port configured
override the proxy server and port configured in Windows.

Configure Power Automate for desktop to bypass a
corporate proxy server
IT administrators can set the following registry key to configure the Power Automate's bypassing of a
corporate proxy server.

） Important

From Power Automate for desktop version 2.45, all proxy settings can be configured through the Power
Automate proxy configuration files. Learn more at Configure Power Automate for desktop proxy
settings.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop DisableWindowsProxy DWORD

Value

1: Power Automate for desktop doesn't honor the Windows Proxy settings and the proxy server is
bypassed for Power Automate's traffic.

Configure Power Automate for desktop to authenticate
to a corporate proxy server using the current user's
credentials
IT administrators can set the following registry key to configure how Power Automate authenticates with a
corporate proxy server.

） Important

From Power Automate for desktop version 2.45, all proxy settings can be configured through the Power
Automate proxy configuration files. Learn more at Configure Power Automate for desktop proxy
settings.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop UseDefaultProxyCredentials DWORD

Value



1: Power Automate for desktop authenticates to the corporate proxy server using the current user's
credentials.

Configure Power Automate for desktop to authenticate
to a corporate proxy server using Windows credentials
IT administrators can set the following registry key to configure Power Automate to use a generic credential
from Windows’ Credential Manager to authenticate to a corporate proxy server.

７ Note

To use this registry key, it’s a prerequisite to first configure the proxy server’s address and port through
the ProxyServer registry key.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop ProxyNetworkCredentialsKey String

Value

Internet or network address: The Internet or network address value of the generic Windows
credential’s entry.

Configure Power Automate for desktop to bypass a set
of addresses while interacting with a corporate proxy
server
IT administrators can set the following registry key to configure a list of IP addresses that are bypassed while
Power Automate interacts with a corporate proxy server.

７ Note

To use this registry key, it’s a prerequisite to first configure the proxy server’s address and port through
the ProxyServer registry key.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop ProxyBypassList String

Value

Address1,Address2 (for example, 192.168.1.1, 10.10.10.* ): The list of addresses to be bypassed.



Configure optional diagnostic usage data collection in
Power Automate for desktop
You can use the following registry entry to enable or disable the collection of optional diagnostic usage data
in Power Automate for desktop.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\WOW6432Node\Microsoft\Power AllowOptionalDataCollection DWORD
Automate Desktop\LogShipper

Value

0: Power Automate for desktop doesn't collect optional diagnostic usage data.
1: Power Automate for desktop collects optional diagnostic usage data.

Prevent Power Automate for desktop from taking
screenshots for action logs upon error
You can use the following registry entry to prevent Power Automate for desktop from taking a screenshot for
the actions logs when an error occurs during a flow run.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate DisableScreenshotCaptureOnError DWORD
Desktop\Global

Value

1: Power Automate for desktop doesn't take a screenshot for the action logs when an error occurs
during a flow run.

Prevent Power Automate for desktop from uploading
action logs after a desktop flow execution
You can use the following registry entry to prevent Power Automate for desktop from uploading detailed logs
per action for the respective run of the flow's run history, after a desktop flow execution.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate DisableFlowExecutionActionLogging DWORD
Desktop\Global

Value



1: Power Automate for desktop doesn't upload detailed action logs for the respective run of the flow's
run history.

Configure or disable desktop flow action logs per
environment (preview)
See Desktop flow action logs configuration (preview).

Configure the generation of desktop flow action logs
on the local machine for designer-based runs
Use the following registry entry to configure whether local Power Automate Desktop Designer runs should
store their action logs on the local machine. This option can be useful for debugging and troubleshooting
scenarios, allowing you to examine the logs without checking each action's input and output individually.

７ Note

This feature does not automatically clean up the logs generated during designer runs. Make sure you
have sufficient local disk space to store the logs or manually clean up older run data.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop EnableDesignerExecutionLogs DWORD

Value

1: Enables persistence of Power Automate for desktop execution logs on the local file system, without
uploading them to Dataverse. After a flow execution from Power Automate Desktop Designer is
completed, the execution logs can be found at the following path:

%LOCALAPPDATA%\Microsoft\Power Automate Desktop\Designer\Scripts\<scriptId>\Runs\

<runId>\Actions.log

Configure Power Automate for desktop notification
settings
You can use the following registry entry to configure how Power Automate for desktop displays notifications
and monitoring information.

ﾉ Expand table

Hive Key Name Type

HKEY_CURRENT_USER SOFTWARE\Microsoft\Power Automate Desktop NotificationsType DWORD

Value



1: Power Automate for desktop displays notifications through the flow monitoring window.
2: Power Automate for desktop uses the integrated Windows notifications.
3: Power Automate for desktop doesn't display notifications.

Configure Power Automate for desktop confirmation
dialog when invoking flows using a URL or desktop
shortcut
You can use the following registry entry to configure the behavior of the confirmation dialog when invoking
flows using a URL or desktop shortcut.

ﾉ Expand table

Hive Key Name Type

HKEY_CURRENT_USER SOFTWARE\Microsoft\Power Automate EnableAskBeforeRunningAFlowExternally DWORD
Desktop

Value

0: Power Automate for desktop doesn't display a confirmation dialog when invoking flows using a URL
or desktop shortcut. The user can change this option through the console settings.

Configure Power Automate for desktop to invoke flows
using a URL or desktop shortcut
You can use the following registry entry to enforce the confirmation dialog or disable invoking flows using a
URL or desktop shortcut.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop ConfigureExternalRuns DWORD

Value

1: Power Automate for desktop always displays a confirmation dialog when invoking flows using a URL
or desktop shortcut. Users aren't allowed to change this option through the console settings.
2: Users aren't allowed to invoke flows using a URL or desktop shortcut.

Configure Power Automate for desktop to keep the
flow run details
You can use the following registry entry to configure Power Automate for desktop to keep the flow run detail
logs in a local folder.

ﾉ Expand table



Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop KeepRunDefinitionFilesCopy DWORD

Value

1: Power Automate for desktop creates a copy of the RunDefinition.json file, preventing the local flow
run details from getting cleaned up.

Configure Power Automate for desktop to prevent
cleanup of flow run action details
You can use the following registry entry to configure the cleanup of local flow run action detail logs.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop\Global DisableRunFilesCleanup DWORD

Value

1: Flow run action details stored in the Actions.log file aren't deleted from the local disk after the run is
completed.

Prevent Power Automate for desktop from running
flows containing cloud connectors
You can use the following registry entry to disable the execution of flows containing cloud connectors.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop\Global DisableCloudConnectors DWORD

Value

1: The machine can't run desktop flows containing cloud connectors. An error message informs users
about the limitation.

Improve troubleshooting of the Power Automate
troubleshooter
You can use the following registry entry to permit the use of the verbose logging functionality in the
troubleshooter.

ﾉ Expand table



Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\Microsoft\Power Automate Desktop AllowVerboseLogging DWORD

Value

1: The verbose logging feature is available to use via the troubleshooter of Power Automate for desktop.

Turn on verbose logging state in Power Automate for
desktop
You can use the following registry entry to turn on the verbose logging state for Power Automate for desktop.

ﾉ Expand table

Hive Key Name Type

HKEY_CURRENT_USER SOFTWARE\Microsoft\Power Automate Desktop UseVerboseLogging DWORD

Value

1: The verbose logging state is turned on for Power Automate for desktop.

Allow users to register their machine to a different
tenant in Power Automate machine-runtime app
７ Note

This registry entry applies to Power Automate desktop version 2.24 and later.

You can use the following registry entry to allow machine registrations to tenants that are different from the
machine joined Microsoft Entra tenant.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\WOW6432Node\Microsoft\Power Automate AllowedRegistrationTenants String
Desktop\Registration

Value

"AllowedRegistrationTenants": (for example, 3EF1D993-CBD4-4DEA-A50E-939AEDB23F21,5B19777D-814C-
43F3-9317-CDBAD0846ED8) : The tenants with the specified IDs can be used during machine registration.

Allow users to register their machine to any tenant in
Power Automate machine-runtime app



７ Note

This registry entry applies to Power Automate desktop version 2.24 and later.

You can use the following registry entry to allow machine registrations to any tenant.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\WOW6432Node\Microsoft\Power AllowRegisteringOutsideOfAADJoinedTenant DWORD
Automate Desktop\Registration

Value

1: Machines can register to any tenant.

Allow users to switch registration of their machine to a
different tenant in Power Automate machine-runtime
app
７ Note

This registry entry applies to Power Automate desktop version 2.24 and later.

You can use the following registry entry to allow switching machine registration to a different tenant.

ﾉ Expand table

Hive Key Name Type

HKEY_LOCAL_MACHINE SOFTWARE\WOW6432Node\Microsoft\Power Automate AllowTenantSwitching DWORD
Desktop\Registration

Value

1: Machine registration can switch to another tenant.

Prevent users from using the copilot's generative
answers capability
To prevent your users from using the copilot’s generative answers capability, Power Platform administrators
turn off the Copilot help assistance in Power Automate via Bing setting in the Power Platform admin center.

Prevent users from sending copilot related feedback
As a Power Platform admin you can prevent users from sending feedback to Microsoft by disabling the
disableSurveyFeedback tenant setting. Find more information about viewing and setting tenant settings here:



List tenant settings (preview)
Set TenantSettings

Prevent your users from using any copilot capability
To prevent your users from using any copilot capability contact Microsoft Customer Support to disable all
copilot functionality in your tenant. More information: Get Help + Support

Related information
Create Power Automate desktop flows.
Run desktop flows.
Manage desktop flows.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Manage security for Power Automate
Article • 02/27/2024

In order to manage security for Power Automate, it's important to understand the
security concepts and terminology of Microsoft Dataverse, which is the underlying data
platform for Power Platform components. Microsoft Dataverse has a strong security
model that uses security roles, teams, and business units to control access to tables,
fields, and records using permission and row-level access control. Learn more: Dataverse
security roles and privileges.

This article explains the built-in security roles that are available for Power Automate
Desktop flows.

７ Note

Dataverse data and configurations are environment-based. Environments can be
used to segregate data, security settings, customizations and resources by
department, project, data residency and data privacy requirements, or organization.
For example, you might have one environment for your sales team, another for
your marketing team, and a third for your customer service team. This allows you to
control access to resources and data at a granular level, and ensures that each team
has access only to the resources they need.

Dataverse access prerequisites
To access an environment, a user must meet the following criteria:

1. Be enabled for sign-in in Microsoft Entra ID.
2. Have a valid license that has a Microsoft Power Platform or Dynamics 365

recognized service plan.
3. Be a member of the environment's Microsoft Entra group (if one has been

associated with the environment).
4. Have at least one Dataverse security role assigned directly to them or to a group

team they're a member of.

If you have difficulties connecting to Dataverse, review this troubleshooting page for
Common user access issues.

Dataverse security-related features



The following components are related to key security configurations in Dataverse.

Security role: A security role is a collection of privileges that define the level of
access that a user or team has to resources in Dataverse. Security roles are used to
control access to tables, columns, and other resources in Dataverse.
Business unit: A business unit is a logical container for users, teams, and other
resources in Dataverse. Business units are used to define security boundaries and
to control access to resources in Dataverse.
Team: A team is a group of users in Dataverse that share a common set of
privileges. Teams 's used to simplify security management and to control access to
resources in Dataverse.
User: A user is an individual who has access to Dataverse. Users are assigned
security roles and are members of one or more business units.
Privilege: A privilege is a permission that controls access to tables, columns, and
other resources in Dataverse. Privileges are used to define the level of access that a
user or team has to a particular resource in Dataverse.
Access level: An access level is a combination of privileges that define the level of
access that a user or team has to a particular resource in Dataverse. Access levels
are used to simplify security management and to control access to resources in
Dataverse.
Sharing: Sharing is the process of granting access to a row or other resource in
Dataverse to another user or team. Sharing is used to provide temporary or ad-hoc
access to resources in Dataverse.
Record-level security: Record-level security is the process of controlling access to
individual rows (records) in Dataverse. Record-level security is used to ensure that
users can only access the rows that they're authorized to view or modify.
Field-level security: Field-level security is the process of controlling access to
individual columns in Dataverse. Field-level security is used to ensure that users
can only view or modify the columns that they're authorized to access.

Overall, these concepts and terminology are used to define the security model in
Dataverse, and are used to control access to resources in a granular and flexible way. By
understanding these concepts and terminology, you can better manage security in
Dataverse and ensure that your users have the appropriate level of access to resources.

Dataverse privileges
The following table provides details about each specific table privilege:

ﾉ Expand table



Privilege Description

Create Required to make a new row. Which rows can be created depends on the access level
of the permission defined in your security role.

Read Required to open a row to view the contents. Which rows can be read depends on the
access level of the permission defined in your security role.

Write Required to make changes to a row. Which rows can be changed depends on the
access level of the permission defined in your security role.

Delete Required to permanently remove a row. Which rows can be deleted depends on the
access level of the permission defined in your security role.

Append Required to associate the current row with another row. For example, a note can be
attached to an opportunity if the user has append rights on the note. The rows that
can be appended depend on the access level of the permission defined in your
security role. In case of many-to-many relationships, you must have append privilege
for both tables being associated or disassociated.

Append Required to associate a row with the current row. For example, if a user has append To
to rights on an opportunity, the user can add a note to the opportunity. The records that

can be appended to depend on the access level of the permission defined in your
security role.

Assign Required to give ownership of a row to another user. Which rows can be assigned
depends on the access level of the permission defined in your security role.

Share Required to give access to a row to another user while keeping your own access.
Which rows can be shared depends on the access level of the permission defined in
your security role.

For each specific privilege, there's a drop-down menu that allows you to define the
access level. Access levels determine how deep or high in the business unit hierarchy the
user can perform the specified privilege in the organization.

The following table lists the levels of access in the table, starting with the level that gives
users the most access. Organization-owned tables, miscellaneous privileges, and
privacy-related privileges will only have Organization or None types.

ﾉ Expand table

Type Description

Organization This access level gives a user access to all rows in the organization, regardless of
the business unit hierarchical level that the environment or the user belongs to.
Users who have organization access automatically have the other types of
access as well. Because this access level gives access to information throughout
the organization, it should be restricted to match the organization's data



Type Description

security plan. This level of access is typically reserved for managers with
authority over the organization.

Parent: Child This access level allows a user to access rows in their business unit and all
Business Unit business units below it. Users with this access level automatically have business

unit and user access. Since this access level provides access to information
across the business unit and its subordinates, it should be restricted to align
with the organization's data security plan. This level of access is typically
reserved for managers with authority over the business units.

Business Unit This access level gives a user access to rows in the user's business unit. Users
who have business unit access automatically have user access. Because this
access level gives access to information throughout the business unit, it should
be restricted to match the organization's data security plan. This level of access
is reserved for managers with authority over the business unit.

User This access level gives a user access to rows that the user owns, objects that are
shared with the organization, objects that are shared with the user, and objects
that are shared with a team that the user is a member of. This is the typical level
of access for sales and service representatives.

None No access is allowed.

Privileges with their access levels are combined to create security roles, which are used
to control access to resources in Dataverse. Security roles are assigned to users and
teams to define their level of access to resources in Dataverse.

For example, you might create a security role that allows users to create, read, and
update Desktop flows, but not delete them. You might also create a security role that
allows users to access all tables and fields in Dataverse, or a security role that allows
users to access only tables and fields that are owned by their team.

Overall, privileges are a key component of the security model in Dataverse, and are used
to control access to resources in a granular and flexible way.

７ Note

To run a desktop flow, you need these minimum privileges:

Basic Append, AppendTo, Create and Write privileges on the flowsession
table.
Basic Append, AppendTo, Create and Write privileges on the workflowbinary
table.
Basic Read privilege on the workflow  table.



Basic Read privilege on the desktopflowbinary  table.

Power Automate specific security roles
Following security roles are available out-of-the-box with Power Automate.

Environment maker
The environment maker role in Dataverse is a built-in security role that lets users create
and manage their resources associated with an environment. This includes apps,
connections, custom APIs, gateways, cloud flows, and desktop flows, as long as the user
has the appropriate license for the intended product area.



Desktop flows machine configuration admin
This role is typically assigned to CoE or IT admins that manage VM images and virtual
networks. Users with this role have full privileges on the VM image and VNet specific
tables, which are used for hosted machine scenarios. In particular, this allows users with
this role to add VM images, image versions and share/unshare VM images to be used



for created hosted machine scenarios in their environment.



Desktop Flows Machine Owner
This role allows users to manage machines and machine groups they own, including
creating, editing, sharing, and deleting machines and machine groups.



Desktop flows machine user
This role allows users to run Desktop flows but not configure machines. A CoE might
assign this role to other users in the environment, so that they can use machines created
and shared by the CoE, but not edit or share them.



Desktop flows machine user can share
This role extends the desktop flows machine user role and allows users to share
machines that have been shared with them.



Desktop flows runtime application user



This role is used by Power Automate cloud services when interacting with the Dataverse
environment.



Desktop flows machine application user
This role is used by Power Automate cloud services when interacting with the Dataverse
environment.



７ Note

The desktop flows runtime application user and desktop flows machine application
user roles are used by the Power Automate cloud services when interacting with the
Dataverse environment. Modifying privileges and configuration for these roles may
break desktop flow features.

More resources
Security in Microsoft Dataverse
Security concepts in Microsoft Dataverse
Security roles in Microsoft Dataverse



Diagnostic data collection in Power
Automate
Article • 02/24/2023

We use diagnostic data to keep Power Automate client software secure and up-to-date;
to detect, diagnose, and fix problems; and to make product improvements. This data
doesn't include a user's name or email address, the content of the user's files, or
information about apps unrelated to the product.

Microsoft is dedicated to being transparent with our customers about the data we
collect from our client software and giving them more control over their data. As part of
this work, diagnostic data we collect from our client software as customers use their
devices is classified as either Required or Optional. This classification will make it easier
for our customers to make informed choices about their privacy.

Power Automate client software doesn't collect optional diagnostic data by default
unless the user specified otherwise during the initial installation process or later in the
product's settings.

This article provides an overview of the types of diagnostic data that are required and
optional, and the specific categories of diagnostic data that are collected by Power
Automate client products.

Required data
Data classified as Required is necessary to keep our products up-to-date, secure, and
working as expected. Required diagnostic data includes the type and version of a
customer's device or software configuration so we can provide connectivity to our cloud
services and security patches to help keep our customers' experiences safe, secure, and
functioning with a high degree of performance; detect significant feature failures; and
then diagnose and fix those failures more quickly to reduce their impact on customers.

Required diagnostic data is the minimum data necessary to help keep Power Automate
client software performing as expected on the device it's installed on. Examples include
summary details about the health and security of the running service, version
information about infrastructure, configuration details, success or errors received, and
aggregated information about failures and security concerns, flow runs, service
interactions, and more.



Required diagnostic data is managed with your organization's and your employees'
security and privacy in mind. You can learn more about our commitments to protect
data in the Microsoft Trust Center .

Required diagnostic data summary
Required diagnostic data in Power Automate client software is organized into various
data categories.

Data Description Examples
category

Device This type of Required diagnostic Data about the user's device,
connectivity data includes details about the device, screen resolution, screen
and its configuration, and connectivity orientation, and other
configuration capabilities configuration details

Product and This type of Required diagnostic Information about memory,
service data includes details about device or processor, and disk usage
performance service health and performance Information about form load

times
Information about process
completion times

Product and This type of Required diagnostic Details about navigation
service usage data includes details about the usage of patterns

the device, operating system, Details about form usage
applications, and services Details about frequency of use of

activities and actions

Software This type of Required diagnostic An event used to ensure new
setup and data includes software installation and users can successfully launch and
inventory update information on the device run Power Automate client

applications for the first time
An event that ensures critical
regression detection for installed
client applications

Optional data
Data in the Optional category isn't essential to the product or service experience. Opting
in to this feature allows us to identify usage trends, which enhances our ability to make
product improvements.



Power Automate client products don't collect optional data unless the user consents
during the product installation process or has enabled the feature through the
application settings later. If users choose to send optional diagnostic data, it's collected
in addition to required diagnostic data.

Data Description Examples
category

Enhanced This type of Optional diagnostic data includes Process names that the
anonymized details about the usage of advanced flow user is trying to
product usage objects, such as selectors automate such as

EXCEL.exe



Get started with a Microsoft account
Article • 02/24/2023

Power Automate enables regular and power users to automate processes on their
desktops, saving time and eliminating human error.

Focus on other activities by automating routine and repetitive tasks like organizing or
backing up your files and folders. Create flows to extract product prices from websites,
save them in Excel spreadsheets, and then email them as attachments. Fill in web forms
by supplying information dynamically from your files.

Create automated workflows with step-by-step guidance and an intuitive, no-code
interface anyone can use, regardless of their technical expertise. Build flows from a wide
variety of premade actions, or record your interactions as steps to be played back
anytime.

Using Power Automate with a Microsoft account is available at no extra cost.

７ Note

Desktop flows built with Power Automate using a Microsoft account are stored
automatically on your OneDrive.

Build your first flow
The following example demonstrates the creation of a short flow. The completed flow
will prompt you to select a folder. Then, it will copy the folder to another folder named
backup on your desktop.

To create the desktop flow:

1. Launch Power Automate and select the New flow button in the console.



2. Enter a name for the flow and then select Create. In this example, the name of the
flow is Copy Folder to Desktop.

3. When the flow designer opens, go to the actions pane, open the Folders group of
actions, and drag the Get special folder action into the workspace.



4. In the modal of action, the desktop folder is selected by default as a parameter.
Select Save to add the action to the flow.

5. Similarly to step 3, go to the Message boxes group of actions, and add the Display
select folder dialog action to the flow. Set Dialog description to Select a folder to
back up:.



6. Next, add the Create folder action to the flow. Set the Create new folder into field
to %SpecialFolderPath% and New folder name to backup.

7. Using the same group of actions, select the Copy folder action. Set Folder to copy
to %SelectedFolder%, Destination folder to %SpecialFolderPath%\backup, and
add the action to the flow.



8. Select Run to run the flow and test that it works as expected.

9. Close the flow designer and save the flow. Now, you can run the flow from the
console.



When prompted for a folder, select any folder you want to copy. The flow will create a
new folder on your desktop called backup with the selected folder inside.

Following this example, it's possible to imagine a wide range of scenarios where these
actions could be combined with other actions. Among the many possibilities, you could:

Select a folder on a flash drive to back up to.
Back up files based on specific criteria.
Create a file structure for the backup.
Iterate through a list of folders and only back up selected folders.

Next steps
Learn how to set up Power Automate.

Begin your journey in Power Automate by creating a Power Automate desktop
flow.

Get familiar with the console and the flow designer.

Find the list of actions available in the Actions reference.



Get started with a work or school
account
Article • 02/24/2023

Power Automate enables users to automate repetitive desktop tasks through a
collection of premade actions.

Using the available actions and built-in recorder, you can automate any business
procedure, such as filling forms, retrieving data from the web or desktop applications,
and sending standardized emails.

Combining these features allows you to create robust flows that disengage humans
from repetitive, unproductive procedures. Tasks like copying data across different
systems are common in business environments, and Power Automate can entirely
handle them.

Apart from third-party applications, Power Automate automates integrated Windows
applications and features. Creating backups of critical files and running diagnostics or
custom scripts can be performed effectively through desktop flows.

Using Power Automate with a work or school account is available at no extra cost. To
use Power Automate for desktop, your default environment must contain a Dataverse
database. To unlock more RPA features, such as running flows automatically, premium
cloud connectors, and flow sharing and monitoring, start a trial or upgrade to an
Organization premium account.

To start a trial, select Go premium on the Power Automate console.

Flow example
To become familiar with the available features of Power Automate, follow the steps
below to create a desktop flow.

The presented flow copies all the files located in the documents folder and creates a
backup to a secondary drive. The original location of each file is appended to an existing
log file.

７ Note

To implement this example, a secondary drive has to be connected to your
machine. If a secondary drive isn't available, select a different destination folder for



the files.

To create the desktop flow:

1. Launch Power Automate and select the New flow button in the Console.

2. Enter a name for the flow and then select Create. In this example, the name of the
flow is Backup flow.



3. When the flow designer is open, add the Get special folder action in the
workspace and retrieve the path of the documents folder.

4. Add the Get files in folder action to retrieve all the files located in the previously
retrieved folder. Optionally, set the action to retrieve the files located in subfolders
of the selected folder.

5. Deploy a For each loop to access and handle each file of the retrieved list
independently.



6. Inside the For each loop, add the Get file path part action to retrieve the path of
the currently selected file.

7. Add the Copy file action to copy the currently selected file to the desired location.
In this example, the destination folder is called Backup and it's located in the D
drive.

７ Note

If a secondary drive isn't available, select a different destination folder for the
copied file.



8. Use the Write text to file action to append a new registry in the log file. In this
example, the file is called Logs.txt, and each registry contains the original path of
the copied file.

9. To test if the flow runs as expected, select the Run button on the upper part of the
flow designer.



10. To check how every single action is implemented, run the flow step by step using
the Run next action button.

11. If the flow runs as expected, select Save and close the flow designer window.

12. Now, you can run your flow directly using the Run button in the console. To stop
the flow before its completion, select Stop.

Next Steps



Learn how to set up Power Automate for desktop.

Begin your journey in Power Automate by creating a Power Automate desktop
flow.

Get familiar with the console and the flow designer.

Find the list of actions available in the Actions reference.



Get started with an organization
premium account
Article • 03/10/2023

Power Automate enables regular and power users to create flows that automate routine
repetitive tasks. For example, build flows from premade actions, or record windows and
web browser activity in real time.

Unlock the full spectrum of RPA features such as premium cloud connectors, the ability
to run your flows automatically, detailed monitoring, and many more.

Power Automate gives you the option to share your flows among your colleagues so
that you can improve automations and build on top of them.

Access your flows from anywhere, harnessing the power of the cloud to establish a
robust and flexible RPA system. Take full advantage of multiple environments to
organize and manage users’ flows.

If you currently use Power Automate with a work or school account or your license
doesn't include attended RPA, you can still use Power Automate for your desktop
automation needs. Start a trial to preview all the features by selecting Go premium on
the Power Automate console.

Creating a flow
1. Begin by signing in to the Power Automate portal . Then, navigate to Create >

Power Automate for desktop.

2. After you assign a name to the flow, you'll be prompted to launch Power Automate
for desktop. Select Open to do so.

3. In the flow designer, start building the flow by double-clicking on actions, or
dragging them from the actions pane on the left into the central workspace pane.

4. Expand the Datetime category, and select the Get current date and time action.
Configure it to only retrieve the date.



5. Next, expand the Text category, and configure the Convert datetime to text
actions as follows. This step will ensure that the current date is displayed in a
filename-friendly format.

6. Use the Get special folder action to retrieve the path of the documents folder.



7. Add the If file exists action from the Conditionals category, and configure it to
check whether the file report.xlsx is present in the documents folder.

8. Finally, add the current date to the file's name by using the Rename file(s) action
from the File category.



9. The resulting flow should look like the following figure:

Following this example, it's possible to imagine a wide range of scenarios where Power
Automate can be used to automate tasks. The abundance of actions, combined with



cloud management capabilities, affords endless possibilities to individual users and
organizations.

Next Steps
Learn how to set up Power Automate.

Begin your journey in Power Automate by creating a Power Automate desktop
flow.

Get familiar with the console and the flow designer.

Find the list of actions in the Actions reference.

Learn how to apply unattended RPA licenses to your flows.



Create desktop flows
Article • 02/24/2023

Using Power Automate, you can develop desktop flows that automate tasks on your
desktop and the Web. This section presents all the available ways to create desktop
flows and start designing your automations.

Start creating desktop flows using examples
Power Automate provides an extensive collection of examples to introduce users to RPA.
You can find all the available examples under the Examples tab in the console.

To copy an example to your flows, right-click the example and select Create a copy. The
copied flow will be stored under the My flows tab.



If you've opened and edited an example in the flow designer, select Save as to copy the
edited example to your flows. The changes can't be saved to the original example flow.

Create desktop flows through the console
To create a desktop flow using Power Automate for desktop:



1. Launch the application and select New flow in the console.

2. Enter a name for the desktop flow, and select Create.

3. Design your flow in the flow designer and select Save. Close the flow designer and
the flow will appear in the My flows tab of the console.



Create desktop flows through cloud flows
Power Automate enables you to create desktop flows through cloud flows and trigger
them remotely. To find more information about this functionality, go to Trigger desktop
flows from cloud flows.



Get started with Copilot in Power
Automate for desktop (preview)
Article • 03/21/2025

[This topic is prerelease documentation and is subject to change.]

Copilot in desktop flows allows you to create automation that helps streamline your
workflow creation quickly and easily using natural language. You can create a new flow
or add more steps to an existing flow by just describing what you want to achieve using
natural language prompts.

） Important

This is a preview feature.
Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.
Copilot is a new technology that is still being developed. It is optimized for
use with English language and has limited support with other languages. As
such, parts of it may appear in English rather than your preferred language.
Copilot’s Natural Language to flow creation is powered by the Azure OpenAI
service. This feature is in Early Access.
Copilot’s generative answers capability is powered by the Azure OpenAI
Service and Bing Search.

Copilot can perform the following actions:

Understand your intent and either create a new flow or enhance an existing one
based on the scenario prompt you provide.
Answer product related questions. For example, you can ask Copilot questions
about desktop flows such as:

How do I read data from an Excel file?
How do I run a PowerShell script?

Prerequisites

Availability by region



Copilot in Power Automate for desktop offers different capabilities, which are available
in environments located in the following countries/regions:

Create flows using Copilot
United States

Answer product related questions
Australia
India
United Kingdom
United States

Summarize actions and subflows
United States

Availability by account type
Currently, Copilot in Power Automate for desktop is only available for users with a work
or school account.

７ Note

If your environment is in a supported region, you are signed in with a work or
school account, and you still can't see Copilot in the Power Automate for desktop
experience, contact your Power Platform administrator. An admin can turn Copilot
off or on in the Power Platform admin center.

Create a desktop flow using Copilot (preview)
You can create a new flow in the Power Automate for desktop console from either
Copilot in the home page or from the Copilot side panel. To create a flow from the
home page, type your prompt in Copilot’s chat area:



To create a flow from the Copilot side panel, open the Copilot chat panel by selecting
the Copilot button on the top right corner of the console and type your prompt. Make
sure the flow creation mode is selected from the drop-down menu:

Alternatively, you can also access the generative answers capability from the designer’s
vertical menu on the right side.

Once you submit your prompt, Copilot processes it and launches the designer with the
newly generated flow for you to review. In the designer’s Copilot side panel, you can
view a list of the actions that were generated. The actions are assigned in groups based
on their functionality. You can view the actions contained in each group by expanding it.
Lastly, these groups are translated to regions in the main designer’s panel.



In the designer's main area, Copilot-generated actions are marked with two comments:
one at the beginning to indicate the start and another at the end to signal the
conclusion. This separation is designed to make it easier to locate and review these
actions.

If Copilot identifies an intention to automate browser or UI tasks, it inserts an action
placeholder. This placeholder serves as a starting point for you to initiate the recorder
and capture the user actions. After you complete this step, the action placeholder is
automatically replaced with the actions created by the recorder. You can also delete the
action and add the necessary UI actions manually.



７ Note

The recording action produces a design time error. This is to remind you that a
significant part of the flow is still missing and needs to be created. To resolve this,
you can either launch the recorder and perform the recording or delete / disable it.

Add actions to an existing flow using Copilot
(preview)
You can easily enhance an existing flow by instructing Copilot to add more functionality.
Just navigate to the Power Automate for desktop’s designer and describe your desired
outcome in the Copilot side panel. Copilot adds the appropriate actions either at the
end of your flow or beneath a selected action. Make sure the appropriate Copilot skill is
enabled before typing your prompt by either selecting the Add a step that button on
the top of the Copilot side panel or by selecting it from the drop-down menu at the
bottom.



How to write a good prompt
Crafting effective prompts involves more than just being specific with your request or
specifying how you want your results displayed. If the initial results aren't what you're
looking for, try adjusting your prompt and running it again.

Be as specific as possible. Instead of a generic prompt like, Email an Excel file, try
the following prompt instead:

Send an email to sales@contoso.com from the account
accounting@contoso.com with subject "Contoso sales data" and attach the
Excel file in "C:\contoso\contoso.xlsx"

Try tweaking your prompt to further fine tune.
Learn more about writing prompts with generative AI at The art of the prompt:
How to get the best out of generative AI .

Use Copilot to get answers to product-related
questions (preview)
Access the generative answers capability from the console by selecting the Copilot icon
located on the top right corner of the console window.

Alternatively, you can also access the generative answers capability from the right side
of the screen in the designer’s vertical menu.



From Copilot’s side panel, make sure the generative answers skill is selected by either
selecting the Help me understand button on the top or the drop-down menu at the
bottom.

In the Copilot pane, ask any product related questions or use one of the proposed
prompts to get you started. The answer generated contains a link to the documentation
page to refer you to additional information. Make sure you always review AI-generated
content.



Use Copilot to summarize actions and subflows
(preview)
The Summarize actions & subflows Copilot skill helps you quickly understand desktop
flows by generating concise summaries for specific actions, multiple actions, or entire
subflows. This skill lets you troubleshoot and maintain flows more efficiently, saving time
and simplifying the process of understanding and optimizing your automation.

Key features
This skill lets you generate summaries for individual actions, multiple actions, or entire
subflows within your desktop flow. You can reference specific line numbers or subflow
names to request descriptions, such as "Summarize action in line 4" or "Summarize
subflow 'main'." You can also customize the level of detail in the summaries by
specifying your preferences, like requesting a high-level overview in a couple of
sentences or a more detailed explanation. For example, you can say "Summarize subflow
<subflow_name> in a couple of sentences".

How to use
To use the "Summarize actions & subflows" skill, select it from the Copilot skill picker
drop-down menu in the Power Automate for desktop flows designer. Then, type your
prompt in natural language to generate a summary.

Help us improve Copilot
To send feedback, select the thumbs up or thumbs down icon under the AI-generated
content. A feedback dialog appears, allowing you to submit feedback to Microsoft.
Learn more about how this data is used and your rights at Microsoft feedback for your
organization.

７ Note

If you can't see the feedback dialog, check if your tenant admin turned it off.

Turn off user feedback functionality
As a Power Platform admin, prevent users from sending Copilot feedback to Microsoft
by using the "Copilot feedback" tenant setting.



Data subject rights requests on user feedback
Tenant administrators can view, export, and delete feedback from users by signing in to
the Microsoft 365 admin center  and selecting Health > Product feedback.

Frequently asked questions (FAQ)
Use this section to find answers to frequently asked questions.

How can I prevent users from using Copilot?
To prevent your users from using any of Copilot's capabilities, contact Microsoft
Support.
To prevent users from using Copilot’s generative answers capability, Power
Platform administrators can turn off the Copilot help assistance in Power
Automate via Bing setting in the Power Platform admin center.

What are the limitations of Copilot in Power Automate
for desktop?

Copilot only supports a subset of the available actions in Power Automate for
desktop. Specifically, only the following actions are supported for flow creation or
when adding steps in an existing flow:

Clipboard
CMD session
Compression
Conditionals
Database
Date Time
Email
Excel
File
Flow Control
Folder
HTTP
Loops
Message Boxes
Mouse and Keyboard
Outlook
PDF



Scripting
System
Text
Variables
Word
XML

You can’t use Copilot in Power Automate for desktop if you’re using a personal
Microsoft account. For example, you can’t use someone@live.com . Use a work or
school account like someone@contoso.com  instead.
Only environments located in the United States have access to Copilot.
Copilot supports English language only.

Why are some of the generated actions marked as
erroneous when I create a flow or add actions to an
existing flow using Copilot?
Copilot generates actions based on your prompt. If the prompt doesn't include the
mandatory parameters of an action, its left empty when generated and is marked as
erroneous. You can try providing a more detailed prompt to avoid having actions with
empty parameters. For example, a prompt such as Open an excel file and read all data
results in a design time error, as the Excel file path is a mandatory parameter of the
Launch Excel action. If the instruction is to Open the Excel file located at
"c:\contoso\myExcel.xlsx" and read all data, then the Launch Excel action is prefilled with
the file path, ensuring no design time errors occur.

What are some example prompts I can use to create
flows?

Check if the folder c:\contoso exists. If it does, search for all Excel files. Add every
Excel file found into an archive c:\Contoso\archivedExcels.zip using the best
compression level.
Search in the Excel file c:\contoso\employees_list.xlsx for the string "Foo" in any of the
cells. If there's a match, send an email using Outlook from the account
sales@contoso.com to accounting@contoso.com with Subject "Here is your Excel file"
and attach the Excel file.
Read the text from the file c:\contoso\sample_text.txt. Replace any occurrences of
<telephone number>  with 514-555-0100 and any occurrences of <email address>
with sales@contoso.com. Lastly, display the whole text in a dialog and email the text
file to accounting@contoso.com with subject: "Here's the text that I parsed." Put in
the email body the text of the file and also attach the file.



Add a PowerShell script that performs an API call to
https://contoso.com/api_endpoint  and passes the "employee_details" variable.
Then create a new Excel file and write the employee_details variable to it. Lastly, save
the Excel file to c:\contoso\employees.xlsx
*Add an action that compresses the following folder
"C:\Users\contoso\Desktop\Invoices" and save it on my desktop.
Open the following Excel file "C:\Users\contoso\Desktop\data.xlsx" and delete
column B from the first sheet. Then save the Excel file and close it.*
Connect to my email account sales@contoso.com, search for the last email sent by
accounting@contoso.com and display in a message the order number from that
email's subject.
Create a flow that prompts the user for the name of an application and then
searches for that application to check if it's running. If not, use run application to
launch it by first locating its exe from program files.
Find all png files in c:\temp and to compress them in a new file with name pngs.zip.
Connect to the SQL Database "Server=server-name;Database=database-name;User
Id=username;Password=password;" and get the row count of the table car_entries.

Related information
FAQ for Copilot in Power Automate for desktop
Responsible AI FAQs for Power Automate
FAQ for Copilot data security and privacy in Microsoft Power Platform

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create desktop flows using Record with
Copilot (preview)
Article • 04/01/2025

[This article is prerelease documentation and is subject to change.]

Introduction
Building desktop flows is now easier than ever with Record with Copilot, also known as
the AI Recorder, in Power Automate desktop. This feature lets you build desktop
automations by sharing your screen and describing the task you want to automate, as if
you were explaining it to someone else. Record with Copilot captures your voice, mouse,
and keyboard inputs during the recording. Then, it processes them and converts them
into a desktop flow. You can review, edit, and save the flow before running it.

） Important

This is a preview feature.
Preview features aren’t meant for production use and might have restricted
functionality. These features are subject to supplemental terms of use , and
are available before an official release so that customers can get early access
and provide feedback.

Watch this short video to learn how to use Record with Copilot:
https://learn-video.azurefd.net/vod/player?id=853935fc-c43c-4bf2-9a9d-
12b83f3abcfd&locale=en-us&embedUrl=%2Fpower-automate%2Fdesktop-
flows%2Fcreate-flow-using-ai-recorder

Prerequisites
Before you use Record with Copilot, make sure you meet these requirements:

Availability by region
Currently, Record with Copilot is available only in environments in the United States.
Learn how to create an environment in the United States at Create and manage
environments in the Power Platform admin center.



Availability by account type
Currently, Record with Copilot is available only for users with a work or school account.

Minimum Power Automate Desktop
You need Power Automate desktop version 2.48 or higher. Learn how to download the
latest version at Install Power Automate .

Create a desktop flow using Record with
Copilot
To create a desktop flow using Record with Copilot:

1. Open Record with Copilot:

In Power Automate for desktop, select Record with Copilot, and then select Start.
If this option isn’t available, check the Prerequisites.

2. Review the welcome screen:

A welcome screen shows some tips on using the recorder. Select Next to continue.

3. Choose your recording settings:



If you have more than one monitor, select the one you want to record. Also, select
the microphone and speaker you want to use for narration. Select Next to
continue.

4. Listen to the recording tips.

You hear some final tips before you start. When you're ready, select Record.

5. Record the process:

Describe the process you want to automate as if you’re teaching someone how to
do it. The more detail you give, the better the results.

6. Finish recording:

When you finish, select Done. Power Automate analyzes the video, your narration,
and mouse movements to create the automation. This process takes a few
minutes.

7. Review and customize:

After the analysis is done, the automation appears in the flow designer. Check it,
make any changes you need, and fill in any missing details. When you're happy
with it, save and run your automation. For more customization options, explore the
flow designer options.

Frequently asked questions

What are some limitations of Record with Copilot?
Record with Copilot is available only in environments based in the United States for
users with work or school accounts. It supports only English at this time. We're
working hard to expand support to more regions and languages soon.

Record with Copilot needs you to speak and explain the automation process. If you
don't provide narration, it doesn't generate an automation.

You need to interact with clicks or keystrokes during recording. Just talking over a
screen without any mouse or keyboard interaction doesn't produce an automation
suggestion.

How can I get the best results from Record with Copilot?



Speak clearly and show each step in detail as you demonstrate the process. Wait for
screens to load completely and avoid interruptions or distractions during recording.

Where can I watch a demo of Record with Copilot?
The following videos shows a demo of Record with Copilot:
https://learn-video.azurefd.net/vod/player?id=853935fc-c43c-4bf2-9a9d-
12b83f3abcfd&locale=en-us&embedUrl=%2Fpower-automate%2Fdesktop-
flows%2Fcreate-flow-using-ai-recorder

https://learn-video.azurefd.net/vod/player?id=cb7fd0a9-ce47-49f0-95d1-
1ebeb135ac4e&locale=en-us&embedUrl=%2Fpower-automate%2Fdesktop-
flows%2Fcreate-flow-using-ai-recorder

What are some scenarios I can try with Record with
Copilot?
You can try different scenarios, such as moving data from Excel to a web form,
navigating websites, and extracting data.

What languages are supported?
Record with Copilot supports English right now. We'll add more languages in future
updates.

How is Record with Copilot different from the Recorder?
The Recorder captures interactions like mouse clicks and keystrokes, and creates a
desktop flow that repeats those actions. However, it doesn't capture logic such as
conditions or loops.

Record with Copilot lets you explain the process verbally while showing it. The AI model
then interprets your actions and narration and suggests an automation that includes
conditions, loops, and necessary interactions.

Why does the flow suggested by Record with Copilot
have missing actions or UI selectors?



Record with Copilot is in preview, and we're constantly improving its accuracy. As an AI-
powered tool, Record with Copilot is designed to get better over time. If you run into
issues, we'd love your feedback to help us improve Record with Copilot for your specific
use case. Contact us at powerautomate-ai@microsoft.com and we're happy to chat with
you.

How does the system manage recordings, and what
measures are taken to ensure privacy and security?
When you use the recorder, your recording is securely uploaded to the cloud, where an
AI model transforms it into a Power Automate desktop flow. The recording is kept only
for a brief period necessary for processing and is deleted once processing is complete.
The maximum delay for the recording to be deleted from the cloud service is 24 hours.

To protect your data, all recording data sent from and to Power Automate desktop is
encrypted both during transit and at rest.

The recordings aren't used for training the AI model.

What details does the recorder capture during a session?
When you start a recording, you can choose which screen to record and which
microphone to use. A colored border shows around the screen being recorded. To avoid
capturing sensitive information, make sure it isn't shown during the recording. If you
accidentally record something you don't want to include, you can restart the recording
or close the recorder. In these cases, the recordings aren't sent to the cloud for
processing.

The recorder captures a video of the selected screen, audio from the chosen
microphone, and necessary UI metadata to build the desktop flow.

Can you turn off Record with Copilot?
You can turn off Copilot for Power Automate, which also turns off Record with Copilot.
Learn more in Enable or disable Copilot in Power Automate.

Share your feedback
Do you have any thoughts on Record with Copilot? We'd love to hear from you! Send us
a note at powerautomate-ai@microsoft.com. We’d love to chat with you.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Repair flow automation errors (preview)
Article • 04/01/2025

[This topic is prerelease documentation and is subject to change.]

This feature uses Copilot to find and repair the selectors of the required UI elements on
the screen. Users simply need to review and approve Copilot's suggestions.
Alternatively, users can manually indicate the UI elements on the screen, and Power
Automate for Desktop adjusts the selectors accordingly.

） Important

This is a preview feature.
Preview features aren’t meant for production use and might have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.
Copilot is a new technology that's still being developed. It's optimized for use
with English language and has limited support with other languages. As such,
parts of it might appear in English rather than your preferred language.

Prerequisites

Availability by region
Copilot in Power Automate for desktop offers different capabilities, which are available
in environments located in the following countries/regions:

United States

Availability by account type
Currently, Copilot in Power Automate for desktop is only available for users with a work
or school account.

７ Note

If the environment is in a supported region, you're signed in with a work or school
account, and you still can't use "Repair with Copilot" in the Power Automate for



desktop experience, contact the Power Platform administrator. An admin can turn
Copilot off or on in the Power Platform admin center.

Repair a flow at runtime

How to turn on the feature
You need Power Automate desktop version 2.51 (11.2412.xxx.y) or higher. Learn
how to download the latest version at Install Power Automate .

For repairing with Copilot, ensure the Copilot setting in the Power Platform Admin
Center is turned on.

Turn on the use of AI for self-healing issues. The Repair at runtime setting for the
desired run mode ( attended  and unattended ) can be found under the Desktop
flow repair at runtime configuration setting in the Power Platform admin center.



For newly created flows, turn on the Repair flow errors option.

For existing flows, navigate to the respective desktop flow properties in the Power
Automate for desktop console. Turn on the Repair flow errors property in the
desktop flow's properties.

Repair with Copilot: This option allows for automated issue resolution with the
assistance of Copilot.
Repair: This option turns on manual issue resolution, requiring you to specify
the UI element on the screen at the moment of failure during runtime.



Attended experience step-by-step
The feature triggers when a cloud flow initiates a desktop flow that's on the verge of
failing. This potential failure occurs because a UI or browser automation action
encounters an error when the UI element intended for interaction isn't located using
one or more preconfigured selectors. Next, a "Repair with Copilot" notification window
appears on the screen. Copilot then attempts to find the necessary UI element by
analyzing the UI elements present on the relevant screen or web page. Selecting Cancel
stops the entire process and the action fails, which means that the desktop flow fails (or
activates the error handling mechanism of the failed action). Select Repair manually,
and you indicate the required UI element manually on the screen by capturing it.



７ Note

The timer is set to 15 minutes from the initial display of the notification window.
Reset the timer at any point within this period to restart the 15-minute countdown.

Repair with Copilot



When Copilot locates the UI element successfully, the options are:

Apply for every run: The newly identified selector is added to the selectors list for
the UI element, positioned as the last in order. The desktop flow is updated with
this new selector, ensuring that in future runs, the suggested selector is included in
the list for this UI element.
Apply Once: The suggested selector is accepted for this run only. The new selector
is added to the UI element's selector list and used for this execution, but isn't
saved for future runs.
Repair Manually: You reject the Copilot suggestion and must manually identify and
capture the required UI element on the screen.
Cancel or Close: You reject the suggestion, causing the desktop flow to fail or
trigger the error handling mechanism for the failed action.

If you accept the suggestion, the notification window closes, and the action interacts
successfully with the correct UI element.

Check the UI element suggested by Copilot by selecting the Target button on the
screen.



When the AI service can't locate the UI element successfully, you're prompted to locate
the UI element manually. You can cancel the repair, and the desktop flow fails (or
activates the error handling mechanism of the failed action).



Repair manually
You can also repair the issue manually. Similar to the previous method, a notification
window appears at runtime, prompting you to capture the UI element using Power
Automate for Desktop's highlighter. To initiate this process, select the Repair button in
the notification window, which turns on the highlighter. Next, hover over the necessary
UI element on the screen and press "Ctrl" along with a left-click to capture it.



The manual repair experience is also triggered if Copilot can't locate the UI element or if
you select the Repair manually option from the notification window's drop-down menu.

Unattended experience step-by-step

７ Note



Repair with Copilot feature for unattended runs is only supported in managed
envrionments.

If you enabled repair at runtime for unattended runs in the Power Platform admin
center, you receive repair requests directly under Recommendations within the
Automation Center experience. The repair request will automatically time out after 10
minutes if no action is taken.



Once you select the Repair with Copilot button, a side panel opens with the repair
request details. This panel contains a list of desktop flow runs for which alternative UI
selectors were identified to recover failing unattended runs.



As soon as you select a row in the recommendation list view, you can choose one of the
following actions:

Repair with Copilot: Opens a panel showing the problematic control along with
the original and new selector identified by Copilot.
Ignore and continue: Ignores the repair request, likely causing the run to fail since
the selector wasn't changed.
Flow details: Navigates to the flow details page for which the request was created.
Run details: Navigates to the desktop flow run details page for which the request
was created.
Refresh: Refreshes the list of repair recommendations.

Repair with Copilot action



On the panel that opens once you select Repair with Copilot, you see 2 main areas and
an action list at the bottom. The upper part of the panel shows the problematic element
together with script, location, and selector details.



In the lower part of the panel, you see a Suggested fix area displaying a visual
representation of the element identified by Copilot along with the new selector. A red
bounding box labeled "Copilot found this element" highlights the exact position on the
screen or control.





On the bottom of the panel, you see a button menu labeled Apply once from which you
can choose:

Apply once: Temporarily applies the selected fix for the current run.

Ignore and continue: Ignores the repair request, likely causing the run to fail since
the selector wasn't changed.



If you choose Apply once, a confirmation message indicates whether the selector was
applied successfully. When you return to the previous screen, you notice that the system



replaced the Repair with Copilot button with View outcome, which shows an audit trail
of the action taken.



Known limitations
This feature is available only in attended and unattended executions through the
portal (cloud flow).
This feature is available only in desktop flows saved in Schema v2.
This feature is available only in the US region.
The feature doesn't handle UI elements in virtual desktops.
The feature doesn't support PictureInPicture executions.
The feature doesn't support child flow execution.
The feature doesn't support UI element collections.
The feature can't apply to selectors that contain one or more variables.
The unattended version of this feature doesn't yet support persisting a new
selector in the desktop flow script during runtime.
Drag-and-drop actions aren't supported at this phase.
The Apply for every run option uses the user identity logged into the Power
Automate for desktop console. If no user is signed into the console, the option
isn't available.

Help us improve this feature
To send feedback, select the thumbs up or thumbs down icon under the AI-generated
content. A feedback dialog appears, allowing you to submit feedback to Microsoft.



Learn more about how this data is used and your rights in Microsoft feedback for your
organization.

７ Note

If you can't see the feedback dialog, check if your tenant admin turned it off.

Turn off user feedback functionality
As a tenant admin, you can prevent users from sending feedback to Microsoft by
disabling the disableSurveyFeedback  tenant setting. Learn more about viewing and
setting tenant settings at Get-TenantSettings and Set-TenantSettings.

Data subject rights requests on user feedback
Tenant administrators can view, export, and delete feedback from users by signing in to
the Microsoft 365 admin center  and selecting Health > Product feedback.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Trigger desktop flows from cloud flows
Article • 02/21/2025

Prerequisites
A registered machine or machine group that will run the triggered desktop flows.
Machines are the physical or virtual devices you use to automate desktop
processes. Machine groups allow you to handle multiple machines as one entity
and distribute your automation workload.

A work or school account.

A configured desktop flow connection.

To run the triggered desktop flows, you need to have the appropriate license (for
attended runs) or an unattended add-on (for unattended runs). The user who
needs to have the appropriate license is the creator of the connection.

Trigger a desktop flow from a cloud flow
To trigger a desktop flow from a cloud flow:

1. Go to Power Automate  and sign in with your credentials.

2. Create a new cloud flow that you'll later use to trigger your desktop flow. This flow
can be an instant or an automated cloud flow.

3. The following example displays the creation of a manually triggered cloud flow.
This step may differ depending on the type of cloud flow you want to create.



4. In the cloud flow designer, select + New step.

5. In the Choose an action dialog, search for Power Automate for desktop. Under
Actions, select Run a flow built with Power Automate for desktop.



6. If you haven't already created a desktop flow connection, the action will prompt
you to create one. You can find more information regarding desktop flow
connections in Create desktop flow connections.



7. Set the desired run mode (attended or unattended) for your desktop flow and
select Create a new desktop flow in Desktop flow. If you want to trigger an
existing desktop flow, select its name instead.

8. Enter a name for the new desktop flow and select Launch app.



9. A message from the browser may appear, asking whether to allow the page to
open Power Automate. Select Open.

10. At this step, Power Automate should have created a new desktop flow and opened
it in the flow designer.



11. Desktop flows can contain input and output variables to pass data between
desktop and cloud flows.

Input variables enable you to pass data from cloud to desktop flow, while output
variables allow you to pass data from desktop to cloud flows. To see more
information about input and output variables, go to Input and output variables.

12. Back in the Power Automate portal, any input variables appear as fields in the Run
a flow built with Power Automate for desktop action.

７ Note

If an input variable contains sensitive data, you may want to obfuscate or
omit it from the logs. To find more information regarding sensitive text
inputs, go to Manage sensitive input like passwords.
The limit of the input size for a desktop flow is 2 MB (1 MB for China
regions).
The size limit for a cloud-triggered desktop flow and its dependencies is
16 MB.



Known limitations
We currently support up to 70 desktop flows runs per minute for every connection.
Cancelling a parent cloud flow doesn't stop its child desktop flows if the
Asynchronous Pattern is disabled under the 'Run a flow built with Power Automate
for desktop' action settings.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Run unattended desktop flows
Article • 02/10/2025

Triggering desktop flows from cloud flows enables you to run desktop flows in
unattended mode. Unattended desktop flows are ideal for automating tasks that don't
need human supervision.

 Tip

For unattended desktop automation, you need the Power Automate Process
plan. More information: Allocate and assign the Process license

Power Automate uses the selected desktop flow connection to automatically sign in to
your machine and run the unattended desktop flow. When the flow is complete, it signs
out from the device and reports its activity.

When running desktop flows in unattended mode, keep in mind that:

Power Automate creates a remote desktop (RDP) session on the machine to run
unattended desktop flows. Connecting to the machine's console session isn't
available for unattended runs.

Power Automate creates, manages, and then releases the Windows user session on
the target devices.

Unattended desktop flows keep the screen of the target machine locked so no one
can see them running.

Windows 10 and Windows 11 devices can't run unattended desktop flows if any
active Windows user sessions are present (even a locked one).

On Windows Server, if you have a locked Windows user session open with the
same user as the desktop flow connection, you receive an error.

The user specified in the connection must have permissions to create a remote
desktop session on the machine. In most cases this means the user must be a
member of the Remote Desktop Users group on the machine. On some Citrix
configurations, the user must be in the Direct Access Users group.

The default screen resolution of the remote desktop session might be different
than the one used during flow authoring. This might create different conditions,
such as smaller screen size, less visible elements in target app, and so on, for the



flows that run in unattended mode. This can result in errors if a target element isn't
found, or even in interacting with the wrong element if keyboard or mouse actions
are used. To prevent this behavior, set the proper screen resolution on unattended
mode.

） Important

Unattended desktop flows require an available machine with all users signed
out.
Locked Windows user sessions will prevent unattended desktop flows from
running.
Unattended desktop flows can't run with elevated privileges.
Logging into a machine during an unattended flow execution isn't supported
and might cause the flow to fail.

Reuse a Windows session in unattended mode
Desktop flows can run on a Windows session as long as it exists and is unlocked for
unattended runs.

Power Automate creates a new session for each unattended run on the machine using
the credentials provided in the connection. The flow runs on this session, and then
Power Automate signs it off.

The reuse Windows session functionality allows desktop flows to run on an existing
session. After a desktop flow run, the session gets locked, and Power Automate can
reuse it for another run.

To allow reusing Windows session:

1. Sign in to Power Automate.

2. Select Monitor, and then select Machines.

3. Select the target machine or machine group.

4. Select Settings in the Command bar.

5. Enable Reuse sessions for unattended runs.

７ Note



When you add machines to machine groups, they inherit the settings of the group.
When you remove machines from machine groups, they keep the settings defined
at the group level.

Admin consent for unattended runs using CBA
or sign-in credentials with NLA (preview)
[This topic is prerelease documentation and is subject to change.]

To perform unattended runs with Microsoft Entra ID using certificate-based
authentication (CBA) or sign-in credentials with Network Level Authentication (NLA),
follow these steps:

） Important

This is a preview feature.
Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.

Step 1 - Enable Microsoft Entra authentication for RDP
Enable Microsoft Entra authentication for RDP only for the AppID a4a365df-50f1-4397-
bc59-1a1564b8bb9c  (MSRDspId).

Step 2 - Hide the consent prompt dialog for a target
device group
Hide the consent prompt dialog only for the AppID a4a365df-50f1-4397-bc59-
1a1564b8bb9c  (MSRDspId).

The desktop flow fails with an MSEntraRemoteDesktopAppConsentRequired  error if consent
isn't granted.

７ Note

To authenticate with Microsoft Entra ID using a username and password with
Network Level Authentication, ensure the following prerequisites are met:



Install Power Automate Desktop version 2.50 or later on your machine.
Ensure required endpoints for Power Automate services are accessible,
specifically config.edge.skype.com .

Known issues and limitations
Reusing sessions isn’t supported on machines that allow users to have multiple
sessions (users aren’t restricted to a single session).
Audio peripherals (such as microphones and speakers), cameras, webcams, and
video capture peripherals aren't supported in unattended desktop flows.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Run desktop flows sequentially
Article • 04/09/2024

Power Automate enables you to schedule multiple desktop flows to run on one or more
devices. If you trigger more than one desktop flow on the same device:

1. The first desktop flow runs on the target machine based on priority and time
requested.

2. The other desktop flows are added to a queue and get marked as Queued.

3. When a desktop flow run completes, the next desktop flow starts running based
on priority and time requested. This desktop flow is marked as Next to run.

You can view the state of the queues in real time and manually change the order of the
desktop flows in them at runtime, either by changing the priority or moving them to the
top of the queue.

） Important

A time-out occurs when desktop flows don’t run within six hours after being
requested.
The presented orchestration rules apply to desktop flow runs scheduled by
any user on the same device.



Run desktop flows concurrently
Article • 10/09/2023

） Important

Gateways for desktop flows are now deprecated except for the China region. Switch
to our machine-management capabilities. Learn more about the switch from
gateways to direct connectivity.

Windows Server (2016, 2019, and 2022) allows multiple users to sign in simultaneously
on the same machine. Power Automate uses this OS capability to run multiple desktop
flows simultaneously, allowing organizations to reduce infrastructure costs.

７ Note

Running multiple concurrent desktop flows by the same user isn't supported. You
need to have different users running desktop flows simultaneously to benefit from
this feature.

Replicate the following steps to run multiple desktop flows concurrently on a single
machine:

1. Set up a Windows Server 2016, 2019, or 2022 device with the latest version of
Power Automate installed.

2. Use two or more user accounts to create desktop flow connections targeting this
device. To find more information about desktop flow connections, go to Create
desktop flow connections.

Power Automate automatically scales the number of concurrent desktop flow runs to
the supported maximum. The machine run queue follows a first-in, first-out approach,
which means the first run received is the next one executed. If all available machines
have reached their maximum concurrent sessions and can't execute the next run in the
queue, the queue is blocked until a machine becomes available to run the next run in
the queue. If the machine's capacity is exceeded, the remaining runs wait as described in
Run desktop flows sequentially.

） Important



If you want to use more than two parallel user sessions on Windows Server, you
must turn on Remote Desktop Services (RDS). To learn more about RDS, go to
License your RDS deployment with client access licenses.



Best practices
Article • 03/18/2025

This article presents the best practices for running Power Automate desktop flows and
distributing the workload.

Avoid time-outs and distribute load across
machines
Desktop flows queue for up to six hours until a machine is available. Adopt one of the
recommended strategies to distribute the workload and ensure that all desktop flows
run successfully without overloading the target machines.

Spread the load over time by planning your desktop flows to run at different times.
This practice works best if you have a limited set of machines and can control the
triggers that start your desktop flows.

Create machine groups that run desktop flows with identical configurations in
parallel. To find more information about machine groups, go to Manage machine
groups.

Anticipate the number of unattended desktop flows your organization plans to run
in parallel, and purchase an adequate number of Process licenses. Learn more in
Power Automate Process license.

All the presented strategies prevent desktop flows from competing to run on the same
device and failing due to time-outs.

７ Note

If a target device goes offline due to a restart or connectivity issues, desktop flows
wait up to six hours before failing. This wait time allows for transient machine states
and lets you run automation successfully even if the devices go through restart or
update cycles.

Support long-running desktop flows
Some desktop flows may run for long durations—for example, more than 24 hours. To
ensure that those flows run successfully and don't fail due to the default time-out



values, perform the following steps:

1. Select the ellipsis (…) on the top of the Run a flow built with Power Automate for
desktop cloud action, and then select Settings.

2. Select Timeout and update the duration to handle your desktop flow runs
appropriately.

3. Select Done.

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Run desktop flows via URL or desktop
shortcuts
Article • 03/15/2024

Power Automate, apart from triggering flows through the console, flow designer, and
cloud flows, enables you to run desktop flows using run URLs and desktop shortcuts.

You can use URLs to trigger desktop flows through many different sources, such as
browsers, the Windows Run application, the command prompt, and the Windows Task
Scheduler. Alternatively, you can create desktop shortcuts and run your desktop flows
directly through them.

If a triggered flow requires input variables, the console will ask you to enter the
appropriate values.

By default, Power Automate always prompts you to confirm the triggering of a desktop
flow via URL or desktop shortcut. To disable this functionality, navigate to the console
settings and disable Display confirmation dialog when invoking flows externally or
modify the appropriate Windows registry entry.

２ Warning

Disabling the confirmation dialog poses security threats because you could run
without notice a questionable flow shared by a malicious actor.



Prerequisites
Power Automate for desktop needs to be installed on the machine.
The user must be signed in.
The user needs a Power Automate Premium plan or access to a pay-as-you-go
environment.

Create a desktop shortcut
To create a shortcut for a desktop flow, right-click its name in the console and select
Create desktop shortcut. All shortcuts are automatically created in your desktop folder,
but you can move them to any folder of your machine.



Create a run URL
） Important

If a flow is already running, it won't run again when the URL is invoked.

To generate a URL that triggers a desktop flow, use one of the following formats:

"ms-powerautomate:/console/flow/run?workflowName=[workflowName]"

"ms-powerautomate:/console/flow/run?workflowId=[workflowId]"

"ms-powerautomate:/console/flow/run?environmentId=
[environmentId]&workflowId=[workflowId]"



"ms-powerautomate:/console/flow/run?environmentId=
[environmentId]&workflowName=[workflowIName]"

７ Note

You can find an automatically created run URL consisting of the environment and
flow IDs on the properties section of the desktop flow. You can find more
information about flow properties in Desktop flow properties.

The first two formats don't define a specific environment, so Power Automate
automatically uses the currently selected console environment. The command will be
neglected if either flow ID or flow name isn’t specified.

If the console is set to another environment than the one specified in the URL, the
console environment will automatically change.

Find environment and desktop flow IDs
To find the ID of an environment, navigate to the Power Automate portal  and select
the desired environment. Then, navigate to the My flows tab and copy the environment
ID from the address line.

To find the ID of a desktop flow, launch the Power Automate console, select or right-
click the appropriate flow, and select Properties.



Add optional parameters to a run URL
Apart from the mandatory input parameters, you can add optional parameters to a run
URL.

Add flow input variables to a run URL
Add the inputArguments  parameter to a run URL to configure the flow's inputs.

If the inputArguments  parameter contains all the input variables of the flow, then Power
Automate console doesn't ask for user input during the flow run.

A URL containing the inputArguments  parameter should have the following structure.
The parameter can be added to any of the previously mentioned URLs.

） Important

All special characters in the JSON string must be escaped. For example, all double
quotes must be backslash-escaped.

"ms-powerautomate:/console/flow/run?workflowId=[workflowId]&inputArguments=
{\"[External name 1]\": [Value 1],\"[External name 2]\": [Value 2]}"



For example, the below run URL invokes a desktop flow with text, numeric and boolean
inputs:

"ms-powerautomate:/console/flow/run?&workflowid=dfd0c814-2c30-4cd8-849d-
a4b2d2f4f33b&inputArguments={\"NewInput\": \"Hello\", \"NewInput2\": 123, 
\"NewInput3\": true}"

７ Note

Only Text, Numeric and Boolean data types are supported.
The Boolean values are case sensitive, and the value can be either true or
false.
If there are additional flow inputs that aren't included in the inputArguments
parameter, then during the flow run the Power Automate console asks for
user input.
The source that invokes the run URL may have a limit of maximum allowed
characters, which will cause the flow to fail if that limit is exceeded.

） Important

To trigger the run URL through a web browser, unescape the inputArguments
parameter's JSON string value and use URL encoding to convert the
characters into a valid ASCII format.
To unescape the double quote characters, remove the backslashes. For
example, inputArguments={"NewInput": "Hello", "NewInput2": 123,
"NewInput3": true}

Sign in silently with the current Windows account
Add the autologin  parameter to a run URL to sign in to Power Automate without any
user interaction, with the current Windows logged in user.

As prerequisites, the user must be signed out and Power Automate must not be running
on the machine.

） Important



If the user has explicitly signed out of Power Automate through the UI, then Power
Automate respects user’s preferences and does not perform auto-login.

A URL containing the autologin  parameter should have the following structure. The
parameter can be added to any of the previously mentioned URLs.

"ms-powerautomate:/console/flow/run?workflowId=[workflowId]&autologin=true"

Save logs for desktop flows run via URL
Add the runId  parameter to a run URL to define a unique GUID for the desktop flow
logs.

Power Automate uses this GUID to create a folder and store the logs inside it. The logs
are stored in: C:\Users\[Username]\AppData\Local\Microsoft\Power Automate
Desktop\Console\Scripts\[Flow ID]\Runs\[Run ID]

７ Note

A GUID is a 128-bit value consisting of one group of 8 hexadecimal digits, three
groups of 4 digits each, and one group of 12 digits, for example: e6f82a20-47f7-
4dd8-a97f-63df36797d0f.

A URL containing the runId  input parameter should have the following structure. The
parameter can be added to any of the previously mentioned URLs.

"ms-powerautomate:/console/flow/run?workflowId=[workflowId]&runId=[GUID]"

Use a run URL in the command prompt
To trigger a flow using the command prompt, use a command with the following syntax
(applies to MSI installations):

"C:\Program Files (x86)\Power Automate Desktop\PAD.Console.Host.exe" "ms-



powerautomate:/console/flow/run?workflowName=[workflowName]"

７ Note

You can replace the second part of the command with any of the previously
presented URL formats.

Trigger flows automatically with Task Scheduler
To trigger a flow using the Task Scheduler application of Windows:

1. Create a new task, navigate to the Actions tab of the Create Task dialog, and add a
new action.

2. Populate the following value in the Program/script field.

For MSI installations:

C:\Program Files (x86)\Power Automate Desktop\PAD.Console.Host.exe

For Microsoft Store installations:

C:\WINDOWS\system32\WindowsPowerShell\v1.0\powershell.exe

3. Populate the following value in the Add arguments field.

For MSI installations:

ms-powerautomate:/console/flow/run?workflowName=[workflowName]

For Microsoft Store installations:

-Command "Start-Process \"ms-powerautomate:/console/flow/run?
workflowName=[workflowName]""



７ Note

You can replace the given argument with any of the previously presented URL
formats.



Run desktop flows via keyboard
shortcuts 
Article • 04/20/2023

Power Automate enables you to control desktop flow runs using keyboard shortcuts.
You can press key or key combinations to trigger desktop flows and pause/resume or
stop the running flow. 

If a triggered flow requires input variables, the console will ask you to enter the
appropriate values. 

Prerequisites 
Power Automate for desktop needs to be installed on the machine. 

The user must be signed in. 

Set a keyboard shortcut 
To create a keyboard shortcut that triggers a desktop flow, right-click its name in the
console and select Properties. Then enter the key or key combination that will trigger
the flow. 

To create a keyboard shortcut that pauses/resumes or stops the running flow go
to Console Settings.



７ Note

A list of all keyboard shortcuts can be found at  %localappdata%\Microsoft\Power
Automate Desktop\Console\console.config  for each user that has signed into Power
Automate on the current machine and under the current user in the past.

Limitations
Supported keys and key combinations include either a single Functional key or a
combination of at least one modifier key along with any other key. 

Keyboard shortcuts are saved per user and per machine. Each user with access to a
desktop flow can set their own shortcuts for each machine. 



Runtime notifications
Article • 02/24/2023

７ Note

Runtime notifications are displayed when a flow is run directly from the console.
When a flow is run from the portal, Power Automate doesn't display notifications.

Power Automate provides two different types of notifications while running desktop
flows, depending on the user's preferences.

Through the Monitoring/Notifications option of the console settings, you can choose
between the integrated Windows notifications, the flow monitoring window, or disabling
the notifications.

The Windows notifications option displays a Windows notification pop-up when a
desktop flow is running, paused, stopped, finished running successfully, or encountered
an error. Additionally, the notification pop-up enables users to pause or stop the flow
through the respective buttons.

The Flow monitoring window option provides the same functionality as the Windows
notifications, while it offers some extra functionality.

Instead of displaying separate notifications for each desktop flow, the monitoring
window displays the state of all running flows in a single window. Further, it shows
which subflow and action are running at any given time for each desktop flow. If an
error occurs, you can copy the error details directly through the monitoring window for
easier debugging.

７ Note

When Power Automate pop-up dialogs appear, like input variable dialogs or
update notifications, users can't interact with the flow monitoring window until they



close the displayed dialog.



Run desktop flows in picture-in-picture
Article • 09/30/2024

Power Automate enables you to run attended desktop flows within a virtual window that
replicates your desktop, so that you can continue working on your machine while the
automation is running in parallel.

This attended run mode is called picture-in-picture and uses the Child Sessions
technology.

Here's a quick video tutorial about running desktop flows in picture-in-picture.
https://learn-video.azurefd.net/vod/player?id=0454b032-9e88-4bfd-a04e-
a8cd4ba2310e&locale=en-us&embedUrl=%2Fpower-automate%2Fdesktop-
flows%2Frun-desktop-flows-pip

Prerequisites
Power Automate for desktop needs to be installed on the machine.

The user must be signed in to use Power Automate.

The user needs a Power Automate Premium plan or access to a pay-as-you-go
environment.

The user running flows in picture-in-picture should be part of the following
Windows policies:

Computer Configuration\Windows Settings\Security Settings\Local

Policies\User Rights Assignment\Allow Log On Locally

Computer Configuration\Windows Settings\Security Settings\Local

Policies\User Rights Assignment\Access this computer from the network

A device that runs Windows 10 (Pro or Enterprise), Windows 11 (Pro or Enterprise),
Windows Server 2016, Windows Server 2019, or Windows Server 2022.

Enable picture-in-picture on the machine
To enable the picture-in-picture run mode on the machine, follow one of the methods
described here.

） Important



Administrator rights on the local machine are required for all methods. For
Microsoft Store installations, only the manual method is available.

ﾉ Expand table

Method Description

Manually Run a desktop flow in picture-in-picture mode on the machine. You're asked to
enable the feature.

MSI Install Power Automate with the MSI installer and select the Enable picture-in-
installer picture mode option during the installation process.

Silent Install Power Automate with silent installation. During silent installation, picture-in-
installation picture is enabled by default on the machine. To skip the enablement, add the -

SKIPENABLEPIPMODE argument. More information: Command line arguments

Command Update an existing installation and enable or disable the picture-in-picture run
mode on the machine with a command. Open the Start menu, search for Command
Prompt, right-click it, and then select Run as administrator. Go to the installation
directory of Power Automate, by default cd C:\Program Files (x86)\Power Automate
Desktop  and run the command PAD.ChildSession.Installer.Host.exe  to enable
picture-in-picture or PAD.ChildSession.Installer.Host.exe -d  to disable it.

Trigger a desktop flow from Power Automate
console in picture-in-picture
You can trigger a desktop flow in picture-in-picture mode through the Power Automate
console.

Select the target flow, open the More actions menu, and then select Run in picture-in-
picture.



Alternatively, enable the Run in picture-in-picture flow property so that the flow always
runs in picture-in-picture mode when triggered locally.



When you authenticate on the picture-in-picture session, the flow starts running within
the picture-in-picture window.

Enable options View only to block user input, and Always on top to always keep the
window on the foreground.

 Tip



When running multiple flows in picture-in-picture mode one after the other, it's
recommended to keep the picture-in-picture window open. This ensures faster flow
execution, as user authentication and session loading will only happen once.

Trigger a desktop flow from a cloud flow in
picture-in-picture
You can trigger a desktop flow in picture-in-picture mode from a cloud flow.

Triggering desktop flows from cloud flows enables you to run desktop flows in attended
or unattended mode.

） Important

Running flows in picture-in-picture is available only for attended runs.

To trigger a desktop flow in Picture-in-Picture, open the action configuration pane of the
Run a flow built with Power Automate for desktop cloud action. Set the Run Mode
field to Attended, and in the Advanced parameters section, set the Attended Mode field
to Picture-in-picture.

When you trigger the desktop flow, the Picture-in-picture window appears, prompting
you for authentication. Once authenticated, the flow starts running, similar to when you
trigger a desktop flow from Power Automate console in picture-in-picture.

Debug a desktop flow in picture-in-picture



You can debug a desktop flow in a picture-in-picture session directly through the Power
Automate flow designer.

To enable the picture-in-picture run mode in the designer, select Debug > Enable
picture-in-picture mode.

Limitations of Browser automation in picture-
in-picture
Two instances of a web browser (Chrome, Firefox, or Microsoft Edge) can't open
concurrently with the same user data folder in both main and picture-in-picture
sessions.

If a web browser is already open on the desktop with a user data folder, then it opens in
picture-in-picture with another user data folder, and vice versa.

This limitation is handled automatically with the User data folder parameter in the
launch browser actions in the Power Automate designer. For more information, see
Launch new Microsoft Edge.

The User data folder parameter has the following options:

Picture-in-picture default (default option)
Browser default
Custom



When set to Picture-in-picture default, Power Automate creates a new user data folder
for the browser to use when the flow runs in picture-in-picture mode.

） Important

For browser automation to work successfully, use a launch browser action to
open your web browser within the picture-in-picture window and enable the
Power Automate browser extension on the Picture-in-picture user data
folder.
Use the troubleshooter in Power Automate for desktop to diagnose issues
related to picture-in-picture.

If set to Browser default, the browser within the picture-in-picture session uses the
default user data folder, which is the same as the one used when the flow runs in the
main session.

） Important

When User data folder is set to Browser default, the web browser can only
open in one session at a time.

When set to Custom, you can enter a custom user data folder to be used by the browser
in picture-in-picture flow runs.

Known issues and limitations
If you're using a PIN to sign in to Windows, PIN authentication only works the first
time the picture-in-picture session is opened. After that, it can only be
authenticated with username and password.
Applications that start on Windows startup are automatically opened within the
picture-in-picture session as well. This might cause a conflict between the two
sessions, as two instances of an application are running concurrently. To avoid this
issue, don't set the applications to start automatically on Windows startup. To
resolve this issue, it might be required to sign out and sign in again or restart the
machine.
Windows Home editions aren't supported.
The machine can't be restarted or shut down while the picture-in-picture session is
open.



The clipboard is shared between the picture-in-picture session and the main
session.
With Windows Server, if multiple users are connected concurrently to the server,
only one picture-in-picture session can be opened at a time.
The default timeout to start a process in a picture-in-picture is 120 seconds. If the
sign in takes longer than that, a timeout error is thrown.
Picture-in-picture asks for credentials every time it starts in case the following
Windows policy is set to Disabled:

Local Group Policy\Computer Configuration\Administrative

Templates\System\Credential Delegation\Allow delegating default credentials

If smartcard is used to sign in to Windows, the following policy should be set to
Not Configured or Disabled:

Computer Configuration\Administrative Templates\Windows Components\Remote

Desktop Services\Remote Desktop Session Host\Device and Resource

Redirection\Do not allow smart card device redirection

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Manage machines
Article • 01/14/2025

Machines are the physical or virtual devices you use to automate desktop processes.
When you connect your machine to Power Automate, you can instantly start your
desktop automation using any of the available triggers, such as predefined schedules.

Connecting your machine directly to Power Automate and the cloud allows you to
harness the full power of robotic process automation (RPA).

Our direct connectivity is the easiest way to connect your machine to the cloud. Sign in
to the latest version of Power Automate for desktop, and your machine will be
registered automatically. Once registered, you can immediately create a connection in
your cloud flows.

） Important

Direct connectivity is only available for Power Automate 2.8.73.21119 or later.
If you currently use an earlier version, update to the latest .
Direct connectivity isn't available for machines running Windows 10 Home or
Windows 11 Home.
To register your machine and use the machine management features, your
Power Platform environment must have a version of the
MicrosoftFlowExtensionsCore solution that is greater than or equal to 1.2.4.1.
Before registering a machine to run desktop flows from cloud flows, ensure
the machine is secured and the machine's admins are trusted.

Register a new machine
Your machine is automatically registered on the currently selected environment in Power
Automate for desktop. If you don't have permission to register machines in that
environment or want to use another environment, update the environment manually.

1. Install the latest version of Power Automate on your device. If you already have the
latest version, skip this step. During installation, make sure you've checked the
Install the machine-runtime app to connect to the Power Automate cloud portal
option.



2. Launch Power Automate machine runtime.



3. Sign in to Power Automate machine runtime. Your machine should be
automatically registered in the currently selected environment.

4. If the machine hasn't been registered yet, a message will prompt you to select a
machine-running environment. Power Automate will use this environment to run
all the triggered desktop flows.



5. When the connection is established successfully, the machine settings will display
the following fields regarding the machine:

Machine name: A unique name to identify the machine.
Machine description: An optional description of the machine.
Machine environment: The running environment of the machine.

７ Note



To successfully register a machine, ensure the services specified in Desktop
flow services required for runtime are accessible.
You need an Environment Maker or Desktop Flow Machine Owner role to
register machines. Before registering a machine, ensure you have the required
permissions and an available environment to register the new machine.
In the case of a virtual machine, don't clone the virtual machine after installing
Power Automate machine runtime.
Machines aren't affected by changes in the Power Automate for desktop
organization.
Although you can create and debug desktop flows in Teams environments,
you can't register machines in them.
If you reset your PC, your machine registration will be lost.

Update running environment for your machine
Each machine can only run desktop flows from the cloud in one environment at a time.
To update the running environment in which a machine can run desktop flows:

1. Launch Power Automate machine runtime and select Machine settings.

2. Under Machine environment, select an environment in the dropdown list.

７ Note

Changing the running environment of a machine removes all its current
connections.

Trigger a desktop flow to run on your machine
Power Automate enables you to trigger desktop flows from cloud flows using events,
schedules, and buttons.

1. Edit an existing cloud flow or create a new cloud flow.

2. Create a desktop flow connection using the instructions in Create desktop flow
connections.

3. Follow the instructions in Trigger desktop flows from cloud flows to trigger a
desktop flow from your cloud flow.



） Important

To apply this functionality, you need a premium per-user plan with attended
RPA .
When you create a desktop flow connection, you allow Power Automate to
create a Windows session on your machine to run your desktop flows. Make
sure you trust co-owners of your flows before using your connection in a flow.
If you consistently encounter issues when creating a connection on a new
machine, first try to remove it, and then register it again.

Enable your machine for unattended mode
To trigger desktop flows in unattended mode on your machine, you need some
unattended bots on the machine. Each unattended bot on a machine can carry one
unattended desktop flow run at a time. So if a machine needs to execute multiple
unattended runs simultaneously, it needs as many unattended bots as it has
simultaneous unattended runs to perform.

To create unattended bots, allocate process capacity or unattended RPA capacity to your
machine. Learn how to allocate process capacity as an unattended bot on a machine.

Maintenance mode for machines
The maintenance mode enables you to stop all the desktop flow runs on machines or
machine groups. This feature is useful when you need to do installations or deployments
on machines and avoid run failures.

To use the maintenance mode:

1. Sign in to the Power Automate portal .

2. Go to Monitor > Machines.

3. Select a machine, go to its details page, and select Settings.

4. Turn on the toggle for Enable maintenance mode.

5. Select Activate in the dialog.

All the machines that are in maintenance mode are indicated with a red pictogram in
the list of machines.



７ Note

If a machine group is in maintenance mode, all the machines of the group are
in maintenance mode and you can't change them individually.
When machines require some specific actions (such as key rotation),
maintenance mode is disabled.
If a desktop flow is currently running on your machine when the maintenance
mode is enabled, the run doesn't get canceled.
When a machine is in maintenance mode, no new run is assigned to it. If the
machine is standalone, the desktop flow run is put in the run queue. If the
machine is part of a machine group, the desktop flow is assigned to an active
machine. Timeout remains the same by default.

View list of machines
Once you've registered a machine to an environment, you can view its details at any
time in the Power Automate portal. You can also view all other machines that you have
access to.

1. Sign in to the Power Automate portal .

2. Go to Monitor > Machines.

3. Select the desired machine. For each machine you can view:

Machine name.
Machine description.
Machine version.
Group that the machine is a part of, if applicable.
Machine status.
Number of flows running on the machine.
Number of flows queued on the machine, if applicable.
Type of access you have to the machine.



Machine owner.

７ Note

The version of the machine gets updated with the first registration and after each
desktop flow run.

Share a machine
You can share a machine with other users in your organization and give those users
specific permissions to access it.

1. Sign in to the Power Automate portal .

2. Go to Monitor > Machines.

3. Select your machine from the list, and then select Manage access.

4. Select Add people, and enter the name of the person in your organization with
whom you’d like to share the machine.

5. Select the name of the person to choose which permissions they can access the
machine with.

There are two levels of permissions that you can assign when managing access to
your machine:

Co-owner. This access level gives full permissions to that machine. Co-owners
can run desktop flows on the machine, share it with others, edit its details,
and delete it.

User. This access level only gives permission to run desktop flows on the
machine. No edit, share, or delete permissions are possible with this access.

ﾉ Expand table

Actions Co-owner User

Run a desktop flow on the machine X X

Share the machine X

Add machine to group X

Edit details X



Actions Co-owner User

Delete machine X

6. Select Save.

７ Note

When a user isn't part of an environment anymore, you'll continue seeing the user
as deactivated. You'll be notified in the Manage access section of the machine if it's
shared with deactivated users. In this situation, remove access to them.

Receive user session related recommendations
(preview)
） Important

This is a preview feature.
Preview features aren’t meant for production use and might have restricted
functionality. These features are subject to supplemental terms of use , and
are available before an official release so that customers can get early access
and provide feedback.



The Receive user session related recommendations (preview) setting sends
orchestration-based notifications when an unattended desktop flow run is queued but
can't start due to a locked or disconnected user session of the same user on the
machine. When turned on, users receive an Automation Center recommendation titled
"Desktop flows not running" that details all affected desktop flow runs, allowing you to
take corrective actions within a 10-minute timeout window.



Supported actions

ﾉ Expand table

Action Details

Disconnect Disconnect the users of the selected active runs.
users

Flow details Opens the flow details page of the desktop flow listed on the the selected run.

Run details Opens the desktop flow run details page of the desktop flow listed on the
selected run.

Refresh Refreshes the active run list.

Who receives user-session based recommendations
To receive user orchestration recommendations in the Automation Center, you must
own the desktop flow connection that created and assigned the desktop flow
connection within a cloud flow.

Delete a machine
Although you can't delete a machine from the Power Automate machine runtime, you
can do it from the Power Automate portal:

1. Sign in to the Power Automate portal .



2. Go to Monitor > Machines.

3. From the list, select the machine you want to delete.

4. Select Delete machine in the command bar.

Switch from gateways to direct connectivity
） Important

Gateways for desktop flows are no longer supported. Switch to our machine-
management capabilities.

７ Note

To determine which desktop flow connections that are still using a gateway:

1. Sign in to Power Automate .
2. Go to Data > Gateways.
3. Select a gateway, go to its details page, and then select the Connections tab.

Any desktop flow connections listed should be switched to direct connectivity.
4. Repeat step 3 for each gateway in the list.

You can easily switch to direct connectivity by changing the desktop flow connection
and using one with the directly to machine option.

You can edit the connection or create a new one for each desktop flow action in your
cloud flow:

1. If you haven't done it yet, update Power Automate for desktop to version
2.8.73.21119 or later.

2. If you’ve already created a desktop flow connection, select the three dots on the
top right of the action, and select +Add new connection under My connections.

3. In the Connect field, select Directly to machine.

4. Select the name of your machine.

5. Enter the credentials you would use to sign in to your machine.

6. Select Create.



You can also change the connections used by a cloud flow in its details page when you
select Run.

Update permissions based on security role
By default, all users with an Environment Maker role can register their machines in an
environment. You can restrict actions on machines and machine groups by modifying
the Flow Machine and Flow Machine Group permissions for a particular security role.

Environment admins can also restrict machine registration to a specific set of users using
the three security roles that come with machine management.

ﾉ Expand table

Actions Desktop Flows Desktop Flows Desktop Flows Machine
Machine Owner Machine User User Can Share

Register a X
machine

Run a desktop X X X
flow

Share a machine X X

Share a machine X X
group



Actions Desktop Flows Desktop Flows Desktop Flows Machine
Machine Owner Machine User User Can Share

Add machine to X
group

Edit machine X
details

Edit machine X
group details

Delete machine X

Delete machine X
group

Machine and machine group limitations
ﾉ Expand table

Name Limit

Maximum number of machines in a group 50

Maximum amount of time a desktop flow can run 24 hours

Maximum amount of time a desktop flow can be queued Six hours

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Silent registration for machines
Article • 10/30/2023

This article describes how to use our mass deployment tool that allows you to easily
install Power Automate on multiple machines. You can both register your machines to
Power Automate and add them to machine groups.

Prerequisites
To silently register your machines, you need to download and install Power Automate
for desktop on the targeted devices. Visit this page to understand how to install Power
Automate silently.

To silently register your machine and join a group, we recommend that you use a service
principal account. You can also use your Microsoft Entra account.

Using a service principal account
７ Note

To create the application user, you need to have admin rights on the Dataverse
environment of your tenant.

1. Create an Azure app:

a. Go to the Azure portal: https://portal.azure.com/

b. Search App registrations.



c. Select New registration.

d. Define a name and select Single tenant (or multitenant) and then select
Register.

2. Give your app the following permissions:

Select Add a permission.
Select Flow Service.
Select Flow.Read.All.

3. Create an application user.

７ Note

Administrators must set users at least as Environment Makers (or Desktop
Flows Machine Owners) to allow them to register machines and join groups.

4. Get the following information that will be used in the Machine Registration app:

Application ID
Directory (tenant) ID
Client credentials (certificate or thumbprint)

Use the machine registration app
1. Open the Start menu.

2. Search for "command prompt" (or "PowerShell"), and then run it.



3. Change the directory to the Power Automate installation folder (by default:
C:\Program Files (x86)\Power Automate Desktop).

CMD

cd C:\Program Files (x86)\Power Automate Desktop

4. You can use the help menu to have an overview of what you can do with the silent
app.

CMD

.\PAD.MachineRegistration.Silent.exe -help

Silently register a new machine
To silently register your machine in Power Automate with the service principal account,
use the register operation -register with the following arguments:

Connection arguments (for service principal account):

1. Applicationid : The application to use.

2. Clientsecret : The secret of the applicationid  (you can also use the
certificateThumbprint). You shouldn't use this input as an input to the command
line. See the “Secure input” section to see options you can choose to provide it.

3. Tenantid : The tenant identifier to use.

Machine registration arguments:

1. Environmentid  (optional): The environment where the machine will be registered. If
not provided, the machine is registered in the default environment. You can
retrieve it in the URL of Power Automate.

2. Machine name (optional): The name of the registered machine.



3. Machine description (optional): The description of the registered machine.

4. force  (optional): The force flag used to override an existing registration.
Overriding a registration will break existing connections to the machine.

７ Note

"force" argument can be really useful in case your existing machine is in a bad
state with no other available environment to unregister/re-register your
machine.

CMD

.\PAD.MachineRegistration.Silent.exe -register -applicationid appid -
clientsecret (or -certificatethumbprint thumbprint) -tenantid tenantid 
-environmentid envid 

７ Note

If you decide to use an Microsoft Entra account, you can specify the username: -
username [UPN] instead of service principal account arguments

Silently join a machine group
７ Note

You can't create a machine group silently. You'll need to create it from the portal
(and share it with your application user if you're using a service principal) before
adding machines silently.

To join a group silently with the service principal account, use the join group operation -
joinmachinegroup  with the following arguments:

1. Environmentid : The environment where the machine group is registered. You can
retrieve it in the URL of Power Automate.

2. Groupid : The ID of the machine group you want to join. You can retrieve it in the
URL of Power Automate when you are in the machine group details page.

3. Grouppassword : The password of your machine. If this machine is the first machine
of the group, you need to define it. If not, you need to provide the defined



password of the group. You shouldn't use this input as an input to the command
line. Go to the “Secure input” section to see options you can choose to provide it.

CMD

.\PAD.MachineRegistration.Silent.exe -joinmachinegroup -groupid groupid -
grouppassword -applicationid appid -clientsecret (or -certificatethumbprint 
thumbprint) -tenantid tenantid -environmentid envid

７ Note

To use an Microsoft Entra account, specify the username: -username [UPN] instead
of service principal account arguments.

Secure input
In the machine registration tool, you'll have to provide secure inputs for registration and
joining the group.

You have two options to provide a secure input:

1. Type when asked: You'll be prompted to enter this data when needed. This option
is an interactive action that isn't adapted if you need to do mass deployment.

2. Redirect string/file to the silent registration application:

Redirect string (if you need to input multiple strings, you can do it easily in
PowerShell):

PowerShell



    echo clientsecret mypassword | 
.\PAD.MachineRegistration.Silent.exe -joinmachinegroup -
applicationid appid -clientsecret -groupid groupid -grouppassword 
-tenantid tenantid

Redirect file:

a. Create a TXT file that contains your password and save it in a Power
Automate folder (you'll need admin privileges).

b. Use the following command:

For cmd prompt:

CMD

 grouppassword < pwd.txt

For PowerShell:

CMD

Get-Content password.txt | .\PAD.MachineRegistration.Silent.exe 
-joinmachinegroup -groupid groupid -grouppassword



Manage machine groups
Article • 02/27/2024

Machine groups allow you to group multiple machines together to help distribute your
automation workload and optimize productivity.

You can assign desktop flows to a machine group, and they'll be automatically queued
to it when triggered to run. Then, when a machine in the group is available, Power
Automate will assign the next available desktop flow to it. To find more information
about queues, go to Monitor desktop flow queues.

Create a machine group
You can create machine groups through the Power Automate machine runtime
application or the Power Automate portal.

７ Note

To launch Power Automate machine runtime, launch Power Automate for desktop
and go to Settings > Open machine settings.

From the Power Automate machine runtime application:

1. Sign in to the Power Automate machine runtime application.

2. Select Machine group and then select New machine group.

3. Enter a name for your machine group, and optionally add a description.

4. Select Create.



From the Power Automate portal:

1. Sign in to the Power Automate portal .

2. Go to Monitor > Machines.

3. Select New machine and then select Group.

4. Enter a name for your machine group, and optionally add a description.

5. Select Create.

Add your machine to a group
You need at least one machine in a group to run desktop flows. To add a machine to a
machine group:

1. Launch Power Automate machine runtime and select Machine group.

2. In the displayed list, you can find all the available machine groups. Select the
desired group and fill in the required credentials.



3. If it's the first time adding a machine to this group, you need to create a password
for your group. This password limits access for users who can add machines to the
group. Make sure you keep the password, as you'll be unable to recover it. If
you've added a machine before, enter the password for the group.

4. Select Add machine.

When you add your machine to a machine group, any connections currently targeting
your machine will break. Update these connections to target the machine group.

７ Note

To register a machine, you need to have an Organization premium account.
In the case of a virtual machine, don't clone the virtual machine after installing
the Power Automate machine runtime application.
Machines aren't affected by changes in the Power Automate for desktop
organization.

Trigger a desktop flow to run on your machine
group
Power Automate enables you to trigger desktop flows from cloud flows using events,
schedules, and buttons.



1. Edit an existing cloud flow or create a new cloud flow.

2. Create a desktop flow connection using the instructions in Create desktop flow
connections.

3. Follow the instructions in Trigger desktop flows from cloud flows to trigger a
desktop flow from your cloud flow.

） Important

If you use local Windows accounts, all machines in the group must have the
same local account with the same password. Use these credentials when you
create the desktop flows connection.
If you use Active Directory or Microsoft Entra joined machines, confirm that
the user account in the desktop flow connection can access all the machines
in the cluster.

Maintenance mode for machine groups
The maintenance mode allows you to stop all the desktop flow runs on machines or
machine groups. This feature can be useful when you need to do installations or
deployments on machines and avoid run failures.

To use the maintenance mode:

1. Sign in to the Power Automate portal .

2. Go to Monitor > Machines.

3. Select a machine group, go to its details page, and select Settings.

4. Turn on the toggle for Enable maintenance mode.

5. Select Activate in the dialog box.

７ Note

If a machine group is in maintenance mode, all the machines of the group are
in maintenance mode and you can't change them individually.
If a desktop flow is currently running on your machine when the maintenance
mode is enabled, the run doesn't get canceled.



When a machine group is in maintenance mode, the desktop flow run is put
in the run queue. Timeout remains the same by default.
When a machine group is back to active mode, all the machines of the group
are activated again (except if there is an action required on the machine).

View list of machine groups
Once you've created a machine group in an environment, you can view its details at any
time in the Power Automate portal. You can also view all other machines groups that
you have access to.

1. Sign in to the Power Automate portal .

2. Go to Monitor > Machines.

3. Select Machine groups.

4. Select the desired machine group. For each machine group you can view:

The name of the machine group.
The description of the machine group.
The number of the machines in the group.
The number of flows running in the machine group.
The number of flows queued in the machine group.
The type of access you have to the machine group.
The owner of the machine group.

Share a machine group
You can share a machine group with other users in your organization and give those
users specific permissions to access it.

1. Sign in to the Power Automate portal .

2. Go to Monitor > Machines.

3. Select Machine groups and then select the desired machine group from the list.

4. Select Manage access.

5. Select Add people and enter the name of the person in your organization with
whom you’d like to share the machine group.



6. Select the name of the person to choose which permissions they can access the
machine group with.

There are two levels of permissions that you can use when managing access to
your machine groups:

Co-owner. This access level gives full permissions to the machine group. Co-
owners can run desktop flows on the machine group, share it with others,
edit its details, and add or delete machines.

User. This access level only gives permission to run desktop flows on the
machine group. No edit, share, or delete permissions are possible with this
access.

ﾉ Expand table

Actions Co-owner User

Run a desktop flow on the group X X

Share the machine group X

Add machines to group X

Remove machines from group X

Edit details X

Delete machine group X

7. Select Save.



７ Note

When a user isn't part of an environment anymore, you can continue to see the
user as deactivated. You'll be notified in the Manage access section of the machine
group if it's shared with deactivated users. In this situation, remove access to them.

Access for machine groups is managed at the group level. All machines in the group will
use the same permissions and connections.

If the permissions of a machine and its group fall out of sync, certain actions for that
machine might no longer be available, and your machine and machine group might not
behave as expected. For example, this issue might appear if you modify the permissions
of the group directly in Microsoft Dataverse. Ensure the permissions between the
machine and machine group are consistent to avoid any such issues.

Change the machine group of a machine
To change the machine group that contains your machine, select another group in the
list of the available machine groups and fill in the required credentials. If you want to
remove the machine from a group without adding it to a new one, select Remove from
group.

Change machine group's password



To change the password of the currently used machine group:

1. Select the dots on the machine group card and then select Edit group password.

2. Select Re-generate password, copy the automatically generated password, and
save the changes.

Update permissions based on security role
By default, all users with an Environment Maker role can register their machines in an
environment. You can restrict actions on machines and machine groups by modifying
the Flow Machine and Flow Machine Group permissions for a particular security role.



Environment admins can also restrict machine registration to a specific set of users using
the three security roles that come with machine management.

ﾉ Expand table

Actions Desktop Flows Desktop Flows Desktop Flows Machine
Machine Owner Machine User User Can Share

Register a X
machine

Run a desktop X X X
flow

Share a machine X X

Share a machine X X
group

Add machine to X
group

Edit machine X
details

Edit machine X
group details

Delete machine X



Actions Desktop Flows Desktop Flows Desktop Flows Machine
Machine Owner Machine User User Can Share

Delete machine X
group

Machine and machine group limitations
ﾉ Expand table

Name Limit

Maximum number of machines in a group 50

Maximum amount of time a desktop flow can run 24 hours

Maximum amount of time a desktop flow can be queued Six hours

Other known limitations
Machine groups aren't available in the Government Community Cloud (GCC),
Government Community Cloud - High (GCC High), Department of Defense (DoD),
or China regions. You can still run desktop flows using machine-management
capabilities. Learn more about switching from gateways to direct connectivity.
When you trigger multiple desktop flows in parallel on a machine group, machine
selection might take up to 50 seconds before assigning the desktop flow to an
available machine. In these rare cases, desktop flow runs might seem to be running
sequentially, if they have short run durations.



Machine group certificate renewal
Article • 02/24/2023

７ Note

This feature is currently under rollout until March 31, 2023.

Machine group certificates secure credentials in desktop flow connections and identify
machines with Power Automate. Security best practices require certificates to be
renewed regularly. Power Automate automatically performs this renewal that doesn’t
affect your runs.

While using Power Automate, you may notice a key icon next to your machine in the
Power Automate portal, and the following message: Machine group security has been
updated. Re-generate a machine group password before adding a new machine.

These messages indicate that if you need to add another machine to the group, you
must sign in to one of its existing machines and regenerate the password. These
messages appear after a certificate renewal has started on that machine group.

Prerequisites
Machines with Power Automate for desktop version 2.23 or above.
Machines need to be online at least once in the last six months before the
certificate expires (once every five years). The mentioned values are the default, but
can be changed.

Recommendation
During the renewal period of a machine group, use Desktop flow connections
targeting this group once. This step will prevent the need to fix your Desktop flow
connections when the renewal period has ended. For more information about
desktop flow connections, go to Create desktop flow connections
.

） Important

The certificate renewal duration is long enough for machines and Desktop flow
connections to be updated without needing specific user action.



Information for admins
To find information for admins about machine group certificate renewal, go to Machine
group certificate renewal for admins.

Corner cases
Case: I can't add my machine to an empty machine group. The Power Automate
machine runtime app says the password is incorrect.

Description: Machine groups need at least one machine connected to have their
certificates renewed. If a machine group is empty or inactive during the renewal, its
certificate will expire. You can't use these machine groups and you should delete
them.

Case: Following a certificate renewal, my machines on Power Automate for desktop
version 2.21 or earlier can't be connected anymore.

Description: These versions are outdated and can't renew their certificate. You
must update Power Automate for desktop and rejoin them to their group.



Introduction to the Power Automate
hosted RPA
Article • 05/01/2024

Microsoft Power Automate supports two hosted robotic process automation (RPA)
scenarios that provide developers and Center of Excellence admins a simple way to set
up and scale automations:

1. Hosted machines enabling developers to build or test automation and business
users to run automation.

2. Hosted machine groups can automatically scale workloads to optimize
unattended automation in production, delivering improved business process
continuity and governance at scale.

Using Microsoft hosted infrastructure running in Azure, Power Automate hosted RPA
empowers you to run RPA quickly and at scale while freeing up resources and reducing
costs.

Setting up RPA infrastructure manually is time consuming. It can take days to get
machines for automation—from the initial machine request and creation to installation
and assignment. Power Automate delivers a consistent setup experience and license for
both individual hosted machines and hosted machine groups, making it faster and
easier to set up and manage RPA for your organization. Instead of doing all the heavy
lifting yourself, anyone with just a few basic parameters can build, test, and run a large-
scale automation in minutes. Just give it a name, select the base image and account to
be used, and you’re all set!



If you need more advanced automation for specific desktop applications, you can bring
your own virtual machine (VM) image through our integration with Azure Compute
Gallery. For common scenarios, a Windows image sufficient for web automation is
provided by default.

Hosted machines for attended and unattended
automation
Hosted machines give developers a quick and simple way to build, test, and run desktop
flows without providing or setting up any physical machines.

When testing is complete, the desktop flow can be deployed on a single machine to
support individual business users running in both attended and unattended mode. For
unattended scenarios that are more robust, you start by building the desktop flow on a
hosted machine. Then, it can be assigned to a machine group that distributes and scales
the automation workload based on demand.

Hosted machine groups for unattended
automation at scale

Automatically react to spikes in demand with scalable
infrastructure
Planning for variability in RPA utilization is challenging and time-consuming, making it
difficult to guarantee response times when speed is necessary. When additional capacity
is needed, critical processes are slowed or put on hold waiting for support teams to set
up and allocate more machines. In some cases, large pools of machines are allocated to
support peak-load processes, resulting in low average machine utilization and higher
costs.

Hosted machine groups solve this problem by automatically provisioning hosted bots
when needed. Bots are virtual machines running in Azure that run your automation
flows unattended and can scale to run simultaneously on multiple Windows VMs. When
a desktop flow waits in the queue and no bot is available, a new bot is created
automatically up to the maximum number of bots determined by the admin. There's no
need to set up or register those machines and they can be easily reassigned to different
workloads whenever you need them.



You don’t have to worry about whether you have enough machines to run your
automations when demand spikes, or whether you underutilized machines adding cost
without delivering value to your organization.

Improve efficiency with dynamic load balancing
Hosted machine groups let you share resources among different automation scenarios.
Multiple RPA processes with varying load levels are automatically scaled in and out
based on real-time load. The number of bots allocated to the group are automatically
assigned across different RPA processes, ensuring available machines are efficiently
utilized.

For example, you can have 10 bot capacity shared between two groups—let’s say one
for sales and one for finance. If finance requires additional processing capacity while
sales workloads are light, the majority of the 10 bot capacity will be assigned to finance.
When finance’s processing is complete or returns to normal levels, the bot machines
assigned to finance are available again for sales or other hosted machine groups to run
their workloads.

Get started with hosted machines and groups
Learn more about Hosted machines and Hosted machine groups and see pricing for
hosted process licenses .

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Hosted machines
Article • 03/10/2025

Hosted machines allow you to build, test, and run attended and unattended desktop
flows without providing or setting up any physical machines.

You can create hosted machines directly through the Power Automate portal. Power
Automate automatically provisions a Windows machine based on your configuration
and registers it to your environment. Access your hosted machines in the Power
Automate portal and start building your desktop flows within minutes. Hosted machines
use Windows 365  for provisioning and access.

Here are some of the highlights of what you can do with hosted machines:

Build and test desktop flows using Power Automate for desktop.
Run attended and unattended desktop flows.
To distribute your automation workload, assign your hosted machines to machine
groups.

Key capabilities:

Work or school account integration: Enables access to resources that are part of
the business plan linked to your organization, such as Office, SharePoint, and
Azure.

Vanilla or custom VM images for your hosted machine: Use a vanilla virtual
machine (VM) image provided by Microsoft or personalize your hosted machines
by providing your own Windows image directly from your Azure Compute Gallery.
Providing your own Windows image allows you to have all your applications
installed on the provisioned hosted machines.

Connect to your own virtual network: Securely communicate with each other, the
Internet, and your on-premises networks.

７ Note
Sign-in access is only available to the creator of the hosted machine.
You can run unattended desktop flows using a work or school account that
is different from the creator of the hosted machine, provided that you add
the account on the hosted machine.



Licensing requirements
To use hosted machines, you need the Power Automate Hosted Process license
(previously Power Automate hosted RPA add-on). Assign to your environment as much
capacity as the number of hosted machines you want to run in your environment.

You also need the following prerequisite licenses: Windows, Intune, Microsoft Entra ID.

７ Note

The Hosted Process licenses the machines and not the user. The Premium user plan
is required to run attended RPA, and for RPA developers to build and manage
desktop flows on the Power Automate portal. To learn more about the Premium
RPA features that come with the Premium user plan, go to Premium RPA features.

Trial licenses for evaluation
To evaluate hosted machines, you need one of the following trial licensing options:

Use the Power Automate Hosted Process license

The Power Automate Hosted Process license has trial versions that last 30 days and
can be extended once to a total of 60 days. Organization admins can obtain up to
25 seats from Microsoft 365 admin center  and assign Power Automate Hosted
Process capacity to the targeted environment.

Use the 90-days self-assisted premium trial.

７ Note

This trial licensing option for hosted machines is suspended until further
notice.

Trial users are granted the capacity of one hosted machine per tenant. To start a
trial, select Try free under Power Automate Premium in the Power Automate
pricing page  or the desktop flow page of the Power Automate portal .

Prerequisites
This section presents all the prerequisites to create and use hosted machines.



Microsoft Entra and Intune requirements
A valid and working Intune and Microsoft Entra tenant.
Ensure that Intune device type enrollment restrictions are set to Allow Windows
(MDM) platform for corporate enrollment.

To find more information about the Microsoft Entra and Intune requirements, go to
Windows 365 requirements.

Windows 365 Cloud PC and Azure Virtual Desktop service
principal

７ Note

The Windows 365 and Azure Virtual Desktop service principals should automatically
be created in your tenant. You can skip this step, unless you face an error with
service principals not created in your tenant when you provision the hosted
machine.

1. Validate if the Windows 365 service principal is already created:

a. Sign in to the Azure portal .

b. Navigate to Microsoft Entra > Enterprise applications > All applications.

c. Remove filter Application type == Enterprise Applications.

d. Fill filter Application ID starts with with the Windows 365 application ID
0af06dc6-e4b5-4f28-818e-e78e62d137a5.

If the service principal is provisioned in your Microsoft Entra, the page should
look like the following screenshot:

Microsoft Azure Search resources, services, and docs (G+/) Copilot 1 administrator@contoso.onmicro
CONTOSO (CONTOSO.ONMICROSOFT.COM

Home Enterprise applications

Enterprise applications | All applications
Contoso

New application Refresh Download (Export) Preview info Columns Preview features Got feedback?

Overview
View, filter, and search applications in your organization that are set up to use your Microsoft Entra tenant as their Identity Provider. 

Manage
The list of applications that are maintained by your organization are in application registrations.

All applications

Private Network Search by application name or object ID Application ID starts with 0af06dc6-e4b5-4f28-818e-e78e62d137a5 Add filters
connectors 1 application found
User settings Name  Object ID  Application ID  Homepage URL  Created on  Certificate Expiry Status  Active Certificate Expiry Da

App launchers W3 Windows 365 aaaaaaaa-0000-1111-22220-bafb0b6bdbcb6-beb4bbb5b-b4f28-818e-e78e62d137a5 5/19/2023 - -
Custom authentication 
extensions

If the application is like the presented screenshot, you don't need to perform
any extra steps. However, you must create the service principal if the application



isn't showing up.

2. Create the Windows 365 service principal.

You can create an Azure service principal with the az ad sp create command from
the Azure Command-Line Interface (CLI).

Azure-CLI-command

az ad sp create --id 0af06dc6-e4b5-4f28-818e-e78e62d137a5

3. Create other service principals related to Azure Virtual Desktop.

To create a hosted machine, you must create the following Azure Virtual Desktop
services in your tenant.

ﾉ Expand table

Application name Application ID

Azure Virtual Desktop 9cdead84-a844-4324-93f2-b2e6bb768d07

Azure Virtual Desktop Client a85cf173-4192-42f8-81fa-777a763e6e2c

Azure Virtual Desktop ARM Provider 50e95039-b200-4007-bc97-8d5790743a63

Follow the same instruction as for creating the Windows 365 application to check
and create the service principals.

Get access to the default VM image

７ Note

The default VM image provided by Power Automate with Microsoft Edge
preinstalled is based on the Windows 365 Cloud PC image template:
Windows 11 Enterprise Cloud PC 24H2 . If you have specific software,
configuration, or security constraints, use the custom VM image capability.

The default VM image is available to all users in the environment. If you can't see the
default VM image, your admin disabled sharing of default VM images with users. In this
case:



Users need either the System Administrator or Desktop Flows Machine
Configuration Admin role to see and manage the default image.
For other users, the System Administrator or Desktop Flows Machine
Configuration Admin must share the default image with them before they can use
it.

View the default image in Monitors > Machines > VM images.

Share the default image
1. Sign in to Power Automate .

2. Go to Monitor > Machines > VM images.

3. Select the default Windows desktop image from the list.

4. Select Manage access.

5. Select Add people and enter the name of the person in your organization with
whom you’d like to share the image.

6. Select the names of the persons and choose which permissions they can access the
machine with.

7. Select Save.



Create a hosted machine
To create a hosted machine:

1. Sign in to Power Automate .

2. Go to Monitor > Machines.

3. Select New > Hosted machine.

4. In the hosted machine creation wizard:

a. Enter a name for your hosted machine and optionally add a description.

b. Select the VM image to use for your hosted machine. A proposed default
Windows 11 image called Default Windows Desktop Image is available. If you
don't see it, make sure you followed the steps described in Prerequisites.

Alternatively, you can select a custom VM image that is shared with your
account.

c. Optionally, select the custom network connection you want your hosted
machine to be provisioned with. Otherwise, you automatically connect to the



Microsoft Hosted Network.

d. Review and create your hosted machine.

７ Note

The time needed to provision a hosted machine varies depending on the
configuration of the hosted machine. It can take over 30 minutes for the machine
to be ready for access.

Access a hosted machine
1. Sign in to Power Automate .

2. Go to Monitor > Machines.

3. Select the Machines tab

4. Select your hosted machine from the list of machines.

5. In the machine details page, you should observe the following details:

Machine type: Hosted machine
Connectivity status: Connected
Machine status: Active



6. Select Open in browser.

7. A new tab in the browser should open and load the hosted machine access. Sign in
with your work or school account.

8. The hosted machine is preregistered into the Power Automate environment.

Use custom VM images for your hosted
machine



You can personalize your hosted machines by providing your own Windows image
directly from your Azure Compute Gallery. This feature allows you to have all your
applications installed on your hosted machines.

Create an Azure Compute Gallery in Azure and add an
image

1. Go to the Azure portal .

2. Create a new Azure Compute Gallery and select Role based access control (RBAC)
in the Sharing tab.

3. Select Review + create, and once you validated all the settings, select Create.

4. Once you created an Azure Compute Gallery, create an image definition following
the steps in Create an image definition and an image version. You should create
the image in the exact location where we deploy your hosted machines. You can
find the following mapping with your environment Geo:

Australia: Australia East
Asia: East Asia
Brazil: Brazil South
Canada: Canada Central
Europe: North Europe
France: France Central
Germany: Germany West Central
India: Central India
Japan: Japan East
Korea: Korea Central
Norway: Norway East
Singapore: Southeast Asia (Allowlisted tenants only)
Switzerland: Switzerland North
United Arab Emirates: UAE North
United Kingdom: UK South
United States: East US

Image requirements
Custom VM images must meet the following requirements:

Windows 10 Enterprise version 20H2 or later
Windows 11 Enterprise 21H2 or later



Generation 2 image
Generalized VM image. Learn more in generalize VM image.
Single Session VM images (multi-session isn’t supported)
No recovery partition. To find more information about how to remove a recovery
partition, go to Windows Server command: delete partition
Default 64-GB OS disk size. The OS disk size is automatically adjusted to 256 GB
The image definition must have trusted launch enabled as the security type

Share the reader permission on Azure subscription with
Windows 365 service principal
To use your VM image for hosted machines, you need to grant Windows 365 service
principal with the following permissions:

Reader permission on the Azure subscription.

When you upload a custom image, you must be signed in with an account that is an
owner or admin of the subscription.

Share the Azure Compute Gallery with Power Automate
makers
The last step before using your image in Power Automate is to share the image with the
Power Automate makers.

1. In the Azure portal , go to your Azure Compute Gallery.

2. Go to the Access Control (IAM) settings.

3. Select Add > Add role assignment.

4. Assign at least Reader permissions access to the Power Automate makers you want
to share the gallery with. Then select Next.

5. Select Select members and search for the Power Automate makers you want to
share with.

6. Once you selected all the members to add, review the permissions and users, and
assign them.

Add a new custom VM image
1. Sign in to Power Automate .



2. Go to Monitor > Machines.

3. Select New > VM image.

4. Enter a VM image name, a description, and the usage.

VM Image name: A unique name to identify the image.
VM Image description: An optional description for the image.
Use with: Select either Hosted machine or Both, if you want the image to
work with both hosted machines and hosted machine groups.

5. Select one of the images that you have access to from the Azure Compute Gallery.

７ Note

The image needs to be replicated in the same Azure region as the
hosted machine.
The list of images available may vary depending on the usage you are
selecting.

Share the image
1. Sign in to Power Automate .

2. Go to Monitor > Machines > VM images.



3. Select the image you created.

4. Select Manage access.

5. Select Add people and enter the names of the persons in your organization with
whom you'd like to share the image.

6. Select the names of the persons and choose with which permissions they can
access the image.

7. Select Save.

７ Note

When a user isn't part of an environment anymore, you can continue to see the
user as deactivated. You are notified in the Manage access section of the image if
it's shared with deactivated users. In this situation, remove access to them.

Use a custom virtual network for your hosted
machines
You can connect to your own virtual network with your hosted machines to securely
communicate with each other, the Internet, and on-premises networks. Providing your
own virtual network from your Azure subscription allows your hosted machines to be
provisioned with your virtual network automatically.

７ Note



You can have up to 30 custom virtual networks configured per tenant.

General network requirements
To use your own network with hosted machines, you must meet the following
requirements:

You must have a virtual network in your Azure subscription in the same region
where you created the hosted machines.
Follow Azure’s Network guidelines.
A subnet within the virtual network and available IP address space.
Allow network connectivity to required services.

The virtual network needs to be created in the same location as your hosted machines.
You can find the following mapping with your environment Geo:

Australia: Australia East
Asia: East Asia
Brazil: Brazil South
Canada: Canada Central
Europe: North Europe
France: France Central
Germany: Germany West Central
India: Central India
Japan: Japan East
Korea: Korea Central
Norway: Norway East
Singapore: Southeast Asia (Allowlisted tenants only)
Switzerland: Switzerland North
United Arab Emirates: UAE North
United Kingdom: UK South
United States: East US

Additional requirements for Microsoft Entra hybrid joined
hosted machines
To use your own network and provision Microsoft Entra hybrid joined machines, you
must meet the following requirements:

Domain requirements



You must configure your infrastructure to automatically Microsoft Entra hybrid join
any devices that domain joins to the on-premises Active Directory. This
configuration lets them be recognized and managed in the cloud.
Microsoft Entra hybrid joined hosted machines require network line of sight to
your on-premises domain controllers periodically. Without this connection, devices
become unusable. For more information, see Plan your Microsoft Entra hybrid join
deployment.
If an organizational unit is specified, ensure it exists and is valid.
An Active Directory user account with sufficient permissions to join the computer
into the specified organizational unit within the Active Directory domain. If you
don't specify an organizational unit, the user account must have sufficient
permissions to join the computer to the Active Directory domain.
User accounts that are creators of hosted machines must have a synced identity
available in both Active Directory and Microsoft Entra ID.

Role and identity requirements
Hosted machines users must be configured with hybrid identities so that they can
authenticate with resources both on-premises and in the cloud.

DNS requirements
As part of the Microsoft Entra hybrid join requirements, your hosted machines must be
able to join on-premises Active Directory. That requires that the hosted machines be
able to resolve DNS records for your on-premises AD environment. Configure your
Azure Virtual Network where the hosted machines are provisioned as follows:

1. Make sure your Azure Virtual Network has network connectivity to DNS servers
that can resolve your Active Directory domain.

2. From the Azure Virtual Network's Settings, select DNS Servers and then choose
Custom.

3. Enter the IP address of DNS servers that environment that can resolve your Active
Directory Domain Services domain.

Share the virtual network with Windows 365 service
principal
To use your virtual network for hosted machines, you need to grant Windows 365
service principal with the following permissions:

Reader permission on the Azure subscription



Windows 365 Network Interface Contributor permission on the specified resource
group
Windows 365 Network User permission on the virtual network

７ Note

Ensure the resources have the specified role requirements assigned to the Windows
365 service principal, even if other roles with the same or higher permissions are
already assigned.

７ Note

For virtual networks created before November 26, 2023, the Network Contributor
role is used to apply permissions on both the resource group and virtual network.
The new RBAC roles have more specific permissions. To manually remove the
existing roles and add the new roles, refer to the following table for the existing
roles used on each Azure resource. Before removing the existing roles, make sure
that the updated roles are assigned.

ﾉ Expand table

Azure Existing role (before November Updated role (after November 26,
resource 26, 2023) 2023)

Resource Network Contributor Windows 365 Network Interface
group Contributor

Virtual Network Contributor Windows 365 Network User
network

Subscription Reader Reader

Share the virtual network with Power Automate makers
The last step before being able to reference your virtual network from Power Automate
is to share the virtual network with the Power Automate makers.

1. Go to the Azure portal .

2. In the Azure portal, go to your Virtual network.

3. Go to the Access Control (IAM) settings.



4. Select Add > Add role assignment.

5. Assign at least Reader permissions access to the Power Automate makers you want
to share the virtual network with. Then select Next.

6. Select Select members and search for the Power Automate makers you want to
share with.

7. Once you selected all the members to add, review the permissions and users, and
assign them.

Add a new network connection
1. Sign in to Power Automate .

2. Go to Monitor > Machines.

3. Select New > Network connection.

4. Enter a network connection name, a description, and the usage.

Network connection name: A unique name to identify the network
connection.
Description: An optional description for the network connection.
Use with: Select hosted machine.

5. Select one of the Azure virtual network available in Azure that meets the network
requirements.

6. Select the Subnet the hosted machine uses.

7. Select the Domain join type the machine uses.

8. If the 'Microsoft Entra hybrid join' is selected, the following information is
required:

DNS domain name : The DNS name of the Active Directory domain you want
to use for connecting and provisioning hosted machines. For example,
corp.contoso.com.
Organizational unit (optional) : An organizational unit (OU) is a container
within an Active Directory domain, which can hold users, groups, and
computers. Make sure that this OU is enabled to sync with Microsoft Entra
Connect. Provisioning fails if this OU isn't syncing.
Username UPN : The username, in user principal name (UPN) format, you
want to use for connecting the hosted machines to your Active Directory



domain. For example, svcDomainJoin@corp.contoso.com. This service
account must have permission to join computers to the domain and, if set,
the target OU.
Domain password : The password for the user.

７ Note

It takes 10-15 minutes to provision a new network connection with Microsoft
Entra hybrid join domain join type.

Share the network connection
1. Sign in to Power Automate .

2. Go to Monitor > Machines > Network connection.

3. Select the network connection you created.

4. Select Manage access.

5. Select Add people and enter the names of the persons in your organization with
whom you’d like to share the network connection.

6. Select the names of the persons and choose which permissions they can access the
network connection with.

7. Select Save.



７ Note

When a user isn't part of an environment anymore, you can continue to see the
user as deactivated. You are notified in the Manage access section of the network
connection if it's shared with deactivated users. In this situation, remove access to
them.

View list of hosted machines
Once you created your hosted machine in an environment, you can view its details in
the Power Automate portal.

1. Sign in to Power Automate .
2. Go to Monitor > Machines.
3. Select Machines.

The list contains both hosted machines and standard machines. For each item in the list,
you can view:

The name of the machine.
The description of the machine.
The Power Automate for desktop version of the machine
The machine group it belongs to, if it's part of a machine group.
The number of flows running in the machine.
The number of flows queued in the machine.
The type of access you have to the machine.
The owner of the machine.



Selecting a hosted machine in the list takes you to the hosted machine details page
where you can:

View and edit the details of the machine.
Access the machine.
Add the machine to a machine group.
Monitor the run queue.
View past runs.
List existing connections referencing the machine.
View provisioning errors on the machine, if any.
Manage access of the machine.
Delete the machine.

Share hosted machines
You can share your hosted machines with other users so they can run desktop flows with
the creator's connection on them. To share a hosted machine:



1. Sign in to Power Automate .

2. Go to Monitor > Machines.

3. Select the Machines tab.

4. Select a hosted machine in the list and navigate to the details page of it.

5. Select Manage access.

6. Enter the username or email you want to share the hosted machine with, and
select the user you want to add.

7. For each user, you can grant different permissions: User or Co-owner.

User permission only allows the targeted user to run desktop flows on the selected
hosted machine. A Co-Owner can also edit the hosted machine details.

７ Note

Sign-in access is only available to the creator of the hosted machine.
You can run unattended desktop flow using a work or school account that is
different from the creator of the hosted machine, provided that you add the
account on the hosted machine.
When a user isn't part of an environment anymore, you may continue to see
the user as deactivated. You'll be notified in the Manage access section of the
hosted machine if it's shared with deactivated users. In this situation, remove
access to them.

Run desktop flows on hosted machines
Power Automate enables you to trigger desktop flows on your hosted machines as you
do on standard machines. To implement this functionality, you need a desktop flow
connection to your hosted machine.

To find more information about triggering desktop flows from cloud flows, go to Trigger
desktop flows from cloud flows.

７ Note

If you intend to run unattended desktop flows on your hosted machine using the
default virtual machine (VM) image option, you need to disable Network Level



Authentication on your machine.

Restart hosted machines
Power Automate enables you to restart your hosted machines from the Power Automate
portal. To restart your hosted machine:

1. Sign in to Power Automate .

2. Go to Monitor > Machines.

3. Select the Machines tab.

4. Select a hosted machine in the list and navigate to the details page of it.

5. Select Restart machine.

７ Note

The hosted machine is restart may take a few minutes to complete. Please wait for
a few minutes before trying to access the hosted machine.

Permissions based on security roles



Hosted machine permissions and roles are iterations on top of Desktop Flows Machine
Management permissions and roles. A hosted machine group follows the same rules
and privileges as a regular group.

Creation of hosted machine and privileges
This section describes the permissions for hosted machines.

Environment Maker role
By default, the Environment Maker role can create hosted machines in their
environment. The entities that require privileges to use hosted machines are:

Flow Machine
Flow Machine Group
Flow Machine Image
Flow Machine Network (if using custom virtual network for your hosted machine)

The Environment Maker role can create and share custom VM images, as these actions
require create and append privileges on the Flow Machine Image.

The Environment Maker role can create and share custom virtual network, as these
actions require create and append privileges on the Flow Machine Network.

Admins can also use the roles provided as part of Desktop Flows. You can find more
information about desktop flow security roles in Manage Machines.



Desktop Flows Machine Owner role
By default, the Desktop Flows Machine owner can create hosted machines, but can't
create custom VM images or custom virtual network. They can only use previously
shared custom VM images or custom virtual networks in their own hosted machine.



Desktop Flows Machine Configuration Admin role
The Desktop Flows Machine Configuration Admin role role only brings full privileges
on the Flow Machine Image and Flow Machine Network entities. In particular, it allows
users with this role to share/unshare VM images and virtual network to be used for
created hosted machines in their environment. You can find more information about
sharing pre-provisioned VM images and virtual network in Create hosted machines.



Custom virtual network permissions
The custom virtual network feature requires permissions to the Flow Machine Network
table. You can grant or deny privileges to this table to control which user can create and
share custom virtual networks.

Hosted machines limitations
This section presents the limitations of hosted machines.

Geographical availabilities/restrictions
The following list displays all the supported Power Platform geographies in the public
cloud:

Australia
Asia
Brazil
Canada
Europe
France
Germany



India
Japan
Korea
Norway
Singapore (Allowlisted tenants only)
Switzerland
United Arab Emirates
United Kingdom
United States

７ Note

Hosted machines aren't yet available in sovereign clouds.

Azure tenant country/region and supported geographies
in the public cloud
A hosted machine stores limited metadata in the geography of your tenant's
country/region, which can be different from the region of your Power Automate
environment. By default, the cross-geo support for hosted machines is enabled. System
admins and environment admins can disable or enable the feature from the Power
Platform admin center.

1. Sign in to the Power Platform admin center .

2. Go to Environments, and select the appropriate environment.

3. Select Settings > Features.

4. Under Hosted RPA, select the toggle for Enable cross-geo support for hosted
machines to disable or enable this feature.



5. Select Save.

７ Note

Disabling this feature at the environment level will restrict creation of hosted
machines when your tenant's country or region on Azure don't fall within the same
scope of the region for your Power Automate environment. To check the tenant
country/region on Azure:

1. Go to the Azure portal .

2. Open the Tenant properties service. The Country or region is available as one
of the properties.



Deletion of unused resources
For environments without the Power Automate Hosted Process license, we clean unused
resources to ensure our service is available for everyone. A hosted machine that is
inactive for 14 days is automatically deleted. The deleted hosted machine is still visible
but can't be used anymore. An inactive hosted machine is a machine that has no flow
runs and no usage of Power Automate for desktop for the last 14 days.

７ Note

You need to delete the inactive hosted machine and recreate a new one to continue
using the hosted machines feature. You need to reconfigure the connections
associated with your cloud flows.

Troubleshoot hosted machines
To find information on how to troubleshoot hosted machines, go to Troubleshoot
hosted machines.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Hosted machine group
Article • 03/11/2025

Hosted machine group allows you to run unattended automation at scale without
providing or setting up any machines. You can create hosted machine groups like any
other machine group, and Power Automate automatically provisions the machines
based on the specified configuration.

Desktop flows assigned to a hosted machine group get queued to it when triggered to
run. Then, like for any machine group, the next desktop flow in the queue runs when a
bot in the group is available. To find more information about queues, go to Monitor
desktop flow queues.

Here are some of the key features of hosted machine group:

Run unattended desktop flows at scale.
Autoscale the number of bots in your hosted machine group based on current
workloads.
Load balance bots across all hosted machine groups in an environment.
Work or school account integration: Enables access to resources that are part of
the business plan linked to your organization, such as Office, SharePoint, and
Azure.
Vanilla or Custom VM images: Use a vanilla VM image provided by Microsoft or
personalize your hosted machine group by providing your own Windows image
directly from your Azure Compute Gallery.

Licensing requirements
To use hosted machine group, you need the Power Automate Hosted Process license
(previously Power Automate hosted RPA add-on). Assign to your environment as many
capacity as the number of hosted bots you want to run in parallel in your environment.

Trial licenses for evaluation
To evaluate the hosted machine group, you need one of the following trial licensing
options:

Use the Power Automate Hosted Process license

The Power Automate Hosted Process license has trial versions that last 30 days and
can be extended once to a total of 60 days. Organization admins can obtain up to



25 seats from Microsoft 365 admin center  and assign Power Automate Hosted
Process capacity to the targeted environment.

Use the 90-days self-assisted premium trial.

Trial users can create up to 10 hosted machine groups and have up to two bots
running in parallel in a given environment. To start a trial, select Try free under
Power Automate Premium in the Power Automate pricing page  or the desktop
flow page of the Power Automate portal .

Prerequisites
This section presents all the prerequisites to create and use hosted machine groups.

Get access to the default VM image

７ Note

The default VM image provided by Power Automate with Microsoft Edge
preinstalled is based on the Windows 365 Cloud PC image template:
Windows 11 Enterprise Cloud PC 24H2 . If you have specific software,
configuration, or security constraints, use the custom VM image capability.

The default VM image is available to all users in the environment. If you can't see the
default VM image, your admin disabled sharing of default VM images to users. In this
case:

Users need either the System Administrator or Desktop Flows Machine
Configuration Admin role to see and manage the default image.
For other users, the System Administrator or Desktop Flows Machine
Configuration Admin has to share the default image with them before they can
use it.

View the default image in Monitors > Machines > VM images.



Share the default image
1. Sign in to Power Automate .

2. Go to Monitor > Machines > VM images.

3. Select the default windows desktop image from the list, and then Manage access.

4. Select Add people, and then enter the names of the persons in your organization
with whom you'd like to share the image.

5. Select the names of the persons and which permissions they have to get access to
the machine or co-own it as well.

6. Select Save.

７ Note

When users aren't part of an environment anymore, you can continue to see them
as deactivated users. You'll be notified in the Manage access section of the image if
it's shared with deactivated users. In this situation, remove access to them.



Create hosted machine groups
To create a hosted machine group:

1. Sign in to Power Automate .

2. Go to Monitor > Machines.

3. Select New > Hosted machine group.

4. In the hosted machine group creation wizard

Enter a name for your hosted machine group, then optionally add a
description.

Determine if you want to reuse a Windows session in unattended mode.

Define the maximum number of bots you want to assign to this group.

７ Note

Max bots allow your hosted machine group to automatically scale to the
max bots configuration when required and when resources are available.
If multiple hosted machine groups are used in the same environment,
bots are automatically load balanced between the groups.
You can't exceed the total number of Hosted Process capacity assigned
to your environment.



To find more information about load balancing, go to Load balance
hosted machine groups.

Define the committed number of bots (optional) you want to assign to this
group.

７ Note

Committed bots guarantee your hosted machine group to automatically
scale to the committed bots configuration when required.
The sum of hosted machines and committed bots configured in your
environment can't exceed the Hosted Process capacity assigned to the
environment. View usage of Hosted Process capacity in your
environment in the Hosted Process capacity utilization dashboard.

Select the VM image to use for your hosted machine group. A proposed
default Windows 11 image called Default Windows Desktop Image is
available. If you don't see it, make sure you followed the steps described in
Prerequisites.

Select the Network connection (optional) to use for your hosted machine
group.

Select how you would like to access your hosted machine group. You can use
your work or school account or use a local admin account you want created.



This account is used to run your automations by the bots.

７ Note

If you select work or school account, enter your email address (and not
domain\username) when creating a connection to the hosted machine group.

Review and create your hosted machine group.

Hosted machine groups availability
Hosted bots in a hosted machine group are created when needed. Whenever a desktop
flow waits in the queue and no bot is available, a bot is created automatically. A bot is
created as long as the maximum number of bots for this group isn't reached and you
have enough unattended add-ons assigned to your environment. You can find more
information about licensing requirements in Licensing requirements.

７ Note

If the hosted machine group has just been created or hasn't been used for more
than three hours, hosted bots are created before a run gets addressed from the
queue. The creation of a bot can take more than 10 minutes depending on its
configuration.



Use custom VM images for your hosted
machine groups
You can personalize your hosted machine groups by providing your own Windows
image directly from your Azure Compute Gallery. This feature allows you to have all your
applications installed on your hosted machine group.

Image requirements
Custom VM images must meet the following requirements:

Generation 2 images
Generalized VM image. Learn more in generalize VM image.
127-GB limit on VM image size
Microsoft Edge version 80 or higher
The image definition must have trusted launch enabled as the security type

Create an Azure compute gallery in Azure and add an
image

1. Go to the Azure portal .

2. Create a new Azure Compute Gallery and select Role based access control (RBAC)
in the Sharing tab.

3. Select Review + create, validate all the settings, and select Create.

4. Once you've created an Azure Compute Gallery, create an image definition
following the steps in Create an image definition and an image version. You should
create the image in the exact location where we deploy your hosted machine
group. You can find the following mapping with your environment Geo:

Asia: East Asia
Australia: Australia East
Brazil: Brazil South
Canada: Canada Central
Europe: North Europe
France: France Central
Germany: Germany West Central
India: Central India
Japan: Japan East



Korea: Korea Central
Norway: Norway East
South Africa: South Africa North
Singapore: Southeast Asia (Allowlisted tenants only)
Switzerland: Switzerland North
United Arab Emirates: UAE North
United Kingdom: UK South
United States: East US

Share the Azure compute gallery with Power Automate
Hosted Machine Groups service principal
To use the image in Power Automate, you need to share the image with Power
Automate through the Azure portal.

1. In the Azure portal , go to your Azure Compute Gallery.

2. Go to the Access Control (IAM) settings.

3. Select Add > Add role assignment.

4. Select the role Reader and search for the Hosted machine group application:
Power Automate Hosted Machine Groups. This allows our service to access the
image to create the Hosted machine group.

７ Note

If you can't find the application above, verify that the application exists in your
tenant and provision it if necessary. To verify that the application exists, go to the
Azure portal  > Microsoft Entra > Enterprise applications > All applications, and
search for application id: 51699864-8078-4c9e-a688-09a1db1b2e09. If you can't
find the application, provision it using the following command:

az ad sp create --id 51699864-8078-4c9e-a688-09a1db1b2e09

Share the gallery with Power Automate makers
The last step before using your image in Power Automate is to share the image with the
Power Automate makers.



1. In the Azure portal , go to your Azure Compute Gallery.

2. Go to the Access Control (IAM) settings.

3. Select Add > Add role assignment.

4. Assign at least Reader permissions access to the Power Automate makers you want
to share the gallery with. Then select Next.

5. Select Select members and search for the Power Automate makers you want to
share with.

6. Once you select all the members to add, review the permissions and users, and
assign them.

Add a new custom VM image
1. Sign in to Power Automate .

2. Select New > VM image.

3. Enter an image name, a description, and the usage.

Image name: A unique name to identify the image.
Image description: An optional description for the image.
Use with: Select either Hosted machine group or Both, if you want the image
to work with both hosted machines and hosted machine groups.

4. Select one of the images that you have access to from the Azure Compute Gallery.



７ Note

The image needs to be replicated in the same Azure region as the
hosted machine group.
The list of images available may vary depending on the usage you are
selecting.

Share the image
1. Sign in to Power Automate .

2. Go to Monitor > Machines > VM images.

3. Select the image you created.

4. Select Manage access.

5. Select Add people and enter the names of the persons in your organization with
whom you'd like to share the image.

6. Select the names of the persons and choose with which permissions they can
access the image.



7. Select Save.

７ Note

When a user isn't part of an environment anymore, you can continue to see it as a
deactivated user. You'll be notified in the Manage access section of the image if it's
shared with deactivated users. In this situation, remove access to them.

Use a custom virtual network for your hosted
machine groups
You can connect to your own virtual network with your hosted machine groups to
securely communicate with each other, the Internet, and on-premises networks.
Providing your own virtual network from your Azure subscription allows your hosted
machine groups to be provisioned with your virtual network automatically.

７ Note

You can have up to 30 custom virtual networks configured per tenant.

General network requirements
To use your own network and provision Microsoft Entra joined hosted machine groups,
you must meet the following requirements:

You must have a virtual network in your Azure subscription in the same region
where you created the hosted machine groups.



Follow Azure’s Network guidelines.
A subnet within the virtual network and available IP address space.
Allow network connectivity to required services.

The virtual network needs to be created in the same location as your hosted machine
groups. Following are the currently supported Power Platfrom geographies and their
region mapping:

Asia: East Asia
Australia: Australia East
Brazil: Brazil South
Canada: Canada Central
Europe: North Europe
France: France Central
Germany: Germany West Central
India: Central India
Japan: Japan East
Korea: Korea Central
Norway: Norway East
South Africa: South Africa North
Singapore: Southeast Asia (Allowlisted tenants only)
Switzerland: Switzerland North
United Arab Emirates: UAE North
United Kingdom: UK South
United States: East US

Additional requirements for Microsoft Entra hybrid joined
hosted machines groups (preview)
[This topic is prerelease documentation and is subject to change.]

Microsoft Entra hybrid join using custom virtual networks (VNETs) with hosted machine
groups lets your hosted machine group bots enroll in both your on-premises Active
Directory (AD) and Microsoft Entra ID. This feature is useful when automation requires
authentication using an AD account or when devices need to be managed using Group
Policy (GPO).

） Important

This is a preview feature.



Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.

To use your own network and provision Microsoft Entra hybrid joined machines, you
must meet the following requirements:

Domain requirements
Configure your infrastructure to automatically Microsoft Entra hybrid join any
devices that domain joins to the on-premises Active Directory. configuration lets
them be recognized and managed in the cloud.
Microsoft Entra hybrid joined hosted machines need periodic network line of sight
to your on-premises domain controllers. Without this connection, devices become
unusable. Learn more in Plan your Microsoft Entra hybrid join deployment.
If you specify an organizational unit, ensure it exists and is valid.
Ensure an Active Directory user account has sufficient permissions to join the
computer into the specified organizational unit within the Active Directory domain.
If you don't specify an organizational unit, ensure the user account has sufficient
permissions to join the computer to the Active Directory domain.
User accounts that create hosted machines must have a synced identity available in
both Active Directory and Microsoft Entra ID.

Role and identity requirements
Hosted machine groups users must be configured with hybrid identities so that they can
authenticate with resources both on-premises and in the cloud.

DNS requirements
As part of the Microsoft Entra hybrid join requirements, ensure your hosted machine
groups can join on-premises Active Directory. To achieve this requirement, the hosted
machine groups must resolve DNS records for your on-premises AD environment.
Configure your Azure Virtual Network where the hosted machine groups are
provisioned as follows:

1. Ensure your Azure Virtual Network has network connectivity to DNS servers that
can resolve your Active Directory domain.

2. From the Azure Virtual Network's Settings, select DNS Servers and then choose
Custom.



3. Enter the IP address of DNS servers that can resolve your Active Directory Domain
Services domain.

Share the virtual network with Power Automate Hosted
Machine Groups service principal
To use your virtual network for hosted machine groups, you need to share the virtual
network with Power Automate through the Azure portal.

1. In the Azure portal , go to your Virtual Network

2. Go to the Access Control (IAM) settings.

3. Select Add > Add role assignment.

4. Select the role Network Contributor and search for the Hosted machine group
application: Power Automate Hosted Machine Groups.

７ Note

If you can't find the application above, verify that the application exists in your
tenant and provision it if necessary. To verify that the application exists, go to Azure
portal  > Microsoft Entra > Enterprise applications > All applications, and
search for application id: 51699864-8078-4c9e-a688-09a1db1b2e09. If you can't
find the application, provision it using the following command:

az ad sp create --id 51699864-8078-4c9e-a688-09a1db1b2e09

Delegate subnet to Microsoft.PowerAutomate/hostedRpa
To use the subnet configured in your virtual network for hosted machine groups, you
need to perform subnet delegation to the Microsoft.PowerAutomate/hostedRpa
service.

1. In the Azure portal , go to your subnet

2. Go to the Subnet Delegation section.

3. Select Microsoft.PowerAutomate/hostedRpa from the dropdown list.



Share the virtual network with Power Automate makers
The last step before being able to reference your virtual network from Power Automate
is to share the virtual network with the Power Automate makers.

1. Go to the Azure portal .

2. In the Azure portal, go to your Virtual network.

3. Go to the Access Control (IAM) settings.

4. Select Add > Add role assignment.

5. Assign at least Reader permissions access to the Power Automate makers you want
to share the virtual network with. Then select Next.

6. Select Select members and search for the Power Automate makers you want to
share with.

7. Once you selected all the members to add, review the permissions and users, and
assign them.

Add a new network connection
1. Sign in to Power Automate .

2. Go to Monitor > Machines.

3. Select New > Network connection.

4. Enter a network connection name, a description, and the usage.

Network connection name: A unique name to identify the network
connection.
Description: An optional description for the network connection.
Use with: Select hosted machine group (preview).

5. Select one of the Azure virtual network available in Azure that meets the network
requirements.

6. Select the Subnet the hosted machine groups use.

7. Select the Domain join type for the machine.

8. If you select 'Microsoft Entra hybrid join (preview)', provide the following
information:



DNS domain name : The DNS name of the Active Directory domain used for
connecting and provisioning hosted machines. For example,
corp.contoso.com.
Organizational unit (optional) : An organizational unit (OU) is a container
within an Active Directory domain that can hold users, groups, and
computers. Ensure this OU syncs with Microsoft Entra Connect. Provisioning
fails if this OU isn't syncing.
Network credential : Stored as an Azure Key Vault credential. The user
principal name (UPN) and its password connect the hosted machine groups
to your Active Directory domain. For example,
svcDomainJoin@corp.contoso.com. This service account must have
permission to join computers to the domain and, if set, the target OU.

７ Note

Provisioning a new network connection with Microsoft Entra hybrid join
domain join type takes 10-15 minutes.

Share the network connection
1. Sign in to Power Automate .

2. Go to Monitor > Machines > Network connection.

3. Select the network connection you created.

4. Select Manage access.

5. Select Add people and enter the names of the persons in your organization with
whom you’d like to share the network connection.

6. Select the names of the persons and choose which permissions they can access the
network connection with.

7. Select Save.



７ Note

When a user isn't part of an environment anymore, you can continue to see the
user as deactivated. You are notified in the Manage access section of the network
connection if it's shared with deactivated users. In this situation, remove access to
the deactivated users.

View list of hosted machine groups
Once you created your hosted machine group in an environment, you can view its
details in the Power Automate portal.

1. Sign in to Power Automate .

2. Go to Monitor > Machines.

3. Select Machine groups.

The list contains both hosted machine groups and standard machine groups. For
each item in the list, you can see:

The name of the item.
The description of the item.
The number of the machines in the group (only for standard machine
groups).
The number of flows running in the item.
The number of flows queued in the item.
The type of access you have to the item.



The owner of the item.

Selecting a hosted machine group in the list takes you to the machine group's
details page where you can:

View and edit the details of the hosted machine group.
Update the VM image used by the hosted machine group.
Monitor the machine group's run queue.
View past runs.
List existing connections referencing the hosted machine group.
View provisioning errors on the hosted machine group, if any.
Manage access by sharing (or not) the hosted machine group.
Delete the hosted machine group.

Share hosted machine groups
You can share your hosted machine groups with other users so they can create
connections and run desktop flows on them. To share a hosted machine group:

1. Sign in to Power Automate .

2. Select Monitor > Machines.

3. Select the Machine groups tab.

4. Select a hosted machine group in the list, or navigate to the details page of the
desired hosted machine group.

5. Select Manage access.

6. Populate the username or email you want to share the hosted machine group with,
and select the user you want to add.

7. For each user, you can grant different permissions: User or Co-owner.



User permission only allows the targeted user to run desktop flows on the selected
hosted machine group. A Co-Owner can also edit the hosted machine's group
details.

７ Note

When a user isn't part of an environment anymore, you may continue to see the
user as a deactivated user. You'll be notified in the Manage access section of the
hosted machine if it's shared with deactivated users. In this situation, remove access
to them.

Run desktop flows on hosted machine groups
Power Automate enables you to trigger desktop flows on your hosted machine groups
as you do on standard machine groups. To implement this functionality, you need a
desktop flow connection to your hosted machine group.

To find more information about triggering desktop flows from cloud flows, go to Trigger
desktop flows from cloud flows.

） Important

Only direct connectivity connections are supported for hosted machine
groups.
Only available for unattended run mode.
Desktop flows targeting hosted machine groups aren't yet compatible with
the Test flow feature. It's possible that you observe errors when trying to test
your flow. This problem is due to the nature of the machine groups
availability. The scheduled test run will still be accessible from the flow run
history.

Monitor your hosted machine groups
You can't directly access or sign in to your hosted machine groups. They're not persisted
unless they're running desktop flows. Hosted bots in a group are created based on the
current size of the queue, the configuration of the group, and the licenses assigned to
the current environment.



For instance, if the hosted machine group is newly created or it wasn't used for more
than 3 hours, new hosted bots might need to be provisioned before desktop flow runs.
The creation of a bot takes at least 10 minutes, depending on the type of VM Image in
use. It's expected that the queue would appear stuck for more than 10 minutes before
desktop flows start running.

After this process, new hosted bots are provisioned to run desktop flows in the queue as
efficiently as possible.

To monitor your hosted bots:

1. Sign in to Power Automate .

2. Go to Monitor > Machines.

3. Select Machine groups.

4. Select one of your hosted machine groups.

In the following example, two hosted bots are available to pick up the first two
desktop flows in the queue, and three other desktop flows are queued. The
desktop flow runs are marked as Running or Queued to indicate their state.

After a few minutes, another bot is provisioned to run a third flow as the queue is
large enough.



Load balance hosted machine group
The key feature of hosted machine groups is the ability to automatically load balance
hosted bots between different groups, hence optimizing your automation resources
seamlessly between your different workloads.

The number of hosted bots that can run in your environment is equal to the number of
Hosted Process capacity you assigned to your environment excluding the number of
hosted machines provisioned in the environment (for example, if you have 10 Hosted
Process assigned to your environment, and two hosted machines provisioned, then the
number of hosted bots that can run in your environment is eight). This capacity is then
load balanced across all the hosted machine groups you have in your environment. Each
hosted machine group has a max bot and committed bot configuration that enables you
to control the scaling capabilities of the hosted machine group.

The hosted machine group requests to scale out when there aren't enough hosted bots
to run desktop flows. It takes into consideration the max and committed bot
configuration in the hosted machine group and the available capacity in the
environment. The hosted machine group scale-in when the desktop flow queue is lesser
than the number of available hosted bots. This capacity then becomes available to other
hosted machine groups in the environment.



７ Note

Max bots allow your hosted machine group to automatically scale to the max
bots configuration when required and when resources are available.
Committed bots guarantee your hosted machine group to automatically
scale to the committed bots configuration when required.
View usage of Hosted Process capacity in your environment in the Hosted
Process capacity utilization dashboard.

To update the scaling configuration of your hosted machine group:

1. Sign in to Power Automate .

2. Select Monitor > Machines.

3. Select Machine groups.

4. Select one of your hosted machine groups.

5. Select Settings at the top of the page.

Hosted machine group scaling & load balancing example
In this example, the customer has 10 Hosted Process capacity assigned to the
environment and has configured three hosted machine groups with the following
configuration.

ﾉ Expand table

Hosted machine group name Max bots Committed bots

Invoice Processing 10 4



Hosted machine group name Max bots Committed bots

New Sales Processing 10 4

Refund Request Processing 10 2

ﾉ Expand table

Time Event

9AM - The Invoice Processing group has a high volume of desktop flow jobs and autoscales
11:59 to 10 hosted bots (Max bots configuration) as no other groups have desktop flow jobs.
AM

12PM - In addition to the high volume of desktop flow jobs for the Invoice Processing group,
4:59 PM the New Sales Processing group now also has a high volume of desktop flow jobs

queued, and therefore consumes the committed capacity of four hosted bots.

5PM - In addition to the high volume of desktop flow jobs for the Invoice Processing and
6:59 PM New Sales Processing groups, the Refund Request Processing group now also has a

high volume of desktop flow jobs queued, and therefore consumes the committed
capacity of two hosted bots.

Update VM Image used by the hosted machine
group



You can update the VM image that is used by your hosted machine group. This is
beneficial in situations where a custom VM image requires software updates and
additional customization to run desktop flows. This feature allows you to update the VM
image to be used when creating new hosted bots in your hosted machine group,
eliminating the need to delete and recreate it. To update VM image:

1. Sign in to Power Automate .

2. Select Monitor > Machines.

3. Select Machine groups.

4. Select one of your hosted machine groups.

5. Select Update VM image at the top of the page.

6. From the drop-down list, select the updated VM image to be used by the hosted
machine group.

７ Note

Upon updating of VM image, all existing hosted bots complete their ongoing
desktop flow runs prior to being reprovisioned with the new VM image.
The current and updated VM image must have the same security type. For
example, you can't update from non-trusted launch enabled to trusted launch
enabled, and vice versa.



Permissions based on security roles
Hosted machine group permissions and roles are iterations on top of Desktop Flows
Machine Management permissions and roles. Hosted machine groups follow the same
rules and privileges as regular machine groups.

Environment Maker role
By default, users with the Environment Maker role can create hosted machine groups in
their environment. The four tables that require privileges to use hosted machine groups
are:

Flow Capacity Assignment
Flow Machine
Flow Machine Group
Flow Machine Image
Flow Machine Network (if using custom virtual network for your hosted machine
groups)

The Environment Maker role can create and share custom VM images because this
functionality requires create and append privileges on the Flow Machine Image.



The Environment Maker role can create and share custom virtual networks because
these actions require create and append privileges on the Flow Machine Network.

Admins can also use the roles provided as part of desktop flows. Learn more about
desktop flow security roles in Manage Machines.

Desktop Flows Machine Owner role
By default, Desktop Flows Machine Owners can create hosted machine groups but can't
create custom VM images. They can only use previously shared custom VM images in
their own hosted machine groups.

Desktop Flows Machine Configuration Admin role
The Desktop Flows Machine Configuration Admin role brings full privileges on the
Flow Machine Image entity and Flow Machine Network entities.. In particular, it allows
users with this role to share/unshare VM images to be used for created hosted machine
group in their environment. You can find more information about sharing pre-
provisioned VM Images in Create hosted machine groups.



Custom virtual network permissions
The custom virtual network feature requires permissions to the Flow Machine Network
table. You can grant or deny privileges to this table to control which user can create and
share custom virtual networks.

Use your work or school account
Hosted machine groups support work and school accounts. If you use your work or
school account, your hosted machine group has access to your resources that are part
of the business plan linked to your organization, such as Office, SharePoint, Azure, and
more.

When you register a hosted machine group with this access option, you aren't
prompted for credentials. Instead, the machine is registered to your Microsoft Entra, and
you can sign in with your Microsoft Entra credentials. To create a desktop flow
connection to target the hosted machine group, enter your work or school account
email address and the associated password.



Disable/enable work or school accounts in an
environment
The work or school accounts feature is enabled by default. System admins and
environment admins can disable or enable the feature from the Power Platform admin
center.

1. Sign in to the Power Platform admin center .

2. Go to Environments, and select the appropriate environment.

3. Select Settings > Features.

4. Under Hosted RPA, select the toggle for Enable work or school accounts for
hosted machine groups to disable or enable this feature.

5. Select Save.

７ Note

Disabling this feature at the environment level will remove the Work or school
account option in the hosted machine group creation wizard. Also, it will prevent
any desktop flows from running using hosted machine groups configured with
work or school accounts.



Disable work or school accounts at tenant level
To prevent users from creating hosted machine groups with work or school accounts at
the tenant level, send a request to support to disable the feature at the tenant level.

７ Note

Disabling this feature at tenant level won't hide the Work or school account
option in the hosted machine group creation wizard. However, the hosted
machine group creation will fail with an error.
Desktop flows will continue to run using work or school account connection.
You need to manually remove hosted machine groups that have been created
with the Work or school account option.

Hosted machine groups limitations
This section presents all the limitation of hosted machine groups.

Geographic availability and restrictions

） Important

Starting May 2nd, 2024, we will be updating the region mapping for environments
in the United States and United Kingdom to ensure our services are deployed in
regions with Azure Availability Zones support. This change will enhance the
resiliency and availability of our services. The updated region mapping is as follows:

United States: West US -> East US
United Kingdom: UK West -> UK South

After the transition date, all new hosted machine groups will be provisioned in the
updated region. If you have an existing hosted machine group that was provisioned
before the transition, you will have the option to reprovision your hosted machine
group via the Power Automate portal. If you’re using a custom VM image, please
ensure that the VM image version has been replicated to the updated region
before you reprovision your hosted machine group. Please ensure there are no
desktop flow runs queued on the hosted machine group before you run the
reprovision process.



The following list displays all the supported geographies in the public clouds:

Asia
Australia
Brazil
Canada
Europe
France
Germany
India
Japan
Korea
Norway
South Africa
Singapore (Allowlisted tenants only)
Switzerland
United Arab Emirates
United Kingdom
United States

The following list displays all supported sovereign clouds:

Government Community Cloud (GCC): US Gov Virginia
Government Community Cloud High (GCC High): US Gov Virginia
Department of Defense (DoD): US DoD East

Hosted machine groups aren't yet available in the following sovereign cloud:

China

Default VM image deprecation for Windows 11 Enterprise
22H2
Windows versions are supported for a limited time to provide the latest security
updates, performance improvements, and features. The default VM image on Windows
11 Enterprise 22H2 is deprecated and replaced by Windows 11 Enterprise 24H2.

７ Note

This deprecation doesn't affect Windows version used in custom VM images.

Image scheduled for deprecation:



ﾉ Expand table

Name Description Reference Deprecation End of
date (0:00 support
UTC) date

(0:00
UTC)

Default Default Windows MicrosoftWindowsDesktop:windows- February 28, May 31,
Windows Desktop Image ent-cpc:win11-22h2-ent-cpc-os 2025 2025
11 for use in
Enterprise Microsoft
22H2 Desktop Flows.
Image Windows 11

Enterprise 22H2
with Microsoft
Edge.

Recommended alternative image:

ﾉ Expand table

Name Description Reference

Default VM image Default Windows Desktop Image MicrosoftWindowsDesktop:windows-ent-
– Windows 11 for use in Microsoft Desktop cpc:win11-24h2-ent-cpc
Enterprise 24H2 Flows. Windows 11 Enterprise

24H2 with Microsoft Edge.

Impact:

After the deprecation date, you can't deploy new hosted machine groups with the
deprecated image.
If you don't take action by the end of support, affected hosted machine groups are
automatically reprovisioned to the recommended default image.

Action:

1. Review all affected hosted machine groups by navigating to the VM images tab
under the Machines page in the Power Automate Portal.

2. To ensure compatibility, test your desktop flows with the recommended alternative
image in a nonproduction environment.

3. After validation, use the update VM image to reprovision the hosted machine
groups to the recommended alternative default image.

Sovereign clouds limitations for hosted machine groups



The following features aren't supported in sovereign clouds:

ﾉ Expand table

Feature not supported Sovereign clouds

Work or school account GCC, GCC High, DoD

Custom VM images GCC, DoD

Remote desktop to hosted machine groups
Remote desktop to hosted machine groups isn't supported. Hosted machine groups are
meant to be used for unattended runs only, and remote desktop access from the
Internet isn't required to run Power Automate desktop flows.

Limit on the number of hosted machine groups per
environment
The number of hosted machine groups is limited to 10 for each environment. If you
reach this limit, delete an existing hosted machine group to create a new one.

Limit on the number of bots per hosted machine group
The maximum number of hosted bots per hosted machine group is limited to 50.

Delete unused resources
We delete unused resources to ensure the service is available for everyone. Therefore, all
hosted machine groups that don't have a committed bot configured are automatically
deleted if they remain inactive for more than 28 days. Although the deleted groups
remain visible, they can't be used. An inactive group is defined as a group that hasn’t
run any desktop flows in the last 28 days.

７ Note

You must delete the hosted machine group and create a new one to continue using
its features. You'll need to reconfigure the connection that's associated with your
cloud flow.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Hosted RPA Best Practices and FAQ
Article • 03/10/2025

This section provides an overview of the best practices and frequently asked questions
related to hosted RPA (Robotic Process Automation). It covers various aspects such as
hosted machines and hosted machine groups configuration, maintenance and
management, custom virtual machine (VM) images, access, and security.

Capability summary
ﾉ Expand table

Feature Hosted Machine Hosted Machine Group

Description Hosted machines offer Hosted machine groups provide scalable,
developers an easy setup to unattended automation by dynamically
build, test, and deploy desktop provisioning virtual machines to handle
flows, enabling both attended spikes in demand, optimizing resource
and unattended modes, with allocation, and reducing costs by
scalability through machine balancing bot capacity across multiple
groups for robust automation. processes based on real-time needs.

Custom VM Supported Supported
image via Azure
Compute Gallery

Custom VNET Supported Supported
via Azure Virtual
Network

Device join • Microsoft Entra join • Microsoft Entra join
types • Microsoft Entra Hybrid join • Microsoft Entra Hybrid join (preview)

User accounts • Work or school account • Work or school account
• Local account

Device • Intune • Conditional access policy
management • Active Directory (AD)-based

Group Policy (GPO) if using
Microsoft Entra Hybrid join
• Conditional access policy

Implementation checklist



ﾉ Expand table

Phase Checklist                                 Description

Setup • Licensing • Licensing: Refer to the licensing section to
• VM image requirement understand how hosted virtual machines are
• Network requirement licensed and how many you need for your project.
• Device join requirement • VM image requirement: If you're running Web
• Environment requirement automation, then the vanilla VM image provided

by Microsoft might be sufficient. If you need
specific desktop apps as part of your desktop
flow automation, then you might consider using a
custom VM image or using device management
tools such as Intune to install the required
desktop apps via policies.
• Network requirement: If you need to access on-
premises resources or want to manage inbound
and outbound traffic of your hosted virtual
machines using Azure Firewall or Network
Security Groups (NSGs), you need to configure a
custom network connection.
• Device join requirement: All hosted virtual
machines are Microsoft Entra joined by default. If
your automation requires a device joined to the
Active Directory (AD) domain, you need to
configure Microsoft Entra Hybrid join.

Governance • Permissions Refer to the governance section to understand
• Device management how IT and Center of Excellence (COE)
• Security administrators can govern the use of hosted
• Capacity management virtual machines.

Maintenance • Updates Refer to the maintenance and management
• Monitoring section to understand how IT and Center of

Excellence (COE) administrators can ensure
hosted virtual machines stay up to date with the
latest security patches and desktop automation
requirements, and how to monitor them.

Licensing
Hosted RPA requires the Power Automate Hosted Process license (Power Automate
Pricing ) (previously known as the Power Automate hosted RPA add-on). Each Power
Automate Hosted Process capacity can provision one hosted machine or be used as
shared capacity across hosted machine groups.



For example, an environment with 20 Power Automate Hosted Process capacity could be
utilized as such:

10 hosted machines
Three hosted machine groups sharing 10 bots. Refer to load balancing hosted
machine groups.

Learn more about licensing in the Power Automate licensing page.

Governance
A Center of Excellence (COE) Administrator controls user access to specific resources
within the hosted RPA solution in Power Automate. Learn more about the permissions
based on security roles relevant to the hosted RPA solution that leverages Microsoft
Dataverse enforcement using security roles, teams, and business units to control access
to tables, fields, and records with permission and row-level access control.

IT & COE Administrators have the necessary tools to manage hosted virtual machines:

ﾉ Expand table

Tools Description Supported
scenarios

Microsoft Intune With Intune, you can create policies that applies to these • Hosted
devices to ensure that they are compliant based on your machines
organization's policies.

Active Directory Devices that are hybrid joined can utilize GPOs for • Hosted
(AD)-based Group configuration and policy management, allowing machines
Policy (GPO) if using administrators to apply GPOs as they would with any
Microsoft Entra other domain-joined device.
Hybrid join

Conditional access Conditional Access policy in Microsoft Entra ID (formerly • Hosted
policy Azure AD) is a security feature that enforces access machines

requirements based on specific conditions. It is structured • hosted
as an "if-then" statement, where assignments define the machine
conditions (who, what, and where), and access controls groups
specify the actions to be taken (e.g., grant or block
access).

COE Administrators can also monitor and govern the usage of the hosted RPA solution
within an environment using the Hosted Process capacity utilization dashboard.



Custom VM images
Use a custom VM image for hosted virtual machines to create a consistent and tailored
environment. Custom VM images include preconfigured applications, security settings,
and performance optimizations to support automation and compliance needs.

Create custom VM images: Find instructions and requirements for creating custom
VM images for hosted machines and hosted machine groups.

Update VM images: Since hosted machines are persistent virtual machines, regular
patching and updates after provisioning is recommended. For hosted machine
groups, you can update the custom VM image by following these update
instructions. Learn more about keeping your hosted VMs up-to-date by reviewing
Maintenance and Management guidance.

Delete VM images: Power Automate prevents users from deleting VM images from
the Power Automate Portal if they're currently in use by a hosted machine or
hosted machine group. However, a VM image can still be deleted directly from the
Azure Compute Gallery, which fails if a hosted virtual machine is being provisioned.

Custom network connection
A custom network connection connects hosted virtual machines to your virtual network.
It enables secure communication among hosted machines, the Internet, and on-
premises networks, providing full control over traffic.

Create custom network connections: Follow the instructions and requirements for
creating custom network connections for hosted machines and hosted machine
groups.

７ Note

Ensure access to the required service endpoints:

Power Automate service endpoints
For hosted machines, refer to specific requirements for Windows 365 service,
Azure Virtual Desktop session host virtual machine, Microsoft Intune
service, and physical devices network connectivity.

Maintenance and updates



Proper maintenance and update of hosted virtual machines ensure smooth operations.
When provisioning hosted machines or hosted machine groups using the default VM
image provided by Microsoft, these images are automatically updated monthly
following the Windows Servicing & Delivery security patch release schedule.

Options for updating hosted virtual machines
Hosted machines. Use Intune to manage devices by applying policies that ensure
compliance with your organization's requirements. For example, ensure devices are
regularly updated with the latest security patches.

Hosted machine groups. Since hosted machine groups are considered stateless,
they're provisioned based on the specified VM images. When you use custom VM
images, use tools such as the Azure VM Image Builder to integrate the image-
building process with your existing DevOps pipeline.

Miscellaneous
Additional information on hosted RPA:

Common registry customization settings for Microsoft Edge. As web-based
automation using Microsoft Edge is a common automation scenario, it might be
useful to define Microsoft Edge behavior in areas such as startup behavior,
password management, and pop-up handling. Use the Microsoft Edge Browser
Policy for configuration, which can be enforced via registry settings applied to a
custom VM image.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create an Azure Key Vault credential
Article • 03/21/2025

The Credentials page in Power Automate allows you to create, edit, and share sign in
credentials using Azure Key Vault and use them in desktop flows or desktop flow
connections.

You can also create credentials with CyberArk® (preview).

） Important

Currently, this feature isn't available for US Government Clouds.

Prerequisites
Credentials use secrets stored in Azure Key Vault. To create credentials, your admin must
first set up Azure Key Vault.

In short, the admin needs to ensure:

1. Microsoft Power Platform resource provider is registered in Azure subscription.
2. There's an Azure Key Vault that contains the secrets to be used in the credentials.
3. Dataverse service principal has permissions to use the secrets.
4. Users who create the environment variable have appropriate permissions to the

Azure Key Vault resource.
5. The Power Automate environment and the Azure subscription must be on the

same tenant.

To configure Azure Key Vault, follow the steps described in Configure Azure Key Vault.

Certificate-based authentication (preview)
Microsoft Entra ID certificate-based authentication is a single factor authentication that
lets you meet multifactor authentication (MFA) requirements. Instead of using
password-based authentication, use certificate-based authentication (CBA), which
verifies your identity based on digital certificates.

To use CBA, follow the steps in Configure certificate-based authentication. Otherwise,
start creating a credential.



Create a credential
To create your credentials:

1. Go to the Credentials page. If you don't see the Credentials page, follow these
steps:
a. Select More in the left nav, then select Discover all.
b. Under Data, select Credentials. You can pin the page in the left navigation to

make it more accessible.

2. On the Credentials page, create your first credential by selecting New Credential.

Define credential name
Provide the following information to create your credential:

Credential name: Enter a name for the credential
Description (optional)

Select credential store
1. After selecting Next, select location to use credential.
2. Select Connection, Desktop flow, or Network as the location to use the credential.
3. If prompted, select Azure Key Vault as the type of credential store, and then select

Next.

ﾉ Expand table



Location to use Description Supported Azure Key
credential Vault authentication

Connection Used in a desktop flow connection, the credential is • Username and
used to sign into the machine during runtime password
(attended and unattended runs). • Certificate-based

authentication

Desktop flow In desktop flow automation, credentials let you sign • Username and
in, enter passwords, and perform similar actions password
without storing sensitive information in the script.

Network Used when creating Microsoft Entra hybrid join • Username and
network connection for hosted machine groups. password

Select credential values
In the last step of the wizard, select credential values. Depending on the location to use
the credential, there might be two types of supported authentications:

1. Username and password: The secret stored in the vault is a password.
2. Certificate-based authentication: The secret stored in the vault is a certificate.

Username: To select a username, you can use the dropdown. If you don’t have any
environment variables, select new:

Display name. Enter a name for the environment variable.

Name. The unique name is automatically generated from the Display name, but
you can change it.

Value. Populate the name of the user. For local users, provide username. For
domain users, provide <DOMAIN\username>  or <username@domain.com> .



７ Note

Credential username is a text environment variable. You can also create a text
variable from the solutions page and select it as username.

Password: To select a password, you can use the dropdown. If you don’t have any
secret environment variables, select new:

Display name. Enter a name for the environment variable.
Name. The unique name is automatically generated from the Display name, but
you can change it.
Subscription id. The Azure subscription ID associated with the key vault.
Resource group name. The Azure resource group where the key vault that
contains the secret is located.
Azure key vault name. The name of the key vault that contains the secret.
Secret name. The name of the secret located in Azure Key Vault.



７ Note

The subscription ID, resource group name, and key vault name can be found on the
Azure portal Overview page of the key vault. The secret name can be found on the
key vault page in the Azure portal by selecting Secrets under Settings. User access
validation for the secret is performed in the background. If the user doesn’t have at
least read permission, this validation error is displayed: "This variable didn't save
properly. User is not authorized to read secrets from 'Azure Key Vault path'."
Passwords use secret environment variables. You can also create a secret variable
from the solutions page and select it as password.

Create desktop flow connections using a
credential



You can now use your credential in a desktop flow connections

Use the credential in a desktop flow action
(preview)
） Important

Preview features aren’t meant for production use and might have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.
For more information, go to our preview terms .
This action isn't available in sovereign clouds yet.

1. Make sure you have a registered machine where your desktop flow runs. The
credential is retrieved from this machine.

７ Note

The registered machine is required for credentials to work properly at
runtime, even for local attended or debugging runs.

2. In the desktop flow designer, select the Power Automate secret variables
(preview) module and then select the Get credential (preview) action.

3. Specify the credential to retrieve. You see only the credentials defined as usable in
a desktop flow. In public preview, only credentials using Azure key vault or
CyberArk as a vault are supported.

4. Define the name of the variable you create. This variable is marked as "sensitive"
and can't be changed. This means the value of this variable isn't stored in the logs.

７ Note

Credential type variables are always enforced to be sensitive, independently
of how they're produced (Get credential (preview) action or reassigning a
credential variable to a new one, which inherits the same variable type). The
same applies to the 'Password' property of credential variables.



5. After you select Save, use your credential in another action. All Power Automate
actions can use credentials.

6. In the action field, select the variable picker. In your flow variables list, find your
credential and expand it. You can see the attributes Username and Password.
Select the one you want to use in this action (double-click).

7. Run your flow.

View where secrets are used
From Solutions page, you can retrieve all the dependencies of secret environment
variables. This helps you to understand where your Azure Key Vault secrets are used
before editing them.

Select one environment variable.
Select the advanced option and select Show dependencies.
You can see:

The credentials using this environment variable.
The connections using this environment variable.

Share a credential
You can share the credentials you own with other users in your organization and give
those users specific permissions to access it.

1. Sign-in to Power Automate , and then go to Credentials.
2. Select your credential from the list of credentials.
3. On the command bar, select Share.
4. Select Add people, enter the name of the person in your organization with whom

you would like to share the credentials, and then select the role you want to grant
to this user:

Co-owner (can edit). This access level gives full permission to that credential.
Co-owners can use the credential, share it with others, edit its details, and
delete it.
User (can view only). This access level only gives permission to use the
credential. No edit, share, or delete permissions are possible with this access.
User (can view and share). This access level is the same as the can view only
option, but it gives permission to share.

5. Select Save.



７ Note

By sharing your credential, all the environment variables used in the credential are
shared as well. Removing permissions on a credential doesn't remove permissions
on the environment variables.

Delete a credential
1. Sign in to Power Automate , and then go to Credentials.
2. From the list, select the credential you want to delete, and then select Delete

machine on the command bar.

７ Note

Deleting a credential doesn't delete the associated environment variables.

Export a desktop flow connection using
credential
７ Note

You should first read the article about ALM for desktop flows.

You can export a cloud flow with a desktop flow connection using credential. You should
import the solution containing the credential and the related environment variables first
then import the one containing the cloud flow and the desktop flow.

Limitations
Currently, this feature is available only for desktop flow connections.
You can't edit the selected username and secret in an existing credential. If you
want to change the value of username and password, you need to either update
the environment variables or the Azure Key Vault secret.
If your environment uses a managed identity to access your Azure Data Lake, that
identity is also used to access your Azure Key Vault. Only one enterprise policy can
connect to the Dataverse environment simultaneously. Ensure that the managed
identity has the appropriate permissions to the Azure Key Vault resource.



Update a secret (password rotation) -
Deprecated
７ Note

This section is now deprecated for desktop flow connections. Desktop flow
connections using Credentials are now retrieving secrets during the flow execution.
It is not necessary anymore to create this custom flow to update the connections.
The connections using Credentials created before April 2024 should be updated to
benefit of the automatic update.

Prerequisites for updating a secret (password rotation)
Ensure Event Grid is registered as a Resource provider in Azure. Learn more about
resource providers.
Ensure users who use Event Grid trigger in Power Automate have Event Grid
Contributor permissions. Learn more

７ Note

This section requires specific permissions such as system admin of the organization
otherwise only your own desktop flow connections will be updated.

Create a cloud flow using Event Grid trigger
When you edit secrets in your Azure Key Vault, you want to ensure that the credentials
and connections using these secrets are always up to date to avoid breaking your
automations. In Power Automate, you need to create a cloud flow that updates the
credentials when secrets are changed in Azure Key Vault.

This cloud flow contains one trigger and one action:

1. Trigger: When a resource event occurs (Event Grid)

Resource type: Microsoft.KeyVault.vaults
Resource name: Provide the name of the key vault.
Subscription: Provide the name of the subscription.
Event type: Microsoft.KeyVault.SecretNewVersionCreated

2. Action: Perform an unbound action (Dataverse)



Action name: NotifyEnvironmentVariableSecretChange
KeyVaultUrl: Topic
Secret name: Subject

If you use one Key Vault for all your secrets, you need only one cloud flow. If you have
several Key Vaults, you need to duplicate the cloud flow and update the resource name.

To ensure that your cloud flow is working correctly with Azure Key Vault:

1. Go to your Key Vault.
2. Select Events.
3. In Events subscriptions, check if you can see a LogicApps webhook.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create a CyberArk credential
Article • 03/21/2025

This feature allows users to create a Power Automate credential that retrieves CCP
CyberArk secrets from vault during runtime.

Availability
Currently, this feature isn't available for US Government Clouds.

Prerequisites

Set up your CyberArk Central Credential Provider (CCP)
If your CyberArk Central Credential Provider (CCP) isn't set up, complete the following
actions:

1. Install the Central Credential Provider (CCP). Learn more at
https://docs.cyberark.com/credential-providers/latest/en/Content/CCP/CCP-
Installation.htm .

2. Ensure that your machines can communicate with the CyberArk server.
3. Allow https connections to contact the CCP AIMWebService.

Create an application with client certification
authentication from PVWA
A signed certificate enables the application authentication with a certificate serial
number.

To add a signed certificate:

1. Sign-in to CyberArk’s Password Vault Web Access (PVWA).

2. From the left navigation, select the Applications tab and then select Add
Application.



3. Provide the information in the Application window (at least a name) and select
Add.

4. In the details of the application, select Add on the Authentication tab.

5. Select Certificate serial number and enter the value. Learn more in Application
authentication methods .

Set up a CyberArk safe that contains their user accounts
(Optional) If you don’t have a safe yet, you can create a Safe from PVWA:

1. From the left navigation, select Policies and then select Safes.

2. Select Create Safe.

3. Enter a safe name and select PasswordManager.

4. Enter Safe members and Access then select Create Safe.

From PVWA, you can then add your machine accounts.

７ Note

You can also create accounts from PrivateArk client.

5. From the left navigation, select Accounts > Add Account.

6. Select Windows as system type.

7. Select the safe you created to store your robotic process automation (RPA)
machine accounts.

8. Provide information about your account and select Add.



Define application and credential provider as safe
member

1. Add the Credential Provider user as a Safe Member with the following
authorizations:

List accounts
Retrieve accounts
View Safe Members

2. Add the application as a Safe Member with the following authorizations:

Retrieve accounts

Add a CyberArk application to machine / group
） Important

It isn't currently possible for users to associate a CyberArk application with
machines or groups that are shared with other users.

If you want to run a desktop flow on a machine or a group using CyberArk credentials,
you need to add your CyberArk application information in the Power Automate portal.



1. Sign-in to Power Automate .

2. From the left navigation, select Machines, and then select the machine or the
group.

3. In the Machine details, select Configure CyberArk.

4. Select New application.

5. Enter the app ID of the application you created from CyberArk PVWA.

6. Select the certificate, which stores the private and the public key of the certificate.

The allowed formats are .pfx or .p12 files.
The private key should be marked as exportable.

7. Enter the certificate file password that is used to open the certificate file.

７ Note

The password is not stored. The certificate is opened and encrypted with the
public key of the machine group so it is only readable from the registered
machines.

8. Enter a description (optional) and then select Save.



Create a CyberArk credential
Now that you complete all the prerequisites steps, you can create your CyberArk
credentials.

1. From the left navigation, select Credentials.

2. Select New credential.

3. In the wizard, define a credential name and a brief description, then select Next.

4. When creating a credential in Power Automate, specify where this credential is
used. You can use a credential for two types of usage:

Connection: These are the credentials of the user session on which the
desktop flow runs.

Desktop flows (preview): These are credentials that you want to use in a
desktop flow. For example, SAP credential, SharePoint credential, Excel
password, etc.

７ Note

For public preview, credentials used in desktop flow actions require
CyberArk.

5. Select CyberArk CCP as the type of credential store.

6. If you already defined a CyberArk store, you can select it from the dropdown.
Otherwise, select Create new.

Display name: Provide a name for your CyberArk store.



Server address: The server address is the Central Credential Provider URL. For
example, https://svc.skytap.com:8992 .

７ Note

Versions below the August release don't support a server address ending
with a "/".

Application Id: To find the Application ID, open CyberArk PVWA (Password
Vault Web Access) on a web browser and navigate to the Applications tab.

Safe: Populate the name of the safe displayed in CyberArk PVWA.

Folder (optional): Populate the folder name where your credentials are
stored. By default, credentials are stored in the "Root" folder.

7. In the last step of the wizard, you need to provide the information about the user
account:

Username: Select a username from your text environment variables or create
a new one by selecting new.

If you create a CyberArk credential to be used in a desktop flow connection,
provide your device account. Populate the name of the user (for example,
<MACHINENAME\User>  or <local\User> ) or a Microsoft Entra ID account, such as
<DOMAIN\User>  or <username@domain.com> .

Object name: The object name corresponds to the CyberArk object name
store in the CyberArk safe. This value is also called account name in PVWA.



Use the credential in a desktop flow connection
Your credential is now created. You can use it in a desktop flow connection to run
desktop flows from cloud flows.

Use the credential in a desktop flow action
(preview)
） Important

Preview features aren’t meant for production use and might have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.
For more information, go to our preview terms .
This action isn't available in sovereign clouds yet.

1. Ensure you have a registered machine where your desktop flow is executed. The
credential is retrieved from this machine.

７ Note

The registered machine is required for credentials to work properly at
runtime, even for local attended or debugging runs.

2. In the desktop flow designer, select the Power Automate secret variables
(preview) module and then select the Get credential (preview) action.

3. Specify which credential to retrieve. You see only the credentials defined as usable
in a desktop flow. In public preview, credentials using Azure Key Vault or CyberArk
as a vault are supported.

4. Define the name of your produced variable. This variable is marked as "sensitive"
and can't be modified. This means the value of this variable isn't stored in the logs.

７ Note

Credential type variables are always enforced to be sensitive, independently
of how they are produced (Get credential (preview) action or reassigning a



credential variable to a new one, which inherits the same variable type). The
same applies to the 'Password' property of credential variables.

5. After you select Save, use your credential in another action. All Power Automate
actions can use credentials.

6. In the action field, select the variable picker. In your flow variables list, find your
credential and expand it. You can see the attributes Username and Password.
Select the one you want to use in this action (double-click).

7. Run the flow.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Configure certificate-based
authentication
Article • 03/31/2025

Power Automate lets you create credentials using certificate-based authentication (CBA).
Microsoft Entra ID certificate-based authentication helps meet multifactor
authentication (MFA) requirements.

How CBA credentials work in Power Automate

1. Certificates are stored and managed in Azure Key Vault.
2. Credentials are created in Power Automate and stored in Dataverse.
3. Credentials are used in the desktop flow connection.

７ Note

CBA is supported for Windows session credentials (desktop flow connection) but
cannot be used within the desktop flow or with other connectors.

How to configure Microsoft Entra certificate-
based authentication
To use this feature, make sure you meet these prerequisites.

７ Note

These operations require an Entra ID tenant admin.



Follow the instructions in Configure the certification authorities to set up and use
Microsoft Entra CBA for tenants in Office 365 Enterprise and US Government plans.

(Optional) Microsoft Entra ID CBA supports validating
MFA requirements
Microsoft Entra CBA can be used as a second factor to meet MFA requirements with
single-factor certificates.

Certificates are stored in Azure Key Vault
To use certificates with Power Automate, store them in Azure Key Vault. Learn more at
how to import a certificate in Azure Key Vault.

７ Note

The certificate format must be .pfx (not PEM).

Create a credential
After completing these steps, create your Azure key vault credential.

Admin consent for unattended runs
Admin consent is required for unattended runs with certificate credentials on a
Microsoft Entra ID joined device. Learn more at Admin consent for unattended runs.

Limitations and minimal requirements
1. To use certificate-based authentication (CBA) credentials in Power Automate, store

them in Azure Key Vault. Other vaults aren't supported today.
2. Use Power Automate for desktop version 2.49 or later.
3. If you're using Windows Server, version 2019 or later is supported.
4. Target machines must be joined to Microsoft Entra ID.

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Create a machine mapping credential
(preview)
Article • 02/19/2025

[This article is prerelease documentation and is subject to change.]

This feature lets you map user account credentials to your robotic process automation
(RPA) machines.

） Important

This is a preview feature.
Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.
This feature is gradually rolling out across regions and might not be available
in your region.

How a machine mapping works
A machine mapping is a type of credential that can be used in desktop flow connections
to use specific credentials depending on the machine assigned.

Example 1

For a machine group that contains multiple machines, you can define for each
machine which user account must be used to sign in.

７ Note

There isn't a restriction on mapping multiple credentials to the same machine.

Example 2

For a server, you can define all the user accounts that can execute your desktop
flow.



Availability
Currently, this feature isn't available for US Government Clouds and China regions.

Prerequisites
To create a mapping between machines and credentials, follow these steps:

1. Ensure the Microsoft Flow Extensions core package (MicrosoftFlowExtensionsCore)
Dataverse solution in your environment equals to 1.8.36.0 or higher.

2. Ensure the version of Power Automate desktop app is 2.50 or higher.
3. Create your credential using Azure Key Vault or CyberArk. To select them in your

mapping, define these credentials as usable in connection.
4. Register your machines in this environment. If your machine isn't registered, follow

the steps in Manage Machines.
5. CyberArk only: Configure all machines using CyberArk credentials with a CyberArk

application.

Create a machine mapping
1. From the left navigation, select Credentials.

2. Select New > Mapping between machine and account credential(s).

3. In the wizard, define a credential name and a brief description, then select Next.

4. Define the default value of your mapping used when an assigned machine doesn't
have a mapped credential.



5. For each machine, select one or several credentials to be used to sign in to the
machine.

a. From the machine dropdown, select the machine you would like to apply the
mapping to.

７ Note

You can map a machine with multiple credentials.
After a machine is mapped with credentials, it can't be selected for
another mapping.
Map all your machines with credentials in the same machine mapping
or define a mapping for each machine group.

b. From the credential dropdown, select the credentials to map to this machine.

７ Note

In the dropdown, you only see credentials that are usable in connections.
All credentials listed for a machine must be working credentials for that
machine. In other words, if one credential fails for a machine, this machine
is considered as not available even if there are other credentials defined for
this machine. You can't map a mapping credential to another mapping.



6. Once the mapping between a machine and credentials is done, you can see it in
the list of mappings. You can edit the mapping to change the credentials or delete
it.

7. If you need to define a new mapping, select Add new.

8. After you complete the mappings, select Save.

Use the machine mapping in a desktop flow
connection
You can now use this mapping in a desktop flow connection. Instead of selecting a
single credential, you can select this mapping.

During runtime, the appropriate user account credential defined in your mapping is
used to connect to the assigned machine.

Share a machine mapping



From the list of credentials, you can share a mapping with other users:

1. Select a credential.
2. Select Share.
3. From Add People, enter the name of the people you want to share the mapping

with.
4. Finally, select the permissions for this user (user, user + share, co-owner).

When you share the mapping, you also share all the credentials selected for this
mapping. Whenever you update the mapping with new credentials, those credentials
are shared with other users of this mapping. Removing permissions on a machine
mapping credential doesn't remove permissions on the mapped credentials.

Limitations
1. The run detail page doesn't display the credential used in the credential mapping.

Retrieve the credential used in the flowsession  table in the credentials  field.
2. In machine mapping credential, the default credential can be exported and

imported, but you must reconfigure the mappings between machines and user
credentials in the environment where the machine mapping credential is imported.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Manage desktop flow connections
Article • 01/28/2025

） Important

Before using a machine to run desktop flows from the cloud, ensure that the
machine is secured and the machine's admins are trusted.

Before using the Run desktop flow action in your cloud flow to trigger a desktop flow,
you need to create a connection to your machine. To create a connection:

1. Sign in to Power Automate , go to Data > Connections, and then select New
connection.

2. Search for Desktop flows, and then select the appropriate result.

７ Note

Desktop flows connection cannot be shared with other users.

There are two different methods to connect Power Automate with your machines (or
groups).

Create a connection: Connect with username
and password



With this option, you need to provide the machine information and device credentials:

Connect: Select if you want to connect to a machine or a machine group.

To connect to a machine or a machine group, select Connect with username and
password, and choose the appropriate machine or machine group in Machine or
machine group.

Option 1: Select credential
1. Select Switch to credentials.
2. You can now select the credential you want to use on the selected machine and

select Create. If you don't have any credential yet, select New credential. You can
create credentials with secrets stored in Azure Key Vault or CyberArk® (preview).



Option 2: Enter username and password
Domain and username: Provide your device account. To use a local account,
populate the name of the user (for example, <MACHINENAME\User>  or <local\User> )
or a Microsoft Entra ID account, such as <DOMAIN\User>  or <username@domain.com> .

Password: Your account’s password.



Create a connection: Connect with sign-in for
attended runs
With this option, you don't need to provide session credentials. This option might be
helpful when your organization doesn't allow username and password for user sessions.

Prerequisites
To use connection with sign-in, you need to meet the following prerequisites:

Microsoft Entra ID users must be in the same tenant as the selected environment
in the Power Automate portal.
The target (machine / group) should be Microsoft Entra joined or AD domain-
joined. Microsoft Entra joined targets must be synchronized with Microsoft Entra
ID.
If the target is AD domain-joined but not Entra joined, you must allowlist your
Power Platform tenant.
The Microsoft Entra user account must be granted permission to open a Windows
session on the target machines (interactive sign in). At runtime, there should be a



Windows user session matching the connection user opened on the machine in
order to process the run (same as running attended with other connection types).
The tenant of the target Microsoft Entra account is configured to use modern
Authentication with Microsoft Entra ID.

Set up the connection with sign-in
To set up a connection with sign-in:

1. Select Connect with Sign-in in the Connect dropdown.
2. Select the target (machine or machine group).
3. Select Sign in.
4. Pick or provide an Microsoft Entra account in the sign in pop-up.

The desktop flow connection is automatically created.

How it works
An access / refresh token is created by the Microsoft Entra ID authentication
during connection creation.
The created token's scope is limited to executing desktop flows.
The Power Platform services manage these tokens.

Limitations
Connect with sign-in works only for attended runs. Running unattended with this
kind of connection will fail.
Connect with sign-in runs likely fail with a PasswordlessTokenExpiry error if
AsyncDisabled is set to True.
Queue time duration is limited to one hour.
On AD-joined but not Entra-joined machines, you must allowlist your Power
Platform tenant for your machine to trust passwordless tokens from that tenant. If
your tenant is not allowlisted, connect with sign-in runs will most likely fail with
UnallowedTenantForConnectWithSignIn  errors. Connect with sign-in connection
creation and testing will fail with either Unable to connect. The credentials for
the machine are incorrect.  or Tenant [tenantId] needs to be explicitly
allowlisted to authorize 'connect with sign-in' runs on the machine  error
messages.

） Important



If you consistently encounter issues when creating a connection on a new machine,
first try to remove it, and then register it again.

Share a desktop flow connection (preview)
[This article is prerelease documentation and is subject to change.]

You can share a connection with other Service Principal users in your organization and
give those Service Principal users specific permissions to access it.

） Important

This is a preview feature.
Preview features aren’t meant for production use and might have restricted
functionality. These features are subject to supplemental terms of use , and
are available before an official release so that customers can get early access
and provide feedback.

To share a desktop flow connection:

1. Sign in to Power Automate .
2. Go to Monitor > Connection.
3. Select your connection from the list, and then select the Share button.
4. Enter the name of the service principal user in your organization with whom you

want to share the connection.
5. Select the permissions they can access the connection with:

Can use
Can edit

6. Select Save.

Limitations
You can only share desktop flows with a specified run owner identity. Learn more
in Select a run owner.
Recipients of desktop flow connection sharing are limited to service principal users.
You can't share a desktop flow connection with the "Can Share" permission (only
"Can use" or "Can edit").



Select a run owner
A run owner of a desktop flow is the user whose permissions are checked during the
flow execution.

By default, connections created using the Power Automate portal use the connection's
creator as the run owner.

You can select a specific identity as the run owner. Learn more in Set a run owner on a
desktop flow connection.

Desktop flow connection audit
You can see the desktop flow run owner on the run status page. Learn more in Run
status. You can also see the summary of desktop flow run owner usage on the Desktop
Flow activity page. Learn more in Desktop flow activity.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Allowlist your Power Automate tenant
to allow registration and connect with
sign-in
Article • 09/10/2024

For added security, connect with sign-in now requires your Power Automate tenant to
be allowlisted to authorize connections on Active Directory domain-joined machines
that aren't Microsoft Entra joined. Learn more about this security patch here .

Allowlisting a tenant also allows this machine to register to that tenant.

How to find your Power Automate tenant ID
Use the following steps if you don't know your tenant ID:

1. Sign into the Power Automate portal .
2. Select Ctrl  + Alt  + A .
3. Locate the tenant ID in the tenantId  property.

How to allowlist a tenant ID on your machine
） Important

The following steps can be used to allowlist your tenant on a single machine.
However, we recommend consulting with your domain administrators to create a
Group Policy Object (GPO) that applies the appropriate allowlist across all your
machines. Creating a GPO like this can centrally specify which tenants are trusted to
use Power Automate Desktop on the machines in your tenant.

1. Open the registry editor and navigate to this key
Computer\HKEY_LOCAL_MACHINE\SOFTWARE\WOW6432Node\Microsoft\Power Automate

Desktop\Registration

2. If the AllowedRegistrationTenants  registry value doesn't already exist, create it by
right-clicking and selecting New > String Value. Name it
AllowedRegistrationTenants .



3. Right click the AllowedRegistrationTenants registry value and select Modify. Edit
the value to add your tenant ID. The expected value is a comma-separated list of
tenant IDs such as "aaaabbbb-0000-cccc-1111-dddd2222eeee" or "aaaabbbb-
0000-cccc-1111-dddd2222eeee,bbbbcccc-1111-dddd-2222-eeee3333ffff".

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Manage desktop flows
Article • 02/21/2025

After creating desktop flows, you might need to view, edit, or check their status. To
achieve all these tasks, go to My flows > Desktop flows in the Power Automate portal.

See a list with desktop flows
1. Sign in to the Power Automate portal .

2. Go to My flows > Desktop flows.

Using the available options in this tab, you can create new desktop flows and edit
or delete existing desktop flows.

７ Note

If you delete or rename a desktop flow, select the refresh button to reflect the
changes in the desktop flows list.

See details of desktop flows
For each of your desktop flows, you can see its details by selecting its name from the list
of desktop flows. You can see various details including:

The run history with details of each run.
The applications or websites used in the desktop flow.



Follow these steps to see the details for a desktop flow:

1. Sign in to the Power Automate portal .
2. Go to My flows > Desktop flows.
3. Select any of your desktop flows.

Generate flow description using Copilot
(preview)
[This topic is prerelease documentation and is subject to change.]

Generate a flow description for flows by the press of a button. Copilot then analyzes the
flow and generates a description for it. This feature is also available from the flow
properties in the Power Automate for desktop console. More information: Power
Automate for desktop console

） Important

This is a preview feature.
Preview features aren’t meant for production use and might have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.
To understand the capabilities and limitations of this feature, go to FAQ for
generating a flow description using Copilot.

Prerequisites



Currently, the generate flow description using Copilot functionality is only available
in environments located in the United States.
Currently, the generate flow description using Copilot functionality is only available
for users with a work or school account.

Use Copilot to generate the description
To generate a flow description, go to the details of the flow where you want to generate
the description, and then select Edit. Under the Description text area, select Let Copilot
create a description. Copilot analyzes your flow and populates the description with a
summary of your flow.

Help us improve this feature
Send feedback by selecting the thumb up or thumb down icon underneath the AI-
generated content. Once you do, a dialog box appears, which you can use to submit
feedback to Microsoft.

７ Note

If you can't see the dialog box, your Power Platform admin might have turned it off.
More information: Disabling the user feedback functionality



Disabling the generate flow description using Copilot
functionality
To disable the generate flow description using Copilot functionality, Power Platform
admins can contact Microsoft support. More information: Get Help + Support

Disabling the user feedback functionality
As a Power Platform admin you can prevent users from sending feedback to Microsoft
by disabling the disableSurveyFeedback tenant setting using PowerShell. More
information:

List tenant settings (preview)
Set TenantSettings

Data subject rights requests on user feedback
Tenant administrators can view, export, and delete the feedback from users by signing in
to the Microsoft 365 admin center , and then select Health > Product feedback.

Related information
FAQ for generating a flow description using Copilot

Share desktop flows
You can share a desktop flow with other users in your organization, giving those users
specific permissions to access your flows.

Follow these steps to share a desktop flow:

1. Sign in to the Power Automate portal .

2. Go to My flows > Desktop flows.

3. Select the desktop flow you want to share, and then Share.

4. Select Add people, and then enter the name of the person in your organization
with whom you'd like to share the desktop flow.

７ Note



You can also enter a Microsoft Dataverse team name instead of the name of
the person. If you want to share with a Microsoft Entra group, you first need
to create a Microsoft Entra Group team in Dataverse based on the Microsoft
Entra Group. More information: Microsoft Dataverse teams management

5. Select the user and then select either User or Co-owner as the permission for the
person with whom you share the flow.

Co-owner: This access level gives the co-owner full permissions to the
desktop flow. They can edit, share, and delete the desktop flow.
User: This access level gives permission to only use that desktop flow in a
cloud flow and run it locally with Power Automate for desktop. No edit,
rename, delete, or share permissions are possible with this access.
Alternatively, those users can create a copy of the desktop flow using the
Save as option, and work independently.

6. Select Save.

７ Note

Once a desktop flow is shared, owners and co-owners can change the access of
each user by selecting Manage access on the desktop flow details page. If
someone shares a desktop flow with you, select the refresh button to see it in the
Shared with me flows list. After you share a desktop flow with new co-owners, the



co-owners see all the desktop runs that happen in the future. However those co-
owners don't see the desktop flows already completed before sharing.

Reassign desktop flows
To reassign a desktop flow to another user:

1. Sign in to the Power Automate portal .

2. Go to Data > Tables.

3. Go to the All tab, and then search for the Process table.

4. Select Edit.

5. Select your desktop flow in the list, and then select Edit row using form.

6. Select Assign, and then confirm the changes.



Copy desktop flows
To duplicate an existing desktop flow:

1. Sign in to the Power Automate portal .

2. Go to My flows > Desktop flows.

3. Select the flow you want to copy.

4. Select Save As.

5. Enter a name for the new desktop flow.

6. Select Save.

Manage desktop flows access
For each of your desktop flows, you can manage its access by selecting Manage access
in the desktop flows details page.



In this page, you can:

Share the desktop flow with another user.
Edit users' permissions.
Remove users' permissions for this desktop flow.

７ Note

Users of an environment with a Dataverse security role that grants them Read
access to all records in the Process table (where different types of flows are
stored), are listed as Co-owners of any desktop flows created in that
environment. They can't be removed as co-owners unless you change
privileges and access level in the underlying security role.
The System Customizer role is an example of a security role with
environment-wide Read privileges for desktop flows. This role has Read
permission set to Organization on the Process table, allowing users with this
role to view all desktop flows in the environment and be marked as co-
owners. It's highly recommended to review each security role before assigning
it to users to ensure that the privilege set and access level are appropriate for
the intended use case.
Starting from version 2.46 of Power Automate for desktop, if a message
appears indicating that the user doesn't have sufficient permissions in an
environment using schema V2, Read access must be provided to their
respective security role on the Solution entity in Dataverse.
When a user isn't part of an environment anymore, you can continue to see it
as a deactivated user. You're notified in the Manage access section of the



desktop flow if this flow is shared with deactivated users. In this situation,
remove access to them.

Learn more
Create desktop flows.
Trigger desktop flows from cloud flows.
Monitor desktop flow runs.
Desktop flow activity.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Work queues overview
Article • 10/14/2024

Work queues in Power Automate can be used to store process-relevant data and
provide a way to decouple complex processes and automations, allowing them to
communicate asynchronously.

They can play a crucial role in improving the efficiency, scalability and resiliency of
automations and help prioritize work, with the highest-priority items being completed
first, regardless of whether they've been processed by digital workers, human workers,
or through integrations.

Just as manufacturing assembly lines are designed to decouple different complex stages
of production, work queues can help decouple different areas of a process allowing
each part to operate independently and exchange prioritized inputs and outputs
asynchronously.

The following illustration shows and end-to-end process that uses work queues to
communicate prioritized work between process steps and automations.



Prerequisites
To use work queues in Power Automate the following are required:

Premium Power Automate license
Environment maker role (or other roles that include access to work queue tables)
Power Automate URL and IP address configurations

Public cloud
Government cloud



Work queue benefits
The following table lists some of the benefits of using work queues.

ﾉ Expand table

Benefit Description

Increased Work queues can increase the efficiency and throughput of an automation
efficiency and process by helping to ensure timely and resilient completion of work. They
scalability can also help decouple parts of your automation so that you can scale them

independently.

Better resource By using work queues, you could improve robot utilization, and optimize
utilization the number of robots needed to complete work.

Consistent Work queues can help you prioritize work items, with the highest-priority
prioritization items being completed first, regardless of whether they've been processed

by digital workers, human workers, or through integrations.

Centralized Work queues provide human-in-the-loop monitoring experiences that allow
monitoring fusion teams of business users and IT professionals to work hand-in-hand to

remediate work queue processing exceptions.

By using work queues in combination with other digital workforce management tools,
such as hosted machine groups, advanced analytics with Power BI, and process mining,
organizations can gain deeper insights into the performance of their automation to
improve the efficiency, scalability and resiliency while also reducing costs and improving
the quality of services.

When to use work queues
Work queues are a highly versatile tool for managing workloads more effectively and
ensuring that important work is completed on time, regardless of the complexity of the
process or the size of the automation they're being used for.

Example of a typical work queue use case
As part of a supply chain process, thousands of transactions have to be processed
every day.

Process completion is based on a strict SLA and has to be complete by 11PM since the
outcome is used as input to another process.

To conform with the SLA, automations need to be built that:



1. Push transactions to a centrally managed and monitored work queue.
2. Process transactions concurrently across a dedicated machine group of 20

machines.

In cases where the automation is unable to process a particular transaction within the
SLA, users are notified to have the transaction processed manually instead.

How to get started
Create your first work queue

Learn more
Manage work queues
Bulk-import work queue data
Trigger work queues
Process work queues
Known issues and limitations
Work queues actions

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Manage work queues
Article • 12/05/2024

Power Automate provides rich user experiences and features that allow you to efficiently
and centrally manage work queues within your environments.

View work queues
To view the list of work queues:

1. Go to Power Automate  and sign in with your credentials.
2. On the left menu, select the Monitor section.
3. Select Work queue.

If you have already created work queues or if any work queue has been shared with you,
you see a list similar to the below.



Create a work queue
To create a work queue:

1. Go to Power Automate  and sign in with your credentials.
2. On the left menu, select the Monitor section.
3. Select Work queue and then select + New work queue.
4. In the New work queue side panel, enter a work queue name for the queue.
5. (Optional) Enter a description for the work queue.
6. (Optional) Enter a work queue key for the work queue. When provided, the value

must be unique within this queue. If left empty, a unique value is automatically
provided by the system.

7. (Optional) Activate this section and select a default lifespan value for work queue
items in the Items expire after fields.

７ Note



If you set an Items expire after value for a work queue, any item added
without an explicit expiration date will expire after the entered Items expire
value has elapsed. So if you set the Items expire after to 30 minutes, an item
added at 2:00 PM will expire at 2:30 PM.

8. (Optional) Select either JSON or XSD as the schema type for work queue item
input validation to ensure that input data conforms to the defined schema. Next,
select Add schema to enter or paste the desired schema.

７ Note

Once a schema is added to a work queue, it can't be changed to avoid
data inconsistencies and processing failures.
Currently supported JSON schema version is draft 3.

Edit a work queue
To edit a work queue:

1. Go to Power Automate  and sign in with your credentials.
2. On the left menu, select the Monitor section.
3. Select Work queues.
4. In the work queue list, select the work queue you would like to edit.
5. Select Edit work queue on the toolbar and update the values in the update pane.
6. (Optional) Enter a Description for the work queue.
7. (Optional) Enter a Work queue key for the work queue. When provided, the value

must be unique within this queue. If left empty, a unique value is automatically
provided by the system.

8. (Optional) Activate Set default item expiration and select a default lifespan value
for work queue items in the Items expire after fields.

9. Select Save.

Share a work queue
To share a work queue:

1. Go to Power Automate  and sign in with your credentials.
2. On the left menu, select the Monitor section.
3. Select Work queue.
4. In the work queue list, select the work queue you would like to share.



5. Select Manage access on the toolbar.
6. In the Share pane, enter the email or name of the person you want to share with.
7. Add the user to the list and select the user under the New section to confirm the

access level.

View advanced fields of a work queue
If you're ingesting or programmatically interacting with work queue data through the
Dataverse connector or APIs, it's helpful to quickly identify internal field values that
might be required for your use-case.

To view advanced work queue details:

1. Go to Power Automate  and sign in with your credentials.
2. On the left menu, select the Monitor section.
3. Select Work queue.
4. In the work queue list, select the work queue you would like to share.
5. Select Advanced details on the work queue details card.
6. In the Advanced details pane, you can use the 'Copy' icons to copy each of its

values.

Delete a work queue
To delete a work queue:

1. In the work queue list, select the work queue you would like to delete.
2. Select Delete work queue on the toolbar.
3. In the delete confirmation dialog, select Delete.

Ｕ Caution

When you delete a work queue, all related records, including work queue items and
their processing history, are permanently deleted.

Create work queue items
To create a new work queue item through the Power Automate portal:

1. Go to Power Automate  and sign in with your credentials.

2. On the left menu, select the Monitor section.



3. Select the work queue you would like to create items for and then select See
details.

4. Select + New work queue item on the toolbar.

5. In the New work queue item side panel, enter a Name for the work queue item.

７ Note

If you don't provide a value for the work queue item name, the internal work
queue ID is displayed instead in the work queue item list pages.

6. (Optional) Set the Status to On hold if the created item requires review or other
preprocessing work before they can be queued.

7. (Optional) Select a different Priority for the work queue item if you wish to
influence processing priority.

8. (Optional) Enter a Unique Id or reference if you wish to provide a custom unique
value within this queue. If left empty, a unique value in the format of system-
<GUID>  is automatically provided. |

9. (Optional) Activate the Expiration date section and select a custom Expiration
date value for the work queue item.

10. Enter the actual alphanumeric Input value of the work queue item.

11. (Optional) Enter Processing notes relevant to this work queue item.

Looking for more ways to create work queue data?

Learn how to bulk-import work queue data

Edit a work queue item
） Important

To help protect data integrity during processing, work queue item names or values
aren't allowed to be changed for items that are in the Processing state.

To edit a work queue item:



1. Select the work queue item you would like to edit and then select Edit work queue
item .

2. In the Edi work queue item side-panel, you can update all values as long as the
item isn't in the Processing state.

７ Note

If you don't provide a value for the work queue item name, the internal work queue
id is displayed instead in the work queue item list pages.

Work queue item statuses

ﾉ Expand table

Status Purpose When to Use Example

Queued The item is waiting to When the item is ready to An invoice was received
be picked up for be processed. This status and added to the
processing. is the default when adding processing queue.

items to a work queue.

Processing A system or a human is When the item is actively A customer service
currently processing the being worked on. representative is working
item. on resolving a customer

complaint.

On hold The item is temporarily When additional An order is on hold
paused and isn't information is required or because the payment
available for processing. a dependent task needs to confirmation is pending

be completed. from the customer.

Processed The item is successfully Use this status to indicate A customer refund was
processed and that the work on the item processed and confirmed.
completed. finished successfully.

Generic The item encountered When an unexpected error An unexpected system
exception an unspecified, occurs that doesn't fit into error caused an order

unexpected error or other more specific processing to fail.
issue during processing. exception statuses.

IT The item encountered a When processing is An order processing failed
exception technical error or IT- interrupted by a technical due to a network or

related issue during failure, such as a server database server outage.
processing. error or connectivity issue.



Status Purpose When to Use Example

Business The item encountered a When processing fails due A vendor invoice is
exception business rule-related to a business logic error or rejected because the

issue during processing. violation, such as incorrect vendor sending the invoice
data input. is blocked.

Processing The item failed to When processing takes A data extraction process
timeout complete processing longer than the from a remote application

within the allocated predefined time frame for is taking longer than the
time limit. the work queue. set timeout limit.

Allowed status transitions
Status transitions rules have been established in order to optimize the lifecycle
management of work queue items. As a result, certain work queue item statuses might
be unavailable for selection either interactively or during runtime processing if they
don't fall under the allowed transition path. More information about these paths is in
the following table.

ﾉ Expand table

Status Details Allowed
transitions

Queued This is the default state when items enter the work queue, and the Processing
only state under which work queue item dequeuing is allowed.

Processing Indicating that the item is currently being processed. Processed,
Exception

Processed Indicating that the item is currently processing. Queued, On
hold

Exception An exception has been raised during work item processing. Queued, On
Depending on your exception scenarios, you have the option to hold
choose between Generic, **IT, and Business exceptions.

On hold A business or IT user has picked an item to review, assess, and Queued
potentially remediate issues.

Next steps
Learn how to process work queues



Related information
Work queue overview
Manage work queues
Trigger work queues
Process work queues
Known issues and limitations

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Bulk-import work queue data
Article • 06/23/2023

With Power Automate and work queues being an integral part of the Power Platform,
you can easily streamline your data management processes. The suite of tools available
is comprehensive, ranging from highly end-user optimized wizards to powerful cloud-
based ETL services and even pro-code options. Whether you're a business user, an IT
professional or a developer, you can find the right tool to create or bulk upload data
with ease and efficiency.

Comprehensive bulk-import options
Here's a comprehensive list of data management and bulk-import options you can
choose from.

＂ Using a cloud flow with the Dataverse connector action - Add a row new action to
add one or more rows to the Work Queues and Work Queue Items tables.

＂ Using Microsoft Dataverse bulk-import options
Import using a connector - Supporting data transformation with Power Query
and connecting to many different sources, such as Excel, Azure, SQL Server, CSV,
JSON, XML, Text, OData, and more.
Import from Excel or CSV - Supporting Excel and CSV files with data validation
and a visual mapping experience.

＂ Using Power Platform Dataflows with its powerful cloud-based ETL services.

Adding work queue items with cloud flow and
Dataverse connector

1. Go to Power Automate  and sign in with your credentials.

2. On the left menu, select My flows.

3. In the toolbar, select + New flow and select Instant cloud flow.

4. Provide a Flow name and then select Manually trigger a flow option.

5. Select Create.



6. Once the flow designer opened, select + New step and select the Microsoft
Dataverse connector.

7. In the list of actions, select Add a new row.

8. The following highlighted fields, represent the minimum fields required to add
items to a work queue.





When using the Dataverse connector Add a row row action, it expects a certain
pattern to be followed when referencing a parent record. An example of this
pattern can be seen in the 'Work Queue ID (work Queues)' field, which uses the
work queue ID (Guid) to reference the parent work queue, for example,
/workqueues(44e44ea8-1af2-ed11-8848-000d3ae86f97) .

9. Select Save and Test the flow.

10. Navigate to the work queue details page of the work queue you have specific in
the action, and confirm that the newly created work queue item has been added.

Tutorial: Import a work queue and items from
CSV
This tutorial showcases both mentioned Dataverse bulk-import options for importing a
work queue along with its associated work queue items, which in this example is vendor
invoices.

７ Note

While the easiest and most straight forward way to create work queues is through
the Power Automate portal  as described in Create a work queue, we've included
work queue import steps as well to demonstrate the import from Excel or CSV
approach.

） Important

The CSV sample data for this tutorial includes three special columns:
workqueuekey, componentstate, and overwritetime, along with their values. The
componentstate  and overwritetime  fields typically have default values of 0  and
01/01/1900 00:00 , respectively. The default value of the workqueuekey  field is a
Guid and is auto-generated when you create a work queue through the Power
Automate portal. However, if you create a work queue through an import file (like
in this example) or through the Dataverse connector in cloud flows, you can supply
a more descriptive work queue key, such as Vendor Invoices . These fields are part
of the work queue record and must be included in any import. To view their values,
go to Power Apps  and under Tables, search for Work Queue.

Prerequisites



Power Automate or Power Apps premium license
Some parts of this tutorial require OneDrive for Business access

Phase 1/3: Create sample files
1. Create a local file called vendor-invoice-queue.csv and paste the following text

into it:

JSON

defaultitemtimetoliveinminutes,description,name,prioritytype,overwritet
ime,componentstate,workqueuekey,workqueuetype
1440,Vendor invoice queue with a 14 day SLA.,Vendor invoice 
processing,Fifo,01/01/1900 00:00,0,Vendor Invoices,Work Queue

2. Save the file.

3. Create another file called vendor-invoice-items.csv and paste the following rows
into it:

JSON

WorkQueueItemId,InvoiceId,InvoiceDate,AccountName,ContactEmail,Amount,S
tatus,WorkQueueKey,ComponentState,OverwriteTime
653d9256-a217-4742-8cfc-f7d0a4a0f902,I-
1001,01/04/2023,Fabrikam,invoicing@fabrikam.com,4232.16,Paid,Vendor 
Invoices,0,01/01/1900 00:00
01634ba7-93bf-4aa6-85f7-15a4d6cb3b20,I-1002,02/04/2023,Litware 
Inc.,adixon@litware.com,2455.00,Paid,Vendor Invoices,0,01/01/1900 00:00
6fa8c944-5400-4db6-af6d-2f18d8b74bed,I-1003,03/04/2023,Proseware 
Inc.,lrobbins@proseware.com,7458.98,Paid,Vendor Invoices,0,01/01/1900 
00:00
683be530-017f-48a7-899b-c7390836fc37,I-1004,04/04/2023,Tailspin 
Toys,p.gupta@tailspintoys.com,5237.26,Paid,Vendor Invoices,0,01/01/1900 
00:00
daedf721-40e8-40a0-b6f9-e332e90c1187,I-1005,05/04/2023,WingTip 
Toys,b.friday@wingtiptoys.com,2230.99,Invoiced,Vendor 
Invoices,0,01/01/1900 00:00
64d6dbbb-52a8-47b1-8587-b791ae7e612a,I-
1006,06/04/2023,Fabrikam,invoicing@fabrikam.com,1253.78,Paid,Vendor 
Invoices,0,01/01/1900 00:00
688e12f2-6528-43b1-ae36-d31214fad7dd,I-1007,07/04/2023,Proseware 
Inc.,lrobbins@proseware.com,3345.87,Paid,Vendor Invoices,0,01/01/1900 
00:00
36ecf154-9cc4-43aa-aaa6-2b3e6807d6d2,I-1008,08/04/2023,Tailspin 
Toys,p.gupta@tailspintoys.com, 967.45 ,Paid,Vendor 
Invoices,0,01/01/1900 00:00
7404787b-e9c1-49fc-90cf-c1f3372d2577,I-1009,09/04/2023,WingTip 
Toys,b.friday@wingtiptoys.com,1437.75,Paid,Vendor Invoices,0,01/01/1900 
00:00



53970b80-b23e-46e5-afb4-9f6f6f46c365,I-
1010,10/04/2023,Fabrikam,invoicing@fabrikam.com,1687.43,Paid,Vendor 
Invoices,0,01/01/1900 00:00
41cf9fd8-c98f-4dea-be0a-ff70bc9c74b9,I-1011,11/04/2023,WingTip 
Toys,b.friday@wingtiptoys.com,2854.67,Paid,Vendor Invoices,0,01/01/1900 
00:00
95ea6270-6efe-476f-a86c-892483242532,I-1012,12/04/2023,Litware 
Inc.,adixon@litware.com,6743.12,Invoiced,Vendor Invoices,0,01/01/1900 
00:00
c639cd8c-b603-4a30-9659-30de6e333c2f,I-
1013,13/04/2023,Fabrikam,invoicing@fabrikam.com,2997.12,Invoiced,Vendor 
Invoices,0,01/01/1900 00:00
9dcefd8a-f4cf-4592-b179-1e1bdfa808b4,I-1014,14/04/2023,Proseware 
Inc.,lrobbins@proseware.com, 843.76 ,Invoiced,Vendor 
Invoices,0,01/01/1900 00:00
4775f771-4168-46ca-9e10-5957c15e4145,I-
1015,15/04/2023,Fabrikam,invoicing@fabrikam.com,1349.24,Invoiced,Vendor 
Invoices,0,01/01/1900 00:00
5450ea15-1a69-4692-b083-ba1ac0e8cb6e,I-1016,16/04/2023,Tailspin 
Toys,p.gupta@tailspintoys.com, 367.13 ,Invoiced,Vendor 
Invoices,0,01/01/1900 00:00
c7718c58-8b9c-4915-b9d7-f067ceac726b,I-1017,17/04/2023,Litware 
Inc.,adixon@litware.com,3984.54,Invoiced,Vendor Invoices,0,01/01/1900 
00:00
ab1c46f8-6de2-4583-b0ba-0959a962e8f1,I-
1018,18/04/2023,Fabrikam,invoicing@fabrikam.com,1943.89,Uninvoiced,Vend
or Invoices,0,01/01/1900 00:00
9d5b0ab6-1cb0-40b8-af91-326417843eee,I-1019,19/04/2023,Proseware 
Inc.,lrobbins@proseware.com,2853.39,Paid,Vendor Invoices,0,01/01/1900 
00:00
154d6965-1a4c-49c3-96e2-ce94f5bc92f1,I-
1020,20/04/2023,Fabrikam,invoicing@fabrikam.com,8764.14,Paid,Vendor 
Invoices,0,01/01/1900 00:00
b5ff78f0-c3d7-4da0-b233-9cdbc0798f7c,I-1021,21/04/2023,Litware 
Inc.,adixon@litware.com, 643.68 ,Paid,Vendor Invoices,0,01/01/1900 
00:00
816463ca-4ecd-4433-b56c-7d16df6a9fe0,I-1022,22/04/2023,Proseware 
Inc.,lrobbins@proseware.com,4232.16,Invoiced,Vendor 
Invoices,0,01/01/1900 00:00
2d1e88b7-f4f7-4885-98f0-f56e33218291,I-1023,23/04/2023,Tailspin 
Toys,p.gupta@tailspintoys.com,3345.87,Invoiced,Vendor 
Invoices,0,01/01/1900 00:00
338d57d0-f869-4707-b817-f9d1bbd9ed92,I-1024,24/04/2023,WingTip 
Toys,b.friday@wingtiptoys.com,3345.87,Invoiced,Vendor 
Invoices,0,01/01/1900 00:00
67b2184d-8a3a-40e8-8647-298852529070,I-
1025,25/04/2023,Fabrikam,invoicing@fabrikam.com,3345.87,Invoiced,Vendor 
Invoices,0,01/01/1900 00:00
475b5afa-5c21-427e-af32-d4af33a018c2,I-1026,26/04/2023,Proseware 
Inc.,lrobbins@proseware.com,6743.12,Invoiced,Vendor 
Invoices,0,01/01/1900 00:00
23b08df8-49de-475d-96c6-894880d6d2ad,I-1027,27/04/2023,Tailspin 
Toys,p.gupta@tailspintoys.com,4232.16,Invoiced,Vendor 
Invoices,0,01/01/1900 00:00
2a3425b7-3e84-4560-a2eb-b20d5c666c25,I-1028,28/04/2023,WingTip 



Toys,b.friday@wingtiptoys.com,6743.12,Invoiced,Vendor 
Invoices,0,01/01/1900 00:00
58b40e26-a34a-493d-865f-d6dbe32edb96,I-
1029,29/04/2023,Fabrikam,invoicing@fabrikam.com,4232.16,Invoiced,Vendor 
Invoices,0,01/01/1900 00:00
989ae0b3-a4d4-491c-be3a-5f32791c465a,I-1030,30/04/2023,WingTip 
Toys,b.friday@wingtiptoys.com,3345.87,Invoiced,Vendor 
Invoices,0,01/01/1900 00:00

4. Save the file.

Phase 2/3: Import work queue
1. Next, go to https://make.powerapps.com  and sign-in with your credentials.
2. Confirm that you're in the correct environment and select Tables in the side-menu.
3. Select the All tab.



4. Search for Work Queue table and open its details page.



5. In the toolbar, select Import and then select Import data from Excel.



6. Select Upload and choose the vendor-invoice-queue.csv file.



7. Confirm that the automapping was successful, or if needed adjust it by selecting
Map columns.



8. Select Import.
9. Depending on your data volume, this might take some time to complete. Once

complete, navigate to the work queue list page and confirm that vendor invoice



queue has been added.



Phase 3/3: Import work queue items
1. Next, go to https://make.powerapps.com  and sign-in with your credentials.
2. Confirm that you're still in the correct environment and select Tables in the side-

menu.
3. Select the All tab.
4. Search for Work Queue Item table and open its details page.
5. In the toolbar, select Import and then Import data.
6. In the Power Query dialog that opens, select the Text/CSV option.



7. Next, select Upload file (Preview) and then Browse... for the vendor-invoice-
items.csv file.





8. If needed, establish a connection to your OneDrive for Business folder.



9. Select Next and confirm that you see the work queue item records and that
Comma is selected as delimiter.



10. Select Next.

７ Note



The next few steps are not required if all you want to do is import basic, already
formatted values into the work queue items table. However, if you're looking to
reshape the source data before you import it, then the following Power Query
transformations might come in handy for your future use-cases.

11. In the Power Query transformation window, select the Add column tab on the
ribbon toolbar and then select Custom column.



12. In the Custom column dialog box, enter Input as the new column name and
Text.FromBinary(Json.FromValue(_)) in the custom column formula field.



Here's what the formula does:



Json.FromValue(_): This part of the expression takes the input value (that is, a
row of the table) and converts it into a JSON-formatted text.
Text.FromBinary(): This part of the expression takes the JSON-formatted text
and converts it into binary format. This step is primarily used for optimizing
data storage or transmission.

By using both of these functions together, the expression can turn each row of the
table into a JSON object and store the resulting JSON object in a new column
called Input. This process is repeated for each row of the table.

13. Select Ok.

14. Select Next.

15. On the mapping under the Load settings section, select Load to existing table.

16. Under Destination table, select workqueueitem.

17. Under Select key (optional) select workqueueitemid.

18. In the Column mapping section set the following mapping:

Source column Destination column

Input input

InvoiceId name

ComponentState workqueueid.ComponentState

OverwriteTime workqueueid.OverwriteTime

WorkQueueKey workqueueid.workqueuekey





19. Select Next and then select Publish.

20. Go to the Power Apps maker portal  and select Dataflows from the left-menu
(you might have to select More first to get to the Dataflows menu).

21. Confirm that you see a new dataflow entry and that both icons show success once
the import is complete.



22. Once complete, navigate to the work queue details page of the vendor invoice
queue and confirm that the work queue items have been added.





Next steps
Learn how to process work queues

Learn more
Work queue overview
Manage work queues
Trigger work queues
Process work queues
Known issues and limitations



Process work queues
Article • 03/10/2025

Work queue processing refers to the management of a list of work items that need to be
completed in a particular order. This list contains information about each item, such as
its name, priority, expiration date, status, and the actual value to be processed.

Ways to process work queues:

＂ Desktop flow-based processing in Power Automate desktop (PAD).

＂ Cloud flow and connector-based processing.

＂ Cloud flow-based processing with desktop flow support.

＂ Using Dataverse pro-developer features (for advanced integration scenarios only):
Dataverse Web API
Dataverse SDK for .NET

Learn more about Dataverse's pro-code tooling: Dataverse developer documentation.

Processing walkthroughs
To showcase some of the available processing options, here are three different
processing scenarios.

Desktop flow-based work queue processing in Power
Automate desktop (PAD)

Process work queue items & Update examples
The first step to using work queue actions in Power Automate desktop is to create a
work queue in the environment that you're working in and load some queue items with
data to be consumed downstream. Queue items can be loaded into a work queue
through a desktop flow, cloud flow or in bulk as outlined here, which populates queue
items. In this example, some queue items have been added manually into a work queue
to explain how actions in Power Automate desktop can be used.

The work queue items have been created and the value field includes text in JSON
format that will be used downstream in the desktop flow.





The example flow we'll be using to demonstrate work queue action usage mimics a
process that would consume a work queue item from the cloud, process the data
included in the value field and convert it to a custom object to be processed
downstream. Note that it isn't mandatory to use JSON or custom objects as values for
your work queue items, but it can be a useful method for organizing values that have
multiple properties and follow a specific schema.



1. The Process work queue items action is used to designate which work queue to
consume items from and process in your desktop flow. The action can be
configured to select a work queue from a list using the dropdown arrow, pass a
variable including the queue name. When run, this action works by bringing in the
first (oldest) item from the work queue into your flow that contains a status of
queued. Once the queue item begins processing in your flow, its status
automatically changes to processing.

７ Note



If you're using a variable to dynamically select the work queue, use the ID of the
work queue as input. The work queue ID is available under Advanced details of the
work queue details page.





1. A breakpoint (red dot) was set by clicking next to action 3 in the flow and then run
through the PAD console. When the process pauses at the breakpoint, the
WorkQueueItem variable can be opened by double clicking the populated value
under Flow variables and this shows all the properties associated with the work
queue item being processed.

７ Note



The WorkQueueItem variable shows the information of the current work queue
item when there are remaining items to process. If there are no more work queue
items to process and the action is complete, it shows the information of the last
work queue item.



1. In action 2 of the flow, I converted the returned JSON value, which in this case is
accessed via %WorkQueueItem.Value% into a custom object. The reason for this is
because it helps parse the JSON and use the JSON properties downstream in your
flow. In this hypothetical case, the info would be used to make entries into
Farbrikam’s finance portal.

JSON

{
 "InvoiceId": "I-1006",
 "InvoiceDate": "06/04/2023",
 "AccountName": "Fabrikam",
 "ContactEmail": "invoicing@fabrikam.com",
 "Amount": 1253.78,
 "Status": "Paid",
 "WorkQueueKey": "Vendor Invoices",
 "ComponentState": 0,
 "OverwriteTime": "1900-01-01T00:00:00"
}





For instance, let's say there was a requirement to enter the invoice ID into a field of
a finance system as part of a process where you're automating the UI of a web or
desktop app – you can call that value using %JsonAsCustomObject.InvoiceId% to
populate a text field and push a button.

2. Moving along, this example contains some conditional statements once it
completes processing the steps and uses the data from the custom object within
the subflow Fabrikam Data Entry. If the process runs end-to-end without
encountering any input system related exceptions the Update work queue item
action is used to change the status of the work queue item to Processed and the
processing result field can be used to input some optional notes. If the expires
field is left blank, the new queue item retains the Items expire after value defined in
the work queue properties.

７ Note

If work queue items are stuck in the processing state because a desktop flow
fails to complete, use a cloud flow to retrieve and update the work queue
items.





Exception handling options can be configured by clicking on error in the update
work queue item action configuration window. Three options are available for
customization under the advanced tab. Work queue item not found might occur if
the work queue item is removed from the queue, either manually or through
another systematic process, before it finishes processing in PAD. Work queue item
on hold might occur if an automated process, or somebody changes the status of
the work queue item being processed to on hold in the flow portal while the
queue item is being processed. Failed to update work queue item might occur if
the queue item no longer exists in the queue, or has been placed into the status
on hold. All the above are edge cases, which might occur - learn more about
handling errors in desktop flows here.





3. If some issue was determined during processing the data of the work queue item
into the data entry system, the item could alternatively be assigned a status of
generic exception, IT exception, or business exception. These exceptions statuses
are available to be used when, or if, your automated use case meets criteria, which
might apply.





Let’s say that while processing a queue item, scenario 2 was met. In this case, the
queue item is marked as generic exception in the originating queue. Depending on
the scenario, you might decide to change the status of queue items, which couldn't
be processed successfully as one of the alternative status options. From there, you
can decide whether human intervention is required, or build a subsequent process
with the logic required to manage each exception status.



Auto-retry pattern
The Process work queue items action in Power Automate Desktop includes an
advanced option to configure or override an auto-retry mechanism. This feature allows
you to specify the maximum auto-retry count per work queue item, which is useful for
handling IT exceptions like transient network errors or temporary system unavailability.
It enables the machine to retain the item and perform controlled retries without
requeuing the item, ensuring more efficient and resilient work queue processing.

You can set and centrally control the maximum retry count on the work queue record in
Dataverse. This default value applies to all desktop flows that process this work queue
through the Process Work Queue Items action.

To override the queue-level default in your flow, navigate to the Advanced section of
the Process work queue items action, and toggle the Override work queue auto-retry
configuration option. This setting lets you adjust the maximum retry count to a higher
or lower value, or even disable the retry mechanism by setting the max retry count to 0.

When you use the Update work queue item action with a status set to IT exception
and a max auto-retry count greater than 0, the system doesn't immediately send the
update to the work queue orchestrator. Instead, it retries the operation until it reaches
the specified max retry count. The only value updated in the work queue item is the
retrycount . This value increases from the second update attempt onwards until the max
auto-retry count is reached. Additionally, a local work queue item variable called
CurrentRetryCount  increments with each retry. This variable allows you to implement
custom logic based on its value if needed.





The flow won't request a new item when it loops back to the top of the Process work
queue items action if the following conditions are met:

The maximum retry count is not reached.
No other updates occur except for IT exceptions.

When the max retry count is reached, the update action sends the update to the
orchestrator, changing the item's status to IT Exception and including any provided
processing notes.

Adding and requeuing work queue items examples from PAD
The Add work queue item enables desktop flow users to populate work queue items
into a work queue, which has been set up in the flow portal. Batch item creation is
supported by using the Add work queue items action.

In this example, an Excel file in .csv is dropped into a directory on a daily basis and each
row needs to be added to a work queue.





The first couple of actions in this sample process map a folder where the daily Contoso
Invoices.csv file is dropped - when the process runs it begins by reading the data table
from the CSV file. The CSVTable variable contains the data, which has been imported
and will be processed to new queue items.



Actions 3 and 4 generate the time at which we choose the new queue items to expire
after being added into a work queue. Action 3 captures the current system data and
time, then for this example 7 days are added onto it by using the %Add to datetime%
action. The output is stored into a variable called ExpiryDatetime which will be used in
the Add work queue item action.





Action 5 introduces the For each loop, which is used to iterate through each row of data
in the imported CSVTable - this action renders a data row for the current item being
processed.



All of the preceding actions in this example desktop flow are now incorporated into
setting the values for the Add work queue item action.





The work queue parameter is set to the queue that we want to add new work queue
items into - in this case Demo PAD queue was selected by choosing it from the
dropdown menu.

The Priority parameter is left at the default, Normal, but options for Low and High are
also optional. Higher priority work queue items are processed first, then normal and last
when mixed into the same work queue.

The Name parameter has been set with a static prefix along with the variable value
CurrentItem['ID'] - which contains the value from the ID cell of the data row being
processed. This is optional but can be useful depending on your use case.



Using the values from the data row in the variable CurrentItem the Input parameter was
entered in JSON format. Note each header name was appended to the currentitem
variable using the notation ['name of header']

The Expires field is populated with the datetime variable we added 7 days onto in the
previous steps. When left blank, the work queue item being added will contain the Items
expire after value set for the work queue.

Processing notes are optional - use as deemed necessary.

When the process is run, each data row in the imported CSV creates a work queue item
containing a Queued status, which means it's available for processing.



These are just some of many ways that work queue actions can be used in PAD. Take
some time to explore and find creative uses to incorporate work queues into your Power
Automate flows!

Requeue item with delay example
The Requeue item with delay action enables desktop flow users to requeue items and
set a delay period at which time the item it can be released again for processing.

In this example, there's a work queue loaded with items, which are set to expire in 24
hours, but they can't be processed in time because there's some ongoing routine
system maintenance being performed by IT and the items need to be requeued. The
maintenance will be completed overnight, so we'll proceed to delay each queue item by
24 hours and then set them to expire 24 hours after the release period.





The first three actions of this example process are date time actions. The 'Get current
date and time' action captures the system datetime at the moment the action is run.
Next we used the 'Add to datetime' action to cover two requirements, first we need to
define the delay time by adding 24 hours to the current datetime - then we need to add
48 hours to the current datetime as an expiry.









Next in the example, the 'Process work queue items' action is configured to point to the
loaded work queue and the 'Requeue item with delay' is placed within the loop.





The values generated for the delay and the expiry can now be passed into the 'Requeue
item with delay' action. The 'work queue item' field is populated by the variable
produced by the loop - this instructs which queue item to requeue. Next we plugged in
the values created using the datetime actions for the 'delay until' and 'expires' fields. The
'delay until' is mandatory, but you can use 'expires' and 'processing result' at your
discretion.

With this simple process, you can requeue all available items in a queue, delay them for
a certain time, with options to also set an expiration date and processing result.

Cloud flow and connector-based processing
The simplest way to dequeue a work queue item and process it is as follows:

1. Go to Power Automate  and sign in with your credentials.

2. On the left menu, select My flows.

3. On the toolbar, select + New flow and then select Instant cloud flow.

4. Provide a Flow name, such as My first work queue flow, and then select Manually
trigger a flow.

5. Select Create.



6. Once the flow designer opens, select + New step, and then select the Microsoft
Dataverse connector.

7. In the list of actions, select Perform a bound action.

ﾉ Expand table

Parameter Value Description

Table Work The name of the work queue table.
name Queues

Action Dequeue The action, which gets the next available item from the queue.
name

Row ID [Work The work queue ID (GUID) of the queue you'd like to dequeue from. You
Queue can get to this value by navigating to the work queue details page of
ID] your queue and opening the Advanced details panel.

request request FetchXML in stringified JSON format you want to apply on the Work
Queue ID. Example: { "query": "<fetch mapping=\"logical\"
returntotalrecordcount=\"true\" page=\"1\" count=\"1\" no-
lock=\"false\">\n<entity name=\"workqueueitem\">\n<filter
type=\"and\">\n<condition attribute=\"workqueueid\" operator=\"eq\"
value=\"38b14649-cb09-ee11-8f6e-00224804934a\"/>\n<condition
attribute=\"statuscode\" operator=\"eq\"
value=\"0\"/>\n</filter>\n</entity>\n</fetch>"}



７ Note

A bound action is a Dataverse action that is defined on a specific table (work
queues in our example) and can only be executed on records of that table. Bound



actions are used by the platform to perform custom business logic or operations on
a specific record.

1. Your flow should look similar to this now.



1. Select Save and then Test your flow.

2. In the testing side-pane select Manually, Test, Run flow and then Done.

3. If the flow ran successfully, you should get a similar result (but with different IDs).





1. Next, copy the whole JSON content from the body field and then select Edit in the
upper right corner of the flow.

 Tip

After dequeuing a work queue item, use the JSON content of the item as a schema
example for parsing the item's JSON properties. This allows you to easily access any
property of the item returned by the work queue orchestrator in subsequent flow
actions.

1. Add a new step by selecting + New step and search for an action called Parse
JSON and select it.



1. Position your mouse in the Content field and select the body property from the
previous action.





1. Next, select Generate from sample and paste the previously copied JSON string
into the dialog and select Done.

2. Select + New step and then select the Microsoft Dataverse connector.

3. From the list of actions, select Update a row.

4. In the Table name field, select the Work Queue Items table and position your
cursor in the Row ID field.

5. In the Dynamic content list, you'll now have all fields that are available in the work
queue item table.

6. Select Show advanced options and then set the RowID, Processing Result, Status,
and Status Reason fields to the following values.

ﾉ Expand table

Field Value Details

Row ID workqueueitemid This value can be selected in the dynamic
content list dialog.

Processing The item has been successfully
Result processed.

Status Processed

Status Reason Processed





1. Select Save and Test the flow once more.

2. If the flow ran successfully, you should get a similar result as the following.



3. Now, navigate to the work queue details page and in the work queue item list
section select See all.

4. Filter the Status field to only show Processing and Processed items to confirm that
our dequeue and update actions worked as expected.









Congratulations, you just completed your first work queue processing scenario!

Cloud flow-based processing with desktop flow support
For this scenario, we extend the previous one by adding a desktop flow processing step
as well.

1. Go back and edit the My first work queue flow.

2. Add a new action right after the Parse JSON action and search for Desktop flows
connector and the Run a flow built with Power Automate for desktop.

3. In the desktop flow dropdown, either choose and edit an existing desktop flow or
select + Create a new desktop flow and follow the instruction on screen to create
the desktop flow and launch Power Automate for desktop. If you're new to
desktop flows, you can learn more here.

4. Once the Power Automate for desktop designer opens, create two input variables
called WorkQueueItemValue and WorkQueueItemName and then add two
output variables called ProcessingNotes and ProcessingStatus respectively, all of
which should have Text as their data type.

5. Provide a default value for the WorkQueueItem variable so that you can later test
the script locally. In case you've followed the bulk-import tutorial you should have



work queue items in the Vendor invoice queue that have their values in JSON
format. Here's an example of one of the values used.

JSON

{
 "InvoiceId": "I-1006",
 "InvoiceDate": "06/04/2023",
 "AccountName": "Fabrikam",
 "ContactEmail": "invoicing@fabrikam.com",
 "Amount": 1253.78,
 "Status": "Paid",
 "WorkQueueKey": "Vendor Invoices",
 "ComponentState": 0,
 "OverwriteTime": "1900-01-01T00:00:00"
}



6. Now, Save the flow.

7. In the action panel, open the Variables action group and double-click the Convert
JSON to custom object action to add it to the design canvas, which opens its
property window.



8. Select the variable icon in the JSON field and choose the WorkQueueItemValue
variable.

9. Rename the produced output variable from JsonAsCustomObject to
VendorInvoice and select Save.

10. Next, add an If action from the Conditionals group and configure its properties as
follows:

ﾉ Expand table

First operand Operator Second operand

%VendorInvoice['Amount']% Less than (<) 5000

11. Select Save.

12. Add another action from the Conditionals group called Else and add it between
the If and End action.

13. Now, add another two actions from the Variables group called Set variable and
add them within the If and Else actions and set the ProcessingNotes and
ProcessingStatus variables to the following values:

ﾉ Expand table

Variable Value

%ProcessingNotes% The invoice has been processed

%ProcessingStatus% Processed

14. Copy the two Set variable action and paste them between the Else and the End
action and change their values to match these:

ﾉ Expand table

Variable Value

%ProcessingNotes% Business exception: The invoice amount is greater than $5000, which
requires manager approval.

%ProcessingStatus% Exception

15. Your flow should look similar to this now.





16. Save the flow and run it to confirm that the flow logic works as expected.

17. Go back to edit the My first work queue flow.

18. Select the newly created (or edited) desktop flow from the list and then select
Attended as its Run Mode.

19. Fill in the Work Queue Item Value and Work Queue Item Name parameters as
shown here:



20. Add a Condition action before the Update a row action.

21. Position your mouse in the Choose a value field and select Processing Status from
the dynamic content list dialog.



22. Position your mouse in the other Choose a value field and enter Processed as the
text value.

23. Drag and drop the Update a row action into the If yes section of the condition
action.

24. Open the Update a row action details and replace the values to match the
following:



25. In the red If no box, add another Update a row action and select Work Queue
Items as the Table name.

26. Next, select workqueueitemid as Row ID and open Show advanced options
section select Processing Notes as the Processing Results value.

27. Select Error as Status and GenericException for Status Reason.



28. Select Save and Test to test the overall automation and observe the output from
the desktop flow action.





29. To confirm that the work queue item has been processed you can go to the work
queue details page, select See all in the work queue items section and filter the
items by Processed status.



Well done, you just completed a more advanced scenario that included hybrid work
queue processing!

Next steps
Learn how to trigger work queues

Learn more
Work queue overview
Manage work queues
Bulk-import work queue data
Trigger work queues
Known issues and limitations



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Trigger work queues processing
Article • 10/26/2023

Power Automate provides a variety of triggers that can be used to initiate work queue
processing. These triggers can be categorized into different types based on their
functionality.

Manual Triggers: These triggers are initiated manually by the user. They're useful
when you want to start a flow on-demand, such as when you need to perform a
specific task.

Automated Triggers: These triggers are initiated automatically based on a specific
event or condition. For example, you can use the "When a new email arrives"
trigger to initiate a flow whenever a new email is received.

Scheduled Triggers: These triggers are initiated based on a specific schedule. You
can use them to perform tasks at specific times or intervals, such as sending a daily
report.

Instant Triggers: These triggers are initiated immediately when a specific event
occurs. For example, you can use the "When a file is created or modified" trigger to
initiate a flow whenever a file is created or modified in a specific folder.

UI-based Triggers: These triggers are initiated based on user interactions with a
user interface. For example, you can use the "When a button is clicked" trigger to
initiate a flow when a user select a button on a form.

Learn more
Work queue overview
Manage work queues
Bulk-import work queue data
Trigger work queues
Process work queues



Known limitations for work queues
Article • 03/11/2025

The following table lists known limitations for work queues in Power Automate for
desktop.

ﾉ Expand table

Limitation Details Potential workaround

Dequeuing Keep work queue dequeueing concurrency When applying concurrency
concurrency within moderate levels. Up to five parallel patterns in cloud flows, align

dequeue operations per work queue is the concurrency level to
recommended. available machine capacity to

ensure that the number of
work items being processed
in parallel matches the
number of machines
available to process them.

Dataverse limits Work queues are based on Dataverse
technologies, hence the same service
protection and API limits apply. Learn more:
Service protection API limits.

Work queue The work queue connector that is applicable You can enable the work
connector to Power Automate for desktop only, is queue connector and its
disabled in GCC disabled by default for customers operating actions. More information:
High and DoD in GCC High and DoD environments. Disable new connectors by
environments default in GCC High and

DoD.

Work queue DLP There may be a delay before new work queue
policy connector actions added to Power Automate
configuration desktop are visible and configurable through
support DLP policies in Power Platform Admin Center.

Additionally, if you want to limit the use of
work queues in cloud flow and API-based
scenarios, you should use Dataverse RBAC to
control access to the underlying tables. This is
because work queues are built on the
Dataverse platform, and their actions (such as
adding, updating, deleting and dequeueing)
are accessible by-design through the native
Dataverse connector, which cannot be
completely blocked by DLP policies.



Limitation Details Potential workaround

Throughput and Work queues aren't suited for high
scaling throughput (subsecond processing time)

scenarios, where hundreds or thousands of
items need to be processed in seconds. If you
do have such throughput requirements,
consider using other queuing solutions such
as Azure Service Bus Queues.

Related information
Work queue overview
Manage work queues
Bulk-import work queue data
Trigger work queues
Process work queues

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Desktop flow activity
Article • 08/29/2023

As you scale the automation of your business processes, you may need access to
aggregated data to monitor your desktop flows effectively. The Desktop flow activity
section of the Power Automate portal (Monitor > Desktop flow activity) provides
dashboards, tables, and graphs to monitor desktop flows, measure effectiveness, and
quickly identify issues.

You can filter the presented data by date, desktop flow, cloud flow, machine, run mode,
run status, and error. Filtering enables you to focus on a specific range of data and
handle it more efficiently.

７ Note

Some filters may not be available for some pivots because of the nature of the
presented data.
When you move between pivots, the tab keeps the active filtering selection.
Select Clear filters to reset the applied filters.

Available data for admins and makers
The Desktop flow activity section is helpful for Center of Excellence (CoE) users who
want to monitor all activity in an environment and makers who want to get an
aggregated view of their automation. Learn more about the CoE in Microsoft Power
Platform Center of Excellence Starter Kit.

If you're the admin of the current environment, you can see all the desktop flows,
machines, and machine groups that exist in Dataverse for the environment. If you're a
maker, you can see all your desktop flows and machines, including the flows that others
share with you.

７ Note

If a cloud flow appears as private flow, it means that it isn't shared with you. Cloud
flows aren't saved in Dataverse, and environment admins need to get access to the
flows to read details about them.



Last runs: Monitor desktop flow runs
The Last runs section provides graphs and tables to get meaningful insights about your
desktop flow runs, such as the number of runs, the percentage of errors, and the run
modes.

You can find information regarding each table in the following list:

Completed desktop flows: This card provides the number of desktop flow runs in
a selected period of time.

Desktop flows runs and error rate: This chart shows the number of desktop flow
runs and the error percentage by date. If no desktop flows run for one or several
days, the corresponding data aren't available in the table.

Desktop flows completion status: This donut chart displays the proportion of
desktop flows that succeeded, failed, or got canceled.

Run status – Trends: This stacked area chart helps you understand how your flows
work across time. Use this chart to quickly identify if there was a particular issue
during a dedicated time period, such as too many failures and low number of runs.

Top desktop flows runs status: This card presents the desktop flows that ran the
most during a dedicated time period. For each presented desktop flow, the card
gives details about the run mode (attended, unattended or local) and the run
status (successful, skipped, failed, canceled). If you want to review specific desktop
flows, select them in the appropriate filter.

Last desktop flows runs: This card displays the latest completed desktop flows
runs.



Errors: Monitor desktop flow errors
You can use the Errors section to identify the most common errors that occur while your
flows run. These pivot tables provide information about desktop flows, cloud flows, and
machines in which errors occurred, allowing you to view details to identify the source of
errors.

By default, this section displays the desktop flow run errors for the last seven days.
Optionally, you can select another time period and filter on specific errors.

You can find information regarding each table in the following list:

Top errors: This card displays the errors that occur most frequently during your
desktop flow runs. If you can't see a specific error in the card, select the All errors
filter, and then choose the error that you want to see.

Top failed desktop flows: This card displays the desktop flows that failed the most
in your environment. You can select each desktop flow to display its details page.

Top cloud flows with failed desktop flows: This card provides a list of cloud flows
that are the most impacted by failures in desktop flows. For example, if a cloud
flow contains two desktop flows and these desktop flows failed two times each,
you'll see this cloud flows with a count of four errors.

Top machine failures: This card displays information about the machines on which
desktop flow runs failed most frequently. You can select each machine name to



display its details page.

Error trends: This chart displays daily trends for errors in desktop flow runs. These
trends can help you to identify if an error started to appear recently or several days
ago. In addition to trends per error, the chart can display trends per desktop flow
and machine. Select the dropdown menu of the table to display the type of pivot
you prefer.

Machines: Monitor your machines and machine
groups
You can use the Machines section to monitor your machines and machine groups. These
pivot tables provide information about the number of machines, groups, connection
status, Power Automate for desktop versions installed on machines, and lists of
machines and machine groups.

Connection status: This card displays the connection status of your machines
(connected, disconnected, action needed). If you want to see machines that are
disconnected, select See more. In the pane, you can see all the machines per
connection status. You can select the machine name to reach its details page.

７ Note

There is a limit of 40 connection statuses displayed at one time. If you have more
machines in your environment, use the filters to reduce the current selection.



Versions on machines: This card displays for each version of Power Automate for
desktop, the number of machines that use this version. This feature is useful to
understand which machines require updates (you should update your application
regularly). From filters, you can select a dedicated version and see machines that
are using this version.

Machines and Machine groups: These cards display the 10 last modified machines
and machine groups (name, description, version, status). Select See all to view the
full list of items, if you have more than 10 machines or groups.

Current runs: Monitor your queued and
running desktop flows
You can use the Current runs section to monitor active desktop flow runs. These pivot
tables provide information about the number of running and queued desktop flows, and
lists with the running and queued desktop flows.

By selecting Auto refresh, all the cards will be refreshed automatically.

Currently running and Currently queued: These cards display the total number of
desktop flows that are currently running or are in queue.

Running desktop flows: This card displays the number of running flows per period
of time. It allows you to see if some of your desktop flows are stacked during their
execution or if there's throttling on specific machines.

Running desktop flows and desktop flow in run queue: These cards display the
list of flows that are running or are currently in queue. You can select Requested
items to reach the run details page, Desktop flow items to reach the desktop flow



details page, and Target items to reach the machine or machine group details
page.

７ Note

Limitations: Target for run queue table doesn't display information for standalone
machines.

Monitor desktop flow activity with Power BI
desktop (preview)
[This topic is pre-release documentation and is subject to change.]

Power Automate enables you to download a Power BI template to monitor desktop flow
activity from the Power BI desktop application. Learn more about Power BI desktop.

You can use this template to retrieve the data and charts displayed on the desktop flow
activity page, such as last runs, main errors, and machine information.

Additionally, you can:

Customize filters and graphs from the existing data in the Desktop flow activity
page.
Add your own data to build your own business dashboards.
Publish the template to share it with your organization.

Prerequisites
Install the latest version of the Power BI desktop application .



Ensure the TDS endpoint is enabled in the selected environment.

Download the Power BI template
To download the template:

1. Navigate to the Desktop flow activity page, and select Open in Power BI
(preview).

2. Select Get template on the pop-up window and save the template locally on your
machine.



3. Once the template has been downloaded, open it in the Power BI desktop
application.

4. On the first screen, provide your orgId and select Load. You must sign in with your
organization account the first time you open the template.

７ Note

You can copy the orgId from the pop-up window in Power Automate.

5. Once the template is open, you can save it as a standard PBIX file to avoid re-
entering the orgId.

Limitations



Some data aren't available in the Power BI desktop template: current runs, machine
statuses, top failed cloud flows, and the see more option.

Power BI desktop is only available in English.

Microsoft can regularly provide updates for this template. You need to redownload
the Power BI template if you want to get the latest version of it.

There's no migration of your changes between template versions.

The Power BI model doesn't adjust the timezone based on a user's location or
locale. Time is displayed in UTC timezone.



Monitor desktop flow runs
Article • 02/11/2025

As you scale the automations in your business, you might need an easy way to ensure all
your desktop flows are running as expected. Monitor all your desktop flow runs in just
one location to keep your automations running smoothly.

View list of all desktop flow runs
1. Sign into Power Automate
2. Select Monitor > Desktop flow runs

From this page, you can view all your desktop flow runs for the current environment to
which you have access.

Prerequisites
In order to see runs in this list, one of the following items must be true:

You ran an attended or unattended desktop flow in the current environment
Another user shared their desktop flow with you, which ran in the current
environment
You have permission to view all data in the environment

） Important



For cloud-initiated desktop flows based on desktop flow log V1, there's a
maximum action log capacity of 32 MB, which equates to approximately
50,000 to 80,000 action log entries. Once this limit is reached, any subsequent
actions aren't recorded in the log. If you encounter this limitation, you can
either split your flow into smaller, separate flows or switch to desktop flow
log V2. Desktop flow log V2 provides significantly more log capacity and
includes near-real-time logging while the flow is running.
Desktop flows launched within the Power Automate desktop designer don't
collect action logs.

Desktop flow run information
The following information is available on your runs:

ﾉ Expand table

Property Description

Requested The time when the desktop flow was requested by the parent flow. This value might
not be the same as the time when the desktop flow started running on the
machine.

Desktop The name of the desktop flow which was run.
flow

Status The status of the desktop flow run.

Run mode The mode in which the desktop flow was run.

Duration How long the desktop flow took to run on the machine, excluding any time spent in
the run queue.

Parent flow The cloud flow that triggered the desktop flow to run.

Customize your view
You can make changes to your view to narrow the list of runs to only the runs you're
interested in seeing. Select the column name to change the order of items or filter them
to specific values.

View all runs from the parent flow run



You might have several desktop flow runs that were triggered by one flow run. Select
the three dots next to the desktop flow name, then select See all desktop flow runs in
the parent flow.

View the run queue for a queued run
） Important

Gateways for desktop flows are now deprecated. This feature is no longer
supported from June 30, 2023, and for China regions from September 30, 2023.
Learn more

Machines and gateways can be used to run multiple desktop flows. To see the
placement of a desktop flow in the run queue, select the three dots next to the name of
the desktop flow and select See desktop flow in run queue.

Auto refresh



To keep your desktop flow run information always up to date, you can activate the Auto
refresh toggle switch at the top of the page.

Auto refresh is only supported for up to 50 desktop flow runs. Loading more runs
deactivates live updates and activating live updates with more than 50 runs trims the list
to the supported amount.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Monitor run details
Article • 02/11/2025

From this page, you can view all the details of one of your desktop flow runs for the
current environment. The information provided in this page can help you to understand
better how your flows are running, what went good or bad, and all the useful related
metadata (owner, inputs, and others).

You can access this page:

from the monitor section in the left nav of Power Automate
from Desktop flow activity: in last runs pivot by selecting one run from the desktop
flows runs card.
from Desktop flow runs

Run details
The run details card displays all the parameters related to your run.

Parent cloud flow run: the name of the cloud flow that contains the executed
desktop flow. The link redirects to the run details page of the parent cloud flow
(for attended and unattended runs). If the run mode is local attended (flow
triggered from Power Automate for desktop), the field remains empty.

Parent desktop flow run: if there's no parent desktop flow, the field remains
empty. The link redirects to the run details page of the parent desktop flow.

Start: when the desktop flow action is requested.

Duration: the duration of the desktop flow runs includes steps where Power
Automate is trying to find the machine to target (it also includes the period in
queue when all the machines are already busy)



Status: displays the result of the desktop flow runs. Result can be succeeded, failed,
canceled, skipped.

Target machine: this provides you with the information about the registered
machine that is selected to run the desktop flow in attended or unattended mode.
If you're running with local attended mode, you don’t see machine information.

Target machine group: when a machine is part of a group or the flow is run on a
hosted group, you see the name of group displayed in this section. Link redirects
you to the details page of the group.

Run mode: can be attended or unattended when the flow is triggered from the
cloud, local attended when the flow is triggered manually from Power Automate
for desktop.

Flow inputs and outputs: when a desktop flow is using inputs or provides outputs,
you can see the details of both inputs and outputs by clicking on See
{inputs/outputs} details.

７ Note

When inputs / outputs are secure inputs / outputs, you won't see the value in
the details but only {}. Inputs and outputs are also viewable from the
Dataverse Flow session  table.

Version: the version of Power Automate for desktop agent used to run the flow.

Action log version: indicates which desktop flow log version is used for this run.

Expiration date: refers to the date and time when action logs based on desktop
flow logs V2 start to be automatically deleted.

Machine credential user: indicates which machine username is used to connect
and run the desktop on the machine.

Run status
The run status is a timeline that allows to understand how works a desktop flow run
from request to finalization. Running a desktop flow from a cloud flow (attended or
unattended) has previous steps before being executed on your machine, the timeline
describes these different steps.



It might be critical for your orchestration to identify if a step took too much time or if a
desktop flow always fails during the same step.

Progressive action logging
７ Note

This feature is only available when desktop flow logs V2 is configured in your
environment.
You need Power Automate desktop version 2.52 or higher installed to use
progressive logging.

With desktop flow logs V2 enabled, you receive near real-time updates of actions as
your desktop flow runs. This feature might be essential for long-running flows that need
frequent action status update monitoring throughout the flow's execution.



Actions details
This card allows you to see information and status for each action of your desktop flow:

Start: timestamp when the action started.



Subflow: your flow can be composed of one or several subflows. By default, your
actions are in the main subflow. This information helps you to quickly identify in
which subflows the action is to fix potential errors.
Action index: in the desktop flow script, each action is linked to an action index
(this corresponds to the number of the line).
Action name
Duration
Log level: indicates the severity level (Info/Warning/Error) of the logged action.
The only action that is associated with a log level is the Log message action. For
any other logged action, the column remains empty.
Status: this column gives you for each action the result of its run.

By default, the actions are sorted from the latest to the earliest. If you don’t see all the
action in the card, select see all to view the full list of action details.

View queue events
The queue event list provides a detailed overview of lifecycle events for desktop flow
runs. It includes the status and progress of each flow run, along with corresponding
machine queue events, enabling users to monitor and understand every stage of the
process.

７ Note

Queue events are only available for desktop flows that were launched from a cloud
flow.

The following table lists the various queue events supported by this feature.



Supported Queue Events

ﾉ Expand table

Event text Event details

A flow run is queued and is ready to The desktop flow service received a desktop flow run, and
run it's now in queue to be executed.

The flow run is starting on machine The desktop flow service starts executing the desktop flow
{0} run now.

Machine {0} is returning error {1}, The desktop flow service selected a machine to run the
preventing it from accepting the run desktop flow, but the machine was unable to accept the
request request due to a specific error.

Before machine {0} can start the run, The desktop flow service selected a machine to run the
it needs to complete some desktop flow. The machine must still run preliminary
preliminary checks checks before execution can start.

This run's priority has changed, While still in queue, the run's priority changed. This might
which might affect its position in the affect its position in the queue.
queue

This run's priority has changed, While still in queue, the run's priority was changed. This
which might affect its position in the change might affect its position in the queue.
queue

This flow run was moved to the front The run moved to the front of the queue. The service
of the queue and will run next executes it next as soon as an available host is found.

This flow run was moved back to its A run was previously moved to the front of the queue, but
previous spot in the queue that action was undone. The run goes back to its previous

position.

This flow run completed successfully The run finished executing without any error.

This flow run completed on machine The run finished executing, but encountered an error.
{1}, but with error {0}

Is there anything else you need help with?

Queue event detail panel



Storage location for queue events
By default, queue event data is stored for seven days (10,080 minutes). If you want to
modify the duration of how long the queue events can be stored, you can update the
TTL for new desktop flow queue log records in the Organization table value on the
Organization table in an environment backed with Dataverse. Depending on your
environment’s storage capacity, you can adjust the length of storage for these queue
event records.

The DesktopFlowQueueLogsTtlInMinutes value on the Organization table can be
changed in the Power Apps table browser or using the Dataverse Web API .

Change queue event data retention time
frames
If the DesktopFlowQueueLogsTtlInMinutes value in the Organization table is changed,
then the lifetime of any new FlowLog record of type queue event is retained for that
length of time. Lowering the value can reduce the number of FlowLog records, and
storage used, over time.

Time To Live (TTL) value calculation examples
Time to live (TTL) values for Organization.DesktopFlowQueueLogsTtlInMinutes and
FlowLog.TTLInSeconds are specified in minutes. The following table contains common
values that can be used in the Organization and FlowLog tables.



ﾉ Expand table

Days Minutes

1 day 1,140 minutes

3 days 4,320 minutes

7 days 10,080 minutes

14 days 20,160 minutes

28 days 40,320 minutes

60 days 68,400 minutes

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Monitor desktop flow queues
Article • 10/08/2024

As you scale the automations in your business, you might need an easy way to ensure
that competing desktop flows are running according to their business priority. Monitor,
manage, and visualize all your queued desktop flow runs in just one location. Desktop
flow queues can be used whether your target device is a machine or machine group.

Setting a priority
The desktop flows connector actions contains a new priority parameter under the
Advanced options section.

Available priorities are High and Normal (the default value). This value can also be
passed dynamically using the custom value parameter. Every time the desktop flow is
triggered, it's executed with the priority that has been set.

When multiple runs are queued, the execution ordering is based on the run priority and
enqueued time. Runs with a high priority that's been enqueued first are executed first.



View run queue for a machine or machine
group
Visit the details page for your machine or machine group, then select on the Run queue
tab to see the list of queued desktop flow runs.

Prerequisites
In order to see runs in this list, one of the following situations must be true:

You're running an attended or unattended desktop flow in the current
environment
Another user shared their desktop flow with you, which ran in the current
environment
You have permission to see view all data in the environment

 Tip

To enable a user to view all the desktop flow runs in the current environment,
ensure they have been assigned at least a System Administrator or
Environment Admin security role for that environment. Learn more about
configuring user security to resources in Configure user security to resources
in an environment.
If you encounter errors related to the desktop flow run queue, go to
Troubleshoot desktop flow run queue errors.

Queue status



A run in a queue can have the following status:

Running
Queued
Next to run

Actions on a run
Four actions are available when clicking on the three dots next to the desktop flow
name:

Change priority
Move to top
See parent flow run
Cancel parent flow run

Change priority
You can change the priority of a specific run by clicking on the three dots then Change
priority. You can only change the priority of a run of which you're an owner, or if you're
a co-owner on the machine/machine group.

Changing the priority only impacts the current run and not any subsequent ones. If you
wish to change the priority of all the upcoming runs, you need to change the priority in
the connector action.

Move to top
The owner of the device or a user with administrator privileges for the machine or
machine group can override the queue priority by moving an item to the top of the
queue. That item is put at the top of the queue regardless of its original priority and
queued time. If multiple runs are moved to the top, the last one added is executed first.

You can cancel moving a run to top. It reverts the run back to its original priority and
queued time.

See parent flow run
If you have permission to access the parent flow, you can use this action to view it's run
details.



Cancel parent flow run
If you're the owner of the flow, or have the role System Administrator or Environment
Admin, you can cancel the parent flow run instance. This cancels the current desktop
flow and all the other actions that were used in the parent flow.

Extended queue prioritization
The extended queue prioritization is a machine and machine group setting, which
optimizes the machine-assignment logic of a run queue.

Enabling this feature means that extended queue prioritization is applied on machines
with multi-session support, such as Windows Server operating systems with RDS
enabled. This optimizes the default run queue prioritization by extending the current
first-in-first-out (FIFO) logic with user prioritization. This feature is enabled automatically
when multi-session support is detected, but you can opt out at any time by disabling it.

７ Note

This feature is currently being gradually rolled-out and might not yet be available in
your region.

With disabled extended queue prioritization
Principle. The machine-assignment algorithm always waits for the first run in queue
Next to run status to be assigned to a machine before considering the next one.

Step-by-step logic for an attended run. The first run in queue is an attended run. Its
connection user is user Y:​

1. ​Filter: The algorithm selects all machines, which are connected and ready to
process runs (not in maintenance, and so on).

2. Filter: The algorithm selects all machines, which have an opened session of user Y.
3. Allocation: The algorithm assigns the run to one of the remaining machines

(randomly). If no machine is remaining after the last filter, the run is failed.

Step-by-step logic for an unattended run. The first run in queue is an unattended run. Its
connection user is user Y:​

1. ​Filter: The algorithm selects all machines, which are connected and ready to
process runs (not in maintenance, and so on).



2. Filter: The algorithm selects all available machines (that is, machines that have at
least one session available).

3. Filter: The algorithm discards the machines, which already have a session opened
by user Y.

4. Allocation: The algorithm assigns the run to one of the remaining machines
(randomly). If no machine is remaining after the last filter, the run is failed.

７ Note

An unattended run can only be processed by a machine if the user session
targeted, which is recorded on the desktop flow connection, isn't already in-
use on the same machine​.
In both attended and unattended run scenarios, if no machines are left after
the final filter, but there are some eligible machines currently offline (that
were discarded in step 1), the run waits for the offline machines to come back
online before marking the run as failed.

 Tip

With disabled Extended queue prioritization, if no machine is available to
execute the first run in queue, it is either failed or it waits for an offline
machine to get back online, blocking the run queue in the meantime.
Enabling Extended queue prioritization allows the algorithm to reprioritize
the queue when the first run in queue can't be processed.

With enabled extended queue prioritization
Principle. The machine-assignment algorithm is able to consider the other runs in the
queue if the first run in the queue can't be processed for the following reasons:

Its targeted user session is currently not active on any machine (for attended runs).
Its targeted user session being already in use on all available machines (for an
unattended run).

Step-by-step logic for an attended run: The first run in queue is an attended run, its
connection user is user Y:​

1. Filter: The algorithm selects all machines, which are connected and ready to
process runs (not in maintenance, and so on).



2. Filter: The algorithm selects all machines, which have an opened session of user Y:

If some machines remain, the algorithm moves to step 4 (allocation).
If no machine remains, the algorithm moves to step 3 (reprioritization).

3. Reprioritization: The algorithm reprioritizes the queue by considering the next run
in queue until a run is assignable to a machine.

4. Allocation: The algorithm assigns the run to one of the remaining machines
(randomly).

Step-by-step logic for an unattended run. The first run in queue is an unattended run. Its
connection user is user Y:​

1. Filter: The algorithm selects all machines, which are connected and ready to
process runs (not in maintenance, and so on).

2. Filter: The algorithm selects all available machines (= machines, which have at least
one session available).

3. Filter: The algorithm discards the machines, which already have a session opened
by user Y:

If some machines remain, the algorithm moves to step 5 (allocation).
If no machine remains, the algorithm moves to step 4 (reprioritization).

4. Reprioritization: The algorithm reprioritizes the queue by considering the next run
in queue (until a run is assignable to a machine).

5. Allocation: The algorithm assigns the run to one of the remaining machines
(randomly)

Known issues
Microsoft recommends that you limit the number of short (~under 1 min) desktop
flows that you queue in large machine groups.
Desktop flow queues are designed using a best-effort FIFO (first-in, first-out)
approach to process runs in the order in which they were received, with the oldest
execution running first. However, due to the way runs are prepared and processed
internally, it's possible that runs added to the queue a few seconds later are started
before the previous one already in the queue, to optimize the use of machines.

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Data loss prevention (DLP) policies
Article • 06/30/2023

Power Automate offers to administrators the option to create and enforce policies that
classify desktop flows action groups as business or non-business and mark actions or
action groups as blocked. That way a non-business action can't be combined with an
action that has been marked as business so that to avoid data exposure outside the
organization. For more details on how to form a data loss prevention (DLP) policy, visit
the respective topic under the Administer Power Platform documentation.

Troubleshoot data loss prevention (DLP)
policies violations
While saving a desktop flow you will be notified about the data loss prevention
violations the flow includes. The same will occur while attempting to run the flow from
the designer and the console. A desktop flow that violates a data loss prevention (DLP)
policy will be marked as suspended and the run option will be disabled.

To resolve a violation navigate to the designer and delete or disable the actions causing
this error.



Business vs non-business data loss prevention
policy
The business vs non-business data loss prevention policy, prevents users to use actions
from the two categories on the same flow.

For example, the flow that appears below contains the Open SQL connection, Execute
SQL statement and Close SQL connection actions which belong to the Database actions
group and the Launch Excel, Write to Excel and Close Excel actions that belongs to the
Excel actions group. Thus it receives an error as the Database group of actions are
marked as business while the Excel group is marked as non-business.

To resolve this data loss prevention policy (DLP) violation, delete or disable actions from
one of the two groups.

Blocked actions and action groups data loss
prevention policy
Apart from marking action groups as business and non-business, the administrator can
mark action groups or particular actions as blocked. In this case these actions can't be
used at all in the flow.

In the example shown below the Email group of actions and the Send email through
Outlook actions are marked as blocked.



To resolve this data loss prevention policy (DLP) violation, delete or disable all actions
that are marked as blocked.

７ Note

In case a flow calls other flows using the Run desktop flow action, the
dependent flows are not being evaluated for data loss prevention (DLP)
violations.
If the suspended desktop flow was used in a cloud flow, this cloud flow will be
also marked as suspended. Once you have fixed the violations on your
desktop flow, make sure that all your cloud flows appear on again.

） Important

For cases that a desktop flow is suspended, it won't be able to run it. Similarly, a
cloud flow using a suspend desktop flow won't be able to run either.

Making use of suspended desktop flows in
cloud flows



A suspended desktop flows due to data loss prevention (DLP) prevention policies
violations won't be available to be selected.

To be able to launch the desktop flow from a cloud flow, edit the desktop flow in the
desktop designer and resolve the DLP violations.You will then be able to select again the
desktop flow to run.

） Important

In case a data loss prevention (DLP) policy rule is set to a desktop flow after it has
been used in a cloud flow, there won't be any notification and the cloud flow will
error out at that step. In case a desktop flow violates any rules and you correct it
you will need to go back to the cloud flow and reselect it from the list.

More info
Learn more about Power Automate DLP
Learn more about DLP policies



Power Automate console
Article • 03/21/2025

The console is the central interface of Power Automate for desktop.

The main area of the console contains four tabs that display different kind of
information: a home screen, your desktop flows, shared desktop flows, and built-in
examples.

On the top of the window, you can see the current user, while on the command bar, you
can see all the available actions, a dropdown list to switch environments, the Settings
and Help buttons, and a search bar.

７ Note

Some options in the console may be disabled due to insufficient permissions in the
current environment. Contact your administrator to grant you access or switch to
another environment. To find more information about security roles, go to
Configure user security.

Starting a desktop flow



To run a desktop flow as local attended, use the Start button next to the selected flow or
on the command bar. The Status column allows you to review the current status of each
flow.

If a running flow contains input variables, a dialog box prompts you to provide the
appropriate values.

Editing a desktop flow



Apart from creating new desktop flows, you can edit existing flows using the Edit button
next to the selected flow or on the command bar.

The development of new flows and the editing of existing flows occur in the flow
designer. To find more information regarding the flow designer and how to develop
desktop flows, refer to Desktop flow designer.

） Important

When more than one person changes a shared desktop flow, the last person who
saves the flow overrides all previous actions.

Console Settings
To configure Power Automate for desktop to your liking, select the Settings button.



Under Appearance, choose if Power Automate should work in light or dark mode
(preview).

Under Flow run control, use the Monitoring/Notifications dropdown to choose if
Power Automate should display integrated Windows notifications, a custom flow
monitoring window, or no notifications. Learn more about Power Automate notifications
in Runtime notifications.



You can also set a hotkey combination to pause or resume a running flow, and another
hotkey to stop running flows instantly.

By default, Power Automate always prompts you to confirm the triggering of a desktop
flow via URL or desktop shortcut. The Display confirmation dialog when invoking flows
externally option allows you to disable this functionality. You can find more information
about external links in Run desktop flows via URL or desktop shortcuts.

To decide whether Microsoft should collect diagnostic data to improve user experience,
navigate to the Data collection settings tab.

） Important

Only admins can change data collection settings.

Desktop flow properties
To review the properties of a desktop flow, right-click on it and select Properties, or
select the same option from the corresponding shortcut. In the General tab, you can
edit the name and description of the flow, set up a keyboard shortcut to trigger the flow
locally, define the On error behavior of the flow run, and determine whether the
desktop flow should time out after a set period of time.

If the Add screenshot to logs option is enabled, a screenshot is captured upon flow run
failure and is uploaded to the flow run action details.

The Flow timeout property is disabled by default. If it becomes enabled, you can specify
the maximum allowed time that the flow is allowed to run. If that maximum duration
limit is reached during (console or cloud initiated) runtime, the desktop flow is forced to
stop and time out. You can use the proposed timeout value, or provide your own using
a combination of an integer value with the preferred time unit (seconds, minutes, or
hours).

） Important

Access to the flow run logs is a premium feature, which requires a Power
Automate subscription .
The Flow timeout property is also a premium feature requiring the above
license.



The Add screenshot to logs and Flow timeout properties apply only to flows
stored in Power Automate v2 schema.

In the Details tab, you can see the owner, the creation and last modification dates, the
flow ID and the flow’s storage schema version in Dataverse. For more information on the
enhanced desktop flows schema, go to Power Automate v2 schema.

Additionally, there's the Run URL that you can use to run the flow through many
different sources, such as browsers, the Windows Run application, and the Command
Prompt. You can find more information regarding this functionality in Run desktop flows
via URL or desktop shortcuts.



Generate flow description using Copilot
(preview)
[This topic is prerelease documentation and is subject to change.]

Generate a flow description for flows that you own or are a co-owner by the press of a
button. Copilot then analyzes the flow and generates a description for it. This feature is
also available from the flow details in make.powerautomate.com. More information:
Manage desktop flows

） Important

This is a preview feature.
Preview features aren’t meant for production use and might have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.
To understand the capabilities and limitations of this feature, go to FAQ for
generating a flow description using Copilot.

Prerequisites



Currently, the generate flow description using Copilot functionality is only available
in environments located in the United States.
Currently, the generate flow description using Copilot functionality is only available
for users with a work or school account.

Use Copilot to generate the description
To generate a flow description, navigate to the properties of the flow where you want to
generate the description. Under the Description text area, select Let Copilot create a
description. Copilot analyzes your flow and populates the description with a summary
of your flow.



Help us improve this feature
Send feedback by selecting the thumb up or thumb down icon underneath the AI-
generated content. Once you do, a dialog box appears, which you can use to submit
feedback to Microsoft.



７ Note

If you can't see the dialog box, your Power Platform admin might have turned it off.
More information: Disabling the user feedback functionality

Disabling the generate flow description using Copilot
functionality
To disable the generate flow description using Copilot functionality, Power Platform
admins can contact Microsoft support. More information: Get Help + Support

Disabling the user feedback functionality
As a Power Platform admin, prevent users from sending Copilot feedback to Microsoft
by using the "Copilot feedback" tenant setting.

Data subject rights requests on user feedback
Tenant administrators can view, export, and delete the feedback from users by signing in
to the Microsoft 365 admin center , and then select Health > Product feedback.

Related information
FAQ for generating a flow description using Copilot



Update Power Automate for desktop
Power Automate frequently checks for updates and displays appropriate notifications.

Update notifications offer you the option to delay the update and proceed with it at a
later time. If you don't wish to receive any update notifications, clear the Show update
notifications option in the general settings.

To manually update Power Automate for desktop, select Check for updates in the
general settings.

Switch organization
If you're a member of more than one tenant, you can switch organizations by selecting
the organization name at the top right corner of the console and then select Switch
organization.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Power Automate desktop flow designer
Article • 09/21/2024

The flow designer in Power Automate desktop contains all the tools required to design
and debug a Power Automate flow. Additionally, any images, UI elements, or variables
of a desktop flow can be accessed and managed here.

The flow designer consists of multiple elements. The actions pane, the variables pane,
and the workspace, which displays information about the status of the flow and all the
data it contains. Subflows are separated into tabs to help design large, complex flows.
Tools for debugging flows, such as breakpoints and the option to run a desktop flow
step by step, are also available in flow designer. Any error information is displayed, and
erroneous actions are immediately highlighted.

Open the flow designer
1. Open Power Automate desktop.
2. Select New flow or open an existing flow, such as from the My flows tab.
3. If you're creating a new flow, enter the name you want for the flow, such as

Operational flow in this example, and then select Create. The flow designer is
displayed in a separate app window.



Next steps
Configure actions and the actions pane

Manage variables and the variables pane



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Configure actions and the actions pane
Article • 02/21/2025

The actions pane occupies the left side of the flow designer and displays all the available
desktop flow actions.

To find a specific action, populate its name in the search bar at the top of the pane.
Searching also returns partial matches but requires at least two provided characters.
When the search term matches a module name, the results display the module
expanded with all its actions available.

Add actions to the workspace



To develop a desktop flow, find the action you want to deploy, and double-click on it or
drag it into the workspace.

After the deployment, the modal of the action opens and displays the available
parameters of the action. Some actions might have default values for some parameters,
while others require user input. When the configuration is ready, select Save.



Adding actions from the suggested actions panel
(preview)
In addition to adding actions from the actions panel, you can also use the suggested
actions panel.

） Important

This feature is in preview. Preview features aren’t meant for production use
and may have restricted functionality. These features are available before an
official release so that customers can get early access and provide feedback.
To understand the capabilities and limitations of this feature, go to FAQ for
Power Automate for desktop suggested actions.

Availability by region



Currently, the suggested actions functionality in Power Automate for desktop is only
available in environments located in the United States.

Availability by account type
Currently, the suggested actions functionality in Power Automate for desktop is only
available for users with a work or school account.

Using suggested actions in your flows
The suggested actions functionality uses AI to generate a list of actions that you could
use as the next steps in your flow. To do so, select the add button that appears on
mouse hover or when an action is selected.



Once the Suggested actions panel appears, double-click the action that you want to
add to your flow.





Disabling the suggested actions functionality
To disable the suggested actions functionality, Power Platform admins contact Microsoft
support. More information: Get Help + Support

Help us improve this feature
You can send feedback by selecting the thumb up or thumb down icon underneath the
AI-generated action suggestions. Once you do, a dialog box appears, which you can use
to submit feedback to Microsoft.



７ Note

If you can't see the dialog box, your Power Platform admin might have turned it off.
More information: Disabling the user feedback functionality

Disabling the user feedback functionality
As a Power Platform admin you can prevent users from sending feedback to Microsoft
by disabling the disableSurveyFeedback tenant setting. More information:

List tenant settings (preview)
Set TenantSettings

Data subject rights requests on user feedback
Tenant administrators can view, export, and delete the feedback from users by signing in
to the Microsoft 365 admin center , and then selecting Health > Product feedback.

Configure actions
Power Automate actions contain three main elements:

Input parameters have the form of text fields, drop-down menus, and checkboxes
and determine the way the action functions and the data it gets as input. The data
can be hardcoded values or variables.



To use a variable as a parameter, select the appropriate icon on the right side of
the field and pick the desired variable.

Each field can accept specific data types, such as numeric values, text, or lists. If
you use values or variables of wrong data types as inputs, the action results in an
error. To find more information about data types, refer to Variable datatypes.

Produced variables are automatically generated variables that hold the outcomes
of the actions for later use. All the produced variables of an action are available on
the bottom part of its modal.

Like any other variable, produced variables have data types defined by their
content. To find more information about data types, refer to Variable datatypes.

If a produced variable isn't useful for later use, unselect the checkbox next to its
name to disable it.

The name of a produced variable can't contain special characters, white spaces,
and non-Latin characters. Additionally, it can't start with arithmetic characters.



Error-handling configuration allows you to set a custom functionality for the cases
when an action fails. To configure error-handling for an action, select On error in
its modal. To find more information regarding error-handling, refer to Handle
errors in desktop flows.



Enable and disable actions
To disable or enable an action, right-click on it and select Disable action or Enable
action, respectively.

Disabling an action allows you to remove it from the flow without erasing it. This feature
is commonly applied for testing, as it enables you to try different versions of your
desktop flow efficiently.

When an action is disabled, all variables initialized in its modal get hidden from the
variables pane. The flow might display an error if you use the hidden variables in other
actions.

In the following example, two actions throw an error because they contain variables
defined in a disabled action. To find information on how to handle errors, go to Handle
errors in desktop flows.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Assets library
Article • 01/31/2025

） Important

This feature requires Power Automate for desktop v2.32 or later.

Assets library allows you to include more functionality in desktop flows. For example,
you can make certain cloud connectors available in your flow, upload custom actions to
the assets library when required, or you can search for available UI elements collections.

To access the assets library, select the Assets library button at the top-right of the
designer.

Alternatively, use the Tools bar.

Custom actions tab
Custom actions tab shows you the custom actions uploaded in the environment you
selected.

７ Note



You can only see custom actions shared with you.

UI elements collections tab
The UI elements collections tab shows you the UI elements collections that are
published in the environment you selected.

７ Note

You can only see UI elements collections that you have created or are shared with
you.

Connectors tab



The Connectors tab includes all the non-custom cloud connectors available in Power
Automate, offering out-of-the-box integration with the corresponding operations in
desktop flows.

Adding a connector makes it appear in the actions pane of your flow designer, giving
you access to its operations. The connectors that are already available in your flow are
also shown in the Assets library's list and appear marked with the label Added.

If at least one operation from a connector is used in the flow, that connector is loaded
during the designer's launch in the actions pane.

Known limitations
When you manually add a new connector to a flow, there's currently no option to
remove it through the assets library. If you save and reopen the flow designer
without using any actions from a connector, the unused connector is automatically
removed. This isn't the case for the cloud connectors that were introduced before
the Connectors tab in the Assets library, as those connectors are permanently
visible in the actions pane of the designer and can't be removed.
The SFTP and YouTube connectors can't currently be added in the actions pane
through the assets library.

Related information



Cloud connectors
Custom actions
Create custom actions
Upload custom actions
Use custom actions
UI elements collections
Create and publish UI elements collections
Manage UI elements collections
Use and update UI elements collections

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Manage the flow designer workspace
Article • 08/27/2024

The central pane of the flow designer is called the workspace. Workspace is the
component where the series of actions that make up the flow is assembled:

During development, users can add, edit, and delete actions in the workspace.

Drag actions to rearrange them and change the order in which they run. Right-click an
action and select Enable action or Disable action to enable or disable an action
respectively; while running, the flow skips any disabled actions.

Copy and paste any selected actions in the workspace. You can copy and paste actions
within the same subflow, among different subflows, or other open instances of flow
designer.

Setting up subflows
Subflows are groups of actions, which can be referenced as a group within a desktop
flow.

Every flow contains the Main subflow that runs when a desktop flow starts. Any other
subflows can be invoked through the Run subflow action:



Additionally, this action supports dynamic expressions through the toggle parameter,
allowing you to use variables and dynamically invoke the corresponding subflow at
runtime.

Subflows are shown in tabs, directly over the main workspace. To add a new subflow,
select the subflows tab, select +, and enter the subflow name.

Select a subflow tab to edit the respective subflow.

Saving flows
To save a flow, select File in the flow designer's menu bar and then pick Save.
Alternatively, you can press the keyboard shortcut Ctrl  + S .



To save the flow's current state as a new flow, select Save as in the File menu and
populate a name for the new flow in the displayed dialog.

Managing the workspace toolbar
Drag actions to rearrange them and change the order in which they run. Right-click an
action and select Enable action or Disable action to enable or disable an action
respectively. While a flow is running, the flow skips any disabled actions.

To select multiple actions, hold down Ctrl . To select multiple actions, hold down Shift ,
and select the first and last actions. Copy and paste any selected actions in the
workspace.



When you copy actions, all their parameters, images, and UI elements are copied as well.
You can copy and paste actions within the same subflow, among different subflows, or
other flow designer instances. Apart from flows, you can paste actions in other
applications in a text format, such as a text editor, to share flows' sections with others.

７ Note

As the underlying schema of an action or the UI elements or images repository
might change from one version of Power Automate for desktop to another, make
sure when copying flows's sections that the source and target flow designers are on
the same version. If the schema is updated on a new version and a different
version's flow contents are pasted, the action or the associated UI elements or
images might not be recognized.

Searching in the flow
To search for a text string, an action or variable within the flow, use the search field at
the top right of the flow designer window. You can also select CTRL  + F  to focus on the
search field. The results pane shows all occurrences of text string by action and subflow.
Double-click on a result to highlight the action that contains it.

Using the Go to line option
The Go to line function navigates to a specific line within the current subflow. It can be
helpful in subflows that contain a large number of actions.



Select Edit, then Go to line and enter a line. The corresponding action is highlighted.

Using the Run from here option
To run the flow starting from a specific action, right-click the action and select Run from
here. Power Automate ignores all the previous actions and runs the flow from the
selected action onwards.

７ Note

The Run from here option isn't available for actions located in loops, conditionals,
or the On block error action.

Record desktop flows



Power Automate enables you to record desktop flows in real time through the built-in
recorder. The recorder keeps track of mouse and keyboard activity in relation to UI
elements, and records each action separately. The recorder can be used to automate
desktop and web applications.

To record a flow, select Recorder in the toolbar of the flow designer. When the recorder
dialog is launched, select Record to start recording. To suspend the recording, select
Pause. To add a comment to the recorded actions, select Add a comment.

Select the bin icon to remove individual actions, or select Reset to delete all the actions
recorded so far. When the recording is completed, select Done to convert the recorded
steps to desktop flow actions.

You can find more information regarding the built-in recorder in Record desktop flows.



Feedback



Was this page helpful?  Yes  No

Provide product feedback



Debug a desktop flow
Article • 02/24/2023

It is common to have to debug flows in case there are any changes in the system or if a
desktop flow cannot run because it contains errors.

Debug a desktop flow using the following tools:

Errors Pane
Breakpoints
Run flow action by action
Set the Run delay

Run, stop, and pause in flow designer
Select Run or press F5 to run the flow. When the flow runs, Run becomes Pause. Select
Pause or press Ctrl + Pause while the flow is running to pause and inspect any changes
up to that point. Select Run while the flow is paused to resume it. The Run next action
button and the F10 shortcut run the flow action by action and pause it after each action
completes. The Stop button and the Shift + F5 shortcut stop the flow completely.

Adding breakpoints
Click to the left of the running order number in the workspace to place a breakpoint in
the flow, which appears as a red dot. Add a breakpoint to specify at which action to
pause the flow. Resume running the flow by selecting Run or Run next action. Select the
breakpoint to remove it.



Run a desktop flow by action
The Run next action button runs the flow action by action. After each action is
completed, the flow is paused. Open the variables pane to check the value of any
variable at the point where it's paused. This feature is useful for debugging.

The status bar
The status bar on the bottom of the window shows the status of the flow and the
number of the selected actions. Additionally, it shows the total number of actions and
subflows in the current flow.

The Run delay field defines the time that the flow waits after running each action in the
flow designer. You can modify the default value to increase or decrease the milliseconds
that the flow waits.

The status bar also displays the number of errors, if any are present. Select the Errors
option to pop up the Errors pane.

If you search inside the flow, the status bar shows an additional field containing the
number of the results. Select this field to pop up the Find in code pane.

Run from here
To run the flow starting from a specific action, right-click the action and select Run from
here. This ignores all previous actions and runs the flow from the selected action
onwards.



Power Automate reserved keywords
A certain amount of words are being used in the core of Power Automate and can't be
used during development in the variable, subflow, label or error block names.
The list of
these words is displayed below.

A - E F - J K - R S - Z

action FALSE label set

and for loop step

block foreach main switch

call from mod then

case function next throw

default global no times

disable goto not to

else if on TRUE

end in or wait

error input output while

exit repeat xor

yes



Manage variables and the variables
pane
Article • 02/19/2025

The variables pane shows the input and output variables passed to and from Power
Automate desktop flows. It also displays all the variables used in the current desktop
flow under Flow variables.

Through this pane, you can search for variables, rename them, find their usages,
marking them as sensitive, pin them, and filter them by type. Filtering allows you to
select whether to apply it to the pinned variables or not.

The variable value viewer
When a flow runs, the current value of each variable is visible next to its name. Select the
eraser icon at the bottom of the variables pane to clear all the current values.

７ Note

Power Automate automatically omits the variables of disabled actions. Enable a
disabled action to make its variables available in the variables pane.



To examine the value of a variable in more detail, double-click on it. The variable value
viewer displays the datatype of the selected variable and expands any datarows or
datatables to show their contents.



Certain data types might contain nested elements. For example, a custom object might
contain another custom object in its properties. To view the properties of the nested
element, select More.

Select the arrow icon on the top of the dialog to return to the parent element.



Renaming a desktop variable
To rename a desktop flow variable, right-click on its name and select Rename. Power
Automate automatically updates the name of the variable in all its occurrences.

） Important

If you try to rename a variable to an existing name, Power Automate will prompt
you to confirm the merging of the two variables. Unintentional merging may affect
the functionality of your flow and cause errors, so ensure that the merging is
desirable.



Input and output variables
Power Automate lets you exchange data between cloud and desktop flows using input
and output variables, expanding automation capabilities. Input and output variables also
let you pass information between desktop flows through the 'Run desktop flow' action.

Additionally, you can use input variables to set values manually when the flows are
triggered through the console.



To find more information regarding passing data between cloud and desktop flows,
refer to Trigger desktop flows from cloud flows.

Create an input variable
To create an input variable:

1. Select the plus button (+) in the variables pane and then Input.

2. When the New input variable dialog appears, populate the following fields:

Variable name: The name of the variable in the desktop flow.
Data type: The type of the variable: text, number, boolean, custom object, list,
datatable, or instance.
Default value: The default value when the flow runs through the flow
designer or console. When you create a custom object, list, or datatable input
variable, Power Automate allows you to construct the default value through a



visual or JSON editor.

Data subtype: The exact type of the instance (available only when Instance is
previously selected as data type): Excel, Word, Outlook, or Access.
External name: The external name is the name that appears in the cloud flow
designer and the flow inputs dialog when calling the flow from the console.
Description: The description of the variable that appears in the cloud and
desktop flow designer while calling the flow.
Mark as sensitive: Defines whether to mark the variable as sensitive or not.
You can find information regarding sensitive variables in Sensitive variables.
Mark as optional: Defines whether populating this input variable is
mandatory or not. By marking an input variable as optional, you allow it to
receive Blank values and omit passing an actual value, which doesn't result in
an error. You can find information regarding optional input variables in
Optional input variables.

７ Note

The Variable name, Data type, and External name fields are required to
create an input variable.

７ Note

Input variables of instance type (Excel, Word, Outlook, or Access) don't
support default values. Flows with these inputs can run through the 'Run
desktop flow' action of another desktop flow or through the designer for
testing or debugging. In designer runs, instance input variables can be
temporarily initialized by using them as the produced variables of the
respective Launch or Attach actions.



） Important

If you choose an existing flow variable name for a new input variable, Power
Automate will prompt you to confirm the merging of the two variables.
Unintentional merging may affect the functionality of your flow and cause
errors. Also, you can't use the name of an existing input or output variable.

When you trigger desktop flows directly through the console, not a cloud flow, the Flow
inputs dialog prompts you to set values for the input variables manually. For custom
objects, lists, and datatables, the dialog allows you to populate values using a visual or
JSON editor.



Create an output variable
To create an output variable:

1. Select the plus button (+) in the variables pane and then Output.

2. When the New output variable dialog appears, populate the following fields:

Variable name: The name of the variable in the desktop flow.
Data type: The type of the variable: text, number, boolean, custom object, list,
datatable, or instance.
Data subtype: The exact type of the instance (available only when Instance is
previously selected as data type): Excel, Word, Outlook, or Access.



External name: The external name is the name that appears in the cloud flow
designer.
Description: The description of the variable that appears in the cloud or
desktop flow designer while calling the flow.
Mark as sensitive: Defines whether to mark the variable as sensitive or not.
You can find information regarding sensitive variables in Sensitive variables.

７ Note

The Variable name, Data type, and External name fields are required to
create an output variable.

） Important

If you choose an existing flow variable name for a new output variable, Power
Automate will prompt you to confirm the merging of the two variables.
Unintentional merging may affect the functionality of your flow and cause
errors. Also, you can't use the name of an existing input or output variable.

Manage input and output variables



All created input and output variables are available in the appropriate section of the
variables pane.

You can use this pane to rename, update, delete, find the usages, pin and filter each
input/output variable. Filtering allows you to select whether to apply it to the pinned
variables or not.

To update an input/output variable:

1. Right-click on its name in the variables pane and select Edit.

） Important

If you try to rename an input or output variable to an existing flow variable
name, Power Automate will prompt you to confirm the merging of the two
variables. Unintentional merging may affect the functionality of your flow and
cause errors. Also, you can't use the name of an existing input or output
variable.



2. In the Edit input/output variable dialog, update the desired fields and select Save
to apply the changes.

Sensitive variables



） Important

Flows developed in older versions of Power Automate for desktop (v.2.13 or older)
remain unaffected by the sensitive variables functionality as long as you don't edit
them. If you run existing desktop flows through the console or portal without
editing them, they'll keep the old behavior and work like before.

To apply the new functionality, edit and save the flows with Power Automate for
desktop v.2.14 or above. Power Automate will convert past encrypted input
variables and encrypted variables produced by the Get password from CyberArk
action to text variables marked as sensitive.

Some automation scenarios handle confidential information and require special
handling of variables that store and use sensitive data during runtime. Desktop flows
support the creation of sensitive variables, whose values are masked during debugging
in the variables pane of the flow designer.

Additionally, if you've logged in with an organization premium account, the values of
sensitive variables aren't stored in the Run history in the portal, when the desktop flows
run through the console or cloud flows.

Any variable can become sensitive, independently of its type. Sensitivity applies at the
variable level, so lists, datarows, datatables, and custom objects, get sensitive as a whole.
There's no way to mark a list item, a datatable column, or a variable property as sensitive
in an otherwise nonsensitive variable.

You can use, manipulate and process sensitive variables in every action without any
limitation, like every other variable. Additionally, you can combine them with other
variables and include them in expressions. In this case, logs handle the whole expression
as sensitive.

The flow designer handles sensitivity as a mask that you can set on and off. Thus, you
can unmask sensitive variables to see their values and mask them again to hide their
values.

） Important

Sensitive variables aren't meant to provide protection over hardcoded data. You
shouldn't hardcode critical data in plain text, like passwords and PINs, in the
properties of actions like Set variable, even if the said variables are marked as
sensitive. The desktop flow logs will be protected, but the hardcoded values are
visible in the modal and the flow definition in Microsoft Dataverse.



To find more information regarding sensitive inputs in cloud flows, see Manage
sensitive input like passwords.

７ Note

The value of a sensitive variable is visible when you send it outside desktop
flows or displayed through the Display message action.
Sensitivity isn't inheritable in variables. If you add or assign a sensitive variable
to another variable, the resulting variable won't be sensitive by default. The
exception to this rule applies only to credential variable types. Credential
variables, produced either by the respective action or by reassignment from
another variable, are always sensitive, and their sensitivity is enforced. The
same exception also applies to the "Password" property of credential variable
types.
Marking a variable as sensitive hides its values from the summary of the Set
variable action.
The input details of the Set variable action aren't visible in the desktop flow
logs when the contained variables have been marked as sensitive.
Masking sensitive variables during debugging provides only a basic form of
protection to developers from third parties looking at their screens.

To mark a variable as sensitive, right-click on it in the variables pane and select Mark as
sensitive. To stop a variable from being sensitive, right-click on it and select Mark as not
sensitive.



Apart from the context menus, you can use the dedicated icon next to each variable to
mark it as sensitive or not sensitive.

Sensitive input and output variables
When you create or edit an input or output variable, you can select Mark as sensitive in
the respective dialog to make it sensitive.



The default value of an input variable is visible in the creating or editing dialog when
sensitivity is enabled. This value exists only for testing and debugging purposes, as you
have to initialize each input in production runs through the portal or the console. The
default values aren't protected in the action modals and the flow definition in Dataverse.

On the other hand, the default value isn't visible in the variables pane and the Flow
input dialog, which appears when you run a desktop flow with input variables through
the console.

The eye icon to reveal the value isn't available unless you delete the default text value
and provide a new one. New values are visible when populating other datatypes besides
text.



Optional input variables
When you create or edit an input or output variable, you can select Mark as optional in
the respective dialog to make it optional.



By default, input variables are mandatory meaning that you must provide:

A default value when creating it so that it can be used during debugging (console
initiated) runs in case you don't pass another value.
A value of the respective type to ensure proper execution.

If an input variable is marked as optional both of the above can be omitted because it
can receive Blank values.

Setting optional inputs' default value to Blank

Text variables
To set a text variable's default value to Blank:

Set the Data type property to Text.
Enable the Mark as optional control.
Make sure the Default value property is empty.



Blank numeric input
To set a numeric variable's default value to Blank:

Set the Data type property to Number.
Enable the Mark as optional control.
Make sure the Default value property is empty.

Blank boolean input
To set a boolean variable's default value to Blank:

Set the Data type property to Boolean.
Enable the Mark as optional control.
Make sure the Default value property is set to <Blank>.



Blank custom object input
To set a custom object's default value to Blank:

Set the Data type property to Custom object.
Enable the Mark as optional control.
Make sure the Default value property is set to <Blank>. To achieve this, select Edit
next to the property and in the Edit custom object window, enable the JSON
editor control. Delete all the contents, and then select Save.



Blank list input
To set a list's default value to Blank:

Set the Data type property to List.
Enable the Mark as optional control.
Make sure the Default value property is set to <Blank>. To achieve this, select Edit
next to the property and in the Edit list window, enable the JSON editor control.
Delete all the contents, and then select Save.



Blank data table input
To set a data table's default value to Blank:

Set the Data type property to Datatable.
Enable the Mark as optional control.
Make sure the Default value property is set to <Blank>. To achieve this, select Edit
next to the property and in the Edit datatable window, enable the JSON editor
control. Delete all the contents, and then select Save.



Edit variables while debugging a desktop flow
In the design console, Power Automate desktop supports editing common variable
types while running the flow in the debugger. Currently, supported data types include,
text, numeric, datetime, and boolean values.

How to edit variables while running a flow in the
debugger
There are two methods you can employ to begin manually modifying flow variable
values in the design console.
Place a breakpoint at some point before you want to change the value of flow variable.
Run the flow and then wait until the flow pauses at the selected breakpoint. The flow
variables pane is in the bottom right corner of the console – find the variable name in
the list and double-click next to it to open the variable viewer.

Modify a numeric value:



Open the variable that requires editing, place the cursor on the input field and manually
edit the numeric value. Alternatively, there are buttons to count up, or down from the
current value on the right side of the input in the variable viewer. Note, you can't
change the value to something other than numeric.

Modify a text value:

Open the variable that requires editing, place the cursor on the input field and manually
edit the text value. There's a checkbox to wrap text within the input field, which makes it
easier for you to view in the editor. Text value variables accept numbers as inputs, but
keep in mind that if you modify this value and try to pass it to an action with an input
parameter that only accepts numeric value, the flow throws an exception error when it
reaches that point.

Modify a boolean value:

Open the variable that requires editing, place the cursor on the input field, and then
manually edit the boolean value. Use the drop-down list to select true or false.



Modify a datetime value:

Open the variable that requires editing, place the cursor on the input field and manually
edit the datetime value. There's a warning message that appears in the variable viewer if
you enter a value that isn't acceptable.

Known issues and limitations
Issue: Flows built or edited with Power Automate for desktop version 2.14 or above
are incompatible with older versions of Power Automate for desktop. You can't use
older versions of Power Automate for desktop to open or run these flows.

Workarounds: None.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Variable data types
Article • 10/29/2024

When you create variables in your flows, Power Automate converts them to a specific
type based on their content.

Some of these data types are widely used throughout the application, such as numbers,
while others, such as browser instances, require explicit actions or groups of actions.

Simple data types
Simple data types represent single values, such as texts and numbers. You can use these
data types independently or use them to create more complex data structures, such as
lists and datatables.

Text value
This is any kind of text, from email addresses to the text contents of a .txt file.

Text data type properties

To create a Text value variable, use the Set variable action and populate the input
parameter with the desired text without any notation.

Numeric value



Numeric is the type applied to numbers. Only this data type can be used in
mathematical operations.

Τo create a Numeric value variable, use the Set variable action and populate the input
parameter with a number without any notation.

Except for hardcoded numeric values, you can use mathematical expressions with
variables within percentage signs. For more information about mathematical
expressions, go to Use variables and the % notation.

Boolean value
The value can be either True or False.

Τo create a Boolean value variable, use the Set variable action and populate the input
parameter with the expressions %True% or %False%.

Additionally, you can create complex expressions using logical operators, variables, and
the percentage notation. For more information about logical expressions, go to Use
variables and the % notation.



Advanced data types
Advanced data types represent complex data structures. They function as collections of
other data types that you can access as one entity.

List
Lists are collections of items. Depending on the types of the individual list items, there
can be lists of text values, lists of numerical values, and so on. The list data type is the
equivalent of a single-dimension array in programming terms.

You can create a list through the Create new list action and add an item to that list
through the Add item to list action.



You can also create a list through actions that generate lists as output. For example, the
Read text from file action can return a list of text values and the Get files in folder
action returns a list of files.

To retrieve a specific item in a list, use the following notation:
%VariableName[ItemNumber]%

In the example below, the flow stores the first number of the previously displayed list to
a new variable. Keep in mind that the index should be 0 for the first item of the list.

A common practice is to use a For each action to iterate through the items of a list.

If you need to access only a specific part of a list, use the
%VariableName[StartIndex:StopIndex]% notation. For example, the expression
%List[2:4]% retrieves the third and fourth items of the list. The item in the StopIndex
position is the boundary of the slicing and doesn't get retrieved.

To slice a list from the start to a specific item, don't set a StartIndex value, for example,
%List[:4]%. To slice a list from a specific index to the end, don't set a StopIndex value,
for example, %List[2:]%.

List data type properties

Datatable
Datatables contain data in a tabular form and are the equivalent of two-dimensional
arrays in programming terms.

A datatable contains rows and columns that describe the position of each item uniquely.
Datatables can be considered as lists that contain datarows as items.



Power Automate provides the Create new data table action to generate new datatables.
After deploying the action, you can use the visual builder to populate values and
rename the column headers.

Apart from the Create new data table action, three more actions produce datatables to
store extracted data: the Read from Excel worksheet, Execute SQL statement, and
Extract data from web page actions.

Additionally, you can create a datatable using the Set variable action and the
programming array notation. This notation consists of multiple single-dimension arrays
separated by commas and enclosed in curly brackets. The final expression must have the
following form: %{['Product1', '10 USD'], ['Product2', '20 USD']}%.



If you want to add column headers while creating a new datatable using the array
notation, use the ^['ColumnName1', 'ColumnName2'] expression for the first row.

To add a new row to an existing table, use the Insert row into data table action.
Alternatively, create an expression containing the variable name of the datatable, a plus
character (+), and the values you want to add in brackets.



Besides inserting rows into datatables, desktop flows offer various actions that
manipulate datatables. You can find a full list with these actions in the variable actions
reference.

To retrieve a specific item of a datatable, use the following notation:
%VariableName[RowNumber][ColumnNumber]%. Keep in mind that the RowNumber
and the ColumnNumber should be 0 for the first item (row or column).

For example, suppose that a flow retrieves the content of an Excel worksheet and stores
it in the ExcelData variable. To access the first cell on the second row of the retrieved
table, use the expression displayed below.

７ Note



The ExcelData variable contains a table of values extracted from an Excel worksheet
using the Read from Excel worksheet action. It contains some values of a specific
worksheet and not the whole Excel file.

If you want to access a specific column in a datable that contains column headers, use
the %ExcelData[rowNumber]['ColumnName']% notation.

If you loop through a datatable with a For Each action, the variable that contains the
current iteration’s data is considered to be a datarow.

Similarly to lists, you use the %VariableName[StartRow:StopRow]% notation to access a
specific part of a datatable. The expression retrieves only the rows defined by the two
indexes, while the StopRow position is the boundary of the slicing and doesn't get
retrieved.

To slice a datatable from the first row to a specific row, don't use a StartRow value, for
example, %Datatable[:4]%. Likewise, to slice a datatable from a specific row to the end,
don't use a StopRow value, for example, %Datatable[2:]%.

Datatable data type properties

Datarow
A datarow contains the values of a single row of a datatable. When you loop through a
datatable with a For Each action, the variable that contains the current iteration’s data is
a datarow.

To retrieve a specific item of a datarow, use the following notation:
%VariableName[ItemNumber]%

Alternatively, you can use the %VariableName['ColumnName']% notation. The name of
each column is defined by the datatable from which you retrieved the datarow.

Datarow data type properties



Custom object
Contains pairs of properties and values, which can be easily converted to JSON format.

To create a new empty Custom object, use the Set variable action and populate the
following expression %{{ }}%. To create a new Custom object and initialize it with
properties and values, use an expression of the following structure: %{ 'Property1':
'Value1', 'Property2': 'Value2', 'Property3': 'Value2' }%.

） Important

Reserved keywords can't be used as custom object properties. For the full list of
reserved keywords go to Reserved keywords in desktop flows.

To update the value of an existing property or add a new one, deploy a Set variable
action, populate the property's name in the Set field, and enter its value in the To field.



Apart from literal values, you can use variables to dynamically set the properties and
values of custom objects. For example, the following flow uses two variables to add a
new property to a new empty custom object.

Connector object
Connector objects store information from cloud connectors and work similarly to
custom objects. Their properties usually contain lists of other connector objects.
Accessing values works as in custom objects, although accessing nested values might
require more complicated expressions.



List of PDF table info
A variable of this data type can be produced only through the Extract tables from PDF
action.

Each item on the list describes an extracted table and provides all the essential
information about it. To access a specific datatable info item, use the
%VariableName[ItemNumber]% notation.

Every list item provides four properties that allow you to get a specific detail
independently. The available properties are the following:

DataTable – Returns the extracted table.



TableStartingPage – Returns the index of the file page that contains the start of
the table.
TableEndingPage – Returns the index of the file page that contains the end of the
table.
TableOrderInPage – Returns the order of the table on the page.

You can find more information regarding the properties of this data type in Variables
datatype properties.

To access the value of a specific property, use the
%VariableName[ItemNumber].PropertyName% notation. For example, the following
expression returns the datatable value of the first item of the ExtractedPDFTables
variable.



Known issues and limitations
Issue: When a datatable or datarow cell contains a multiline entry, the variable
viewer displays only the first line of it.
Workarounds: None.

Instances
Web browser instance – Contains a browser instance created through the Launch
new Internet Explorer or other browser launching actions.

Web browser instance data type properties

Window instance – Contains a window instance created through the Get window
action.

Window instance data type properties

Excel instance – Contains an Excel instance created through the Launch Excel
action.

Excel instance data type properties

Outlook instance – Contains an Outlook instance created through the Launch
Outlook action.

Connections



SQL connection – Contains a connection to an SQL database established through
the Open SQL connection action.

SQL connection data type properties

Exchange connection – Contains a connection to an Exchange server established
through the Connect to Exchange server action.

Exchange connection data type properties

FTP connection – Contains an FTP connection created through the Open FTP
connection and Open secure FTP connection actions.

FTP connection data type properties

Others
This section presents all the available data types that don't belong to any of the
previous categories.

General value
General value – This data type is used during design time when Power Automate
can't define the data type of a variable or an input parameter. General values get
converted to other data types during runtime based on their data.

Active Directory
Active Directory entry – Contains a connection to an Active Directory server
established through the Connect to server action.
Group info – Contains the name, the display name, a description, and the
members of a specified Active Directory group.
Group member – Represents a member of a specified Active Directory group.
User info – Contains information about a specified Active Directory user, such as
first and last name, initials and a distinguished name, work details (company,
department, and title), contact information (telephone number, extension, and
email), and location (country/region, city, state, street address, and postal code).

Active Directory data type properties

Amazon Web Services (AWS)



EC2 client – Contains an EC2 session created through the Create EC2 session
action.
EC2 instance – Represents a retrieved EC2 instance.
EC2 instances info – Contains information about an EC2 instance.
Instance state change – Contains information about an EC2 instance that was
started or stopped.
EBS snapshot – Represents an EBS snapshot.
EBS volume – Represents an EBS volume.

AWS data type properties

Azure
Azure client – Contains an Azure session created through the Create session
action.
Azure resource group – Represents a retrieved Azure resource group.
Azure managed disk – Represents a retrieved Azure disk.
Azure snapshot – Represents an Azure snapshot.
Azure virtual machine – Represents a retrieved Azure virtual machine.
Azure virtual machine info – Contains information about an Azure virtual machine.
Azure subscription – Represents a retrieved Azure subscription.

Azure data type properties

CMD
CMD session – Contains a CMD session created through the Open CMD session
action.

CMD data type properties

Credentials
Credential – Contains a credential retrieved through the Get credential (preview)
action.

Credential data type properties

Dates and time
Datetime – Contains date and time information. To create a datetime variable
through the Set Variable action, populate the input parameter with the expressions



%d"yyyy-MM-dd HH:mm:ss.ff+zzz"%, where:

ﾉ Expand table

Notation Description

yyyy Year

MM Month

dd Day

HH Hour

mm Minutes

ss Seconds

ff Milliseconds

zzz UTC Offset

For example, %d"2022-03-25"% assigns the 25th of March 2022 date to the target
variable.

Dates and time data type properties

Email
Mail message – Represents an email message. The Retrieve emails action
populates these variables.

Email data type properties

Exchange
Exchange mail message – Represents an email message retrieved from an
Exchange server. The Retrieve Exchange email messages action populates these
variables.

Exchange data type properties

Files and folders
File – Represents a file.
Folder – Represents a folder.



FileSystemObject – Represents either a folder or a file. This data type is used in
input parameters that accept folders and files.

Files and folders data type properties

FTP
FTP file – Represents an FTP file.
FTP directory – Represents an FTP directory

FTP data type properties

OCR
OCR Engine – Contains an OCR engine created through the Create OCR engine
action.

Outlook
Outlook mail message – Represents an email Outlook message. The Retrieve
email messages from Outlook action populates these variables.

Outlook data type properties

Terminal
Terminal session – Contains a terminal session created through the Open terminal
session action.

Terminal data type properties

XML
XML node – Contains the content of an XML document. The Read XML from file
action populates these variables.

XML data type properties

Error
Error – Contains information about the last occurred error in the desktop flow. The
Get last error action creates this type of variable.



Error properties

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Variable data type properties
Article • 10/29/2024

Some of the built-in data types have properties that are associated with the value stored
in the variable.

A property may contain a part of the information stored in the variable, like the day of a
date, or an extra attribute describing the variable, like the size of a list.

The value of these properties can be accessed directly through the following notation:
%VariableName.PropertyName%.

For example, if you have a list of files called Files, you can get the number of the stored
files using the expression: %Files.Count%

The data types that have properties are displayed in the following lists.

Texts
ﾉ Expand table

Property Description

Length The length of the stored text in characters.

isEmpty This property is true if the variable is empty or false if it contains some characters.

ToUpper The text of the variable written in upper case characters.



Property Description

ToLower The text of the variable written in lower case characters.

Trimmed The text of the variable written without white characters in the begging and the end.

Dates
ﾉ Expand table

Property Description

Year The year part of the datetime value.

Month The month part of the datetime value.

Day The day part of the datetime value.

DayOfWeek The name of the day (Sunday, Monday etch).

DayOfYear The day of the year part of the datetime value (1-365/6).

Hour The hour part of the datetime value.

Minute The minute part of the datetime value.

Second The seconds part of the datetime value.

Lists
ﾉ Expand table

Property Description

Count The number of items stored into the list.

Files
ﾉ Expand table

Property Description

FullName The full path to the file.

RootPath The root path of the file, for example C:\.



Property Description

Directory The directory where the file is stored.

Name The name of the file, including the extension.

NameWithoutExtension The name of the file without its extension.

Extension The extension of the file.

Size The size of the file in bytes.

CreationTime The date when the file was created.

LastAccessed The date when the file was last accessed.

LastModified The date when the file was last modified.

IsHidden This property is true if the file is hidden or false if the file is visible.

IsSystem This property is true if the file is a system file or false if it isn't.

IsReadOnly This property is true if the file is read only or false if it isn't.

IsArchive This property is true if the file is an archive or false if it isn't.

Exists This property is true if the file exists or false if the file doesn't exist.

isEmpty This property is true if the file is empty or false if the file isn't empty.

Folders
ﾉ Expand table

Property Description

FullName The full path to the folder.

RootPath The root path of the folder, for example, C:\.

Parent The parent directory of the folder.

Name The name of the folder.

CreationTime The date when the folder was created.

LastModified The date when the folder was last modified.

IsHidden This property is true if the folder is hidden or false if the folder is visible.

Exists This property is true if the folder exists or false if the folder doesn't exist.



Property Description

isEmpty This property is true if the folder is empty or false if the folder isn't empty.

FilesCount The number of files in the folder.

FoldersCount The number of folders in the folder.

Mail messages
ﾉ Expand table

Property Description

MailFolder The name folder the email message is retrieved from.

Uid The unique identifier of the message.

From The sender of the email message.

To A list of values containing the recipients of the message.

Cc A list of values containing additional recipients for the message (carbon copy).

Date The date and time in which the message was sent.

Subject The subject of the message.

Body The body of the message. The body can be in plain text or in HTML form.

BodyText If the previous property contains HTML, this property contains the body of the
message in plain text form.

Attachments A list of files that represent the saved attachments of the email message (if any).

Exchange connection
ﾉ Expand table

Property Description

ServerAddress The address of the Exchange server.

Exchange mail messages



ﾉ Expand table

Property Description

MailFolder The name folder the email message is retrieved from.

ItemId The unique identifier of the message.

From The sender of the email message.

To A list of values containing the recipients of the message.

Cc A list of values containing additional recipients for the message (carbon copy).

Date The date and time in which the message was sent.

Subject The subject of the message.

Body The body of the message. The body can be in plain text or in HTML form.

BodyText If the previous property contains HTML, this property contains the body of the
message in plain text form.

Attachments A list of files that represent the saved attachments of the email message (if any).

Outlook mail messages
ﾉ Expand table

Property Description

MailFolder The name folder the email message is retrieved from.

EntryId The unique identifier of the message.

From The sender of the email message.

To A list of values containing the recipients of the message.

Cc A list of values containing additional recipients for the message (carbon copy).

Bcc A list of values containing additional recipients for the message (blind carbon
copy).

Date The date and time in which the message was sent.

Subject The subject of the message.

Body The body of the message. The body can be in plain text or in HTML form.



Property Description

BodyText If the previous property contains HTML, this property contains the body of the
message in plain text form.

Attachments A list of files that represent the saved attachments of the email message (if any).

FTP files
ﾉ Expand table

Property Description

FullName The full path to the file.

Directory The directory where the file is stored on the FTP Server.

Name The name of the file, including the extension.

NameWithoutExtension The name of the file without its extension.message.

Extension The extension of the file.

Size The size of the file in bytes.

LastModified The date when the file was last modified.

FTP folders
ﾉ Expand table

Property Description

FullName The full path to the folder.

Parent The parent directory of the folder.

Name The name of the folder.

LastModified The date when the folder was last modified.

FTP connection
ﾉ Expand table



Property Description

Host The host of the FTP connection.

SecurityProtocol The security protocol used in the connection.

Datatables
ﾉ Expand table

Property Description

RowsCount The number of rows of the data table.

Columns A list that contains the names of the columns of the data table.

IsEmpty This property is true if the datatable is empty or false if it is contains
elements.

ColumnHeadersRow A datarow that contains the table headers.

Datarows
ﾉ Expand table

Property Description

ColumnsCount The number of columns that the data row holds.

ColumnsNames A list that contains the headers of the datarow.

Web browser instance
ﾉ Expand table

Property Description

DisplayRectangleX The position of the top-left corner of the window in the x axel.

DisplayRectangleY The position of the top-left corner of the window in the y axel.

Handle The handle of the browser instance.

HtmlDialogs Contains the dialogs of the current page, if they exist.



Property Description

IsAlive This property is true if the browser window is alive or false if it isn't.

Window instance
ﾉ Expand table

Property Description

Handle The handle of the window instance.

Excel instance
ﾉ Expand table

Property Description

Handle The handle of the Excel instance.

SQL connection
ﾉ Expand table

Property Description

ConnectionString The connection string used for the database connection.

IsClosed This property is true if the browser window is closed or false if it is open.

PDF table info
ﾉ Expand table

Property Description

DataTable The extracted data table of the specified item.

TableStartingPage The index of the file page that contains the start of the table.

TableEndingPage the index of the file page that contains the end of the table.



Property Description

TableOrderInPage The order of the table on the page.

CMD session
ﾉ Expand table

Property Description

IsAlive This property is true if the CMD session is alive or false if it isn't.

ProcessId The unique identifier of the process.

Credential
ﾉ Expand table

Property Description

Username The username stored in the credential variable

Password The password stored in the credential variable (sensitive by default)

Terminal session
ﾉ Expand table

Property Description

IsTerminated This property is true if the terminal session is terminated or false if it isn't.

XML node
ﾉ Expand table

Property Description

Children The children of the XML node.

InnerText The inner text of the XML node.



Property Description

InnerXML The inner XML of the XML node .

Name The name of the XML document.

OuterXML The outer XML of the XML node.

Parent The parent of the XML node.

Value The value of the XML node.

Active Directory entry
ﾉ Expand table

Property Description

LdapPath The LDAP path of the Active Directory connection.

Group info
ﾉ Expand table

Property Description

Description The description of the group.

DisplayName The display name of the group.

Members A list containing the members of the group.

Name The name of the group.

User info
ﾉ Expand table

Property Description

City The city uf the user.

Company The company of the user.

Country The country of the user.



Property Description

Department The department of the user.

Email The email of the user.

Extension The extension of the user.

FirstName The first name of the user.

Initials The initials of the user.

LastName The last name of the user.

PostalCode The postal code of the user.

State The state of the user.

StreetAddress The address of the user.

TelephoneNumber The phone number of the user.

Title The title of the user.

EBS snapshot
ﾉ Expand table

Property Description

DataEncryptionKeyId The id of the data encryption key.

Description The description of the snapshot.

Encrypted This property is true if the snapshot is encrypted.

KmsKeyId The identifier of the AWS Key Management Service customer master key
to use for encryption.

OwnerAlias The alias of the owner.

OwnerId The id of the owner.

Progress The progress of the snapshot.

SnapshotId The id of the snapshot.

StartTime The start time of the snapshot.

State The state of the snapshot.



Property Description

StateMessage The state message of the snapshot.

Tags The tags of the snapshot.

VolumeId The volume id.

VolumeSize The size of the volume.

EBS volume
ﾉ Expand table

Property Description

Attachments The attachments of the volume.

AvailabilityZone The availability zone of the volume.

CreateTime This creation time of the volume.

Encrypted This property is true if the volume is encrypted.

FastRestored This property is true if the fast restore is enabled.

Iops The max IOPS of the volume.

KmsKeyId The identifier of the AWS Key Management Service customer master key to
use for encryption.

MultiAttachEnabled This property is true if the multi-attach is enabled.

OutpostArn The Amazon Resource Name (ARN) of the outpost.

Size The size of the volume.

SnapshotId The id of the snapshot.

State The state of the volume.

Tags The tags of the volume.

VolumeId The id of the volume.

VolumeType The type of the volume.

Azure managed disk



ﾉ Expand table

Property Description

AvailabilityZones The availability zones of the disk.

Configuration The configuration of the disk.

Encrypted This property is true if the disk is encrypted.

IopsSLimit The max IOPS of the disk.

IsAttachedToVirtualMachine This property is true if the disk is attached to a virtual machine.

OperationSystem The operation system installed on the disk.

SizeInGB The size of the disk in GB.

State This state of the disk.

ThroughputLimit The throughput limit of the disk.

TimeCreated The creation time of the disk.

Type The type of the disk.

VirtualMachine The virtual machine that the disk is attached to.

ResourceGroup The resource group of the disk.

Id The id of the disk.

Location The location of the disk.

Name The name s of the disk.

SubscriptionId The subscription id of the disk.

Tags The tags of the disk.

Azure resource group
ﾉ Expand table

Property Description

ProvisioningState The provisioning state of the resource group.

Id The id of the resource group.

Location This location of the resource group.



Property Description

Name The name of the resource group.

SubscriptionId The subscription id of the resource group.

Tags The tags of the resource group.

Azure snapshot
ﾉ Expand table

Property Description

CreationSourceId The creation source id of the snapshot.

CreationSourceType The creation source type of the snapshot.

OperationSystem This operation system on the the snapshot.

SizeInGB The size of the snapshot in GB.

StorageAccountType This storage account type of the snapshot.

TimeCreated The creation time of the snapshot.

ResourceGroup The resource group of the snapshot.

id This id of the snapshot.

Location The location of the snapshot.

Name The name of the snapshot.

SubscriptionId The subscription id of the snapshot.

Tags The tags of the snapshot.

Error
ﾉ Expand table

Property Description

ActionIndex The index of the action that caused the error.

ActionName The name of the action that caused the error.



Property Description

ErrorDetails The details of the occurred error.

Location The name and index information of the action and subflow that caused the error.

Message The message of the occurred error.

SubflowName The name of the subflow that contains the action caused the error.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Use variables and the % notation
Article • 01/18/2024

Variables are used within flows to store data for further processing. Every variable name
must be enclosed by percentage signs (%). The percentage sign is used as a special
character to denote variables. Any expression between percentage signs should be
evaluated.

Occasionally, the percentage sign should be used as a simple character, instead of
denoting a calculation. In those cases, it should be escaped using another percentage
character (%%).

​Power Automate enables you to create complex expressions containing hardcoded
values, variable names, arithmetic and logical operations, comparisons and parentheses.



Hardcoded values
To include a hardcoded text value inside a variable, use quotes. Every value between the
quote characters will be treated as a text value and not as a variable name.

Using blank values
Variables can receive null (empty) values. Any variable, dynamic or not, including nested
properties, can be populated with a Blank value. To check whether a variable holds a
blank value use the Is blank or Is not blank options when configuring the respective
conditional actions.

７ Note



Some action parameters can be assigned a blank value if the input argument is
nullable. If the parameter can't receive a blank value, an error occurs.

Variable names
Variables can be used by adding their name to the expression without any further
notation.

Basic arithmetic
To make mathematical operations, use all the essential, arithmetic operators, such as
addition (+), subtraction (-), multiplication (*), and division (/).

Arithmetic operations are predominantly used with numerical values and variables.
However, you can also use the addition operator to concatenate strings. Adding
numbers and text strings in the same expression will convert the numbers into text, and
concatenate them with the other text strings.

ﾉ Expand table

Expression Result Result variable
type

%5 * 3% 15 Number

%4 / Var% 4 divided by the value of the Variable named Number
“Var”



Expression Result Result variable
type

%'this is ' + 'text'% this is text Text

%'This is the number ' + This is the number 5 Text
5%

Comparisons
Besides arithmetic operators, make comparisons using the following operators

ﾉ Expand table

Operator Description

=, <> Equal/not equal

<, <= Less than/less than or equal

>, >= Greater than/greater than or equal

Keep in mind that comparisons, when evaluated, produce either True or False as a value.
Naturally, comparisons can only be done between values of the same type.

Logical operators
Logical operators can also be used to check multiple conditions simultaneously,
allowing you to implement more complex logic in a single expression. The supported
operators are: AND, OR, and NOT.

ﾉ Expand table

Expression Result

%Index = 1 OR Index = True if the value of the Index variable is 1 OR 2, otherwise False.
2%

%Index = 4 AND Text = True if the value of the Index variable is 4 AND the value of the Text
"Four"% variable is Four, otherwise False.

%NOT(4 <> 4)% Reverses the logical value in the parentheses. In this examples, it
returns True.



Additionally, you can use the following logical expressions to check the value of a string
or variable.

ﾉ Expand table

Expression Arguments Description

%StartsWith(arg1,arg2,arg3)% arg1: Text to search True if the provided string starts with
into the specified value, otherwise False.
arg2: Text to
search for
arg3: Ignore case
(True / False)

%NotStartsWith(arg1,arg2,arg3)% arg1: Text to search True if the provided string doesn't start
into with the specified value, otherwise
arg2: Text to False.
search for
arg3: Ignore case
(True / False)

%EndsWith(arg1,arg2,arg3)% arg1: Text to search True if the provided string ends with
into the specified value, otherwise False.
arg2: Text to
search for
arg3: Ignore case
(True / False)

%NotEndsWith(arg1,arg2,arg3)% arg1: Text to search True if the provided string doesn't end
into with the specified value, otherwise
arg2: Text to False.
search for
arg3: Ignore case
(True / False)

%Contains(arg1,arg2,arg3)% arg1: Text to search True if the provided string contains the
into specified value, otherwise False.
arg2: Text to
search for
arg3: Ignore case
(True / False)

%NotContains(arg1,arg2,arg3)% arg1: Text to search True if the provided string doesn't
into contain the specified value, otherwise
arg2: Text to False.
search for
arg3: Ignore case
(True / False)



Expression Arguments Description

%IsEmpty(arg1)% arg1: Text to check True if the provided string doesn't
contain any characters, otherwise False.

%IsNotEmpty(arg1)% arg1: Text to check True if the provided string contain one
or more characters, otherwise False.

Parentheses
To change the operators' priority, use parentheses. Parentheses are handled the same
way as in algebra and programming languages.



Automate using UI elements
Article • 12/22/2023

Desktop flows utilize UI elements to interact with applications and webpages without
resorting to image recognition and absolute coordinates. UI elements are used as input
in most UI automation and browser automation actions and identify specific elements
on windows and webpages.

UI elements
When deploying a UI automation or browser automation action, you might be required
to provide a UI element as input. To add a new UI element, you can do it directly from
the action properties or through the UI elements pane of the flow designer.

Each one of these action groups accepts a different type of UI elements. UI automation
actions accept desktop UI elements, while browser automation actions accept web UI
elements.



To add a new UI element to your flow, add a new UI element through an action or the UI
elements pane, highlight the respective element, and press Ctrl + Left click. When the
selection is finished, select Done.



Any captured UI elements will be added to the UI elements pane. To access the UI
elements pane, select the UI elements tab on the right-hand side of the flow designer.

Elements can be sorted alphabetically through the Sort option of the UI elements tab.
To remove all the UI elements that aren't used in any action, select the dots icon next to
the Sort option and then Remove unused UI elements.

To rename or delete a UI element, right-click on the respective item and select the
appropriate function.



To find where a specific UI element is being used in the flow, right-click on it and select
Find usages. The results will display all the actions that use this UI element. Double-click
on a result to highlight the action on the workspace.






UI elements types
Desktop flows support two types of UI elements based on their source: desktop UI
elements and web UI elements.

Desktop UI elements can be captured from any Windows application, including the
nonwebpage part of browsers, such as the address bar.

You can use these UI elements as input in UI automation actions to indicate the
component you want to interact with. The UI element picker of UI automation actions
displays and allows you to capture only desktop UI elements.

） Important

Users can capture elements from webpages through the UI element picker of UI
automation actions. However, their selectors will represent desktop elements, not
web elements.

Web UI elements can be captured from webpages and used only in browser automation
actions.

Browser automation actions accept exclusively UI elements captured from webpages.
Therefore, existing UI elements captured from desktop applications aren't displayed in
the UI elements picker of these actions.

To find more information regarding desktop and web automation, refer to Automate
desktop flows and Automate web flows.

UI elements for webpages
To capture a UI element from a webpage, you need to install the appropriate browser
extension. You can find more information about the supported browsers and the
required extension in Use browsers and manage extensions.

Distinguish desktop from web UI elements
The UI elements pane displays distinctive visual indications to help users quickly
recognize desktop and web UI elements.



The same icons are also displayed during capturing, so you can confirm the type of an
element before even saving it.

Another method to check the type of a UI element is to review its selectors. Desktop UI
elements usually have the desktop as their parent element, while web UI elements have
a webpage as their root element.



UI elements in browser windows
The application part of a browser (1) should be automated using desktop UI elements.
For example, you can use UI automation actions to interact with the address bar or the
tabs.

On the other hand, the loaded webpages inside the browser (2) should be automated
using web UI elements and browser automation actions.

During recording, the recorder will automatically distinguish the browser application
area from the webpages and generate the appropriate UI elements and actions.



Interactions with drag and drop web UI elements might not function as expected due to
their inherent limitations. As a workaround, capture desktop UI elements in a web page
by opening the UI element picker through an action of the UI automation group by
selecting Add UI element within the UI element  parameter. The captured UI element is
of desktop type and can be used in the Drag and drop UI element in window  action.
Keep in mind that desktop UI elements can be used only in actions of the UI automation
action group of Power Automate for desktop. It's important to note that desktop UI
elements in web pages aren't as reliable as their web counterparts and are subject to
browser application details, such as the browser's version.

UI elements properties
All UI elements consist of one or more selectors that pinpoint the UI or web component
that Power Automate interacts with.

７ Note

Users can create multiple selectors for a UI element. Whenever a selector fails,
Power Automate uses the following selector in the defined order.

To manage the selectors of a UI element, right-click on it and select Edit. This option
brings up the selector builder, where you can edit the selectors with a visual or a text
editor.



Each selector consists of multiple elements representing the hierarchical structure of the
UI element in the application or webpage. The attributes describe each element
uniquely and distinguish it from other elements.

All selectors are displayed with a default friendly name that makes them easily
accessible. To rename a selector, right-click on its name and select Rename.

When you edit a UI element with multiple selectors, you're able to disable a selector by
right-clicking on it and selecting Disable. This functionality can be helpful during testing.



After editing the selectors, press Save to apply the implemented changes. Saving applies
the changes in all the selectors in a single step.

You can find more information regarding selectors and how to build them manually in
Build a custom selector.

UI elements with text-based selectors
Apart from the default way to generate selectors of UI elements, Power Automate
supports the creation of selectors based on an element's text value.

This feature is helpful for automation scenarios that handle elements in desktop
applications or webpages that always come with specific texts. Selectors based on these
texts are more reliable and resilient to possible future changes in the application or
webpage structure.

Generating text-based selectors is available only when capturing UI elements using the
UI element picker (UI elements pane or browser/UI automation actions). It's not
available during recording.

To capture a UI element with a text-based selector, open the UI element picker, right-
click on the desired element, and select Capture based on text.



Then, a new window with two fields will appear on your screen:

The Text value field holds the element's text as a proposed value. You can change
this value to a hardcoded value or a variable.
You can set the Operator field to various operators to adjust the functionality of
the selector.

Selecting Capture will add the UI element with the proper text-based selector in the UI
elements repository.



Text-based selectors use the Name attribute of the captured element for desktop
automation and the Text attribute for browser automation. They're available only for UI
elements that contain a text value themselves.

In other words, they're available for UI elements with a Name or Text attribute that
includes a value. They aren't available for elements that don't hold such a text value,
even if they have child element(s) with text in their structure.

７ Note

For the SAP application, text-based selectors use the Text attribute instead of the
Name attribute that they generally use on desktop automation. SAP automation
works more efficiently with default selectors based on the ID attribute.

Known issues and limitations
If you select Add UI element, hover the mouse over a whole window, and choose
to capture a UI element based on text, a default selector will get generated. This
selector includes the Process attribute apart from Name.

The combination of a variable and an operator other than Equal to generates a
selector displayed in the custom text editor instead of the visual builder. This



functionality avoids an existing limitation that makes the above combination
nonfunctional in the visual builder.



Inspect a UI element
Article • 10/19/2023

The inspect UI element tool is a powerful feature in Power Automate for desktop that
allows you to explore the hierarchy tree of all UI elements on your screen, check their
attributes and values, and capture them for use in your desktop flow through the UI and
browser automation actions.

Open the inspect UI elements tool
To open the inspect UI element tool, there are three approaches:

Locate the designer component of Power Automate for desktop, and then go to
the UI element repository. Select the Add UI element from the dropdown list and
launch the UI element picker. Then, in the UI element picker window, select the
Inspect UI elements arrow.
Locate the designer component of Power Automate for desktop, and then go to
the UI element repository. Select the dropdown list and then select the Inspect UI
elements option.
In the designer window, navigate to the Tools option in the menu bar and select
the Inspect UI elements option.

Description of inspect UI elements tool
When you open the inspect UI elements tool, a hierarchy tree with all available UI
elements on your machine is displayed. This includes both web and desktop UI
elements, which are separated by their respective icons. Moreover, the web UI elements
are split into each browser for easier navigation, displaying each tab that is opened in
your browser as a parent UI element. Note that the tabs aren't actual UI elements. You
can expand the tree by selecting the expand icon next to a UI element, which loads and
displays all of its children UI elements.

７ Note

You see the desktop UI elements of a virtual desktop when a connection is opened
between your machine and the Citrix virtual desktop or the virtual machine through
Remote Desktop Services (RDS) and Power Automate agent for virtual desktops is
installed and running in the virtual desktop or machine. More information:
Automate on virtual desktops



Selecting a UI element in the hierarchy tree displays its attributes and values on the right
pane of the tool. These attributes and values can be used to create a custom selector in
the UI element builder of the designer for the specific UI element. In order to edit the
selector of a UI element, you have to capture it and open it in the UI element selector
builder window.



You can capture one or more UI elements and store them in the UI element repository
of the desktop flow by hovering to the left of a UI element in the hierarchy tree and
checking those you desire. Then, you can select the Add UI element on the top of the
tool. The captured UI elements can then be used in a UI automation or browser
automation action respectively, depending on its type (desktop or web UI element).



The hierarchy tree is refreshed every time you expand a UI element. You can refresh the
whole tree by selecting Refresh on the top of the tool.

Navigate in hierarchy tree to a specific UI element in the
screen
While the inspect UI elements tool is opened, the Power Automate for desktop
highlighter is visible. Go directly to a specific UI element by hovering with your mouse
over the desired UI element and then right-click. This opens the context menu. Select
the Inspect UI element option that takes you to the specific UI element in the hierarchy
tree of the tool. Select the UI element to display the attributes and the respective values.



Known issues and limitations
Issue: Hierarchy tree of specific web browser pages can't be displayed in the tool
when the browser window containing them is minimized.

Workaround: Ensure the web browser window that you want to inspect isn't
minimized on your machine.

Issue: Specific web browser's tree of UI elements can't be displayed in the tool if
the Microsoft Power Automate web extension isn't installed and enabled.

Workaround: Ensure that the Microsoft Power Automate web extension is installed
and enabled in the respective web browser.

Issue: A specific desktop application isn't displayed in the hierarchy tree in the tool.

Workaround: Check whether the desktop app is running with elevated rights. If
yes, restart Power Automate for desktop and run it with elevated rights. And then
try again.

Issue: A virtual desktop connected through Citrix or RDS, or as a Citrix virtual app
or as a remote app isn't displayed in the tool.

Workaround: Ensure that Power Automate agent for virtual desktops component
is installed, up and running in the respective virtual machine.

Related information



Automate using UI elements

Automate desktop applications

Automate webpages

Build a custom selector

Automate on virtual desktops

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Automate using images
Article • 02/24/2023

To capture a new image in Power Automate, navigate to the Images tab on the right
pane of the flow designer.

Select Capture image, and click and drag the cursor on the area you want to capture. A
magnifying glass will help you to capture the image with high precision.



Alternatively, select the arrow on the Capture image button to capture images on a
timer. Then, choose one of the suggested time options or Capture image with custom
delay to set a custom delay time.



After capturing the image, populate a name for it in the dialog box and select OK to add
it to the flow.



Manage captured images
To remove all the images that aren't used in any action, select the dots icon next to the
Capture image option, and then select Remove unused images. If you navigate inside a
specific folder, the Remove unused images option will remove only the unused images
located in this folder.

To create a new folder, select Add a new folder and specify a name for the created
folder. You can store images into a specific folder by capturing them while the folder is
open.



To rename or delete images and folders, right-click on the respective item and select the
appropriate function. Select the image thumbnail to open and view it.



To find where an image is being used in the flow, right-click on it and select Find
usages. The results will present the actions that use the specific image. Double-clicking
on a result will highlight the action in the workspace.



Use images in actions
After capturing images, you can use them as input in actions that require them, such as
the Move mouse to image action.

In the advanced settings of these actions, you can select which image matching
algorithm you want to use. The Basic algorithm achieves better results with images less



than 200x200 pixels, while the Advanced algorithm is more effective with bigger images
and more robust to color changes.

The Tolerance field defines the acceptable amount of differences between the provided
image and the image is compared with. High tolerance values may affect the precision
of image recognition.



Handle errors in desktop flows
Article • 01/23/2025

During developing and running, you may encounter errors and warnings in your
desktop flows. This article presents the different error and warning types, the Errors
pane, and the available error handling functionality.

Desktop flows error types
Desktop flows can cause two kinds of errors:

Design-time errors are associated with the configuration of the deployed actions.
These errors appear during development and prevent desktop flows from running.
For example, an empty mandatory field or an undefined variable can cause this
type of error.

Run-time errors, also known as exceptions, occur during execution and make
desktop flows fail. For example, an invalid file path can cause this kind of error. Use
any of the available error-handling options to prevent your desktop flows from
failing.

When an action throws an error, the flow designer displays an icon next to it and a pop-
up pane with relevant information. If the error occurred is a design-time error, the flow
designer also displays an error description in the action's modal.



Desktop flows warnings
Apart from errors, the flow designer displays warnings that indicate non-critical issues in
your desktop flows. Warnings don't prevent desktop flows from running but indicate
possible unwanted functionality, such as infinite recursions of subflows.



Review errors and warnings using the errors
pane
The errors pane is the flow designer's component responsible for displaying information
regarding occurred errors and warnings.

It consists of four columns:

Type: Indicates if the displayed item is an error or warning.
Description: A description of the occurred error or warning.
Subflow: The name of the subflow that contains the erroneous action or the action
that causes the warning.
Line: The line number of the erroneous action or the action that causes the
warning.

The pane also provides filters to display errors, warnings, and/or items related to specific
subflows.

To see additional information regarding a design-time error or warning, double-click the
respective item in the errors pane. Once you do so, a dialog will display information
about:

Location: The subflow, line and action that caused the design-time error or
warning.



Error message: The message of the occurred design-time error or warning.

To see additional information regarding a runtime error, double-click the respective item
in the errors pane. Once you do so, a dialog will display information about:

The message of the occurred error or warning.
Location: The subflow, line and action that caused the error or warning.
Possible remediation steps to resolve the issue that occurred (currently only
applicable to Excel actions' errors).
Error details: The error's correlation ID, as well as a long, technical description of
the occurred runtime error.



Configure error-handling functionality
Power Automate enables you to configure error-handling functionality for single actions
and blocks of actions in your desktop flows.

Handle errors of single actions
By default, desktop flows stop their execution when an error occurs. To configure a
custom error-handling functionality for a specific action, select On error in its modal.



The first available option is the Retry action if an error occurs checkbox. This option
makes the flow run the action a set number of times after a set number of seconds. The
default value is one retrying with an interval of two seconds.



To keep your desktop flow running even if the retry option fails, select Continue flow
run. Through the displayed ​drop-down list, you can:

Go to next action: Runs the following action in order.
Repeat action: Repeats the action until it runs successfully.
Go to label: Run the desktop flow from a point defined by a Label action.

Desktop flows offer two more error handling options. Select New rule to:

Set variable: Sets the specified value to a selected variable.
Run subflow: Runs a specified subflow.



If different errors require different error handling functionality, select Advanced and
configure each possible error separately.

Handle errors of group of actions
Some scenarios may require you to implement the same error-handling functionality for
several actions in your desktop flows.

Instead of configuring each action separately, deploy the On block error action and
configure a common error handling behavior for all the actions inside the block.

This action offers the same options as the On error settings of single actions but also
lets you capture unexpected logic errors, such as trying to access a list item from an out-
of-bounds position. Other options include providing a name for this block, as well as
selecting to continue the flow run from the beginning or the end of the block, after an
error occurs.

７ Note

If a retry policy is set and an error occurs, retrying will take place from the
beginning of the block.



If all block retries fail, then the actions specified in block's 'Exception handling
mode' will apply.

Individual error handling/retries from actions within the error block take
precedence from block error retries.

Retrieve occurred errors in desktop flows
To retrieve the latest occurred error in a desktop flow and use it in later actions, use the
Get last error action.

This action returns an error type variable that provides six different properties: the name,
the location and the index of the action that failed, the subflow that contains this action,
and the details and the message of the action.

To avoid retrieving the same error value later in your desktop flow, enable the Clear
error option that clears the last error after storing it in the variable.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Record desktop flows
Article • 02/24/2023

Power Automate enables you to design desktop flows automatically by replicating the
tasks you wish to automate.

Record desktop and web flows
To record a flow that automates desktop and/or web applications:

1. Create a new desktop flow, and select Recorder in the toolbar of the flow designer.

2. Select Record in the recorder window, and start performing the desired actions in
the appropriate application or web page.



The recorder keeps track of mouse and keyboard activity in relation to UI elements,
and it records each action separately. During each recording session, the recorder
can generate both UI and browser automation actions.

７ Note

When you perform a left or right click on a UI element during the recording,
the highlighter displays a Wait for action message, instructing you to wait for
the recorder to record and insert the action.



To see the available actions for a specific element, right-click on it to open its
context menu. The available options depend on the nature of the selected
element.



3. When the recording process is completed, select Done to convert the recorded
steps to desktop flow actions. All the UI elements used in the generated UI and
web automation actions are added automatically to the UI elements pane. You can
find more information regarding UI elements in Automate using UI elements.

To pause the recording process temporarily, select Pause. To add a comment to the
recorded actions, select Add a comment.



Replicate drag and drop steps



The recorder supports steps related to dragging and dropping the mouse pointer;
therefore, the recorder can generate actions like the Resize window and Move window.
Currently, however, the Drag and drop UI element of a window action isn't supported.

Handle drop-down lists
While automating desktop and web applications using the recorder, you may need to
handle drop-down lists.

The Power Automate recorder displays a custom screen every time you select a drop-
down list, and it helps you choose the desired values. This custom screen allows you to
choose one or more values depending on whether the drop-down list is multi-select.

During runtime, Power Automate automatically chooses the defined values and selects
the OK button.

Launch a web browser
To launch a web browser instance while recording web flows, you can use three different
approaches based on the automation scenario.

The first method is to select the dots icon on the right side of the recorder dialog and
then Launch new web browser. You can choose between Microsoft Edge, Google



Chrome, Mozilla Firefox, and Microsoft Internet Explorer.

After you've selected the proper browser, the recorder will detect the loaded web page
automatically and configure the launching browsing step accordingly.

An alternative way to launch a browser is to start recording in an already open web
browser. The recorder will automatically detect the loaded page and will create a
launching browser action.

The last method to launch a browser is to manually launch it through its shortcut on the
desktop, the start menu, the taskbar, or a folder. If you implement this approach, the
recorder will generate UI automation actions that click the browser shortcut and launch
it.

Handle date and color pickers on web pages
Like drop-down lists, the Power Automate recorder displays custom screens to help you
handle date and color pickers on web pages.



When you interact with a date picker, the recorder opens a text field where you can
insert the desired date in the specified format.

The custom screen appears for the following HTML input types:

date
datetime-local
month
time
week

Similarly, when you interact with a color picker, the recorder opens a text field where
you can populate the desired color hex code.



Add text using Input Method Editors (IMEs)
Input Method Editors (IMEs) are software components that enable users to input text in
languages that can't be represented easily on a standard QWERTY keyboard. Users can
type combinations of keys, and IMEs will generate a character or a list of candidate
characters that match the set of keystrokes.

Power Automate for desktop supports the use of IMEs during the flow recording
procedure. To populate a text field using an IME:

1. Right-click on the text field, and select Populate text field on the displayed menu.



2. Populate the popup dialog with the desired text using an IME.

3. Select Add text to generate the respective step in the Recorder window.



Image-based recording
In some cases, the recorder may not record actions in specific applications that don't
meet the appropriate technical requirements. These applications may not expose their
accessibility API or have other technical limitations that block the recording process.

As an alternative way to record flows, Power Automate for desktop provides image-
based recording. The image-based recording uses image recognition and OCR to locate
specific elements on the screen and extract text.

To record flows using images:

1. Create a new desktop flow and select Recorder in the toolbar of the flow designer.



2. Select the dots icon on the right side of the recorder dialog, and then enable
Image recording. After enabling this option, select Record to start recording
actions using image recognition.



Upon clicking on an element, an image is captured automatically and saved with a
default editable name. To preview the captured image, hover, or select the preview
icon.



Extract text with image-based recording
To extract a text value while using image recording:

1. Perform a right-click on the screen, and select Extract text from image.



2. Wait for a popup message that will prompt you to select a text area.

3. Select the text area from which text will be extracted using the Tesseract OCR
engine.



4. Wait for a popup message that will prompt you to select an anchor area.

5. Select an anchor area that isn't expected to change, such as the label next to a
field.



Recording vs building a desktop flow
You can edit manually any actions created through the recorder once the recording is
finished. Use the recorder in a desktop flow that's already under development to add
the recorded steps to it.

７ Note

Use the recorder to create the backbone of your flow. Certain simple tasks may
require no further editing; however, most recorded tasks should be modified to
achieve optimal results. Certain types of actions, like conditionals and loops, can't
be recorded. Also, there may be redundant actions in a recording that should be
removed.

Known issues and limitations
Issue: The recorder may not record all steps from the Windows Start menu or
system tray.

Workarounds: None

Issue: While running a flow created through image-based recording, the click may
be sent to the wrong place.



Workarounds: Edit the auto-generated action Move mouse to image through the
flow designer and decrease the tolerance parameter in the advanced settings.

Issue: The Extract text from image popup that appears after sending a right-click
using the recorder may hide behind the popup of the application.

Workarounds: Send the right-click to another place on the screen.

Issue: Any keystrokes sent to a maximized RDP window through an image-based
recording aren't recorded.

Workarounds: Resize the RDP window so that it doesn't cover the full screen.



Use loops
Article • 02/24/2023

Loops are a fundamental concept in desktop flow development and prove to be
invaluable elements in complex flows. The main idea behind a loop is to make a desktop
flow repeat one or more actions multiple times.

Power Automate provides three different kinds of loops that iterate based on various
factors:

Simple loops - Iterate for a set number of times
Loops condition - Iterate as long as a condition is valid
For each loops - Iterate through a list

Simple loops
The idea behind a loop is to make a desktop flow repeat one or more actions multiple
times. Power Automate implements the simplest type of loops with the Loop action.

This loop repeats the actions between the Loop and End actions for a set number of
times. A loop index variable is created automatically to track the current iteration’s
number.



A simple loop is ideal to use in two cases:

1. The exact number of times that a block of actions should be repeated is known.

2. The loop index variable must be used somewhere inside the loop.



In case you need to exit the loop before the specified iterations are completed, use the
Exit loop action. To skip the current iteration, use the Next loop action.

Loop condition
Unlike simple loops, the Loop condition makes a desktop flow repeat one or more
actions as long as a condition is true.

If the condition is always true, the loop will never end. This situation is called an endless
loop.

The condition consists of two operands and an operator. The platform supports the
most significant logical operations, such as equal, not equal, and greater than.



In case you need to exit the loop before the specified iterations are completed, use the
Exit loop action. To skip the current iteration, use the Next loop action.

For each loop
The For each loop iterates through a list (or data table) and stores the current item in a
variable. Its primary purpose is to get each item of a list (or row of a data table) and use
it in other actions.

You can use this kind of loop to search for specific names, contents, or attributes in all
kinds of lists. For example, you can iterate through a list of retrieved files to find a file



with a specific name.

In case you need to exit the loop before the specified iterations are completed, use the
Exit loop action. To skip the current iteration, use the Next loop action.

You'll find the list of loop actions available in the Actions reference.



Use conditionals
Article • 02/24/2023

Conditionals allow you to execute blocks of actions only if a given condition is met. If
the condition is false, the block of actions will be skipped.

Using conditionals, you can ensure certain elements have a wished value or state before
performing other actions. For example, you can check if a file exists before trying to
rename it.

If/else
The If statement is one of the most commonly used conditionals in flow development
and programming.

Power Automate provides the If action to check whether a given condition is valid. If the
condition is true, the logic between the If and End is executed.

An If action consists of two operands and an operator. The platform supports the most
significant logical operations, such as equal, not equal, and greater than.

An If may optionally contain an Else action. The Else action defines the logic to be
executed when the If condition is invalid. It should be placed between the If and the End
actions.



To set multiple conditions for which different logic is executed, deploy the Else if action.
This action is executed when the previous If and Else if conditions are invalid. It should
be placed within the If/End block and always before the Else action.

In all cases, the variables and values used as operands must be of the same data type.
Comparing variables of different data types makes the condition always false.

If variations



Apart from the standard If action, Power Automate provides some additional conditional
actions:

If file exists: Checks if a file exists or not before executing a block of actions. This
action can be used to ensure that a file exists before performing other operations
on it.

If folder exists: Checks if a folder exists or not before executing a block of actions.

If service: Executes a block of actions if a specific service is running, is paused or is
stopped.

If process: Executes a block of actions if a specific Windows process is running, or
not.

If window: Executes a block of actions if a specific window is open, or not.

If window contains: Executes a block of actions if a specific text or UI element
exists in a window, or not.

If image: Executes a block of actions if a specific image is found on the screen, or
not.

If web page contains: Executes a block of actions if a web page contains a specific
element or some text, or not.

If text on screen (OCR): Checks if a given text is found on the screen or not, using
an OCR Engine of your choice.

Switch-case model
Unlike if-else conditionals, a switch block can address several possible execution paths.
A switch statement is a control mechanism that allows a variable or expression to
change the flow's behavior.

A switch block consists of three main parts:

1. The Switch action that marks the beginning of a switch block. Every Switch is
accompanied by an End action that marks the switch block's end.

2. Inside the switch block, each Case marks a block of actions to execute if the
respective condition is true.

3. In case all conditions are invalid, the flow will execute the actions in the Default
case block, if exists.



You'll find the list of conditional actions available in the Actions reference.



Automate webpages
Article • 10/23/2024

Power Automate offers several actions under the browser automation group to enable
users to interact with web browsers. Browser automation is a special case of UI
automation used for interacting with web elements.

Apart from the built-in Automation browser, four web browsers are currently supported:

Microsoft Edge
Microsoft Internet Explorer
Google Chrome
Mozilla Firefox

） Important

Before automating webpages, you need to install the appropriate browser
extension and configure the browser accordingly. To find more information
regarding the supported browsers and the required extensions, go to Install Power
Automate browser extensions.

To perform web automation, you first need to create a new browser instance. You can
achieve this using the Launch Browser actions, which support Microsoft Edge, Google
Chrome, Mozilla Firefox, and Internet Explorer. With the Launch Browser actions, you can
also specify whether the web page should be launched on your local desktop or in a
virtual desktop environment.

７ Note

To launch a browser on a virtual desktop, first capture at least one UI element
within that desktop. This element needs to be available in the UI element repository
of your flow.

To automate a webpage, you must launch or attach to one of the supported browsers,
and then deploy browser automation actions. Browser automation actions enable you to
interact with webpages and emulate events, such as clicking, using JavaScript scripts.
You can develop the flow manually or using the recorder.

７ Note



Web automation in Power Automate for desktop has a behavior where it can't open
with a different system user or attach to any browser that was opened with a
different system user other than the one used to open Power Automate for
desktop. This behavior occurs for security reasons.

By default, browser automation actions don't move the mouse pointer on the screen. As
a result, they can run even when the web browser is minimized, or the target tab isn't
the focused tab. This functionality allows you to perform other activities on your
machine while a browser automation flow is running.

However, some actions like Click link on web page and Populate text field on web
page support physical interactions for cases where JavaScript events don't work as
expected. If you enable physical interaction, the browser can't be minimized, and the
target tab must be focused.

Use Internet Explorer vs Automation browser
Although Automation browser is based on Internet Explorer, it provides some features
and limitations that increase automation effectiveness.

1. Automation browser works out of the box, while Internet Explorer requires extra
configuration. Security configurations may be unwanted in organizations with strict
security policies that prohibit manual changes.

2. The Click download link on web page action works with Automation browser
whatever the Internet Explorer version. For the actual Internet Explorer, the action
requires version 8 or below.

3. Automation browser suppresses all message dialog boxes that may pop up
unhindered in the Internet Explorer. If this feature is undesirable, apply the
ShowDialogs suffix at the end of the URL in the Launch new Internet Explorer
action.

4. Automation browser doesn't support tabs or opening links in windows. When you
select a link, the browser opens it in the same window/instance.

5. Automation browser has a small performance advantage because it doesn't load
unnecessary elements and add-ons like the Internet Explorer does.

Automate browsers and web elements



Before deploying any other browser automation actions, use one of the browser-
launching actions to create a browser instance. You can start a new browser session or
attach to an existing one.

Launch new Microsoft Edge
Launch new Internet Explorer
Launch new Chrome
Launch new Firefox

When a browser instance is available, you can deploy other browser automation actions
to interact with webpages. The web form-filling actions focus on providing input to
webpages, while the web data extraction actions draw data from webpages.

You can find a list with all the available browser automation actions in the Browser
automation actions reference.



Apart from a browser instance, most browser automation actions require a UI element
to interact with. Existing UI elements are visible in the UI element pane, while new ones
can be added directly through the action's properties or the pane. To find more
information about UI elements, go to Automate using UI elements.

７ Note

Browser automation actions accept exclusively UI elements captured from
webpages. Therefore, UI elements captured from desktop applications aren't
available in the browser automation actions.



To add a new UI element, highlight the appropriate web element and press Ctrl + Left
click. After adding all the required elements, select Done to save them.



Enter data on webpages
To provide input to a webpage, select the appropriate web form-filling action
depending on the nature of the element. For example, use the Set drop-down list value
on web page action to select an item in a dropdown menu.

Extract data from webpages
To extract a specific piece of data from a webpage, use the Get details of web page or
the Get details of element on web page action, depending on whether the data in
question concerns the entire webpage or an element inside it. To find more information
regarding details extraction from webpages, go to Retrieve details from a webpage.



Apart from the pre-populated options, you can manually select to retrieve any HTML
attribute the chosen web element may have.

Additionally, the Get details of element on web page action supports the
waelementrectangle attribute that retrieves the top-left point and the dimensions of a
web element. To find more information about this attribute, go to Get the coordinates
and size of a web element.



Extract structured data from webpages
To extract large amounts of structured data, use the Extract data from web page action.
You can store the extracted data as single values, lists, and tables, or you can paste them
into Excel worksheets.



While the live web helper is open, select or right-click the target data to view the
available extraction options. To extract a value, select Extract element value, and then
choose the HTML attribute that you want to retrieve.

Power Automate automatically identifies lists or tables of data after selecting two or
more of their elements for extraction.



７ Note

To extract an entire HTML table faster, select or right-click the table and select
Extract entire HTML table. This option is available only for elements that Power
Automate recognizes as HTML tables. If the data is structured as a table but isn't
recognized as an HTML table, extract the first two of their elements, as previously
described.

Alternatively, you can manually create or edit CSS selectors that pinpoint specific
elements.

To create a CSS selector, select Advanced settings in the live web helper, and then
choose the type of value you want to extract. You can choose to extract a single value,
multiple handpicked values (a different selector defines each value), lists, tables, and
entire HTML tables.

Each CSS selector consists of the tree structure of the HTML element, the attribute to
extract from it, and optionally a regular expression to implement more advanced
selection.



Extract structured data from multiple pages
If the information to extract is split between multiple pages with the same structure, you
need to set the appropriate paging configuration.

Pagers are web elements that allow you to navigate between multiple pages. To set a
pager for the data extraction, select or right-click the respective pager element and
select Set element as pager.

Additionally, you can manually specify a pager through the Advanced settings of the
live web helper.

When data selection is complete, close the live web helper and configure the
appropriate parameters in the Extract data from web page action. You can select



between extracting data from all the available pages or a specific number of them.

Optionally, you can enable Process data upon extraction to let Power Automate process
the extracted data in different ways, such as removing whitespaces and unwanted
characters. However, this option may affect performance for large amounts of data.

Interact with web services
Power Automate provides various HTTP actions that enable you to communicate directly
with web resources, such as webpages, files, and APIs, without needing a web browser.
You can find a list with all the available HTTP actions in the HTTP actions reference.

Download web resources



Use the Download from web action to directly download webpage content or files
stored on the web.

Both the GET and POST methods can be used within this action. Files can be
downloaded directly to the disk, while webpage contents are saved into variables.

Access web APIs



Use the Invoke web service action to access web APIs. Various methods are compatible
with this action, which is fully customizable in order to accommodate virtually any API.

７ Note

Before using the Invoke web service action, refer to the documentation page of
the web service you want to use. The following example can't be applied to all
scenarios, as each web service requires a different configuration and syntax.



Apart from the Invoke web service action, Power Automate provides the Invoke SOAP
web service action to interact with SOAP web services.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create custom forms
Article • 02/24/2023

７ Note

The Display custom form action is based on the Adaptive Cards technology. Refer
to this page  to find more information regarding Adaptive Cards.

Message boxes enable you to prompt users to enter various inputs, such as text, dates,
and files, or display information and results on the screen.

Although most actions of this group can handle scenarios where a single input is
required, some automations may require a combination of inputs or/and outputs. The
best approach to address these scenarios is the Display custom form action.

To create a custom form, deploy the Display custom form action and select the Custom
form designer button to open the form designer.

On the left side of the designer, there's a list with all the available input elements you
can add to the form, such as text, date, and file inputs, and some non-interactive
elements, such as texts and images.



To add an element to the custom form, double-click it or drag and drop it in the
designer's workspace area. Use the preview pane on the bottom part of the form
designer to see how the configured form will look during runtime.

After adding an element, you can handle all the available properties on the right side of
the form designer. The available properties may differ depending on the nature of the
selected element.

７ Note

Apart from the form elements, the form designer provides some properties to
configure the appearance of the parent dialog of the custom form. To configure
them, select an empty space on the workspace and see the available properties on
the respective pane.

When a user populates a custom form, the provided data are stored into the
CustomFormData custom object variable. To access the value of a specific input element
stored in the custom object, use the following notation:
%CustomFormData['ElementID']%.

） Important



The ID of each element must be unique and can't be empty. Also, it must start with
a letter and can contain Latin letters, numbers and spaces. You can't use variables in
ID fields. If an invalid ID is provided, the last used valid ID will be automatically
restored after closing and saving the form designer.

７ Note

You can find more information regarding custom objects and how to handle them
in Advanced data types.

Apart from input and non-interactive elements, the form designer provides some
actions to implement additional functionality in your forms.

Consider actions as buttons that allow you to run different functions based on which
button was pressed. For example, use a Submit action as a save button to gather and
store the provided user data for later use in your flow.

７ Note

Actions can be added only at the end of the form structure, after any other type of
form element.

Like the other elements, each action has an ID that describes it uniquely. When an action
is selected, its ID is stored into the ButtonPressed variable.



When a form contains multiple actions, use this variable and conditionals to check which
one is pressed and implement different functionality for each scenario. To find more
information on implementing this behavior, refer to Handle custom forms.

The following screenshot shows how the previously configured custom form looks when
the flow runs.

Custom form elements
Element Type Specifications Layout Validaiton Style Background
name properties properties properties image



Element Type Specifications Layout Validaiton Style Background
name properties properties properties image

Custom Parent Title Minimum URL, Fill
form dialog height in mode,

pixels, Horizontal
Vertical alignment,
content Vertical
alignment alignment

Text Input ID, Label, Spacing, Validation
input Default value, Separator, required,

Multiline, Height Error
Style, message,
Maximum Pattern
length

Number Input ID, Label, Spacing, Validation
input Default value, Separator, required,

Minimum Height Error
value, message
Maximum
value

Date Input ID, Label, Spacing, Validation
input Default value, Separator, required,

Minimum Height Error
value, message
Maximum
value

Time Input ID, Label, Spacing, Validation
input Default value, Separator, required,

Minimum Height Error
value, message
Maximum
value

Toggle Input ID, Label, Title, Spacing, Validation
input Default value, Separator, required,

Value when Height Wrap Error
on, Value message
when off

Choice Input ID, Label, Spacing, Validation
set Default value, Separator, required,
input Allow multiple Height, Error

selection, Wrap message
Style, Choices



Element Type Specifications Layout Validaiton Style Background
name properties properties properties image

File Input ID, Label, Spacing, Validation
input Default value Separator, required,

Height Error
message

Text Element ID, Text Spacing, Font type,
block Separator, Size, Weight,

Horizontal Color, Subtle,
alignment, Italic,
Height, Strikethrough
Wrap,
Maximum
lines,
Maximum
width

Image Element ID, URL, Spacing, Style,
Alternative Separator, Background
text Horizontal color

alignment,
Height,
Height in
pixels, Width
in pixels,
Size

Submit Action ID, Title,
Ignore
provided
inputs

Open Action ID, Title, URL
URL

Custom form element properties
Property Optional Accepts Default Description
name

Allow N/A Boolean False Allows multiple choices to be selected
multiple value
selection

Alternative Yes Text value Alternative text describing the image
text



Property Optional Accepts Default Description
name

Background Yes Text value Applies a background to a transparent
color image. This property will respect the image

style. Only hex values are acceptable in this
property

Choices Yes Title and Describes choices for use in the choice set.
Value Consists of a title (text to display) and a

value (raw value for the choice)

Color N/A Default, Default Controls the color of text
Dark, Light,
Accent,
Good,
Warning,
Attention

Default value Yes Text value, The default value of the input element
Numeric
value

Error Yes Text value Error message to display when entered
message input is invalid

Fill mode N/A Cover, Describes how the image should fill the
Repeat area
horizontally,
Repeat
vertically,
Repeat

Font type N/A Default, Default Type of font to use for rendering
Monospace

Height N/A Auto, Auto Specifies the height of the element. The
Stretch, 'Pixels' option is available only for image
Pixels elements

Height in No Numeric 0 Specifies the desired height of the image.
pixels value The image will distort to fit that exact

height. This overrides the 'Size' property.
The default value of 0 determines that no
particular height is specified

Horizontal N/A Left, Center, Text Controls how this element is horizontally
alignment Right block: positioned. For custom forms, it describes

Left 
 how the background image should be
Image: aligned if it must be cropped or if using
Left repeat fill mode



Property Optional Accepts Default Description
name

ID No Text value Depends Unique identifier for the value. Used to
on the identify collected input when the Submit
element action is performed. If an invalid ID is

temporarily used and the form designer is
closed, the last valid ID used will apply

Ignore N/A Boolean False If enabled, this action closes the form
provided value without storing the selected inputs,
inputs operating as a Cancel button

Italic N/A Boolean False If enabled, italicizes the text
value

Label Yes Text value Label for this input

Maximum No Numeric 0 Specifies the maximum number of
length value characters to collect. The default value of 0

determines that no maximum length is
specified

Maximum No Numeric 0 Specifies the maximum number of lines to
lines value display. The default value of 0 determines

that no maximum lines are specified

Maximum Yes Text value Hint of maximum value. For date and time
value inputs, the value must be expressed in

your machine's regional format

Maximum No Numeric 0 Specifies the maximum width of the text
width value block in pixels. The default value of 0

determines that no maximum width is
specified

Minimum No Numeric 0 Specifies the minimum height of the form.
height in value The default value of 0 determines that no
pixels minimum height is specified

Minimum Yes Text value Hint of minimum value. For date and time
value inputs, the value must be expressed in

your machine's regional format

Multiline N/A Boolean False If enabled, allows multiple lines of input
value

Pattern Yes Text value Regular expression indicating the required
format of this text input



Property Optional Accepts Default Description
name

Separator N/A Boolean False When enabled, draws a separating line at
value the top of the element

Size N/A Text block: Text Controls the size of the text or image
Default, block:
Small, Default 

Medium, Image:
Large, Extra Auto
large 

Image:
Auto,
Stretch,
Small,
Medium,
Large

Spacing N/A Default, Default Controls the amount of spacing between
None, this element and the preceding element
Small,
Medium,
Large, Extra
large,
Padding

Strikethrough N/A Boolean False If enabled, crosses out the text
value

Style N/A Text input: Text The style of the text hint, choice set or
Text, Tel, input: image
URL, Email 
 Text 

Choice set Choice
input: set
Compact, input:
Expanded 
 Compact
Image: Image:
Default, Default
Person

Subtle N/A Boolean False If enabled, displays text slightly toned
value down to appear less prominent

Text Yes Text value New text Text to display
block



Property Optional Accepts Default Description
name

Title Yes Text value Toggle Title for the custom form or toggle or label
input: for the button that represents this action
New
toggle
input 

Submit:
OK

URL Yes Text value The URL of the image (for image element
and custom form) or the URL to open (for
Open URL action)

Validation Yes Boolean False Determines whether this input is required
required value or not

Value when Yes Text value False The value when the toggle is off
off

Value when Yes Text value True The value when the toggle is on
on

Vertical N/A Top, Center, Describes how the image should be
alignment Botton aligned if it must be cropped or if using

repeat fill mode

Vertical N/A Top, Center Top Defines how the content should be aligned
content Bottom verically within the container. Only relevant
alignment for fixed-height forms, or forms with a

minimum height specified

Weight N/A Default, Default Controls the weight of text
Lighter,
Bolder

Width in No Numeric 0 The desired on-screen width of the image.
pixels value This overrides the 'Size' property. The

default value of 0 determines that no
particular width is specified

Wrap N/A Boolean False If enabled, allows text to wrap. Otherwise,
value text is clipped

Known issues and limitations
Issue: The preview pane seems to work as expected when the URL property
contains percentage characters, but an Invalid value validation error occurs.



Workaround: This issue happens because Power Automate attempts to resolve the
percentage characters as variables or expressions. To resolve this case, store the
URL in a variable earlier in the flow, escape the percentage characters, and then
use that variable in the URL property. The preview won't show the image, but it will
be shown during runtime.



Automate desktop applications
Article • 02/02/2023

Power Automate offers UI automation actions to allow users to interact with Windows
applications and their components by either providing input with mouse clicks and
keyboard strokes or extracting data.

The actions of the Windows subcategory directly manipulate entire application windows,
while form filling actions interact with more specific components, such as text fields and
buttons.

UI automation actions require the window they interact with to be in the foreground, or
they'll automatically bring it to the foreground.

Desktop automation can be performed by manually adding the required actions or
using the recorder. You can find a list with all the available UI automation actions in the
UI automation actions reference.

Interacting with desktop applications
To identify windows and components in them, Power Automate utilizes UI elements. UI
elements uniquely describe each component and can be managed through the flow
designer's UI elements pane.

To configure a UI automation action, determine the specific element it will interact with.



Existing UI elements are displayed in the UI element pane, while new ones can be added
directly through the action's properties or the pane. You can find more information
regarding UI elements and their different types in Automate using UI elements.

７ Note

UI automation actions accept exclusively desktop UI elements. Therefore, UI
elements captured from web applications using the UI elements pane aren't
displayed in the UI automation actions.

Users can capture elements from web pages through the UI element picker of UI
automation actions. However, their selectors will represent desktop elements, not
web elements.



To add a new UI element, highlight the appropriate element and press Ctrl + Left click.
After adding all the elements, select Done to save them.



To extract a piece of data from an application window, such as its title, location, or size,
use the Get details of window action.

On the other hand, to extract data from specific components within a window, use the
Get details of a UI element in window action.



Automate on virtual desktops
Article • 02/11/2025

With the Power Automate agent for virtual desktops, you can automate processes on
virtual desktops as easily as you can on physical devices. If your virtual desktop uses
Citrix or Microsoft Remote Desktop Protocol (RDP), you can capture UI elements, deploy
UI automation actions, deploy Browser automation actions,and create desktop flows
using the recorder, just like on your physical desktop.

The Power Automate agent for virtual desktops must be running both while you're
designing a flow and when the flow runs. The agent starts automatically when a user
logs in to the virtual desktop. If it isn't running on your virtual desktop, launch the agent
manually. To launch the Power Automate agent for virtual desktops manually, double-
click the shortcut on your desktop, or search for Power Automate agent for virtual
desktops on the Start menu and then select the respective result, or go to the
installation directory of the Power Automate agent for virtual desktops (by default, it's
C:\Program Files (x86)\Power Automate agent for virtual desktops ) and double-click
PAD.RDP.ControlAgent.exe.

It's important to install Power Automate for desktop on the machine where you're
developing and executing your desktop flows, and Power Automate agent for virtual
desktops on the machine where the flow just interacts with for UI automation actions.
This second machine can be a Citrix Desktop, a host machine for a Citrix Virtual App, a
remote desktop with Windows RDP communication, or a machine that hosts a Remote
Desktop app.

Prerequisites
Your physical device and virtual machine must be running Windows 10 Pro,
Windows 10 Enterprise, Windows 11 Pro, Windows 11 Enterprise, Windows Server
2016, Windows Server 2019, or Windows Server 2022.

Make sure the Citrix or RDP connection to the virtual desktop is closed and then
install Power Automate on your physical device .

A device with the following hardware (these requirements don't include the
resources required for the applications involved in your desktop flows):

Minimum hardware:
Processor: 1.50 GHz per session or faster with two or more cores.



Storage: 300 ΜΒ system storage for agent installation, plus 500 MB for each
user (each version of Power Automate for desktop requires a user have 500 MB
of storage space).
RAM: 384 MB per session.

Recommended hardware:
Processor: 2.00 GHz per session or faster with two or more cores.
Storage: 300 ΜΒ or more system storage for agent installation, plus 500 MB or
more for each user (each version of Power Automate for desktop requires a user
have 500 MB of storage space).
RAM: 512 MB or more per session.

Install the Power Automate agent for virtual
desktops

1. Download the Power Automate agent for virtual desktops .

Alternatively, launch the Power Automate desktop designer and select Tools >
Power Automate for virtual desktops.

2. Copy the installer to your Citrix or RDP virtual desktop.

3. As an administrator, run the installer.

When the installation is complete, make sure the agent appears in the virtual
desktop's notification area.



If you notice the agent isn't running, restart it using the shortcut in the notification area.
If you encounter an error, refer to Resolve Power Automate agent for virtual desktops
issues.

Sync Power Automate and agent for virtual
desktops versions
To automate on virtual desktops, the versions of Power Automate and Power Automate
agent for virtual desktops must be the same. If they're different when you start
recording or capturing UI elements, select Sync when you're prompted to sync them.

If the versions are out of sync when a desktop flow is running, Power Automate syncs
them automatically.

７ Note

The DLLs of the synced agent are stored in
C:\Users\username\AppData\Local\Microsoft\Power Automate Desktop\RDP
Automation Agents.



Distinguish UI elements captured on virtual
desktops
Generated selectors of windows and UI elements are the same regardless of whether
they were captured on a physical device or a virtual desktop. Visual indications and the
tree structure in the UI elements pane help you to distinguish UI elements captured on
virtual desktops from those captured on a physical device. Learn more about UI
elements and selectors.

UI elements captured on the physical device are located under the Computer parent. UI
elements captured on a virtual desktop are located under an RDP or Citrix parent. Every
virtual desktop has its own individual tree. A numeric prefix helps you to distinguish
virtual desktops of the same type.

７ Note

When you capture a UI element in a virtual desktop, virtual app or RemoteApp, it is
linked to the details(IP, Name, etc.) of the machine at the time of capture. If you
want to interact with the same UI element on a different machine, you will need to
capture it again on that machine.

Communication between Power Automate for
desktop and Power Automate agent for virtual



desktops if syncing

Basic information
An automation agent is a specialized agent that is sent to the remote desktop after the
initial communication with the control agent is complete. It provides specific
functionality for UI automation for the version of Power Automate Desktop that
requests it.

The Automation Agent Storage Directory refers to the default path where automation
agents are stored. By default, this path is '%LOCALAPPDATA%\Microsoft\Power
Automate Desktop\RDP Automation Agents'. However, if the
'PAD_RDP_STORAGE_DIRECTORY' property is defined on the machine, then the path
becomes '%PAD_RDP_STORAGE_DIRECTORY%\Microsoft\Power Automate Desktop\RDP
Automation Agents'.

Communication phases
The following table and diagram depicts the different phases of communication:

ﾉ Expand table

Phase Description

Initial The first communication between Power Automate for desktop and the Power
handshake Automate agent for virtual desktops. The versions of Power Automate for desktop

and Power Automate agent for virtual desktops aren't the same.

Sync This phase occurs when the user chooses to sync the versions of Power Automate
for desktop and Power Automate agent for virtual desktops.

Retry After the sync process is complete, the handshake between Power Automate for
handshake desktop and the Power Automate agent for virtual desktops is retried.

Automation The runtime of UI automation actions performed on the remote machine through
the Power Automate agent for virtual desktops.





Known issues and limitations
Issue: Virtual desktop automation is available only in Windows RDP, RemoteApp,
Citrix Desktop, and Citrix Virtual Apps. Other virtual desktop platforms aren't
supported.

Workaround: None



Issue: Power Automate agent for virtual desktops isn't compatible with Windows
10 Home and Windows 11 Home.

Workaround: None. Remote desktop connection isn't supported in these Windows
editions.

Issue: Encounter the 'Error communicating with Power Automate for desktop'
message when Power Automate agent for virtual desktop is launched in Citrix
Desktop even though you have installed Power Automate for desktop and Power
Automate agent for virtual desktops correctly and met all prerequisites.

Workaround:
Check the Virtual channel allow list policy setting in your Citrix configuration.

If the Citrix VDA version is earlier than 2407:
The Virtual channel Allow list policy on Citrix is by default either enabled or
set to default. However, if this policy isn't disabled, the Power Automate
agent can't communicate with Power Automate for desktop. Contact your
Citrix administrators to disable this policy, as keeping it set to Default isn't
sufficient.

If the Citrix VDA version is 2407 or later:
Configure a different policy. The older Virtual channel Allow list can remain
set to Default. Configure the new policy Virtual channel allow list for DVC
and add the following values:

C:\Program Files (x86)\Power Automate agent for virtual

desktops\PAD.RDP.ControlAgent.exe,Microsoft.Flow.RPA.Desktop.UIAutomat

ion.RDP.DVC.Plugin,PAD\CONTROL

C:\Users\*\AppData\Local\Microsoft\Power Automate Desktop\RDP

Automation

Agents\*\PAD.RDP.AutomationAgent.exe,Microsoft.Flow.RPA.Desktop.UIAuto

mation.RDP.DVC.Plugin,PAD\UIA

Restart the Citrix machines after applying the policy.

Issue: Virtual desktop automation isn't supported in Power Automate installed
through the Microsoft store.

Workaround: Download and install the Microsoft Visual C++ Redistributable,
which installs Microsoft C and C++ (MSVC) runtime libraries.

Download the x86 version .
Download the x64 version .

Issue: When a flow is running, an element isn't found if the virtual desktop window
is minimized.



Workaround: Use a Focus window action on the virtual desktop window before
deploying UI automation actions to interact with the virtual desktop.

Issue: When you're using the recorder and the virtual desktop window is
maximized, the Populate text field in window and Send keys actions might not
work as expected.

Workaround: Make sure the virtual desktop window isn't maximized while you're
recording.

Issue: UI automation of Java applets running on virtual desktops isn't supported.

Workaround: None

Issue: Citrix UI automation doesn't work if you're using Citrix Desktop and Citrix
App in the same session.

Workaround: None

Issue: Defining a window on virtual desktops using the Window instance/handle
or Window title/class options isn't supported.

Workaround: None

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Build a custom selector
Article • 02/24/2023

Although Power Automate enables users to create selectors automatically, some
particular scenarios need manually created selectors. A common scenario is the
automation of applications that display dynamic content.

When a custom selector is needed, you can modify an existing selector or build one
from scratch.

To edit an existing selector, select the appropriate UI element and choose the selector
you want to edit.

You can create multiple selectors for a UI element. Whenever a selector fails, Power
Automate uses the next selector in the defined order. To add more selectors for a UI
element, capture a new selector using the Selector with recapture button or create a
copy of an existing selector. To create a copy, right-click on the existing selector and
select Create a copy.



In selectors, use the > notation to indicate the hierarchical structure of the selected
elements. Each element in the selector is contained within the element on its left and
displayed in the following form:

element[Attribute1=”Attribute1Name”][Attribute2=”Attribute2Name”]...
[Attributen=”AttributenName”]

The attributes of an element describe it uniquely and distinguish it from other elements
in the same application. Enabling or disabling attributes can change the target
application component of the selector.

７ Note

Web and desktop selectors have the same structure and functionality. The main
differences between them are the available attributes. Web selectors use HTML
attributes, while desktop selectors use different kinds of attributes based on the
application design.

To specify an application component precisely, Power Automate utilizes multiple levels
of selectors.

Selectors use a tree structure that describes the exact location of a component in the
application or webpage. Each level is the child of the upper-level and the parent of the



lower-level selector. The selector in the lower level describes the component you want
to handle.

This functionality enables Power Automate to distinguish a component from
components with similar attributes in the same application. Disabling or enabling levels
of selectors allows you to change the location in which Power Automate will search for
the component.

For example, the following selector pinpoints the File menu option in a Notepad
window. The first two levels of the selector describe the pane and menu bar of the
window, while the third level describes the File option.

７ Note

The Notepad window and the pane are different UI elements, but they have a
parent-child relationship.

Assume that you want to edit the selector to work with a Notepad window named
Notes.txt. To achieve this functionality, change the Name attribute of the selector to
Notes.txt - Notepad. The new selector should be: :desktop >
window[Name="Notes.txt - Notepad"][Process="Notepad"].



Use operators in a custom selector
In the previous example, the selector located a Notepad window with a specific title. To
make the selector more dynamic, replace the Equal to operator with other operators or
regular expressions.



The Equal to operator makes the selector search for a specific hard-coded value.
Although this functionality is effective in static applications, hard-coded values can be a
barrier in dynamic applications.

Use the Contains operator to locate elements that don't have fixed values but always
contain a specific keyword. For example, apply the Contains operator in the Notepad
selector to make it work with all Notepad windows.

Apart from the Equal to and Contains operators, Power Automate provides four more
operators:

Not equal to: Checks if an attribute contains any value except a specific one.
Starts with: Checks if an attribute contains a value that starts with a particular
character, keyword, or phrase.
Ends with: Checks if an attribute contains a value that ends with a particular
character, keyword, or phrase
Regular expression match: Checks if an attribute contains a value that matches a
custom regular expression. Power Automate's regular expression engine is .NET.
You can find more information regarding regular expressions in Regular Expression
Language - Quick Reference.

Use variables in a custom selector



Apart from various operators, Power Automate enables you to create dynamic selectors
using variables. If the value of a selector's attribute depends on calculations and results
of previous actions, replace the hard-coded value with a variable.

To use a variable in a selector, populate its name manually enclosed by percentage signs
(%) or use the variables button. Variables can be used in both the visual and text editor.
You can find more information about the percentage notation in Use variables and the
% notation.

If you use a variable in the Name attribute of the Notepad example, the selector should
be :desktop > window[Name="%WindowName%"][Process="Notepad"].



Test a selector
Article • 04/13/2023

Power Automate enables you to test a selector and ensure that your UI automation
flows are running as expected. With the ability to test both desktop and web selectors,
you can quickly and efficiently automate your application and webpage interactions.

The selector builder window is used to edit UI elements. There, you can find the option
for testing the selector. Select Test selector and Power Automate checks whether the
specified selector from the list can locate a UI element on the screen.

In order to test a selector, you must ensure that a UI element is available on your
computer. If one isn't available, after selecting Test selector the message Ensure that
the UI element is present in the screen before proceeding with the validation is
displayed.

There are three possible outputs:

Success: A UI element was found successfully in the screen.

Failed: No UI element was found in the screen. Power Automate highlights the
element (level) that wasn't found in the Elements list, indicating to the user the
element that should be fixed.



Multiple UI elements found: The selector may locate multiple UI elements in the
screen. If a UI element is used in an action, at runtime Power Automate interacts
with the first respective UI element from the top left corner of the screen. Note
that Power Automate highlights at testing the UI element that will be interacted at
the runtime if the specific selector is used in an action.

You may get more information for each output by selecting the output icon next to the
tested selector.



You can test selectors for both desktop and web UI elements. Desktop selectors are
captured from any Windows application and can be used in actions of the UI
automation group. Web selectors are captured from webpages and can be used only in
browser automation actions.

７ Note

Every time you edit a tested selector, the output icon is removed, and the selector
should be tested again.

Testing all selectors
A UI element may have more than one selector for defining its location. The test selector
feature allows you to test all selectors by selecting the arrow next to Test selector, and
then selecting Test all selectors.

７ Note

When you opt for testing all selectors, the disabled selectors won't be tested from
the list. If you need to test a disabled selector, test it individually.

Desktop UI elements - Open screen selector



Each desktop UI element belongs to a screen (parent UI element). In some cases, testing
of the selector can't be performed because the screen can't be found. In this case, you
should:

Ensure that the screen is available on your computer.
If yes, then select Open screen selector, and fix the screen selector. You may
perform the test selector feature to the screen selector as well.

７ Note

When you navigate to the screen selector through the selector builder window of a
child, then you will return to the child view after closing the screen's selector
builder window.

Web UI elements - Open Web browser tab
If there's a web UI element, in order to proceed with the test the web page that contains
the specific UI element must be available on your computer and the web browser tab
should be selected in the Web browser tab drop-down list.

If no web browser tab is selected in the list and you select Test selector, Power
Automate prompts you to select the browser tab before the testing starts.



Variables
You can test a selector even if one or more variables are contained in the selector. You
must provide values to the selector's variables for the test to be performed.

Highlight
When a selector is tested and the output is success or multiple UI elements found,
Power Automate highlights the UI element that is interacted at run time with the specific
selector.



Text editor
Test selector capabilities can be fully used in the Text editor view of the selector builder
window as well, in the same fashion as in the builder view.

Related information
Build a custom selector

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Repair a selector
Article • 05/12/2023

Repair selector is a powerful feature that enables you to easily and intuitively correct
invalid selectors. By automatically generating a repaired selector for the UI element that
automation needs to interact with, Power Automate for desktop makes it simple to
maintain automation flows. The repair selector feature is available for both desktop and
web UI elements. To take advantage of it, open the UI element selector builder window
and opt for the related option in the screen. This feature can also be used to fix a screen
selector that is the parent element of a desktop UI element.

How to repair a selector
You should select the selector to be repaired and select the Repair option on the screen.
The Repair option can be selected while the user is at the selector builder view or the
text editor view.

When you opt for repairing a specific selector, the UI element picker is launched,
displaying a screenshot of the UI element to be captured.



Note that the UI element picker highlights only the UI elements of the same type as the
type of the respective selector to be repaired. Therefore, if you repair a desktop UI
element, only the desktop UI elements can be highlighted and captured and for the web
selector case, only the web UI elements can be highlighted and captured.

Capture the UI element by hovering over the UI element until the frame appears around
it, then press Ctrl+Left click.

After capturing the UI element successfully, Power Automate for desktop generates a
selector that takes into account both the old selector that is being repaired and the
selector of the just captured UI element.

The repaired selector is presented to you for your review with the changes in the
selector highlighted. Select OK to accept the suggested repair.



The previous select is replaced by the repaired selector. Select Save to complete the
repair.

If you select Cancel, the selector isn't repaired and the old selector remains intact.

There are cases when Power Automate for desktop won't be able to generate a repaired
selector successfully. When this happens, you should make sure that the correct UI
element is captured. If the UI element still can't be repaired, you must repair the selector
manually.



７ Note

The selectors that contain one or more variables can't be repaired. Either replace
the variables with static values or repair the selector manually. More information:
Build a custom selector

Related information
Build a custom selector

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Fallback mechanism for UI elements
Article • 06/18/2024

Power Automate for desktop introduces an enhanced method to bolster the robustness
of your UI/Browser automation flows. Now, you can designate an image as a fallback
mechanism for a UI element, to ensure reliable execution when predefined selectors fail
to identify the element at runtime. By incorporating an image fallback, you significantly
increase the likelihood of successfully executing UI or browser actions that interact with
the specific UI element. When you activate this fallback mechanism and the selectors are
unable to locate the UI element on the screen, the system utilizes the designated image
to find it.

How to set up the image fallback mechanism
for a UI element
To enable the image fallback mechanism, launch the Selector Builder window for the
specific UI element. Select Image as fallback.

This step opens the UI element picker tool.



To create an image selector for a specific UI element, left-click on the element while
pressing Ctrl. This action captures an image of the UI element and generates a
corresponding image selector. Only one image selector can be associated with each UI
element. As a result, the Image as fallback button is disabled once an image selector is
created. You can view the captured image by selecting the image selector from the list
of selectors in the window.



Actions on the image selector of the UI
element
You can perform various actions on the image selector just as you would with standard
selectors. These actions include deleting, renaming, testing, and repairing the image
selector. Deleting an image selector removes it if it's no longer needed, while renaming
allows you to change its name for better identification. Testing the image selector
checks whether the captured image can be found on your screen; remember to ensure
that the image is in the foreground for accurate testing. Repairing the image selector
enables you to replace the current image with a new one.



Known issues and limitations
Fallback mechanism for UI elements isn't supported with the following actions:

Data extraction
Web data extraction

The following actions don't support a fallback mechanism for UI elements when
the parameters Check if window , Wait until window , Check if web page , or Wait
for web page to  are configured with the conditions Contains text  or Doesn't
contain text :

If window contains
Wait for window content
If web page contains
Wait for web page content

The image selector is removed if the following conditions are met:
An image is saved as fallback mechanism for a UI component.
The flow is later opened and saved in a version of Power Automate for desktop
that is v2.44 or earlier.

This deletion is permanent, and the image selector can't be restored, even if the
flow is later accessed with a newer version. To work around this issue, don't save
the desktop flow in the older version of Power Automate for desktop or recapture
the image to set as fallback.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Power Fx in desktop flows
Article • 11/07/2024

Power Fx is the low-code language for expressing logic across Microsoft Power Platform.
It's a general-purpose, strong-typed, declarative, and functional programming language.

Power Fx is expressed in human-friendly text. It's a low-code language that makers can
work with directly in an Excel-like formula bar or Visual Studio Code text window. The
"low" in low-code is due to the concise and simple nature of the language, making
common programming tasks easy for both makers and developers.

Power Fx enables the full spectrum of development from no-code makers without any
programming knowledge to pro-code for the professional developers. It enables diverse
teams to collaborate and save time and efforts.

Using Power Fx in desktop flow
To use Power Fx as an expression language in a desktop flow, you have to create a
desktop flow and enable the respective toggle button when creating the flow through
Power Automate for desktop's console.

Differences in Power Fx enabled flows



７ Note

Each Power Fx expression must start with an "=" (equals to sign).

If you're transitioning from flows where Power Fx is disabled, you might notice some
differences. To streamline your experience while creating new desktop flows, here are
some key concepts to keep in mind:

In the same fashion as Excel formulas, desktop flows that use Power Fx as their
expression language use 1 (one) based array indexing instead of 0 (zero) based
indexing. For example, expression =Index(numbersArray, 1)  returns the first
element of the numbersArray  array.

Variable names are case-sensitive in desktop flows with Power Fx. For example,
NewVar is different than newVar.

When Power Fx is enabled in a desktop flow, variable initialization is required
before use. Attempting to use an uninitialized variable in Power Fx expressions
results in an error.

The If action accepts a single conditional expression. Previously, it accepted
multiple operands.

While flows without Power Fx enabled have the term "General value" to denote an
unknown object type, Power Fx revolves around a strict type system. In Power Fx
enabled flows, there's a distinction between dynamic variables (variables whose
type or value can be changed during runtime) and dynamic values (values whose
type or schema is determined at runtime). To better understand this distinction,
consider the following example. The dynamicVariable  changes its type during
runtime from a Numeric  to a Boolean  value, while dynamicValue  is determined
during runtime to be an untyped object, with its actual type being a Custom
object :



Values that are treated as dynamic values are:
Data tables
Custom objects with unknown schema
Dynamic action outputs (for example, the "Run .NET Script" action)
Outputs from the "Run desktop flow" action
Any action output without a predefined schema (for example, "Read from Excel
worksheet" or "Create New List")

Dynamic values are treated similarly to the Power Fx Untyped Object and normally
require explicit functions to be converted into the required type (for example,
Bool()  and Text() ). In order to streamline your experience, there's an implicit
conversion when using a dynamic value as an action input or as a part of a Power
Fx expression. There's no validation during authoring, but depending on the actual
value during runtime, a runtime error occurs if the conversion fails.

Whenever a dynamic variable is used, a warning message stating "Deferred type
provided" is presented. These warnings arise due to Power Fx's strict requirement
for strong-typed schemas (strictly defined types). Dynamic variables aren't
permitted in lists, tables, or as a property for Record values.

By combining Run Power Fx expression action with expressions using Collect,
Clear, ClearCollect, and Patch functions you can emulate behavior found in the
actions Add item to list and Insert row into data table which were previously not
available for Power Fx enabled desktop flows. While both actions are still available,
use the Collect function when working with strongly typed lists (for example, a list
of files). This function ensures the list remains typed, as using the Add Item to List
action converts the list into an untyped object.

Examples
The =1  in an input field is equivalent to the numeric value 1.



The = variableName  is equal to the variableName variable's value. 
The expression = {'prop':"value"}  returns a record value that is equivalent to a
custom object.
The expression = Table({'prop':"value"})  returns a Power Fx table that is
equivalent to a list of custom objects. 
The expression - = [1,2,3,4]  creates a list of numeric values.
To access the value from a List, use the function Index(var, number) , where var is
the name of the List and number is the position of the value to be retrieved.
To access a data table cell using a column index, use the  Index()  function.
=Index(Index(DataTableVar, 1), 2)  retrieves the value from the cell in row 1 within
column 2. =Index(DataRowVar, 1)  retrieves the value from the cell in row 1.
To include an interpolated value in an input or a UI/web element selector, use the
following syntax: Text before ${variable / expression} text after

Example: The total number is ${Sum(10, 20)}

７ Note

If you want to use the dollar sign ( $ ) followed by a opening curly brace sign ( { )
within a Power Fx expression or in the syntax of a UI/Web element selector and
have Power Automate for desktop not treat it as the string interpolation syntax,
make sure to follow this syntax: $${  (the first dollar sign will act as an escape
character)

Available Power Fx functions
For the complete list of all available functions in Power Automate for desktop flows, go
to Formula reference - desktop flows.

Known issues and limitations
The following actions from the standard library of automation actions aren't
currently supported:

Switch
Case
Default case

Some Power Fx functions presented through IntelliSense aren't currently supported
in desktop flows. Those functions display the following design time error when
used: "Parameter 'Value': PowerFx type 'OptionSetValueType' isn't supported."



What's new
This section lists what changed in each update.

2.48
In September 2024 release:

Re-enable previously unsupported list and data table manipulation actions from
the Variables category.
Native untyped object support, for custom objects, lists, and data tables. Learn
more about untyped objects at Untyped object data type.

This change was introduced to reduce the design-time warnings and usage of
deferred types. Untyped object is a way to handle types with unknown schema
at design time.
In previous versions, dynamic variables (variables whose type or value can be
changed during runtime) and dynamic values (values whose type or schema is
determined at runtime) were handled the same way. When either a dynamic
value or a dynamic variable was used in a Power Fx expression, a warning was
triggered: "Deferred type provided." These warnings occurred because Power Fx
enforces strict type schemas (strongly defined types). Starting with this version,
we distinguished between these two cases. While dynamic variables continue to
generate the "deferred type" warning, dynamic values are now treated as
untyped objects.
All data table variables are untyped, while custom objects resulting from
Convert JSON to a custom object action are untyped. Lists will become
untyped after manipulating them with Power Automate for desktop actions
from the Variables category.
Previously, certain automation actions from the standard library of actions, such
as Read from Excel, Read from CSV, Extract data from a web, Extract data
from window, Execute SQL statement, and Convert JSON to a custom object
would produce a dynamic variable, along with a "deferred type" warning. They
now produce an untyped data table or untyped custom object variable instead.

Set Power Fx function is now enabled but not fully supported yet. While it can't be
used to modify a variable's value directly, it can be used with the above structures
to also update custom object properties and values of lists in specific indexes (for
example, =Set(Index(Index(DataTable, 1), 1), 42)  or
=Set(customObject.property, 17) ).
Fixed an issue with accessing nested list properties of an object in Power Fx
enabled flows.



Ｕ Caution

In version 2.48 of Power Automate for desktop, there have been updates for Power
Fx enabled desktop flows that could impact the execution of Power Fx enabled
flows created with previous versions. It is advised to thoroughly test this version
with your existing Power Fx flows.

Child flow outputs: Exercise caution when using output variables from child
flows in a Power Fx enabled desktop flow. This involves output variables of
types list, custom object, and data table.
Single-value column arrays: An array created using an expression like =[1, 2,
3]  results in a single-value column array in Power Fx enabled flows, whose
items are objects with a single property: {Value: 1} . Attempting to access the
Value  property of this item, after modifying the first array with an action,
results in an authoring error.
Power Fx function usage: In certain Power Fx functions, such as IsEmpty() ,
previous versions accepted a dynamic variable as an argument and didn't
throw a validation error. With the 2.48 version, using a variable that is handled
as a dynamic variable results in a validation error, and a failure to execute
existing flows. The resolution to this is to apply proper casting to the dynamic
(untyped) value. Learn more about casting functions in Untyped object data
type. You might encounter this issue when editing a flow and receive an error
message like "Invalid argument type (UntypedObject). Expecting a Table value
instead." To resolve this issue, follow the error messages to convert your
expression into a valid one.

Other examples of functions that might throw a validation error when
using a combination of dynamic and typed variables are Sum() , Filter() ,
Concatenate()  and operators like in  (for example, "string" in
DynamicValueObject ).

Variable comparison: Similar to the previously mentioned issue, there can be
type incompatibilities when you apply comparison operators ( = , <> , > , <
etc.) on expressions involving dynamic values. Exercise caution and apply the
proper casting before you compare dynamic values.

2.43
In April 2024 release:



Case sensitivity. For example, NewVar is a different variable than newVar.
Run Power Fx expression action is available under the Variables group of actions.
Run Power Fx expression allows you to execute expressions directly on data
sources.
Collect, Clear, ClearCollect Power Fx functions are supported in desktop flows.
Patch Power Fx functions are supported in desktop flows.
Variables and Power Fx expressions can be used in UI element or web selector
syntax.
Interpolated values can now be included in the syntax of a UI/web element
selector. For interpolated strings, you can use this syntax: ${ Power Fx expression }.

） Important

In version 2.43 of Power Automate for desktop, there have been updates for Power
Fx enabled desktop flows that could impact the execution of Power Fx enabled
desktop flows created with previous versions. Specifically:

Case-sensitive variable names: Variable names within Power Fx enabled
desktop flows created with Power Automate for desktop version 2.43 and
later are case-sensitive. Power Fx desktop flows created with Power Automate
for desktop version 2.42 and earlier allowed for case-insensitive variable
names. For example, NewVar and newVAR reference the same variable. For
Power Fx enabled desktop flows created with Power Automate for desktop
version 2.42 and earlier, make sure to review and verify that the produced
variables are as expected.

2.42
In March 2024 release:

IntelliSense capabilities are now available for Power Fx enabled desktop flows.
Syntax colorization
Autocomplete functionality during typing with real time suggestions
Signature helpers for Power Fx functions

７ Note



IntelliSense capabilities are available for expressions. To input an expression use the
equals sign (= your expression ) at the beginning of the respective input or the
string interpolation notation ( ${ your expression } ).

Function picker
You can access the function picker using the fx button in the skittle when
interacting with the respective inputs. All Power Fx functions currently
supported for desktop flows are available there.

2.41
In February 2024 release:

From now on inputs that don't begin with the equals sign (=) are considered as
text type values. Numeric and boolean inputs must always begin with the equals
sign.
Inputs now support interpolated strings. To include an interpolated value in an
input, use the following syntax: Text before ${variable/ expression} text after .

Example: The total number is ${Sum(10, 20)}

７ Note

To use interpolated string syntax, omit the equals (=) sign at the beginning of the
input.

2.39
In December 2023 release:

If the input provided doesn't start with the equals sign, the following rules apply:
Numeric values without spaces are interpreted as numeric values.
True/ False as input, regardless of case and without spaces are interpreted
as boolean values.
All other inputs are considered of text type values.

Feedback
Was this page helpful?  Yes  No



Provide product feedback



Formula reference - desktop flows
Article • 03/22/2024

In this article, learn about all the functions available in Power Automate for desktop.

A
Abs – Absolute value of a number.

Acos – Returns the arccosine of a number, in radians.

Acot – Returns the arccotangent of a number, in radians.

AddColumns – Returns a table with columns added.

AIClassify – Classifies text into one or more of categories.

AIExtract – Extracts specified entities such as registration numbers, phone numbers, or
names of people.

AIReply – Drafts a reply to the message that you provide.

AISentiment – Detects the sentiment of the text that you provide.

AISummarize – Summarizes the text that you provide.

AITranslate – Translates text from another language.

And – Boolean logic AND. Returns true if all arguments are true. You can also use the
&& operator.

Asin – Returns the arcsine of a number, in radians.

Atan – Returns the arctangent of a number, in radians.

Atan2 – Returns the arctangent based on an (x,y) coordinate, in radians.

Average – Calculates the average of a table expression or a set of arguments.

B
Blank – Returns a blank value that can be used to insert a NULL value in a data source.

Boolean – Converts a text string, number, or untyped value to a Boolean value.



C
Char – Translates a character code into a string.

Coalesce – Replaces blank values while leaving non-blank values unchanged.

Concat – Concatenates strings in a data source.

Concatenate – Concatenates strings.

Cos – Returns the cosine of an angle specified in radians.

Cot – Returns the cotangent of an angle specified in radians.

Count – Counts table records that contain numbers.

CountA – Counts table records that aren't empty.

CountIf – Counts table records that satisfy a condition.

CountRows – Counts table records.

D
Date – Returns a date/time value, based on Year, Month, and Day values.

DateAdd – Adds days, months, quarters, or years to a date/time value.

DateDiff – Subtracts two date values, and shows the result in days, months, quarters, or
years.

DateTime – Returns a date/time value, based on both date and time components.

DateTimeValue – Converts a date and time string to a date/time value.

DateValue – Converts a date-only string to a date/time value.

Day – Retrieves the day portion of a date/time value.

Dec2Hex – Convert a number to a hexadecimal text string.

Degrees - Converts radians to degrees.

Distinct – Summarizes records of a table, removing duplicates.

DropColumns – Returns a table with one or more columns removed.



E
EDate – Adds or subtracts months to a date, without changing the day of the month.

EncodeUrl – Encodes special characters using URL encoding.

EndsWith – Checks whether a text string ends with another text string.

EOMonth – Adds or subtracts months to a date, returning the last day of that month.

Error – Create a custom error or pass through an error.

Exp - Returns e raised to a power.

F
Filter – Returns a filtered table based on one or more criteria.

Find – Checks whether one string appears within another and returns the location.

First – Returns the first record of a table.

FirstN – Returns the first set of records (N records) of a table.

ForAll – Calculates values and performs actions for all records of a table.

G
GUID – Converts a GUID string to a GUID value or creates a new GUID value.

H
Hex2Dec – Convert a hexadecimal text string to a number.

Hour – Returns the hour portion of a date/time value.

I
If – Returns one value if a condition is true and another value if not.

IfError - Detects errors and provides an alternative value or takes action.

Index – Returns a record from a table based on ordered position.



Int – Rounds down to the nearest integer.

IsBlank – Checks for a blank value.

IsBlankOrError – Checks for a blank value or error.

IsEmpty – Checks for an empty table.

IsError – Checks for an error.

IsNumeric – Checks for a numeric value.

IsToday – Checks whether a date/time value is sometime today in the user's time zone.

L
Language – Returns the language tag of the current user.

Last – Returns the last record of a table.

LastN – Returns the last set of records (N records) of a table.

Left – Returns the left-most portion of a string.

Len – Returns the length of a string.

Ln – Returns the natural log.

Log – Returns the logarithm in any base of a number.

LookUp – Looks up a single record in a table based on one or more criteria.

Lower – Converts letters in a string of text to all lowercase.

M
Max – Maximum value of a table expression or a set of arguments.

Mid – Returns the middle portion of a string.

Min – Minimum value of a table expression or a set of arguments.

Minute – Retrieves the minute portion of a date/time value.

Mod – Returns the remainder after a dividend is divided by a divisor.

Month – Retrieves the month portion of a date/time value.



N
Not – Boolean logic NOT. Returns true if its argument is false, and returns false if its
argument is true. You can also use the ! operator.

Now – Returns the current date/time value in the user's time zone.

O
Or – Boolean logic OR. Returns true if any of its arguments are true. You can also use
the || operator.

P
Pi – Returns the number π.

PlainText – Removes HTML and XML tags from a string.

Power – Returns a number raised to a power. You can also use the ^ operator.

Proper – Converts the first letter of each word in a string to uppercase, and converts the
rest to lowercase.

R
Radians - Converts degrees to radians.

Rand – Returns a pseudo-random number between 0 and 1.

RandBetween – Returns a pseudo-random number between two numbers.

Replace – Replaces part of a string with another string, by starting position of the string.

Right – Returns the right-most portion of a string.

Round – Rounds to the closest number.

RoundDown – Rounds down to the largest previous number.

RoundUp – Rounds up to the smallest next number.

S



Second – Retrieves the second portion of a date/time value.

Sequence – Generate a table of sequential numbers, useful when iterating with ForAll.

Shuffle – Randomly reorders the records of a table.

Sort – Returns a sorted table based on a formula.

Split – Splits a text string into a table of substrings.

Sqrt – Returns the square root of a number.

StartsWith – Checks if a text string begins with another text string.

StdevP – Returns the standard deviation of its arguments.

Substitute – Replaces part of a string with another string, by matching strings.

Sum – Calculates the sum of a table expression or a set of arguments.

Summarize – Groups records by selected columns and summarizes the remainder.

Switch – Matches with a set of values and then evaluates a corresponding formula.

T
Table – Creates a temporary table.

Tan - Returns the tangent of an angle specified in radians.

Text – Converts any value and formats a number or date/time value to a string of text.

Time – Returns a date/time value, based on Hour, Minute, and Second values.

TimeValue – Converts a time-only string to a date/time value.

TimeZoneOffset – Returns the difference between UTC and the user's local time in
minutes.

Today – Returns the current date-only value.

Trim – Removes extra spaces from the ends and interior of a string of text.

TrimEnds – Removes extra spaces from the ends of a string of text only.

Trunc – Truncates the number to only the integer portion by removing any decimal
portion.



U
Upper – Converts letters in a string of text to all uppercase.

V
Value – Converts a string to a number.

VarP – Returns the variance of its arguments.

W
Weekday – Retrieves the weekday portion of a date/time value.

With – Calculates values and performs actions for a single record, including inline
records of named values.

Y
Year – Retrieves the year portion of a date/time value.

See also
Power Fx in desktop flows

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Custom actions in desktop flows
Article • 02/06/2025

Custom actions developed by your organization and uploaded to the respective
environments can be included in desktop flows and utilized like actions that belong in
the standard library of automation actions.

） Important

This feature requires Power Automate for desktop v2.32 or later.
Ensure the .dll files describing Custom actions, their dependency .dll files, and
the .cab files are properly signed with a digital certificate trusted by your
organization. The certificate should also be installed on the device under the
trusted root certificate authority where the desktop flow with custom action
dependencies is modified and/or executed.
If you use custom security roles to manage access, Power Platform admins
need to update the role to include read permission for the Desktop Flow
Module table ( prvReaddesktopflowmodule ).

Custom actions exist at the environment level. As a best practice, use a "dev—test—
prod" model when developing custom actions.

Known limitations
Custom actions groups can't exceed 30 MB upon upload.
Specific endpoints must be included in the allowlist for desktop flows containing
custom actions to work properly. More information: Desktop flow services required
for runtime
Application lifecycle management (ALM) isn't fully supported for desktop flows
with dependencies on custom actions.
Upload date might differ in the portal than what is shown in the Assets library
inside Power Automate for desktop.
Custom actions are not available for organizations that have enabled Bring your
own key (BYOK) from the protection service.
Machines belonging in a hosted machine group should have the appropriate
certificates required for custom actions, as set by your organization, installed on
them. You can create a golden image, containing the respective certificate(s) and
provide it during the creation process of the respective hosted machine group.



All dependencies used in custom actions and Power Automate for desktop must
be the same version. Using different versions of the same dependency within the
same process isn't supported.

Next steps
Create custom actions

Related information
Assets library
Upload custom actions
Use custom actions

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create Power Automate for desktop
actions using the Actions SDK
Article • 10/14/2024

This article describes how to create custom actions in Power Automate for desktop.

Creating custom actions
） Important

Reserved keywords can't be used as action names and/or action properties. Use of
reserved keywords as action names and/or action properties result in erroneous
behavior. More information: Reserved keywords in desktop flows

Begin by creating a new Class Library (.NET Framework) project. Select .NET framework
version 4.7.2.

To form an action in the custom module created:

Delete the autogenerated Class1.cs file.
Create a new class inside your project to represent the custom action give it a
distinct name.
Include the Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK and
Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK.Attributes
namespaces.
All classes representing actions should have an [Action] attribute above your class.
The class should have public access and inherit from ActionBase class.

C#

using System;
using Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK;
using Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK.Attributes;

namespace Modules.MyCustomModule
{
    [Action(Id = "CustomAction")]
    public class CustomAction : ActionBase
    {
        public override void Execute(ActionContext context)
        {
            throw new NotImplementedException();



        }
    }
}

Most actions have parameters (Input or Output). Input and Output parameters are
represented by classic C# properties. Each property should have an appropriate C#
attribute, either [InputArgument]  or [OutputArgument]  to dictate its type and how
they're presented in Power Automate for desktop. Input arguments can also have
default values.

C#

using System.ComponentModel;
using Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK;
using Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK.Attributes;

namespace Modules.MyCustomModule
{
    [Action(Id = "CustomAction")]
    public class CustomAction : ActionBase
    {
        [InputArgument, DefaultValue("Developer")]
        public string InputName { get; set; }

        [OutputArgument]
        public string DisplayedMessage { get; set; }

        public override void Execute(ActionContext context)
        {
            DisplayedMessage = $"Hello, {InputName}";
        }
    }
}

Adding descriptions to custom actions
Add a description and a friendly name for the modules and actions so that RPA
developers know how to best utilize them.

Power Automate for desktop designer shows friendly names and descriptions.

You can create a "Resources.resx" file inside the Properties folder of the module project.
The new ".resx" file should be named "Resources.resx".

The format of the descriptions for Modules and Actions should be as follows:



"Module_Description" or "Action_Description" and "Module_FriendlyName" or
"Action_FriendlyName" respectively in the name field. The description in the value field.

We also recommend that you provide descriptions and friendly names for parameters.
Their format should be as follows: "Action_Parameter_Description",
"Action_Parameter_FriendlyName".

 Tip

It is recommended to denote what it is you are describing in the comment field
(e.g. Module, Action etc.)

These can also be set with the FriendlyName and Description properties of the
[InputArgument] , [OutputArgument]  and [Action]  attributes.

Here's an example of a Resources.resx file for a custom module.

Another way to quickly add friendly names and descriptions to actions and parameters
is with the FriendlyName and Description properties in the [Action], [InputArguement]
and [OutputArguement] attributes.

７ Note

To add a friendly name and description to a module, you must modify the
respective .resx file or add the respective C# attributes.



Adding error handling to custom actions
To define custom exceptions in your action, use the [Throws("ActionError")]  attribute
above the custom action class. Each exception case you want to define should have its
own attribute.

In the catch block, use the following code:

throw new ActionException("ActionError", e.Message, e.InnerException);

Ensure that the ActionException  name matches the name you provided in the Throws
attribute. Use throw new ActionException  for each exception case and match it with the
corresponding Throws  attribute name. All exceptions defined with the Throws  attribute
are visible in the designer's action error handling tab.

An example of this can be found in the Conditional actions section.

Resources localization
The default language for modules in Power Automate for desktop is assumed to be
English.

The Resources.resx file should be in English.

Any other languages can be added with extra Resources.{locale}.resx files for
localization. For example, Resources.fr.resx.

Custom module categories
Modules can include categories and subcategories for better action organization.

In order to separate custom actions in categories, subcategories, modify the [Action]
attribute that precedes the class that represents the custom action in the following
manner:

C#

[Action(Category = "category.subcategory")]

７ Note



A Module can have multiple categories. Similarly, categories can be comprised by
subcategories. This structure can be indefinite.

The Order property dictates the order by which actions are previewed in the designer.

Action1  belongs in the category "TestCategory" and it's the first action of the module
(this way you explain Order and category with an example).

C#

[Action(Id = "Action1", Order = 1, Category = "TestCategory")]

Conditional actions
Conditional actions are actions that return either "True" or "False". 'If file exists' Power
Automate for desktop action of the standard library is a good example of a conditional
action.

Conditional action example:

C#

using Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK;
using Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK.Attributes;
using System;
using System.ComponentModel;

namespace Modules.CustomModule
{
    [ConditionAction(Id = "ConditionalAction1", ResultPropertyName = 
nameof(Result))]
    [Throws("ActionError")] // TODO: change error name (or delete if not 
needed)
    public class ConditionalAction1 : ActionBase
    {
        #region Properties

        public bool Result { get; private set; }

        [InputArgument]
        public string InputArgument1 { get; set; }

        #endregion

        #region Methods Overrides

        public override void Execute(ActionContext context)
        {



            try
            {
                //TODO: add action execution code here
            }
            catch (Exception e)
            {
                if (e is ActionException) throw;

                throw new ActionException("ActionError", e.Message, 
e.InnerException);
            }
        }

        #endregion
    }
}

Notice the Result boolean variable.

The If file exists action doesn't have an output argument. What it returns is either true
or false, depending on what the boolean variable Result holds.

Custom action selectors
There are particular cases, in which a custom action might be required to have more
than one variation.

An example is the "Launch Excel" action, from the standard library of actions.

Using the "with a blank document" selector, the flow launches a blank Excel document,
whereas using the "and open the following document" selection requires the file path of
the file to open.



The two actions mentioned above are two selectors of the "Launch Excel" base action.

When creating custom actions, you don't have to rewrite functionality.

You can create a single "base" Action, setting its input and output parameters and then
choose what would be visible in each flavor by utilizing action selectors.

Through action selectors a level of abstraction can be added over a single action,
allowing for the retrieval of specific functionality from the single "base" action without
having to rewrite code to form a new variation of the same action every time.

Think of selectors as choices, filtering a single action and presenting only the
information required according to the respective selectors.



To form a new action selector, first create a base action to be utilized by the selectors.

The central action requires either a boolean or an enum property as an input C#
argument.

The value of this property determines which selector is utilized.

The most common way is using an enum. Especially when more than two selectors are
needed, enums is the only option.

For two selector cases, booleans can be used.

This property, also known as a constraint argument, must have a default value.

The central action is declared as a classic action.

Notice the first property (input argument) is an enum. Based on that property's value,
the appropriate selector becomes active.

７ Note

To have the arguments ordered in your desired manner, you set the Order value
next to the InputArgument attribute.

C#

using System.ComponentModel;
using Microsoft.PowerPlatform.PowerAutomate.Desktop.Desktop.Actions.SDK;
using 
Microsoft.PowerPlatform.PowerAutomate.Desktop.Desktop.Actions.SDK.Attributes
;



namespace Modules.CustomModule
{
    [Action(Id = "CentralCustomAction")]
    public  class CentralCustomAction : ActionBase
    {
        #region Properties

        [InputArgument, DefaultValue(SelectorChoice.Selector1)]
        public SelectorChoice Selector { get; set; }

        [InputArgument(Order = 1)]
        public string FirstName { get; set; }

        [InputArgument(Order = 2)]
        public string LastName { get; set; }

        [InputArgument(Order = 3)]
        public int Age { get; set; }

        [OutputArgument]
        public string DisplayedMessage { get; set; }

        #endregion

        #region Methods Overrides

        public override void Execute(ActionContext context)
        {
            if (Selector == SelectorChoice.Selector1)
            {
                DisplayedMessage = $"Hello, {FirstName}!";
            }
            else if (Selector == SelectorChoice.Selector2)
            {
                DisplayedMessage = $"Hello, {FirstName} {LastName}!";
            }
            else // The 3rd Selector was chosen 
            {
                DisplayedMessage = $"Hello, {FirstName} {LastName}!\nYour 
age is: {Age}";
            }
        }

        #endregion
    } // you can see below how to implement an action selector
}

Custom action selectors using enums
In this example, you create three selectors. A simple enum dictates the appropriate
selector each time:



C#

public enum SelectorChoice
{
    Selector1,
    Selector2,
    Selector3
}

Selectors are represented by classes.

Those classes must inherit the ActionSelector<TBaseActionClass>  class.

７ Note

TBaseActionClass is the base action class name.

In the UseName() method, the name of the action selector is declared. This is used as a
name of the action to resolve the resources.

C#

public class Selector1 : ActionSelector<CentralCustomAction>
{
    public Selector1()
    {
        UseName("DisplayOnlyFirstName");
        Prop(p => p.Selector).ShouldBe(SelectorChoice.Selector1);
        ShowAll();
        Hide(p => p.LastName);
        Hide(p => p.Age);
        // or 
        // Show(p => p.FirstName); 
        // Show(p => p.DisplayedMessage);
    }
}

７ Note

The Selector classes should not be declared as actions. The only action is the
central one. Selectors act as filters.

In this specific example we want to display only one of the arguments, thus the others
are filtered out. Similarly for Selector2:



C#

public class Selector2 : ActionSelector<CentralCustomAction>
{
    public Selector2()
    {
        UseName("DisplayFullName");
        Prop(p => p.Selector).ShouldBe(SelectorChoice.Selector2);
        ShowAll();
        Hide(p => p.Age);
    }
}

And Selector3 classes:

C#

public class Selector3 : ActionSelector<CentralCustomAction>
{
    public Selector3()
    {
        UseName("DisplayFullDetails");
        Prop(p => p.Selector).ShouldBe(SelectorChoice.Selector3);
        ShowAll();
    }
}

The final execution is achieved through the Execute(ActionContext context) method
that resides in the central action. Based on the selector, the respective values filtered are
displayed.

C#

public override void Execute(ActionContext context)
{
    if (Selector == SelectorChoice.Selector1)
    {
        DisplayedMessage = $"Hello, {FirstName}!";
    }
    else if (Selector == SelectorChoice.Selector2)
    {
        DisplayedMessage = $"Hello, {FirstName} {LastName}!";
    }
    else // The 3rd Selector was chosen 
    {
        DisplayedMessage = $"Hello, {FirstName} {LastName}!\nYour age is: 
{Age}";
    }
}



Custom action selectors using boolean
The following is an example utilizing Boolean instead of enums.

C#

using System.ComponentModel;
using Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK;
using 
Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK.ActionSelectors;
using Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK.Attributes;

namespace Modules.CustomModule
{
    [Action]
    public class CentralCustomActionWithBoolean : ActionBase
    {
        #region Properties

        [InputArgument, DefaultValue(true)]
        public bool TimeExpired { get; set; }

        [InputArgument]
        public string ElapsedTime { get; set; }

        [InputArgument]
        public string RemainingTime { get; set; }

        [OutputArgument]
        public string DisplayedMessage { get; set; }

        #endregion

        #region Methods Overrides

        public override void Execute(ActionContext context)
        {
            DisplayedMessage = TimeExpired ? $"The timer has expired. 
Elapsed time: {ElapsedTime}" : $"Remaining time: {RemainingTime}";
        }

        #endregion
    }

    public class NoTime : ActionSelector<CentralCustomActionWithBoolean>
    {
        public NoTime()
        {
            UseName("TimeHasExpired");
            Prop(p => p.TimeExpired).ShouldBe(true);
            ShowAll();
            Hide(p => p.RemainingTime);
        }



    }

    public class ThereIsTime : 
ActionSelector<CentralCustomActionWithBoolean>
    {
        public ThereIsTime()
        {
            UseName("TimeHasNotExpired");
            Prop(p => p.TimeExpired).ShouldBe(false);
            ShowAll();
            Hide(p => p.RemainingTime);
        }
    }
}

Setting descriptions for custom action selectors
To create a description and a summary for selectors, use the following format in the .resx
file of your custom module.

SelectorName_Description
SelectorName_Summary

This can also be done in the selector with the WithDescription and WithSummary
methods.

） Important

.dll files describing the custom actions, their .dll dependencies and the .cab file
containing everything should be properly signed with a digital certificate trusted by
your organization. The certificate should also be installed on each machine on
which a desktop flow with custom action dependencies is authored/ modified/
executed, present under the Trusted Root Certification Authorities.

Custom module IDs
Each module has its own ID (assembly name). When creating custom modules make
sure you set unique module IDs. To set the assembly name of your module, modify the
Assembly name property under the General section of the C# project's properties.

２ Warning



Including modules with the same ID in a flow will result in conflicts

Custom module name conventions
For the custom modules to be readable through Power Automate for desktop, the
AssemblyName must have a filename that follows the below pattern:

?*.Modules.?*
Modules.?*

For example, Modules.ContosoActions.dll

The AssemblyTitle in the project settings specifies the module ID. It can only have
alphanumeric characters and underscores and must begin with a letter.

Sign all DLLs inside the custom module
） Important

It is mandatory to have all of the .dll files tha comprise a custom module
(generated assembly and all its dependencies) signed with a trusted certificate

To finalize the creation of the custom module, all generated .dll files, which can be found
under the bin/release or bin/Debug folder of the project, must be signed.

Sign all the .dll files using a trusted certificate by running the following command (for
each .dll file) in a Developer Command Prompt for Visual Studio:

Sign the .dlls files using a trusted certificate by running the following command (for
each dll) in a Developer Command Prompt for Visual Studio:

Signtool sign /f {your certificate name}.pfx /p {your password for exporting 
the certificate} /fd 
SHA256 {path to the .dll you want to sign}.dll

or by running the following command (by creating a Windows PowerShell Script .ps1)
that iterates through all .dll files and sign each one with the provided certificate:



PowerShell

Get-ChildItem {the folder where dll files of custom module exist} -Filter 
*.dll | 
Foreach-Object {

Signtool sign /f {your certificate name}.pfx /p {your password for 
exporting the certificate} /fd SHA256 $_.FullName
}

７ Note

The digital certificate must have an exportable private key and code sign
capabilities

Packaging everything in a cabinet file
The .dll containing the custom actions and all its dependencies (.dll files) must be
packaged in a cabinet file (.cab).

７ Note

When naming the .cab file, follow the file and folder naming convention for
Windows operating system. Don't use blank spaces or special characters such as <
> : " / \ | ? * .

Create a Windows PowerShell Script (.ps1) containing the following lines:

PowerShell

param(

    [ValidateScript({Test-Path $_ -PathType Container})]
[string]
$sourceDir,

[ValidateScript({Test-Path $_ -PathType Container})]
    [string]
    $cabOutputDir,

    [string]
    $cabFilename
)

$ddf = ".OPTION EXPLICIT
.Set CabinetName1=$cabFilename



.Set DiskDirectory1=$cabOutputDir

.Set CompressionType=LZX

.Set Cabinet=on

.Set Compress=on

.Set CabinetFileCountThreshold=0

.Set FolderFileCountThreshold=0

.Set FolderSizeThreshold=0

.Set MaxCabinetSize=0

.Set MaxDiskFileCount=0

.Set MaxDiskSize=0
"
$ddfpath = ($env:TEMP + "\customModule.ddf")
$sourceDirLength = $sourceDir.Length;
$ddf += (Get-ChildItem $sourceDir -Filter "*.dll" | Where-Object { 
(!$_.PSIsContainer) -and ($_.Name -ne 
"Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK.dll") } | Select-
Object -ExpandProperty FullName | ForEach-Object { '"' + $_ + '" "' + 
($_.Substring($sourceDirLength)) + '"' }) -join "`r`n"
$ddf | Out-File -Encoding UTF8 $ddfpath
makecab.exe /F $ddfpath
Remove-Item $ddfpath

This Windows PowerShell Script can then be used for creating the .cab file by invoking it
in Windows PowerShell and providing:

The directory to the .dll files to be compressed.
The target directory to place the generated .cab file.

Invoke the script using the following syntax:

PowerShell

.\{name of script containing the .cab compression directions}.ps1 "{absolute 
path  to the source directory containing the .dll files}" "{target dir to 
save cab}" {cabName}.cab

Example:

PowerShell

.\makeCabFile.ps1 
"C:\Users\Username\source\repos\MyCustomModule\bin\Release\net472" 
"C:\Users\Username\MyCustomActions" MyCustomActions.cab

７ Note

Make sure that the the actual custom actions .dll file is in the root level of the
targetted path when creating the .cab file and not in a subfolder.



The .cab file must also be signed. Unsigned .cab files and/or unsigned .dlls
contained in them will not be usable in desktop flows and will result in error
during inclusion.

Next steps
Upload custom actions

Related information
Assets library
Use custom actions
Custom actions

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Uploading custom actions to an
environment
Article • 10/19/2023

This article explains how to upload custom actions to an environment.

Prerequisites
Ensure that you have the following permissions to upload a custom actions group to an
environment.

You have access to the Power Platform environment.
You're assigned Desktop Flow Module Developer role in the Power Platform
admin center .
This feature requires Power Automate for desktop v2.32 or later.

Upload custom actions
1. Go to Power Automate .

2. Select Custom actions under Data.

3. Select Upload custom action from the top of the screen.



4. Enter the required details for your custom actions group.

ﾉ Expand table

Name Required or Description
optional

Name Required This is how your custom actions group name appears in the
custom actions list, assets library, and if included in a
desktop flow, in the actions tree.

Description Optional A brief description of the custom actions. This information is
visible in the asset library, when the custom actions group is
selected.

Select file Required Select the signed .cab file containing the custom actions
group developed with the custom actions SDK, and any
dependent .dll files if applicable.



5. Select Upload.



The newly uploaded custom actions group appears in the list.

By selecting the uploaded custom actions group, you can go into its details page.

From here, you can perform the following actions.

Edit custom actions
Edit the uploaded custom actions, modifying its name and/or description.

Share custom actions
Share custom actions to allow managing who has access to the custom actions
uploaded and view the given type of access.

There are three types of access a maker can have regarding custom actions.



User - can only use the respective custom actions in desktop flows.
User + Share – can use and share the custom actions.
Co-owner – can also update/delete the custom actions.

） Important

To be a co-owner, you have to be assigned the Desktop Flow Module Developer
role in the environment.

Update file
Only co-owners can update a file. Update files when you want to update existing custom
actions by uploading a .cab file.

Update file (Co-owners only) for when you want to update the existing custom actions
etc. by uploading a .cab file.



Delete file
Only co-owners can delete custom actions. Deleting a custom actions group causes all
dependent desktop flows to fail.

Next steps
Use custom actions

Related information
Assets library
Create custom actions
Custom actions

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Using custom actions in desktop flows
Article • 07/26/2024

７ Note

An Attended RPA license is required to include and use custom actions in desktop
flows.

） Important

Ensure the .dll files describing Custom actions, their dependency .dll files, and
the .cab files are properly signed with a digital certificate trusted by your
organization. The certificate should also be installed on the device under the
trusted root certificate authority where the desktop flow with custom action
dependencies is modified and/or executed.

You can include custom actions in desktop flows through the Assets library using Power
Automate for desktop's designer.

To use Assets library, select Assets library in the designer.

Alternatively, use the Tools bar.



） Important

This feature requires Power Automate for desktop v2.32 or later.

Custom actions tab
Custom actions tab shows you the custom actions uploaded in the environment you've
selected.

７ Note

You can only see custom actions shared with you.



After you complete the custom action inclusion and close the asset library, the custom
actions will be listed at the bottom of the Actions tree under the Custom Actions
section.



To include a custom action in a desktop flow, drag and drop or double-click on it.



Related information
Assets library
Upload custom actions
Create custom actions
Custom actions

Feedback
Was this page helpful?  Yes  No

Provide product feedback



How to build custom actions in Power
Automate for desktop
Article • 11/30/2023

Enhance productivity, reusability, and extensibility with custom actions in Power
Automate for desktop. This article discusses how custom actions in Power Automate for
desktop can help makers create their own reusable actions that can be used across
multiple flows. Makers create custom actions by composing a sequence of steps or
functions into a new action. Custom actions are created using the Power Automate for
desktop actions SDK, which provides a set of APIs that allow makers to create custom
actions using .NET language C#. Custom actions can also be shared with other users
through the custom actions section in Power Automate (make.powerautomate.com). In
this article, find detailed walkthroughs of how to create, build, deploy, use, and update
custom actions.

） Important

While the essential features utilized in creating custom actions are supported, the
provided solutions, assets, and sample scripts mentioned here serve as an example
implementation of these features and don't include support.

Overview
Custom actions capability in Power Automate for desktop allows you to create your own
reusable actions that can be used across multiple desktop flows. Custom actions save
you time and effort by allowing you to reuse complex or frequently used actions without
having to re-create them each time you build a new flow. Makers can apply their
existing skills and knowledge to create custom actions that integrate with other systems
and services. Additionally, pro-developers can wrap the existing functions or code
libraries to make a new custom action that results in increased reusability of
organizational assets.

You create custom actions by composing a sequence of methods or functions into a
new action. Once you create a custom action, use it in any desktop flow by dragging
and dropping it onto the Power Automate desktop designer canvas.

Custom actions can be shared with other users through the custom actions section in
Power Automate, which provides a central repository for sharing and discovering
custom actions. This means that users can benefit from the expertise and knowledge of



others in the organization and can easily find and use custom actions created by other
makers.

Overall, custom actions in Power Automate for desktop provide a powerful way to
extend the functionality of the product, streamline the flow-building process, and foster
collaboration and innovation within the organization.

Prerequisites
Latest version of Power Automate for desktop – Install Power Automate
C# authoring tool such as Visual Studio Community/Professional/Enterprise
2022  with the .NET desktop development workload
Custom actions SDK – NuGet Gallery |
Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK
Digital certificate:

Generate a self-signed certificate – Generate Self-Signed Certificates Overview –
.NET
Enterprise deployment – Your organization’s trusted certificate from certificate
authority – Digital signatures and certificates – Office Support

SignTool:
Using SignTool to sign a file – Win32 apps
SignTool

Windows PowerShell Script (.ps1) – Create custom actions – Power Automate

Create your own custom action
1. Open Visual Studio to create a new project using template of Class Library (.NET

Framework).



2. Configure your new project with a project name, file location, and set the
Framework as .NET Framework 4.7.2.



７ Note

Make sure to follow the naming conventions. More information: Custom
module name conventions



3. In Visual Studio, select Tools > NuGet Package Manager > Package Manager
console.





4. Open a PowerShell window and install NuGet package
PowerAutomate.Desktop.Actions.SDK using this PowerShell command.

PowerShell

Find-Package Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK
NuGet\Install-Package 
Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK

5. Follow the steps in Create custom actions to create the Class file for your custom
action.

Information you can use as reference for your
action
Reference solution archive: .NET Module Solution

Action: Write a message to a local file.

Input parameters: File name, message to write to the file.

Output parameters: Status code – true if successful and false if not successful.

Class Definition:

C#



using System;
using System.IO;
using Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK;
using Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK.Attributes;

namespace ModulesLogEvent
{
    [Action(Id = "LogEventToFile" , Order = 1, Category = "Logging")]
    [Throws("LogEventError")]
    public class LogEventToFile : ActionBase
    { 
        [InputArgument]
        public string LogFileName { get; set; }

        [InputArgument]
        public string LogMessage { get; set; }

        [OutputArgument]
        public bool StatusCode { get; set; }
    
        public override void Execute(ActionContext context)
        {
            try
            {           
                    // To append all of the text to the file
                    File.AppendAllText(LogFileName, LogMessage);
                    StatusCode = true;  
            }
            catch (Exception e)
            {
                if (e is ActionException) throw;

                throw new ActionException("LogEventError", e.Message, 
e.InnerException);
            }
        }
    }
}

Resources
This table lists the descriptions and friendly names for parameters in a Resources.resx file.

ﾉ Expand table

Name Value Comment

LogEventToFile_Description Custom action to log message Action description
to the supplied file



Name Value Comment

LogEventToFile_FriendlyName LogEventToFile Action name

LogEventToFile_LogFileName_Description Input parameter of text type Action input
description

LogEventToFile_LogFileName_FriendlyName LogFileName Action input name

LogEventToFile_LogMessage_Description Input parameter of text type Action input
description

LogEventToFile_LogMessage_FriendlyName LogMessage Action input name

LogEventToFile_StatusCode_Description Output parameter of boolean Action output
type description

LogEventToFile_StatusCode_FriendlyName LogMessage Action
outputName

ModulesLogEvent_Description Module to manage log events Module
description

ModulesLogEvent_FriendlyName LogEvent Module name

Build the package and deploy your custom
action
Create the package and deploy to Power Automate.

1. Acquire the digital certificate so the custom action DLL file can be signed.

） Important

Self-signed certificates are only for test purposes and aren't recommended for
production use. For organizational deployment of custom actions in your
environment, we recommend you use a trusted digital certificate that follows
your organizational guidelines.

 Tip

To streamline the process of developing and using custom actions for Power
Automate for desktop across your organization, you can bundle a trusted
digital certificate with the Power Automate for desktop installer that is
distributed through SCCM/Appstore. > This will enable the certificate to be



installed automatically on both makers and unattended runtime machines
that require Power Automate for desktop, without any need for additional
actions.

For this example, a self-signed certificate is used.

a. Create a self-signed certificate using this script.

PowerShell

$certPFXFileName="C:\PADCustomAction\PADCustomActionCert.pfx";
$certCERFileName="C:\PADCustomAction\PADCustomActionCert.cer";
$certStoreLocation="Cert:\LocalMachine\AuthRoot";
$certname = "PADCustomActionSelfSignCert"
##Create certificate
$cert = New-SelfSignedCertificate -CertStoreLocation 
Cert:\CurrentUser\My -Type CodeSigningCert  -Subject "CN=$certname" 
-KeyExportPolicy Exportable -KeySpec Signature -KeyLength 2048 -
KeyAlgorithm RSA -HashAlgorithm SHA256
$mypwd = ConvertTo-SecureString -String <YOUR CERT PASSWORD GOES 
HERE> -Force -AsPlainText
##Export certificate
$certPFXFile = Export-PfxCertificate -Cert $cert -FilePath 
$certPFXFileName -Password $mypwd
$certCERFile = Export-Certificate -Cert $cert -FilePath 
$certCERFileName -Type CERT -Verbose -Force

b. Import the certificate into certificate store using this command.

PowerShell

##Import certificate
Import-Certificate -CertStoreLocation $certStoreLocation -FilePath 
$certCERFile

c. Validate that the imported certificate appears under Trusted Root Certification
Authorities > Certificates in Certificates Microsoft Manager Console (MMC)
snap-in.

2. Finalize the custom module created by signing the DLL file using a trusted
certificate. Use Visual Studio’s developer command prompt to use the Signtool for
this activity.

PowerShell

Signtool sign /f "C:/PADActions/PADCustomActionCert.pfx" /p 
<YOURCERTPASSWORD> /fd SHA256 



"C:/PADActions/PADCustomActionEventLog/Modules.LogEvent.dll"

3. To deploy the custom action, build the package the contents into a cabinet file
(.cab) by using this PowerShell script.

PowerShell

.\BuildCAB.ps1 "C:/PADActions/PADCustomActionEventLog" 
"C:/PADActions/PADCustomActionEventLog" PADCustomActionEventLog.cab

Go to the sample script file BuildCAB.ps1

4. Sign the generated cabinet file using Signtool.

PowerShell

Signtool sign /f "C:/PADActions/PADCustomActionCert.pfx" /p 
<YOURCERTPASSWORD> /fd SHA256 
"C:/PADActions/PADCustomActionEventLog/PADCustomActionEventLog.cab"

5. Go to the Power Automate custom action section to upload the custom action that
you created. Provide the name, description, and cabinet file and then select
Upload.



You receive a notification when the action is successfully uploaded.



Following these steps, the custom action module is packaged into a cabinet file and
signed with a trusted certificate. Additionally, the custom action cabinet file is uploaded
to the custom action library in Power Automate.

More information: Upload custom actions

Use your custom action activity in desktop flow
using Power Automate for desktop

1. Create a new desktop flow, and then select the Assets Library in the designer.



2. Inspect the custom action available in the assets library. Notice the action
previously created and uploaded to the custom actions section of Power
Automate.

Select Add to add this custom action to the Actions section of the designer.



3. Validate that the custom action is added successfully. Search for it on the Actions
search bar in Power Automate for desktop's designer.





4. Drag the custom action or double-click it to add to the desktop flow.

5. Provide the input parameters and additional steps to test the custom action.



Sample desktop flow using the custom action.





6. Test the flow to see the custom action working in real time.

７ Note

Import the certificate used to sign the cabinet file to the machine used to build
desktop flows with custom actions and to each of the runtime machines that will
run the desktop flows.

Following these steps, a custom action was created, the module packaged into a cabinet
file, signed with a trusted certificate, uploaded to the custom action library in Power
Automate, a desktop flow to use the custom action created and tested for a successful
run.



Update and redeploy the custom action
Update the functionality of the custom action to reflect the updated capability by
following these steps.

1. Update the class file in Visual Studio solution with new action functionality. More
information: Updated .NET Module solution

Modified the signature of the class file to take in a third input parameter as shown.

C#

using System;
using System.IO;
using Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK;
using 
Microsoft.PowerPlatform.PowerAutomate.Desktop.Actions.SDK.Attributes;

namespace ModulesLogEvent
{
 [Action(Id = "LogEventToFile" , Order = 1, Category = "Logging")]
 [Throws("LogEventError")]
 public class LogEventToFile : ActionBase
 { 
     [InputArgument]
     public string LogFileName { get; set; }

     [InputArgument]
     public string LogMessage { get; set; }

     [InputArgument]
     public string LogLevel { get; set; }

     [OutputArgument]
     public bool StatusCode { get; set; }

     public override void Execute(ActionContext context)
     {
         try
         {
                 // To append all of the text to the file
                 File.AppendAllText(LogFileName, LogLevel + ": " + 
LogMessage);
                 StatusCode = true;
         }
         catch (Exception e)
         {
             if (e is ActionException) throw;

             throw new ActionException("LogEventError", e.Message, 
e.InnerException);
         }



     }
  }
}

2. Use similar steps described earlier where you sign the DLL file, create the cabinet
file, sign the cabinet file, and upload the cabinet file to custom actions section in
Power Automate. More information: Build the package and deploy your custom
action

７ Note

Before uploading the updated custom action cabinet file, make sure to
analyze the impact of this change as desktop flows with this action will be
updated with new capabilities.



3. Update the desktop flow as required.

To validate the update capability, we added a third input parameter to the custom
action. Notice that custom action activity is marked as Error in the designer, and it
needs to be updated with new input parameter.







4. Test the flow to see the updated custom action working in real time.



In this section, you updated the underlying functionality of the custom action, built the
package, deployed to Power Automate, refactored the desktop flow, and validated the
functionality by running the desktop flow with updated capabilities of the custom action
in Power Automate for desktop.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



UI elements collections in desktop flows
Article • 03/12/2025

UI elements collections that organization users develop and publish to the respective
environments can be included in desktop flows.

In Power Automate for desktop, UI elements are elements that are grabbed and
captured from the various user interfaces (either desktop applications or web pages).
These elements can be text fields, buttons, links, or anything else that you can interact
with in the target applications.

After these elements are captured, they can be associated with the respective UI or web
automation actions, so that the corresponding interaction with the elements can be
automated in the context of desktop flows.

Previously, UI elements were only available separately to each desktop flow. This means
that they needed to be captured individually in the context of each desktop flow built,
even if the elements happened to be exactly the same among multiple desktop flows. To
avoid this, UI elements collections now offer makers and admins the ability to have
control and central management over "groups" of UI elements, which can be shared
across multiple users and imported in multiple desktop flows as reusable components.
In this way, in case of an application update for instance, the UI elements collection only
needs a one-time adjustment - all desktop flows referencing this collection in the same
environment should then reflect that change automatically.

７ Note

UI elements collections exist at the environment level and are stored in the
Desktop Flow Module Dataverse table. As a best practice, use a "dev—test—
prod" model when deploying UI elements collections.
To add a UI elements collection to a solution, go to your solution and then
select Add existing > More > Other > Desktop Flow Module >
your_collection. This action adds the collection and all its dependencies.
If your solution contains a desktop flow that references a UI elements
collection, select the desktop flow and then select Advanced > Add required
objects to add all dependent components, including the UI elements
collection and its dependencies, to the Solution.



Prerequisites
Power Automate for desktop 2.43 or later.
This feature requires an environment where the Power Automate v2 schema is
enabled. In v1 schema environments, UI elements collections aren't available.
An Attended RPA license is required to include and use UI elements collections in
desktop flows, given that access to the flow designer of Power Automate for
desktop is needed.
If you use custom security roles to manage access, Power Platform admins need to
update the role to include read permission for the Desktop Flow Module table
( prvReaddesktopflowmodule ).

Known limitations
Upload date might differ in the portal than what is shown in the Assets library
inside Power Automate for desktop.

Next steps
Create and publish UI elements collections

Related information
Assets library
Manage UI elements collections
Use and update UI elements collections

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create and publish UI elements
collections in desktop flows
Article • 10/14/2024

Creating and publishing a UI elements collection is possible through the flow designer
of any desktop flow, existing or new. In the UI elements pane, there are now two
different tabs available, Flow repository and Collections.

The Flow repository tab contains all the UI elements that are available only to that
particular desktop flow. Desktop flows created using version 2.42 or earlier, which



include UI elements, show these elements within the Flow repository tab after upgrading
to version 2.43 or higher, if these flows are part of a schema v2 environment.

７ Note

The UI elements collections is a premium feature, available only to organization
premium or trial users. Users with a work or school account or a free Microsoft
account do not have access to UI elements collections.

To create a new collection of UI elements, the UI elements need to be captured first in
the desktop flow, added by default under the Flow repository tab. The tree structure
here remains the same. The desktop where the elements were captured appears on top,
followed by the web pages or desktop application screens containing the elements,
followed by the individual UI elements themselves.

７ Note

Any new UI element that is captured via the button Add UI element is
automatically added under the Flow repository tab. You can't add a new UI element
directly into a collection.

Marking multiple UI elements as checked
Every item in this tree structure comes with a checkbox, which is checked when that item
is selected. Selecting a desktop such as Local computer also checks all its contained
screens/web pages and UI elements. Similarly, selecting a screen or web page also
checks all its related UI elements. This works in the opposite way as well. Checking all
the UI elements under a screen/web page also checks the latter. The same behavior
applies to screens/web pages and their desktop respectively.

There can only be one selected (highlighted) item at a time, even if more items are
checked (either automatically when these items are related to the selected one in the
elements structure, or manually when multiple items are checked directly via their
checkbox). In the context menu of a selected item, the options 'Edit', 'Rename', 'Find
usages' and 'Delete' are individual and apply only to the selected item. However, if
more, unrelated items are checked, these options are disabled to prevent any ambiguity
regarding which item they target.



Publish a new UI elements collection
After you check the UI elements you need to include in a new collection, you can select
the option Publish as new collection. This can be done through the main context menu
located at the upper right of the UI elements pane or by using the context menu for the
currently active (highlighted) element.



７ Note

The collection related options in the items' context menus apply to all checked UI
elements and screens/web pages.

） Important

If you check screens/web pages and UI elements that belong to different desktops
at the same time, the option Publish as new collection is disabled. To create a new



collection, all its UI elements need to be captured in the same desktop (Local
computer, RDP, or Citrix).

Selecting this option opens a confirmation dialog, where you can provide a name for the
new collection. If you associated any or all of the selected UI elements with UI or web
automation actions in your desktop flow, you can also check the 'Auto-update' option
below the collection name field. This automatically updates the related actions, ensuring
they reference the newly established counterparts in the collection, rather than the UI
elements previously accessible only within this flow.

When you select Publish, the popup dialog enters a Publishing state, during which the
collection is saved and uploaded in Dataverse to become available in the specific
environment. While publishing takes place, the UI of the dialog remains disabled. If the
same name of another existing collection is used, an error occurs and you have to
provide a new one.

When the collection is successfully published in this way, a corresponding success
banner appears in the UI elements pane to inform you accordingly. In addition, if you
look at the Collections tab, that collection is now automatically imported into this flow
from which it was created. More precisely, it's imported by default into the same
desktop (for instance Local computer or Remote desktop) in which the collection's UI
elements were originally captured. This step is automatically completed for you, so you
don't have to manually import each new collection you create into the same flow it was
generated from.



７ Note

Picking some UI elements to create a new collection effectively copies (rather than
moving) those elements from the context of a single flow to the collection entity,
which can then be shared and reused in other flows. While the new collection now
appears in the Collections tab, the flow's original UI elements are also still available
in the Flow repository tab. If the latter are no longer needed and used in the
current flow, you can always use the option Remove unused UI elements in the UI
elements pane's main context menu.



） Important

A collection can only include screens/web pages and their UI elements, not the
desktop in which they were captured. This accommodates using the same
collection for a target application, independently of whether it's installed in the
local computer for some makers, or in a remote desktop for others. The collection
would be imported under the proper desktop in each maker's separate flow.

In the Collections tab, as shown in the prior screenshot, the tree structure of the items
therein now consists of four levels:

The desktop in which the collection is imported
The imported collection
The screens/web pages included in the collection
The UI elements included in the collection

７ Note

If needed, you can check multiple UI elements of one or more collections in the
Collections tab to create and publish yet another, new collection, following the
same steps that were explained earlier. In this scenario, auto-updating will still
adjust any affected actions, so they reference the UI elements of the new collection
instead of the existing one(s).

After you publish a new collection, the desktop flow needs to be saved to confirm the
import of that collection, as this is considered an unsaved change for the flow. However,
even if the flow isn't saved, the collection still remains published and available in the
environment, so that it can be used in other flows.

Known limitations
When selected to create a new collection, individual screens and web pages always
carry over their child UI elements with them, as the latter are automatically
checked.

Next steps
Manage UI elements collections



Related information
Assets library
Use and update UI elements collections
UI elements collections

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Manage UI elements collections in
desktop flows
Article • 10/04/2024

After you publish a UI elements collection through the flow designer of a desktop flow,
that collection is uploaded in Dataverse in the same environment where the flow exists.

Portal page of UI elements collections
To inspect this collection, and the list of any other collections that are available to you in
this environment, you can:

1. Go to Power Automate .

2. Select More in the navigation list on the left, then hit the button Discover all.



3. Select UI elements collections under Data. You can optionally pin this option, so
that it remains visible in the left navigation pane.



This is the page containing all the collections that are accessible to you. You can hit on
the Refresh button at the top, to quickly retrieve any recent changes and update your
collections list. By selecting one of the available UI elements collections, you can go into
its details page.



For each collection, you can perform the following actions.

Edit a UI elements collection
Only owners and co-owners can edit collections. You can edit a UI elements collection,
modifying its name and/or description.

Share a UI elements collection
You can share UI elements collections to provide access to those collections and
determine the given type of access.

There are three types of access a maker can have regarding UI elements collections.

User – can only use the respective collection in desktop flows.
User + Share – can use, but also share the collection.
Co-owner – can use, share, update and/or delete the collection.



Delete a UI elements collection
Only owners and co-owners can delete collections. Deleting a collection isn't possible, if
that collection is already imported and used in one or more desktop flows. You need to
remove it from any flows before you can delete it.

Create a copy of a UI elements collection
Quickly create a copy of a collection by selecting the option Save as. This option allows
you to create a duplicate collection, which you can also rename.

７ Note



Power Automate for desktop version 2.45 or greater is required to properly import
collections that have been created in this way (copied from other collections).

Next steps
Use and update UI elements collections

Related information
Assets library
Create and publish UI elements collections
UI elements collections

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Use and update UI elements collections
Article • 10/04/2024

You can include UI elements collections in desktop flows through the Assets library
using Power Automate for desktop's designer.

To open the Assets library, select Assets library in the designer.

Alternatively, use the Tools bar.

You can also use the option Import collection, found in the context menu at the top
right of the UI elements pane.



Import collections
The UI elements collections tab shows you the collections that are published in the
environment you select and are accessible to you.

７ Note

You can only see UI elements collections that you have created or are shared with
you. The list of collections in the respective Assets library tab is identical to the list
available in the portal page for each maker.



After selecting the collection you want to add to your flow, you also need to select a
specific desktop under which the collection will be imported. This determines which
desktop the collection's UI elements are searched when the flow runs.

７ Note

The list of available desktops includes the local computer, the RDP and/or
Citrix desktops that may have already been added in the Flow repository tab,
as well as any currently active RDP and/or Citrix connections in your machine.



Each collection can only be imported into one target desktop per flow.

After you complete the collection inclusion and close the assets library, the collection
will now appear in the Collections tab of the UI elements pane, imported under the
desktop that was previously selected.

Remove collections
After being added to a flow, a collection can similarly be removed through the Assets
library. All added collections are tagged accordingly, so you can select the option



Remove that is available for those collections, to remove them from the flow. In this
way, the UI elements they contain are no longer available in that flow.

） Important

Removing a collection from a flow doesn't delete the collection from the
environment. You can only permanently delete a collection through the UI elements
collections' dedicated portal page.

７ Note

If a collection is removed from a flow while any of its UI elements are already used
in the flow's actions, those actions will throw an error and will need to be fixed.

Use UI elements collections in the actions of a
flow
After a collection is imported and becomes available in a desktop flow, the UI elements
it contains can be used in the UI and web automation actions of that flow. In the
corresponding action modals, in the field where the action's associated UI element is
specified, you can now find the same two tabs of the UI elements pane, Flow repository
and Collections. Under the Collections tab, you can use any UI element you need that
belongs to an imported collection.



Edit a UI elements collection
After creating and publishing a collection, it can be shared with other users so that it's
imported and used in multiple flows. However, the application that the collection targets
may eventually undergo an update, which could lead to the need to update the CSS/UI
selectors of the UI elements that belong to that collection. Similarly, you may need to
add more UI elements to an existing collection, or remove some obsolete elements that
are no longer needed.

To make any required adjustments to a collection, that collection needs to be imported
to a desktop flow, so that you can access the collection's contents in the flow designer.
In addition, you need to be an Owner or have at least Co-owner rights on that
collection to be able to modify it.

The methods to edit and update a collection include the following:

Add more UI elements to an imported collection



When you want to add new UI elements to a collection, you have to normally capture
them first, if they aren't already available in the flow via the UI elements pane. You then
need to mark those elements as checked through their checkbox in the tree structure,
and then select the option Add to imported collection, either via the main context
menu at the top right of the UI elements pane, or through the context menu of the
currently selected (highlighted) element that should be included in the checked ones.

Selecting this option brings up a confirmation dialog, where you need to choose the
target collection to which the elements should be added. The respective dropdown field
lists all the eligible collections for this action, based on the following criteria:

The target collection is already imported into this flow.



All the checked UI elements, and the target collection, belong to the same desktop
in the tree structure of the UI elements pane.

Additionally, if you associated any or all of the selected UI elements with UI or web
automation actions in your desktop flow, you can check the 'Auto-update' option below
the dropdown field. Doing so automatically updates the specified actions for you, so
they no longer reference the UI elements that are only 'locally' available in this flow, but
rather their newly added equivalents that are part of the target collection.

） Important

You can't add UI elements to an existing collection that is not imported in the flow
you are working on. If no collection is imported or meets the required criteria
previously mentioned for a certain selection of UI elements, the option Add to
imported collection is disabled.

７ Note

You can add UI elements to an imported collection by making a selection either
from the Flow repository tab or the Collections tab. In the second scenario, you can
add UI elements from one collection to another, or even add duplicates to the
same collection if needed.

Adding some UI elements to a collection doesn't automatically update that collection
with the new changes. For more information, see Update a UI elements collection.



Edit or rename the UI elements of a collection
Editing a UI element that belongs to a collection is identical to editing any other UI
element found in the Flow repository tab. In the Collections tab, select and highlight the
UI element whose CSS/UI selectors you want to edit, then double click on it, press
'Enter', or select the option Edit in its context menu. This opens the selectors screen for
that UI element, where you can proceed to the necessary changes to the selectors, and
even Repair or Test them through the corresponding options.

Similarly, you can rename a UI element belonging to a collection, by pressing 'F2' or
selecting the option Rename in its context menu.

７ Note

In the context menu of a selected (highlighted) item, the options Edit and Rename
are individual and apply only to that item. However, these options become
disabled, if other unrelated items also happen to be checked, to avoid any potential
confusion around the item they target.

Editing or renaming UI elements in a collection doesn't automatically update that
collection with the new changes. For more information, see Update a UI elements
collection.

Delete UI elements from a collection
Deleting a UI element that belongs to a collection is identical to deleting any other UI
element found in the Flow repository tab. In the Collections tab, select and highlight the
UI element you want to delete, then press Delete  or select the option Delete in its
context menu. This brings up the respective confirmation dialog to permanently delete
that UI element.

） Important

The option Remove unused UI elements in the main context menu at the top right
of the UI elements pane is disabled, when you navigate to the Collections tab. This
option is only available in the Flow repository tab. This behavior is meant to protect
you from the unintentional deletion of a collection's UI elements; there can be
elements that are unused in your current flow, which may still be used in other
flows where the same collection is referenced.



７ Note

In the context menu of a selected (highlighted) item, the option Delete is individual
and applies only to that item. However, this option becomes disabled, if other
unrelated items also happen to be checked, to avoid any potential confusion
around the item it targets.

Deleting UI elements from a collection doesn't automatically update that collection with
the new changes. For more information, see Update a UI elements collection.

Rename a UI elements collection
Apart from the portal page, collections can also be renamed via the flow designer, after
being imported to a flow. In the Collections tab, select (highlight) the collection whose
name you want to change, and press 'F2' or select Rename in its context menu.

Renaming a collection doesn't automatically update that collection with the new change.
For more information, see Update a UI elements collection.

Update a UI elements collection
After making any of the changes described earlier, a collection is only updated locally
within the context of the desktop flow. This is to ensure that you can safely go through
the necessary testing and debugging in the flow designer, to confirm your changes in
the collection have the expected behavior, before affecting any other flows that
reference the same collection.

Once you verify the changes to the collection are correct, you can publish your changes
by updating the collection. To do this, in the Collections tab, select the collection that
was changed, and then select Update collection in its context menu. As a shortcut, you
can also select the Update icon, between the collection's name and its context icon.



Upon selecting Publish in the confirmation dialog that appears, the flow enters a
Publishing state, during which the collection is saved and uploaded in Dataverse, so its
changes become available in the specific environment. While publishing takes place, the
UI of the flow designer remains disabled.



When the collection is successfully updated in this way, the corresponding success
banner appears in the UI elements pane to inform you accordingly. At this point, the
collection's new state has overwritten the previous one, and the desktop flows that
reference this collection in the current environment are affected accordingly in their
following runs, without requiring any manual update themselves.

７ Note

If the collection is up-to-date, the Update collection option is disabled.



If you made changes in multiple collections at the same time, you can always use the
option Update unsaved collections in the main context menu at the top right of the UI
elements pane, to update all of them at once.

） Important

When your imported collections have unpublished changes, trying to save your
flow first will prompt you to also update the collections. If you don't confirm
publishing the updated state of the collections, your flow won't be saved.

Known limitations
When selected to be added to an imported collection, individual screens and web pages
carry over their child UI elements with them, as the latter are automatically checked.

Related information
Assets library
Manage UI elements collections
Create and publish UI elements collections
UI elements collections

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Troubleshooter
Article • 02/21/2025

The troubleshooter in Power Automate for desktop is a component that allows you to
diagnose, and in certain cases, troubleshoot, potential issues that you might face in the
desktop application of Power Automate.

The troubleshooter includes six categories of diagnostics:

connectivity
sign-in
Dataverse
UI/Web automation
picture-in-picture
installation issues
connectivity for cloud runtime



The troubleshooter also hosts the functionality that puts Power Automate in an
improved diagnostics state for troubleshooting purposes.

７ Note

The existing categories don't require you to be logged in to use the troubleshooter.

The troubleshooter can be manually opened via the console and the flow designer,
through the dedicated menu under Help > Troubleshooter. It can also be opened via
the process file PAD.Troubleshooter.exe, found in the installation folder of Power
Automate for desktop.

Connectivity issues
The connectivity issues diagnostic includes a series of steps that are followed in a set
order to check whether Power Automate for desktop has the required access to a
predetermined list of public endpoints. These are necessary for the desktop application
to work without issues.

On a high level, there are three steps that are checked one after the other:

Internet connection
Proxy server
Required services



For the internet connection, the troubleshooter checks in sequence:

1. If an active internet connection can be detected.
2. If there's proper DNS resolution for the endpoints that need to be checked,

mapping their domain names to IP addresses.
3. If a sample Microsoft page can be pinged.
4. If the required endpoints can be reached.

For the proxy server, the troubleshooter checks if there's any proxy related error
regarding the endpoints. For the required services, the troubleshooter checks if the
endpoints are properly set up and running.

If one step fails with an error, the following steps aren't checked at all, as the success of
one check on connectivity issues is a requirement to proceed to the following step.



７ Note

In case of one or more errors, the respective details are displayed in the
troubleshooter screen, after expanding the corresponding error.

After a category is checked for issues end to end, there’s always the option to generate
the report of that check, which includes all the detailed steps that were followed therein.
The report is produced in CSV format and is available independently of whether the
check was successful or had errors.

Τhere can be relevant connectivity errors while using Power Automate for desktop. In
those cases, you're prompted to launch the troubleshooter directly, through a link in the
error dialog. Doing so automatically opens and runs the connectivity issues category.



Sign-in issues
This category detects potential issues when you try to sign in to Power Automate for
desktop:

Authentication: This step checks whether the user is authenticated to sign in.
Authorization: This step checks whether the user is authorized to sign in.
Internet options: This step checks whether the required trusted sites are in place
or missing.

Dataverse issues
This category detects potential issues around Dataverse that might affect Power
Automate for desktop:

Provisioning: This step checks whether the user can provision a Dataverse
database in the selected environment.
Permissions: This step checks whether the user has the required permissions to
access the selected environment.
Required endpoints: This step checks whether the required endpoints for the
respective policies are accessible.

Installation issues
This category diagnoses and troubleshoots potential issues around four different
installation types that might be associated to Power Automate for desktop:

Power Automate installation type: This step identifies the installation type and
exact version of Power Automate for desktop that is installed on your machine.



.NET Framework version: This step identifies whether the minimum .NET
Framework version (4.8.1) is installed on your machine, so that Power Automate for
desktop can work properly.
WebView2: This step verifies whether WebView2 Runtime is installed on your
machine.
Windows Update: This step checks if there are any pending updates for your
Windows on your machine.

Verbose logging
Apart from the various diagnostics, the troubleshooter also hosts the verbose logging
functionality. As per the respective description in the troubleshooter app, the toggle
button can be turned on and off, forcing the Power Automate desktop application to
function in a verbose logging state. This means that any action taken from you, from
that point on, is logged with verbose details in local files. The log files are generated in
the default path mentioned in the description (PowerAutomateVerbose subfolder in
your Documents folder).

Because of this feature’s nature, we recommend that you not leave verbose logging on
permanently as there might be slower performance and capacity issues. While verbose
logging is enabled, Power Automate constantly produces files with verbose logs, which
might eventually consume a larger disk capacity. So enable this mode only for the
purposes of reproducing the issue faced and capturing the respective logs, before
turning it off again.

There are two registry entries related to verbose logging, as explained in Improve
troubleshooting of the Power Automate troubleshooter and Turn on verbose logging
state in Power Automate for desktop.

When verbose logging is enabled, the corresponding info banner appears in the console
and all the flow designers that are open at the same time. This is so you know that
you're in a state that shouldn't be used permanently. You can turn off the functionality
directly through that banner.



The console and the designer are affected immediately, when verbose logging is
enabled. This means that from that point on, your actions produce verbose logs.

７ Note

This is not the case for a recording session, or a flow that may be already running -
those scenarios respect the state of verbose logging at the beginning of the
corresponding procedure, and aren't affected in real time. In other words, verbose
logging needs to be already on, before starting a recording session or running a
flow, for the respective events to be logged under the verbose state.

When you turn off verbose logging, the Export logs button becomes available in the
troubleshooter window. This allows you to collect all the produced log files and zip
them in a single .zip file for convenience, before deleting the original individual files.

Known issues and limitations
When Export logs is used when at least one flow designer is open, not all files can be
saved in the .zip file, as some of them are used in the designer process. Those files can’t
be automatically deleted.

Related information



Troubleshoot desktop flows

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Check if a variable is numeric
Article • 02/24/2023

Power Automate enables users to insert data into flows using message boxes. In some
scenarios, you may want to ensure that the entered data are numbers to make your flow
robust to unexpected failures.

To check whether a variable contains a number or not:

1. Use the Set variable action to create a new variable that indicates whether the
variable you want to check contains a number or not. Initialize this variable to true.
In the following example, the created variable is named IsNumber.

2. Deploy the Convert text to number action and configure it to convert the variable
you want to check to number.



3. Select the On error option in the action, and create a new rule that sets the
IsNumber variable to false every time the action fails. Additionally, configure the
flow to continue running when an error occurs.



4. Now, you can use conditionals to implement different behavior depending on the
value of the IsNumber variable.



Delete columns from a datatable
Article • 02/24/2023

Although Power Automate doesn't provide a direct way to delete columns from
datatables, this functionality is feasible with the following workaround:

1. Use the Launch Excel action to launch a new blank Excel worksheet.

2. Deploy the Write to Excel worksheet action and configure it to write the datatable
to the previously launched worksheet.



3. Use the Delete column from Excel worksheet action to delete the wanted column
of the datatable.

4. Deploy the Read from Excel worksheet action and read all the available values
from the Excel worksheet. The updated datatable is now stored in a variable
named ExcelData.



5. Close the Excel worksheet without saving using the Close Excel action.



Add images to email messages
Article • 04/06/2023

Sending emails that contain images is common in many business procedures. Power
Automate enables users to include images in their emails by attaching them or
embedding them to the email body.

Send images as email attachments
To attach images to an email, use the Attachment(s) field in the Send email, Send email
message through Outlook, Respond to Outlook message, and Send Exchange email
message actions.

You can populate the Attachment(s) field with file paths or a variable containing files. To
populate multiple file paths, enclose them in double quotes ("") and separate them by a
space character.



Embed images to email body
Apart from attaching images to emails, Power Automate allows you to embed images to
email bodies using HTML.

To embed an image, check the Body is HTML option in the appropriate email action and
populate the Body field with the following code.



７ Note

After copying the following code, replace the image-url placeholder with the URL
of the image you want to embed or a variable containing it.

HTML

<html>

    <body>




        <h1>Title</h1>

        <p>This is a paragraph.</p>

        <img src="image-url">

    </body>

</html>


Where:

The URL is a link to the image. This can be a public link or dynamic content from a
previous action, such as a link for an image in SharePoint.
The URL can also be a Base64 encoded image. You can find a tool or website
online that will encode it for you. Or use the Base64 text that has been generated
by a previous "Convert file to Base64" action.
You can specify additional attributes, such as configuring the size of the image or
alt  text, in case the image can't load. See the Resources section below for more
information.

Example image with a link and size:

HTML

<img src="https://encrypted-tbn0.gstatic.com/images?
q=tbn:ANd9GcTf8peeAQ8Jbw4lowjdYM9OYVJFJr8EwgGNTsJ6BtbqPdNHWz2m" width="500" 
height="100">


Example image with base64 (clipped for readability) and the alt  attribute:

HTML

\<img 
src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHMAAABzCAMAAA......" 
alt="SomeImage" />


Resources
More ways to configure <img>: Image Embed element reference .



Use a shared Outlook mailbox in email
automations
Article • 02/24/2023

Shared mailboxes allow groups of people to monitor and send emails from public email
aliases. When a group user replies to messages sent to a shared mailbox, the email
appears to be from the shared address, not from the individual user.

To retrieve emails from a shared mailbox, use the Retrieve email messages from
Outlook action and populate the name of the mailbox in the Account field.



To send emails through a shared mailbox, use the Send email message through
Outlook action.

In the action's properties, select Other mailbox in the Send email message from drop-
down menu, and populate the name or address of the shared mailbox in the Send from
field. Additionally, populate the Account field with the address of your main account.






Automate email accounts with two-step
verification
Article • 02/24/2023

To automate an email account protected with two-step verification, you need to create
an app password.

App passwords are randomly generated passwords that can be used only once when
you sign in to an application or device that doesn't support two-step verification.

To create app passwords for Microsoft personal or organizational accounts, follow the
instructions in Create new app passwords. To create app passwords for other webmail
services, search for information on their help page or community site.

After creating an app password, populate it in the Password field of the IMAP server or
SMTP server section of the email actions.



Convert a CSV file into an Excel
spreadsheet
Article • 10/08/2024

A comma-separated values file (CSV) is a delimited text file that uses a specific character
to separate a series of values. Power Automate allows you to open comma-delimited
and tab-delimited CSV files directly through the Launch Excel action.

７ Note

Excel uses the list separators defined in the Windows regional settings. In
some regions, you have to manually set the semicolon character as a
separator or apply the following workaround.

Run the Launch Excel action
７ Note

If your comma delimited file uses semi-colons, go to Semicolon-delimited CSV
files.

1. Open Power Automate desktop.
2. Open an existing flow for editing or select New flow to create a new one.
3. In the flow designer, on the left Actions pane, expand Excel, and then double-click

Launch Excel.



4. Enter the parameters you want, and then select Save.

Next, launch a blank Excel document using the Launch Excel action and paste the CSV
table into cell A1 using the Write to Excel worksheet action.



Now, you can deploy the Close Excel action to save the Excel worksheet as a new XLSX
file. To do this, select Save document as, and for Document format, select Excel
Workbook (.xlsx).



Semicolon-delimited CSV files
Although the Launch Excel action can handle the previously mentioned cases,
semicolon-delimited CSV files might require a different approach.

To overcome this limitation, deploy the Read from CSV file action and set the semicolon
character (;) as a Custom separator in the Advanced options. If the first row of the CSV
file contains headers, enable the First line contains column names option to use the
respective headers at the retrieved data table.

See also
Excel actions reference

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Run macros on an Excel workbook
Article • 02/24/2023

The Run Excel macro action enables you to run macros in open Excel instances.

To create an Excel instance, deploy the Launch Excel action and select to open the Excel
file containing the needed macro.

） Important

To run macros stored in your personal macro workbook (PERSONAL.XLSB), enable
the Nest under a new Excel process and Load add-ins and macros options located
in the advanced options of the Launch Excel action.



To run the macro, deploy the Run Excel macro action and populate its name in the
Macro field.

To find the name of a macro, open the respective workbook and navigate to Developer
> Macros. The pop-up dialog displays all the available macros in the workbook.

To find the name of a macro assigned to a button, open the workbook, right-click on the
button, and select Assign Macro. The pop-up dialog is the same as in the previous case.






Run SQL queries on Excel files
Article • 02/24/2023

Although Excel actions can handle most Excel automation scenarios, SQL queries can
retrieve and manipulate significant amounts of Excel data more efficiently.

Suppose a flow has to modify only the Excel registries that contain a particular value. To
achieve this functionality without SQL queries, you need loops, conditionals, and
multiple Excel actions.

Alternatively, you can implement this functionality with SQL queries using only two
actions, Open SQL connection and Execute SQL statements.

Open a SQL connection to an Excel file
Before running a SQL query, you have to open a connection with the Excel file you want
to access.

To establish the connection, create a new variable named %Excel_File_Path% and
initialize it with the Excel file path. Optionally, you can skip this step and use the hard-
coded path of the file later in the flow.

Now, deploy the Open SQL connection action and populate the following connection
string in its properties.

Provider=Microsoft.ACE.OLEDB.12.0;Data Source=%Excel_File_Path%;Extended
Properties="Excel 12.0 Xml;HDR=YES";



７ Note

To use the presented connection string successfully, you have to download and
install Microsoft Access Database Engine 2010 Redistributable .

Open a SQL connection to a password-
protected Excel file
A different approach is required in scenarios where you run SQL queries on password-
protected Excel files. The Open SQL connection action can't connect to password-
protected Excel files, so you have to remove the protection.

To achieve that, launch the Excel file using the Launch Excel action. The file is password-
protected, so enter the appropriate password in the Password field.



Next, deploy the appropriate UI automation actions and navigate to File > Info >
Protect Workbook > Encrypt with Password. You can find more information about UI
automation and how to use the respective actions in Automate desktop applications.



After selecting Encrypt with Password, populate an empty string in the pop-up dialog
using the Populate text field in window action. To populate an empty string, use the
following expression: %""%.

To press the OK button in the dialog and apply the changes, deploy the Press button in
window action.



Lastly, deploy the Close Excel action to save the nonprotected workbook as a new Excel
file.

After saving the file, follow the instructions in Open a SQL connection to an Excel file to
open a connection to it.



When the manipulation of the Excel file is complete, use the Delete file(s) action to
delete the nonprotected copy of the Excel file.

Read contents of an Excel spreadsheet
Although the Read from Excel worksheet action can read the contents of an Excel
worksheet, loops can take a significant time to iterate through the retrieved data.

A more efficient way to retrieve specific values from spreadsheets is to treat Excel files as
databases and execute SQL queries on them. This approach is faster and increases the
performance of the flow.

To retrieve all the contents of a spreadsheet, you can use the following SQL query in the
Execute SQL statement action.

SQL

SELECT * FROM [SHEET$]




７ Note

To apply this SQL query in your flows, replace the SHEET placeholder with the name
of the spreadsheet you want to access.

To retrieve the rows that contain a particular value in a specific column, use the
following SQL query:

SQL

SELECT * FROM [SHEET$] WHERE [COLUMN NAME] = 'VALUE'


７ Note

To apply this SQL query in your flows, replace:

SHEET with the name of the spreadsheet you want to access.



COLUMN NAME with the column that contains the value you want to find.
The columns in the first row of the Excel worksheet are identified as the
table's column names.
VALUE with the value you want to find.

Delete data from an Excel row
Although Excel doesn't support the DELETE SQL query, you can use the UPDATE query
to set all the cells of a specific row to null.

More precisely, you can use the following SQL query:

SQL

UPDATE [SHEET$] SET [COLUMN1]=NULL, [COLUMN2]=NULL WHERE [COLUMN1]='VALUE'


While developing your flow, you have to replace the SHEET placeholder with the name
of the spreadsheet you want to access.



The COLUMN1 and COLUMN2 placeholders represent the names of the columns to
handle. This example has two columns, but in a real scenario, the number of the
columns may differ. The columns in the first row of the Excel worksheet are identified as
the table's column names.

The [COLUMN1]='VALUE' part of the query defines the row you want to update. In your
flow, use the column name and the value based on which combination describes the
rows uniquely.

Retrieve Excel data except for a specific row
In some scenarios, you may need to retrieve all the contents of an Excel spreadsheet
except for a specific row.

A convenient way to achieve this is to set the values of the unwanted row to null and
then retrieve all the values except for the null ones.

To change the values of a specific row in the spreadsheet, you can use an UPDATE SQL
query, as presented in Delete data from an Excel row:

SQL

UPDATE [SHEET$] SET [COLUMN1]=NULL, [COLUMN2]=NULL WHERE [COLUMN1]='VALUE'




Next, run the following SQL query to retrieve all the rows of the spreadsheet that don't
contain null values:

SQL

SELECT * FROM [SHEET$] WHERE [COLUMN1] IS NOT NULL OR [COLUMN2] IS NOT NULL


The COLUMN1 and COLUMN2 placeholders represent the names of the columns to
handle. This example has two columns, but in a real table, the number of the columns
may differ. All the columns in the first row of the Excel worksheet are identified as the
table's column names.



Autofit Excel columns using VBScript
Article • 02/24/2023

７ Note

Desktop flows provide the Resize columns/rows in Excel worksheet action to
facilitate the resizing of Excel columns and rows. This article shows an alternative
way to resize Excel columns and rows using scripting.

The autofit feature in Excel enables users to resize cells in worksheets to accommodate
different-sized data without manually changing the column width and row height.

To autofit Excel columns using scripting in Power Automate:

1. Use the Set variable action to create a new variable containing the path of the
Excel file you want to manipulate. In this example, the variable is named ExcelFile.

2. Deploy the Run VBScript action and populate the following code. Before running
the flow, replace the SheetName placeholder with the name of the sheet you want
to autofit or a variable containing it.

VBScript

'Opens the Excel file'

Set objExcel = CreateObject("Excel.Application")

Set objWorkbook = objExcel.Workbooks.Open("%ExcelFile%")

objExcel.Application.Visible = True


'Selects the specified sheet'

Set objSheet = objWorkbook.Sheets("SheetName")




'Autofits the columns of the sheet'S

for col=1 to 19

objSheet.columns(col).AutoFit()

next


'Saves and closes the Excel file'
objWorkbook.Save

objWorkbook.Close SaveChanges = True




Unhide worksheets in Excel using
VBScript
Article • 02/24/2023

If an Excel file contains hidden worksheets, replicate the following steps to make them
visible:

1. Use the Set variable action to create a new variable containing the file path of the
respective Excel file. In this example, the variable is named ExcelFile.

2. Deploy the Run VBScript action and populate the following code.

VBScript

'Opens the Excel file'

Set objExcel = CreateObject("Excel.Application")

Set objWorkbook = objExcel.Workbooks.Open("%ExcelFile%")

objExcel.Application.Visible = True


'Unhides all the worksheets of the Excel file'

For i=1 To objWorkbook.Sheets.Count

objWorkbook.Sheets(i).Visible = True

Next


'Saves and closes the Excel file'
objWorkbook.Save

objWorkbook.Close SaveChanges = True







Use image recognition on machines
with different screen resolutions
Article • 02/24/2023

When you capture images in Power Automate, the stored images are affected by the
source machine's screen resolution and DPI scaling.

In cases where flows perform image recognition on different screens or machines, you
must ensure that all the screens have the exact screen resolution.

To achieve this functionality, you can use the Set screen resolution action to change the
screen resolution of the target machines.

The new resolution has to be the same as the source machine from which the image was
captured. To find the resolution of the source machine, use a temporary Get screen
resolution action or check the Windows display settings.

） Important

To use the Set screen resolution action in flows triggered through the Power
Automate portal, you have to be connected to the console session of your
machine, where you can manually change the screen resolution. For example, you
can use your machine's physical screen to connect to the machine. In remote
sessions, such as unattended scenarios that use remote desktop clients, the action
has no effect, as users can't manually change the resolution.

７ Note

Before using image recognition, ensure that DPI scaling stays the same among the
screens. The use of varying DPI scalings may cause the flow to fail.



If you want to roll back to the original resolution later in the flow, add a Get screen
resolution before the Set screen resolution action.

When all the image recognition procedures are completed, use the retrieved values and
a second Set screen resolution action to set the screen back to the original resolution.






Perform OCR on multilingual
documents
Article • 02/24/2023

Optical character recognition (OCR) enables you to locate and extract text from images
or the screen.

Although most scenarios require you to handle text in a specific language, there are
cases where the sources are multilingual.

To perform OCR on these sources, use a Tesseract engine in the respective OCR action
and enable the Use other languages option in the engine settings.



When the Use other languages option is enabled, the action displays two additional
settings: the Language abbreviation and Language data path fields.

The Language abbreviation field indicates to the engine which language to look for
during OCR.
The Language data path field contains the language data files
(.traineddata) used to train the OCR engine.



After downloading the data files for the needed languages, move them to a common
folder to make them available under the same path.

Next, select the created folder in the Language data path field, and populate the
corresponding language codes in the Language abbreviation field. To separate the
language codes, use the plus character (+).

７ Note



You can find all the available language codes in the source of the language data
files. In the following example, the used codes represent Telugu, Hindi, and English.



Print images
Article • 02/24/2023

Although Power Automate enables you to print documents using the Print document
action, printing image files requires a different approach.

To print an image file, create a batch script that launches Microsoft Paint and prints the
selected image file through it. To develop the script, create a new .txt file, copy the
following code, and save it as Image-printing.bat.

７ Note

Before saving the script, replace the Image_Path placeholder with the file path of
the image you want to print.

Batch

@echo off+


title Print Images


rem The following command launches Microsoft Paint and prints the selected 
file using the default printer.


mspaint /p "Image_Path"


rem The following command ends the Microsoft Paint process. 


taskkill /IM "mspaint.exe"


To run the script, use the Run application action and populate the path of the batch file
in the Application path field.



Alternatively, you can print image files using the Run DOS command action with the
following command as an input:

７ Note

Before running the flow, replace the Image_Path and Printer_Name placeholders
with the file path and the printer's name, respectively.

DOS

rundll32 C:\WINDOWS\system32\shimgvw.dll,ImageView_PrintTo "Image_Path" 
"Printer_Name"




Identify a window by its handle
Article • 02/24/2023

It's common in flow development to create flows that use several windows with the
same title and class.

Power Automate enables users to distinguish identical windows using handles. Handles
are numbers that uniquely identify each window.

To retrieve the handle of a window, launch the application with the Run application
action and set the After application launch drop-down menu to Wait for application to
load. The handle is stored by default in a variable named WindowHandle.



Alternatively, you can use the Get details of a UI element in window action to retrieve
the handle from an already open window.

Select to retrieve the attribute parentwindowhandle from a random element within the
window. The retrieved attribute is stored by default in a variable named AttributeValue.



７ Note

The Get details of a UI element in window action requires a UI element that
specifies the selected element in the window. You can find more information
regarding UI elements in Automate using UI elements.

You can use handles to manipulate windows through the following Windows actions of
the UI automation group:

Focus window
Set window state
Set window visibility
Move window
Resize window
Close window



Close any window through its process
ID
Article • 02/24/2023

When you handle desktop application, you may meet scenarios in which applications
don't have static titles or have the same title as other windows. Power Automate allows
users to close these applications using their process ID.

To get the process ID of a window, use the Get details of a UI element in window action
and retrieve the attribute processid from a random element within the window. The
retrieved attribute is stored by default in a variable named AttributeValue.

７ Note

The Get details of a UI element in window action requires a UI element that
specifies the selected element in the window. You can find more information
regarding UI elements in Automate using UI elements.

To close the window, use the Terminate process action and set it to stop the process
with the previously retrieved ID.






Extract attributes from window
elements
Article • 02/24/2023

The Get details of a UI element in window action enables users to retrieve the values of
various attributes that window elements may have.

These values can be used in various operations, such as managing windows by their
handles and closing windows through their process IDs.

Apart from the four predefined attributes that the action provides, you also retrieve the
following attributes:

Attribute Description

Acceleratorkey The accelerator key combinations for the automation element.

Accesskey The access key that allows you to quickly navigate to the web server
control.

bulktext The text of the element regardless of whether the element or its
subelements are hidden or not.

class The class of the element.



Attribute Description

controltype The control tyoe of the element.

haskeyboardfocus Indicates whether the element has keyboard focus

helptext The help text of the element.

id The id of the element.

iscontentelement Indicates whether the element is a content element.

iscontrolelement Indicates whether the element is a control element.

Iskeyboardfocusable Indicates whether the element is keyboard focusable.

isoffscreen Indicates whether the element is visible on the screen.

ispassword Indicates whether the element is a password.

localizedcontroltype A localized description of the control type.

name The name of the element.

parentwindowhandle The handle of the parent window.

processid The process ID of the parent window.

processname The process name of the parent window.

windowtitle The title of the parent window.



Ensure that application windows
become focused
Article • 02/24/2023

Although Power Automate provides the Focus window action, depending on the nature
of the selected application, the action may not bring the window to focus.

To verify that the Focus window action can't bring a specific window to focus, send
some keystrokes using the Send keys action. If the window isn't focused, the keystrokes
won't work as expected.

To ensure that the window will become focused, send a click on it after deploying the
Focus window action. Depending on the scenario, you can use either of the following
actions to send a click on the window:

Click UI element in window
Move mouse to image - Enable the Send a click after moving mouse option



Send mouse click
Move mouse to text on screen (OCR) - Enable the Send a click after moving
mouse option

７ Note

You can find more information regarding sending keystrokes in Automate
applications using keyboard shortcuts.



Get the position and size of a window
Article • 02/24/2023

When you automate windows and desktop applications, you may need to know the
exact position and size of a window.

To retrieve this information, use the Get details of window action and set the Window
property option to Get window location and size. The action stores the retrieved values
in a text variable named WindowProperty.

７ Note

The Get details of window action requires a UI element that specifies the window
from which it will retrieve the selected attrubite. You can find more information
regarding UI elements in Automate using UI elements.

After retrieving the WindowProperty text value, you have to split it into separate values
and convert them to numbers.

To split the text value, deploy the Split text action and separate the values using the
comma character (,) as a delimiter. The separated values are stored in a list variable
named TextList.



Before converting the texts to numbers, use the Create new list action to create a list
that will store the converted numbers in the following steps.

To access each item of the TextList independently, deploy a For each loop.



Inside the loop, use a Convert text to number action to convert the current text item of
the loop to number.

Next, use the Add item to list action to store the produced number to the previously
created list.



To access the final position and size values later in your flow, use the following
notations:

List[0] - The left point of the window
List[1] - The top point of the window
List[2] - The width of the window
List[3] - the height of the window

To calculate the right and bottom points of the window, you can use the following
expressions:

%List[0] + List[2]% - The right point of the window
%List[1] + List[3]% - The bottom point of the window

７ Note

You can find more information about lists and the VariableName[ItemNumber]
notation in Variable datatypes.



Automate applications using keyboard
shortcuts
Article • 02/24/2023

Many desktop applications provide keyboard shortcuts that make multi-step tasks easy
and fast to perform. Power Automate allows you to apply these shortcuts to create
shorter and less complicated flows.

） Important

Before sending keystrokes to an open application, use the Focus window action to
activate the respective window. To select a specific element in the window, use the
appropriate UI automation action, such as the Click UI element in windows action.

When the window is activated or the required element is selected, use the Send keys
action to send the intended keystrokes.

To send a key, enclose its name inside curly brackets ({}). The curly brackets notation
makes the action simulate the key's physical press. To populate hardcoded text values in
a field, enter the respective text without any notations.



７ Note

To send a specific key multiple times, you can use the following expression instead
of entering the key numerous times: {Key:numberOfTimes}.

Apart from sending keys individually, you can use the Send keys action to send
combinations of keys. To achieve this functionality, enclose the modifier inside curly
brackets and the rest of the keys inside a pair of parentheses. The parentheses indicate
that the keys inside them will be pressed simultaneously with the modifier key.

For example, you can use the Ctrl + B shortcut to apply bold formatting in the currently
selected Excel cell. To use this shortcut, populate the Text to send field of the Send keys
action with the following expression: {Control}({B})

７ Note

You can find all the available Excel keyboard shortcuts in this article .






Automate with mouse, keyboard, and
OCR actions (recommended for
automation in VDI)
Article • 02/24/2023

For cases that a user isn’t able to access the UI elements of web or UI applications and
thus can’t automate using Browser or UI actions or the recorders, it’s strongly
recommended to use alternative methods of automation such as the use of Images or
mouse and keyboard.

The image method, captures sections of the screen which are then used as references to
perform clicks, send text and mouse clicks. Image-based automation can be either
recorded by the image-based recorder or developed manually. Read more on how to
automate using images in this topic.

Conversely, for cases that an image can't be used as a point of reference, consider using
the OCR capabilities to navigate through the screen. Information on OCR capabilities
can be found in the respective actions reference.

In both alternatives described above, the best way to navigate is using mouse clicks and
keystrokes which are explained in the actions reference.

Before building your automation, ensure that the appropriate window is focused and
maximized using the Focus window and Set window state actions.



If you need to wait for specific components to load before running an action, use the
wait group of actions.

Use the Wait action to wait for a set amount of time, the Wait for image action to wait
for an image to appear/disappear, or the Wait for text on screen (OCR) action to wait
for a text to appear/disappear.



To navigate through the web page or application and interact with its components, use
the mouse and keyboard actions.

For example, deploy the Send keys action to use the available keyboard shortcuts, or
the Move mouse to image and Move mouse to text on screen (OCR) actions to move
the cursor to a specific image or text, respectively.



To retrieve text from the screen and store it into a variable, deploy either the clipboard
actions or the Extract text with OCR action. To store a text in the clipboard, highlight the
text using either the Send keys or the Send mouse click action.

You can configure the Send keys action to send the CTRL + A keyboard shortcut that
selects all the text on the web page or application.



７ Note

You can find more information regarding automation using keyboard shortcuts in
Automate applications using keyboard shortcuts.

Alternatively, you can use the Send mouse click action to send a Left button down at
the beginning of the text you want to select and then a Left button up at the end.



After highlighting, deploy the Send keys action to send the CTRL + C keyboard shortcut
that stores the selected text in the clipboard. After storing the text in the clipboard, use
the Get clipboard text action to store the clipboard content into a variable.



Access elements that depend on how
the window appears on the screen
Article • 02/24/2023

There are cases where Power Automate can't detect UI elements if they aren't visible on
the computer screen.

These elements may be located in areas not directly visible on the screen or may not
appear on the window at all. An element may be missing because the window's zoom
level isn't suitable or the screen resolution is low.

To resolve this issue, you can:

Increase the resolution of the screen manually or using the Set screen resolution
action.

） Important

To use the Set screen resolution action in flows triggered through the Power
Automate portal, you have to be connected to the console session of your



machine, where you can manually change the screen resolution. For example,
you can use your machine's physical screen to connect to the machine. In
remote sessions, such as unattended scenarios that use remote desktop
clients, the action has no effect, as users can't manually change the resolution.

Maximize the window of the application using the Set window state action.

Zoom in or out of the window.

In some cases, you can create dynamic selectors that adapt to the state of the window
or application. You can find more information about dynamic selectors in Build a custom
selector.



Automate Java applications
Article • 02/11/2025

Currently, Power Automate for desktop supports the use of UI automation in all Java
apps and applets for the following Java versions:

Java apps: Java version 7 and above.
Java applets: Java version 7 and version 8.

OpenJ9 editions of the Java runtime aren't supported.

The following sections include information for
enabling the UI automation in Java applets.

Install Java configuration
In order to automate Java applications, particular settings must be in place.

To install the Java configuration manually, after Power Automate for desktop has been
installed, navigate to the installation folder (C:\Program Files (x86)\Power Automate
Desktop) and run the PAD.Java.Installer.exe as an administrator.

Logs for Java automation with Power Automate for desktop can be found in the
%temp%/ java_automation_log folder (for example,
C:\Users\username\AppData\Local\Temp\java_automation_log).

Utilization of the default UI automation instead of Java UI
automation
Το prevent the recorder and the UI element picker from recognizing Java elements built
with the SWT framework and make them work with the default desktop UI elements:

Edit the configuration file located under the machine’s Program Files: Power
Automate
Desktop\Microsoft.Flow.RPA.Desktop.UIAutomation.Plugin.Java.dll.config.
Set the BlockSwt property to true.

Uninstalling Java configuration



To uninstall the Java configuration (revert all changes applied to the machine by the Java
installer):

1. Launch the Command Line tool (cmd)

2. Run the following command:

CMD

PAD.Java.Installer.exe -u 

Java automation attach mechanism
For Java versions greater than 8, Power Automate desktop loads its Java automation
agent via the JNI attach mechanism. Ensure that the Attach API is enabled on the JVM.

If the attach mechanism for Java automation doesn't work, add the following arguments
when starting the Java application:

64-bit Java
-javaagent:"C:\Program Files (x86)\Power Automate Desktop\java-
support\PAD.JavaBridge.jar" -Djava.library.path="${env_var:PATH};C:\Program
Files (x86)\Power Automate Desktop\java-support\x64"

32-bit Java
-javaagent:"C:\Program Files (x86)\Power Automate Desktop\java-
support\PAD.JavaBridge.jar" -Djava.library.path="${env_var:PATH};C:\Program
Files (x86)\Power Automate Desktop\java-support\x86"

The paths use the Power Automate Desktop installation location. Adjust the paths if you
install Power Automate Desktop in a different location.

If you can't modify the startup arguments of the Java application, set a new environment
variable named JDK_JAVA_OPTIONS with the appropriate value based on the
architecture of the JDK. This loads the Power Automate Desktop Java automation agent
at the startup of every Java application that uses the Java JDK.

Troubleshooting
If you come across any issues while automating Java applications, there are multiple
potential causes. Learn more in Can't access the elements of a Java application.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Handle links that open new tabs
Article • 02/24/2023

Desktop flows use browser instances to pinpoint specific web pages located in specific
tabs on browser windows.

If a flow clicks a link that opens a new tab, you have to apply additional configuration to
continue automating inside this new tab.

The most straightforward approach is the use of the embedded automation browser
that doesn't support tabs. It opens all the links in the same instance.

７ Note

You can find more information about the features and limitations of the automation
browser in Use browsers and manage extensions.

To navigate back to the previous page, you can use the Go to web page action.

If your flow uses Edge, Internet Explorer, Chrome, or Firefox, there are also methods to
handle links that open new tabs.



You can retrieve the URL behind the link using the HRef option in the Attribute name
field of the Get details of element on web page action. Then, you can navigate to the
retrieved link in the same tab using the Go to web page action.

If the link is in JavaScript, you can retrieve the JavaScript function and run it as a URL in
the Go to web page action. In this case, you should enter JavaScript: and the function to
run.

Another approach is to click the link and then use the Attach to running instance
option of the previously mentioned browsers to attach your flow to the newly created
tab.






Retrieve details from a web page
Article • 02/24/2023

Extracting information regarding web pages is an essential function in most web-related
flows. The Get details of web page action allows you to retrieve various details from
web pages and handle them in your desktop flows.

To use the action, you need an already created browser instance that specifies the web
page you want to extract details from. A browser instance can be created with any
browser-launching action.

After selecting the appropriate browser instance, choose the information you want to
extract from the web page. The Get details of web page action offers six different
options:

The description of the web page
The meta keywords of the web page
The title of the web page
The text of the web page
The source code of the web page
The URL address of the web page

The retrieved information is stored for later use in a text variable named
WebPageProperty.



Prevent errors while retrieving details
Although most properties exist virtually on every web page, there are scenarios in which
the Get details of web page action fails to retrieve the selected detail. For example, web
pages without meta keywords are a common occurrence.

If you're unsure if an attribute exists on a web page, configure the On error options of
the Get details of web page action to continue running the flow after failure. To find
more information about action error handling, refer to Handle errors in desktop flows.

To determine whether the data extraction is successful, use an If conditional to check if
the WebPageProperty variable is empty or not.

The conditional allows you to implement different functionality for the cases of
successful and unsuccessful data extraction. You can find more information regarding
conditionals in Use conditionals.

The following example subflow retrieves the available meta keywords from a web page
and displays them in a message box. If the extraction is unsuccessful, the flow stops and
returns an error message.






Get the coordinates and size of a web
element
Article • 02/24/2023

When you automate web applications and web pages, you may need to know the exact
location and size of a specific element.

To retrieve this information, create a browser instance and deploy the Get details of
element on web page action. In the action's properties, set the Attribute name option
to waelementrectangle. The action stores the retrieved values in a text variable named
AttributeValue.

７ Note

The Get details of element on web page action requires a UI element that specifies
the web element from which it will retrieve the selected attrubite. You can find
more information regarding UI elements in Automate using UI elements.

After retrieving the AttributeValue text value, you have to split it into separate values
and convert them to numbers.



To split the text value, deploy the Split text action and separate the values using the
comma character (,) as a delimiter. The separated values are stored in a list variable
named TextList.

Before converting the texts to numbers, use the Create new list action to create a list
that will store the converted numbers in the following steps.



To access each item of the TextList independently, deploy a For each loop.

Inside the loop, use a Convert text to number action to convert the current text item of
the loop to number.

Next, use the Add item to list action to store the produced number to the previously
created list.



To access the final coordinates and size values later in your flow, use the following
notations:

List[0] - The left point of the web element, relative to the top left corner of the
HTML page
List[1] - The top point of the web element, relative to the top left corner of the
HTML page
List[2] - The width of the web element
List[3] - the height of the web element

To calculate the right and bottom points of the window, you can use the following
expressions:

%List[0] + List[2]% - The right point of the web element
%List[1] + List[3]% - The bottom point of the web element

７ Note

You can find more information about lists and the VariableName[ItemNumber]
notation in Variable datatypes.

To find the coordinates of the top left corner of an HTML page, you can use the web
browser's instance properties DisplayRectangleX and DisplayRectangleY.

After storing a browser's instance into a variable named %Browser%, use the
%Browser.DisplayRectangleX% and %Browser.DisplayRectangleY% expressions to
retrieve the X and Y dimensions.



Additionally, you can retrieve the coordinates specifying the center of a web element
using the waelementcentercoords attribute in the Get details of element on web page
action.



Send physical clicks on a web element
Article • 02/24/2023

There are cases where emulated clicks don't function as expected and don't select links
successfully. Sending physical clicks can help you automate web pages that don't
support emulated clicks.

To send a physical click:

1. Deploy the Click link on web page action and populate a browser instance and the
UI element that specifies the link you want to click. You can find more information
regarding UI elements in Automate using UI elements.

2. Choose the type of click you want to perform in the Click type field.



3. Extend the Advanced settings of the action and enable the Send physical click
toggle button. This option automatically focuses on the parent window of the link,
moves the mouse cursor to the appropriate location, and sends a physical click to
the selected link.






Click all the elements in a list of links
Article • 02/24/2023

In browser automation, it's common to meet scenarios that require you to click all the
elements in a list of links.

To automate these scenarios, use the Extract data from web page action and extract a
random value from two consecutive links. Power Automate will automatically extract the
respective value from all the links in the list.

７ Note

You can find more information regarding web data extraction in Automate web
flows
.

After the extraction, you can use the DataFromWebPage.RowsCount property to get
the number of the elements in the list.

To make the flow iterate through all the links on the page, use a Loop action. The loop
should start from 0 and end at %DataFromWebPage.RowsCount-1%.



Inside the loop, use the Click link on web page action and select a UI element of the
first link as an input.

To make the action click all the links, modify the selector to click a different link in each
loop iteration.



To achieve this functionality, edit the selector with the Text editor. In this step, the right
part of the selector should look something like the following example:
ul[properties] >
li[properties]:eq(0) > a[properties]

To make it select a different link in each iteration, change the tr:eq(0) part to
tr:eq(%LoopIndex%).



７ Note

You can find more information regarding custom selectors in Build a custom
selector.

Lastly, use the Go to web page action to go back to the original page after each click.
You can perform additional operations on each loaded page between the Click link on
web page and Go to web page actions.



Automate browser prompts
Article • 02/24/2023

Many web pages display Save as, Open, and Upload dialogs to prompt users to select
destination folders and files, respectively.

These dialogs aren't part of the web page, but they're handled by the web browser
application or Windows File Explorer. As a result, you can't use the browser automation
actions to automate them.

To automate these dialogs, use either the recorder or the UI automation group of
actions.



Scroll on a web page
Article • 02/24/2023

In some browser automation flows, you may need to scroll on web pages to make
specific elements visible on the screen.

Power Automate allows scrolling on web pages through two different approaches. The
first one requires the Focus text field on web page action, while the second requires
JavaScript scripting.

Scroll on a web page using the Focus text field
on web page action
To scroll to a specific element on a web page, you can deploy the Focus text field on
web page action.

In the action's properties, you have to create a UI element that selects the target
element of the scrolling. Although the action's primary purpose is to focus on text fields,
you can use it for scrolling to any element.

７ Note

You can find more information about UI elements in Automate using UI elements.



Usually, web applications contain loading more elements at the bottom of pages that
display many elements. In these cases, you can target the loading more element to
scroll at the bottom of the page.

Scroll on a web page using JavaScript
Apart from the Focus text field on web page action, you can scroll on web pages using
JavaScript. To run JavaScript on web pages, use the Execute Javascript function on web
page action.

JavaScript provides the window.scrollTo(xpos, ypos) function that scrolls to a specific
part of a web page. The xpos placeholder indicates the horizontal scroll, while the ypos
placeholder indicates the vertical scroll.

JavaScript

function ExecuteScript() 

{

window.scrollTo(xpos, ypos);

}


You can replace both placeholders with hardcoded values, properties, or variables. In the
following example, the function contains hardcoded values.



If you want to scroll to the bottom of a web page, you can replace the ypos placeholder
with the document.body.scrollHeight property.

JavaScript

function ExecuteScript() 

{

window.scrollTo(0, document.body.scrollHeight);

}




If you want to scroll inside an element of a web page, not the page itself, you can use
the HTML DOM property scrollTop. In the following example, the function locates the
divElem and scrolls vertically 10 pixels down.

JavaScript

function ExecuteScript() 

{

document.getElementById('divElem').scrollTop -= 10;

}







Handle iframes on a web page
Article • 02/24/2023

Iframes are HTML documents embedded inside other HTML documents. These elements
are often used to insert content from external sources into web pages.

When an iframe belongs to the same domain as the original page, you can use the
browser automation actions to automate it. You can find more information about
browser automation in Automate web flows.

If the browser automation actions don't work correctly with a particular iframe, you can
use the UI automation actions to handle it. You can find more information about UI
automation in Automate desktop flows.

If an iframe is cross-domain, deploy the Get details of element on web page to retrieve
the Source Link attribute of the element.

Next, use the Go to web page action or the Create new tab action to navigate to the
retrieved source. Now, you can use the browser automation actions to interact with the
iframe.






Populate text fields and click on links
using JavaScript
Article • 02/24/2023

Some web applications may have design constraints that don't allow browser
automation actions to populate text fields or click on links and buttons.

An alternative approach to automate these web applications is the use of the Run
JavaScript function on web page action, which allows you to run JavaScript code on
web pages.

Before deploying the Run JavaScript function on web page action, you need the CSS
selector of the element you want to populate or click. To get the selector, navigate to
the UI elements tab and select Add UI element.

After creating the UI element, navigate again to the UI elements tab, select the created
UI element, and open the selector with the Selector builder.



Now, copy the last element of the selector located on the right side of the last occurred
> character.

７ Note



You can find more information about selectors in Build a custom selector.

To populate a text field, deploy the Run JavaScript function on web page action and
populate the following code in the JavaScript function field. After pasting the code,
replace the CSS-selector and value-to-populate placeholders with the previously copied
selector and the value to populate, respectively.

JavaScript

function ExecuteScript()

{

document.querySelectorAll('CSS-selector')[0].value="value-to-populate";

}


OR


function ExecuteScript()

{

document.querySelectorAll('CSS-selector')[0].innerText="value-to-populate";

}


To click a link or press a button, use the following code:

JavaScript



function ExecuteScript()

{

document.querySelectorAll('CSS-Selector')[0].click();

}




Convert a text value to datetime
Article • 02/24/2023

When a desktop flow reads entries from files or extracts values from applications, the
returned values usually are texts.

It's common in flow development to convert these values to other datatypes to perform
additional operations. For example, you could convert a text value that represents a date
to a datetime variable for later use in datetime actions.

Power Automate provides the Convert text to datetime action to perform the
conversion. This action enables you to convert a date represented in the default format
of your system or a custom format.

The default format is specified by the region and language settings of your machine. For
example, the default date format for the United States is MM-dd-yyyy. The time part, if
it exists, can be represented in both 12-hour and 24-hour formats.

７ Note

If the value doesn't contain a time part, the time of the generated datetime variable
will be automatically set to 12:00:00 AM.



７ Note

Power Automate allows you to use all the standard date separators for the different
parts of the date value. In the previous example, dates represented in the MM-dd-
yyyy and MM/dd/yyyy notations will have the same result.

If the value to convert is represented in a custom format, enable the Date is represented
in custom format option and populate the respective format.

You can find all the available notations in the following table:

Notation Description

yyyy Year

MM Month

dd Day

HH Hour

mm Minutes

ss Seconds

ff Milliseconds

zzz UTC Offset

To separate the different parts of the date, you can use all the standard date separators,
like forward slashes (/), dashes (-), and dots (.).






Convert data using PowerShell
Article • 02/24/2023

Data conversion is an essential functionality in desktop flows, as different actions and
applications may require data in specific formats. Power Automate offers various actions
to direct convert data formats, such as the Convert text to number and Convert file to
Base64 actions.

However, there are conversion scenarios that can't be handled by the available actions.
To address these cases, run a PowerShell script that performs the desired conversion.

To run a PowerShell script, use the Run PowerShell script action and populate the
appropriate command for the conversion you want to do. For example, the following
PowerShell script converts a binary number stored in the BinaryNumber variable to
decimal.

The action produces the PowershellOutput variable that stores the result of the
conversion as a text.

７ Note

You can find more information regarding PowerShell conversion methods in this
article.



Convert Excel to PDF using VBScript
Article • 02/24/2023

To convert an Excel file to PDF:

1. Use the Set variable action to create a new variable containing the path of the
Excel file you want to convert. In this example, the variable is named ExcelFile.

2. Use a second Set variable action to create a variable containing the path of the
PDF file you want to create. In this example, the variable is named PdfFile.

3. Deploy the Run VBScript action and populate the following code.

VBScript

Dim Excel

Dim ExcelDoc




'Opens the Excel file'

Set Excel = CreateObject("Excel.Application")

Set ExcelDoc = Excel.Workbooks.open("%ExcelFile%")


'Creates the pdf file'

Excel.ActiveSheet.ExportAsFixedFormat 0, "%PdfFile%" ,0, 1, 0,,,0


'Closes the Excel file'

Excel.ActiveWorkbook.Close

Excel.Application.Quit




Convert Base64 text to hexadecimal
format
Article • 02/24/2023

Although cryptography actions produce variables encoded in Base64 format, some
cryptography engines use the hexadecimal representation of the encrypted value.

To convert the Base64 text to hexadecimal format, use the Run PowerShell script action
and populate the following command. Before deploying the Run PowerShell script
action, use a Set variable action to store the text you want to convert into a variable. In
this example, the script converts the text stored into the Base64Text variable.

PowerShell

[System.Convert]::FromBase64String("%Base64Text%") | Format-Hex


７ Note

You can find more information regarding PowerShell utility cmdlets in this article.

The action produces the PowershellOutput variable that stores the encrypted or hashed
value in hexadecimal format.



Run SQL queries to Microsoft Access
Article • 02/24/2023

Apart from database servers, Power Automate supports the automation of Microsoft
Access databases.

To establish a connection with a Microsoft Access database, use the Open SQL
connection action, and open the connection string builder.

In the Provider tab of the appeared dialog, select Microsoft Office 12.0 Access
Database Engine OLE DB Provider.

７ Note

If the presented provider is missing from the available options, you have to
download and install Microsoft Access Database Engine 2010 Redistributable .



Next, populate the path of the Microsoft Access database in the Data Source field of the
Connection tab.



The generated connection string must be similar to the following one:

Provider=Microsoft.ACE.OLEDB.12.0;Data Source=DatabasePath;Persist Security
Info=False

７ Note

All the connection strings that establish connections with Microsoft Access
databases consist of three main parts: the provider, the data source, and the
security credentials (if applicable).



To run queries on the connected database, use the Execute SQL statement action.
Power Automate supports all the essential queries, such as SELECT, INSERT INTO, and
UPDATE.



When all the queries have been executed, deploy the Close SQL connection to close the
connection with the database.



Troubleshoot SQL queries
Article • 02/24/2023

While developing desktop flows, you may encounter errors caused by deployed
database actions that run queries on databases. If you can't identify the source of the
issue through the displayed error messages, perform the following troubleshooting
steps:

1. Replace any single quote (') characters with double quotes (") or the other way
around.

For example, the following query produces an error because of the single quote at
the end of the variable’s value.

SQL

SELECT * FROM SALES WHERE VALUE = '%value%'; 


To resolve this issue, replace the single quotes in the SQL statement with double-
quotes.

SQL

SELECT * FROM SALES WHERE VALUE = "%value%"; 


2. Escape percentage signs (%) that don't indicate variables.

Power Automate identifies percentage signs as characters that indicate variables.
To use them as normal characters, escape them using an extra percentage sign.

７ Note

You can find more information about the percentage signs in Use variables
and the % notation.

3. Ensure that the same versions (32 bit or 64 bit) of database, database server, and
Power Automate for desktop are installed on your desktop.

4. Verify that the firewall or any other network security system isn't blocking the
connection between Power Automate and the database.



5. If you're using database actions to run queries on Excel files, ensure that you've
applied the following practices:

The name of the Excel worksheet is used as a database name. Enclose the
worksheet name in brackets ([]) and add a dollar sign ($) at the end, for
example [Sheet1$].
The database columns are the headers of the Excel data table.

SQL

SELECT * FROM [Sheet1$] WHERE Value = "%value%"; 


７ Note

You can find more information regarding running SQL queries on Excel in Run
SQL queries on Excel files.



Update or roll back Power Automate for
desktop
Article • 03/12/2025

This article provides guidance on updating or rolling back Power Automate for desktop
and the machine runtime app, and addresses compatibility concerns.

Update Power Automate
Learn how to install Power Automate, including options for silent installation. You can
manage manual updates and update notifications through the Power Automate for
desktop console and the machine-runtime app.

To prevent users from manually updating Power Automate and receiving update
notifications, a registry key is available. Learn more in Prevent users manually updating
Power Automate for desktop.

Backward compatibility
Power Automate maintains backward compatibility, ensuring that users who update to
the latest version retain functionality and access to their previous work. Newer versions
of the software are designed to operate seamlessly with desktop flows created with
older versions.

Desktop flows are stored in the Process Dataverse table and aren't affected by software
updates.

Each desktop flow is associated with the version of Power Automate for desktop with
which it was created or modified. To update a desktop flow version, edit and save it with
a different software version.

７ Note

Updating the flow properties doesn't change the flow version.

Determine the version associated with a desktop flow:

1. Sign in to the Power Automate portal .
2. Select your environment.
3. Select Tables from the left navigation pane.



4. Change the table filter to All and search for the Process table.
5. Open the Process table and filter by Category = Desktop Flow.

The clientversion property in the Metadata column shows the last Power Automate for
desktop version used to save the flow.



Roll back Power Automate
Rolling back Power Automate isn't supported. The latest version is always installed when
you download using an MSI installer or from Microsoft Store.

） Important

If you require access to an older version for business continuity purposes,
contact Microsoft Support.
To roll back Power Automate, you're required to uninstall the current version
before installing the desired one.

Forward compatibility
Forward compatibility with Power Automate isn't guaranteed. Updates, such as new
features, product enhancements, and fixed functionalities, might not be supported by
older versions. This can lead to potential compatibility issues.



Flows created or edited using a newer version of Power Automate might not work
correctly if you try to edit or run them with an older version of the software. This
scenario might result in the following error message:

This flow has been generated by a newer Power Automate version than the one

currently installed. Download and install the latest version of Power Automate and

try again.

To resolve this issue, update Power Automate for desktop to the version used to create
or edit the flow, or a newer version.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Configure connection strings for
database related actions
Article • 10/23/2024

Summary
This article provides a detailed explanation of how to properly configure and test a
connection string for database related actions.

Open SQL Connection Guide
Power Automate for desktop uses the same functionality provided in Windows when
creating Universal Data Link (UDL) files (Test OLE DB connectivity to SQL Server by using
a UDL file). Any file created like {file name}.udl triggers the procedure described in the
following documentation. This means you can manually create a UDL file to test the
connection with the database.

The following available providers refer to different kinds of relational databases:



The most common database providers used are Microsoft SQL Server, Oracle, MySQL,
and PostgreSQL.

Microsoft SQL Server
Microsoft SQL server (MSQL) requires Microsoft OLE DB Provider for SQL Server, which
is shown in the following configuration:

Assuming the server can be pinged, the server name can also be {ServerDNS}{SQLDNS} . If
the server has access to active directory, Windows NT can be used for authentication.

MySQL, Oracle SQL, PostgreSQL, and other
relational providers
MySQL, Oracle SQL, PostgreSQL, and other relational providers work with “Microsoft
OLE DB Provider for ODBC”. In order to create a connection with the SQL server, you
need to download and install the relevant ODBC driver. Creating a connection follows
the same procedure for every provider, with the sign in only being different. The
following screenshot is an example for MySQL:



Select Use connection string and build the connection string manually using the
provider menu.



Here you choose the file name of the connection. Creating a connection file allows you
to use a previously created login and generate the connection string immediately,
without having to sign in to the SQL server again.

At this point, if you successfully installed the relevant ODBC driver, you see it in the list.



Create a data source file by specifying the full path. Once the data source file is created,
you are directed to the provider configuration screen. Each provider has different
configuration steps at this point. The following example shows configuration for MySQL:

Enter all the required information and test the connection. If the connection is
successful, the test will confirm it:



Select OK and the connection string is generated.

Check the Allow saving password option, so that the provider also includes the
password in the connection string, and select OK, otherwise the connection fails.

７ Note

Due to a known issue in the connection string builder tool (Windows related UDL
functionality), the connection string sometimes has to be manually copied and
pasted from the provider's connection string field into the “Open SQL connection”
action input.

Potential solutions to connectivity issues other
than wrong configuration

Check SQL server configuration:
Make sure the SQL server is configured to listen to the appropriate network
interface or IP address.

Verify network connectivity:
Make sure that both the host machine and the target server are connected to
the same network and can communicate with each other. Ping is a good initial
test, but you should also confirm that there are no network-level restrictions or
firewalls blocking the SQL server port between the host and the target machine.

Check firewall settings:
Make sure the firewall on the target machine allows incoming connections to
the SQL port. You might need to add a rule to the firewall configuration to



permit incoming traffic on SQL’s port. The exact steps depend on the operating
system and firewall software running on the target machine.

Verify SQL server user and permissions:
Check if you have a SQL user account that allows connections from the host
machine. Make sure there's a user account that allows connections from the IP
address or network range of the host machine.

Test connectivity using SQL client:
From the host machine, attempt to connect to the SQL server on the target
machine using a SQL client tool, such as MySQL Workbench or the command-
line client. Specify the IP address or hostname of the target machine, the port
number, and the appropriate SQL user credentials. If the connection fails, take
note of any error messages, as they can provide further insights into the issue.

Verify SQL service status:
Verify that the SQL service is running on the target machine. If it isn't running,
start it using the appropriate commands for your operating system (for
example, systemctl start MySQL  for systems that use Systemd).

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Configure Power Automate for desktop proxy
settings
Article • 06/17/2024

To reach Microsoft's cloud services, it might be necessary for web requests originating from various Power
Automate for desktop components to be directed through a network proxy server.

When to configure proxy settings
Configure proxy settings when you’re connected to the internet using a proxy server.

The following are some of the proxy related errors you might encounter in a Power Automate for desktop
component:

System.Net.WebException: The remote server returned an error: (407) Proxy Authentication Required

System.Net.WebException

This issue might occur if Power Automate for desktop is installed by someone other than the intended user,
such as help desk personnel or through automated deployment solutions like Configuration Manager.

The proxy server in your network requires authentication.

The communication with the cloud services requires network proxy authentication.

During startup Power Automate couldn't sign you in. The proxy server in your network requires

authentication.

How to configure proxy settings
Configure how Power Automate for desktop interacts with a proxy server using the Power Automate proxy
configuration files. As an alternative, you can use the Windows registry to configure proxy settings that aren't
available in the proxy configuration files.

） Important

From Power Automate for desktop version 2.45, the proxy settings can be configured in centralized way,
through the Power Automate proxy configuration files, and are not overridden on a product upgrade.
It is suggested that you configure the proxy settings using only the Power Automate proxy
configuration files, as they apply to all the on-premises components. Proxy settings configured through
Windows registry apply only to a subset of components like the Console and Designer.
If a proxy setting is configured in both Windows registry and configuration files, the registry key takes
precedence. Learn how to configure proxy settings through Windows registry

ﾉ Expand table



Proxy setting Description Configuration file element/value Registry key

Proxy server The proxy address proxyaddress="your_proxy_address" ProxyServer
and port

Use default Authenticate to the useDefaultCredentials="True" UseDefaultProxyCredentials
credentials proxy server with

default account
credentials

Bypass proxy Don't honor the enabled ="False" DisableWindowsProxy
server Windows Proxy

settings and bypass
the proxy server

Bypass list of IP Provide a set of <bypasslist> <add address="bypassed_address" /> ProxyBypassList
addresses regular expressions <add address="bypassed_address" /> </bypasslist>

that describe
addresses that don't
use a proxy

Use network Authenticate with a Not applicable ProxyNetworkCredentialsKey
credentials generic credential

from Windows’
Credential Manager

Automatic Location of the proxy scriptLocation="your_proxy_script_location" Not applicable
detection of configuration script
proxy
configuration
script

How to update proxy configuration files
All proxy configuration files are stored in the installation folder and are listed in the following table. The default
installation folder location is "C:\Program Files (x86)\Power Automate Desktop".

ﾉ Expand table

Proxy file Related component Description Component Account type
type

PAD.Proxy.config All Power Automate for desktop Console, Application User
application components Designer,

some machine
runtime app
functionalities
such as list
environments
and edit
machine
details, etc.

UIFlowService.Proxy.config UIFlowService.exe The Power Service Virtual account
Automate
service
(UIFlowService)
communicates
with Power
Automate
cloud services



Proxy file Related component Description Component Account type
type

for machine
registration
and running
desktop flows

Microsoft.Flow.RPA.LogShipper.Proxy.config Microsoft.Flow.RPA.LogShipper.exe Logs collector Service NetworkService
service

Microsoft.Flow.RPA.UpdateService.Proxy.config Microsoft.Flow.RPA.UpdateService.exe Update Service System
applications
service

To configure the proxy settings:

1. Close all instances of Power Automate for desktop.

Ensure that the icon doesn't exist in the system tray.
Ensure that no processes are running in the background using Windows Task Manager.

2. For all the proxy files, edit each file with administrator rights as shown in the following examples:

Example #1 – Configure proxy with address and authenticate with default account credentials

XML

<defaultProxy useDefaultCredentials="True"> 
    <proxy
      bypassonlocal="True"
      proxyaddress="replace_with_your_proxy_address"
    />
</defaultProxy>

Example #2 - Configure proxy with script location and authenticate with default account credentials

XML

<defaultProxy useDefaultCredentials="True"> 
    <proxy
      scriptLocation="replace_with_your_proxy_script_location"
    />
</defaultProxy>

Example #3 - Configure proxy with address and don't authenticate with default account credentials

XML

<defaultProxy> 
    <proxy
      bypassonlocal="True"
      proxyaddress="replace_with_your_proxy_address"
    />
  </defaultProxy>

For more examples of how to update proxy configuration files, refer to .NET documentation.

3. Save the changes.

4. Restart Power Automate for desktop.



5. Restart the Power Automate services:
a. In Windows, open the Services desktop app. Press Windows + R  to open the Run box, enter services.msc,

and then press Enter  or select OK.
b. Look for Power Automate service, Power Automate log shipper service, and Power Automate update

service.
c. Right-click on each service and select Restart.

７ Note

If the new proxy settings do not take effect even after restarting the services, try clearing the internet cache
from your system. Go to Control Panel, search for and open Internet Options. From the General tab, select
Delete. Ensure that at least Temporary Internet files and Cookies are selected, and select Delete.

For authenticated proxy servers, change the "Power Automate
Service" (UIFlowService.exe) account with an allowed domain service
account
To change the on-premises Service account, use the Troubleshoot tab in the Power Automate machine runtime
application or use the TroubleshootingTool.Console.exe command line utility.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Reduce the size of desktop flows in a
solution
Article • 07/16/2024

This article provides a workaround to reduce the size of desktop flows in a solution by
removing all UI element screenshots of the flows. The objective is to minimize the total
size of the solution to prevent export failures caused by its size.

UI element screenshots help in identifying the captured UI elements when creating a
flow. However, they don't affect the flow's operation or modification and can safely be
removed.

Ｕ Caution

Remove only the Desktop flow ui element screenshot objects from the solution.
Removing any other desktop flow binary object will result in data loss for the
desktop flow, and you will encounter issues editing or running the flow in the
target environment.

７ Note

This workaround applies only to desktop flows saved in v2 Dataverse schema.
Learn more about size limit related errors during flow save at Exceeded size
limit.

To remove all UI element screenshots of desktop flows within a solution:

1. Sign in to the Power Automate portal .

2. Go to Solutions.

3. Select the solution that contains one or more desktop flows.

4. Select all items with name Desktop flow ui element screenshot.

5. Select Remove > Remove from this solution.





Feedback
Was this page helpful?  Yes  No

Provide product feedback



Restore a deleted desktop flow
Article • 03/06/2025

This article provides solutions and workarounds to fully or partially recover a deleted
desktop flow.

７ Note

The solutions and workarounds provided first in this article apply to users who sign
in with work or school accounts, or organization premium accounts. The last
solution applies to users who sign in with Microsoft accounts.

Fully restore a deleted desktop flow
Restore a deleted desktop flow with a solution or an environment backup.

Restore with solutions
As a prerequisite, the deleted desktop flow should be part of a solution that was
previously exported locally.

To restore the flow, import the solution that contains the deleted flow. Learn more at
import a solution.

Restore with an environment backup
To restore the deleted flow through a Power Platform environment backup:

1. Create a new Power Platform environment.
2. Restore a backup of the deleted flow’s environment to the new target

environment. Learn more at restore environments.
3. In the new environment, create a new solution and add the desktop flow.
4. Export the solution locally.
5. Go back to the initial pre-existing environment with the missing flow and import

the solution.

Partially restore a deleted desktop flow
You can partially restore a deleted desktop flow using local flow run data or audit logs.



） Important

Only the flow actions can be retrieved with this workaround. Any other flow
dependencies such as UI elements, images, and connection references can't be
retrieved.

Restore from local flow run data

Prerequisites

The flow was deleted from the Power Automate portal (not from the Power
Automate console).
The flow was run locally from the Power Automate console at least once.

Recover actions of the deleted flow

To recover the actions of the deleted flow:

1. Open %localappdata%\Microsoft\Power Automate Desktop\Console\Workspace\
<deleted desktop flow id>\<random string>\script.robin with notepad.

2. Copy all the lines right under the text @SENSITIVE.

If the flow is segregated into multiple subflows, then:

For the Main subflow, copy all the lines under text @SENSITIVE (not
included) and before the text FUNCTION <subflow_name_1> (not included).
For each of the other subflows, copy all the lines between FUNCTION
<subflow_name_x> (included) and END FUNCTION (included).

3. Open the Power Automate console and create a new flow.

4. Paste the lines of the Main subflow in the main workspace of the designer. Right-
click on the main workspace and select Paste.

5. Paste the lines of each subflow in the Subflows section of the designer. Right-click
on the Subflows section on top of the workspace and select Paste.

Restore from environment audit logs

Prerequisites



Verify auditing is enabled in both the environment and the Process Dataverse table.

Check if auditing is enabled

To check if auditing is enabled:

1. Go to Power Platform Admin Center  > Environments > your_environment_name
> Settings > Audit and logs.

2. Open Audit settings and verify Start Auditing is enabled.
3. Open Entity and field audit settings > filter for All tables > search for the Process

table > Properties > Advanced options. In the For this table section, verify Audit
changes to its data is enabled.

Recover actions of the deleted flow

To recover the actions of the deleted flow:

1. Go to Power Platform Admin Center  > Environments > your_environment_name
> Settings > Audit and logs > Audit summary view.

2. Filter by Delete events in the Process entity to locate the event that deleted the
flow.

3. Select the Delete event to open the record.
4. Copy the Definition field to a text editor and replace all the \r\n  characters with

new lines. Create a new line for each set of \r\n  characters.
5. Follow the same steps as described in Restore from local run data starting from

step #2.

Fully restore a deleted desktop flow using a
Microsoft personal account
When you have signed in with a Microsoft personal account, your desktop flows are
stored in OneDrive, under the path 'OneDrive\Apps\Power Automate Desktop For
Windows'.

You can follow the instructions in this article , to restore deleted desktop flows from
your OneDrive's recycle bin.

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Use logical operations on conditional
statements
Article • 02/24/2023

Data validation is a typical requirement in most business tasks and allows the
implementation of different behavior based on the available data.

Power Automate provides various conditionals that run blocks of actions only if a given
condition is met. If the condition is false, the actions are skipped.

７ Note

You can find more information regarding conditionals in Use conditionals.

While validating data, you may encounter cases where you need to check multiple
variables in the same part of the flow. For example, you may want to run a set of actions
only if two variables have specific values.

To implement this functionality, you can use either multiple nested If actions or a single
If action containing a complex logical expression.

To create a nested if statement, deploy an If action within the block of another If action.
All the actions inside the nested block will run only when both if statements are valid.

Although the implementation of nested if statements is convenient in some cases, it can
lead to complicated flows when many checks are needed.

A more efficient way to achieve the same results is the use of logical expressions. In the
following example, a single If action offers the same result as the previously nested If



actions.

The expression in the First operand field uses the AND operator to check whether the
variables A and B contain the values 10 and 5, respectively.

In general, logical operators can check multiple conditions simultaneously, allowing you
to implement more complex logic in a single expression. The AND operator returns
TRUE when both parts of the expression are valid. To check if either of the two parts (or
both) are valid, use the OR operator.

The Second operand field is populated with the value TRUE, while the selected
Operator is Equals to. This configuration makes the action check if the expression in the
First operand field is valid. If it's valid, the actions inside the if block will run. To check if
an expression is invalid, populate the value FALSE in the Second operand field.

７ Note

Logical expressions must be enclosed by percentage signs (%). The percentage sign
is used as a special character to denote variables and expressions. You can find
more information regarding the percentage notation and logical expressions in Use
variables and the % notation.



To handle more demanding validation scenarios, use multiple logical operators and
parentheses. Parentheses allow you to change the order of operations and work the
same way as in algebra and programming languages.

In the following example, the flow displays a dialog that prompts users to select one or
more files from their desktop. The If action checks whether the user has pressed Cancel
in the dialog or selected more than 100 files.

The first part of the expression on the left of the OR operator returns True when the user
presses Cancel in the dialog. In this case, there are no selected files to process, so the
flow has to stop.

The second part of the expression returns True when the user selects Open, but the
selected files are more than 100. This condition ensures that the user can't select too
many files and prevents the flow from running too long.

If one of these conditions (or both) is valid, the flow will stop and display a dialog
informing the user about the implemented limitations.






Use passwords
Article • 07/09/2024

Certain actions within desktop workflows require the use of passwords. For example, the
configuration of the Launch Excel action is essential for accessing an Excel file secured
by a password.

Desktop flows allow you to either provide a password directly or use a variable as a
password input in the designated password-required fields.



The option Direct password input uses encryption that is machine based to ensure a
maximum level of security.

） Important

Passwords entered in designated fields only work on the machine where they were
initially set. This is due to the machine-specific encryption used for direct password
inputs. If the flow is opened on a different machine, these passwords will not be
valid and will need to be re-entered.

Flows set up with direct password input in specific fields are shown as invalid when
opened on a machine other than the one where the password was first entered. In such
cases, you need to reenter the passwords.

To allow the use of such flows from other machines, you can use the Password input as
variable option.

） Important

Marking variables as sensitive does not secure hardcoded information. Avoid
embedding sensitive details such as passwords and PINs directly into action
properties like Set variable, even if you classify these variables as sensitive. While
desktop flow logs safeguard this data, hardcoded values remain exposed in both



the modal and the flow definition in Microsoft Dataverse. For additional guidance
on handling sensitive inputs in cloud flows, learn more in Manage sensitive input
like passwords.

To enhance the security of the "Password input as variable" feature, it's important to
designate the corresponding variable as sensitive.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Handle custom forms
Article • 02/24/2023

After creating a custom form, it's typical to check which button is pressed and handle
the gathered data accordingly.

To become familiar with this functionality, create a new custom form containing the
following elements:

A text input with ID Name that stores the name of a customer
A text input with ID LastName that stores the last name of a customer
A submit action with ID Save
A submit action with ID Cancel and the option Ignore provided inputs enabled.

The purpose of the flow is to check which form action is pressed. When the Save action
is pressed, the flow stores the gathered data into an Excel spreadsheet. When the
Cancel action is pressed, the flow stops and returns an error.

To implement this behaviour:

1. Deploy an If action and check whether the ButtonPressed variable contains the
value Save.



2. Inside the if block, launch an Excel spreadsheet. For this example, the spreadsheet
must contain two columns for the name and last name of the customer.

3. Use a Get first free column/row from Excel worksheet action to find the first
available row in the spreadsheet.



4. Deploy a Write to Excel worksheet action and write the customer's name in the
first column of the first available spreadsheet row.

All the form inputs are stored in the CustomFormData custom object variable. To
access the value of a specific element of the custom object, use the following
notation: %CustomFormData['ElementID']%.

７ Note

You can find more information regarding custom objects in Advanced data
types



5. Use a second Write to Excel worksheet action to write the customer's last name in
the second column of the first available spreadsheet row.

6. Save and close the Excel file using the Close Excel action.



7. Add an Else action inside the if block and use a Stop flow action to stop the flow
when the if statement is false.



8. When running the desktop flow, the displayed form will be similar to the one
presented in the following screenshot:



Share/export a desktop flow
Article • 07/29/2024

To replicate a desktop flow regardless of your account, edit it through the flow designer,
and copy the actions within a subflow.

The copied text can be sent directly to others users or saved to a text file for easier
sharing. The receiver can paste the text to a flow designer and run it.

７ Note

When copying actions, all their parameters, images, and UI elements are copied as
well. Only one subflow can be copied at a time. If there are more than one
subflows, repeat the procedure for each one individually or save the actions into
separate text files.

If you signed in with an organization premium account, you can also choose one of the
following methods:

1. Share the desktop flow directly through the Power Automate portal.

To share a desktop flow with other users in your organization, give them specific
permissions to access the flow. Learn more about sharing flows through the Power
Automate portal at Share desktop flows and Share desktop flows that contain
connector actions.

2. Export a solution that contains the desktop flow.

To move a desktop flow from one environment to another, host it in a solution. For
more information about importing flows into solutions and building solution-
aware flows, see Overview of solution-aware flows.

７ Note

If the solution fails to export because of its size, learn how to Reduce the size
of desktop flows in a solution.

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Run desktop flow from other desktop
flows
Article • 01/23/2025

Power Automate provides the Run desktop flow action to enable users to call desktop
flows while running other desktop flows.

Using this feature, you can split complicated flows into smaller ones and call them when
needed. For example, you can create separate flows to handle specific error scenarios in
the main flow.

To use the action, add it to the workspace and select the desktop flow you want to call.

When the action runs, depending on the state of the 'Wait for flow to complete' toggle,
the parent flow either pauses until the called desktop flow completes or runs in parallel.



If the called flow contains input variables, you're prompted to populate them. Likewise,
if the called flow has output variables, the action returns their values in the parent flow,
as long as the parent flow remains paused. If the child flow runs in parallel, no output
variables are produced.

） Important

Only one parallel flow is allowed to run at this time. If a second child flow is
set to run in parallel, an error occurs during runtime.
Child flows aren't allowed to run another child flow in parallel. A parallel flow
run is only allowed, if invoked directly from the parent (root) flow.

７ Note

You can find more information regarding input and output variables in Input and
output variables.

Power Automate doesn't allow two flows to directly or indirectly call each other to
prevent recursions. Additionally, a flow can't have more than 150 dependent flows. If a



dependent flow is missing or the parent flow has more than 150 dependencies, the flow
doesn't run.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Use connector actions in desktop flows
Article • 07/23/2024

In desktop flows, you can utilize not only the standard set of actions available in the
action library but also some of the most popular connectors. These connectors act as
proxies or wrappers around APIs, enabling the underlying services to communicate with
Microsoft Power Automate, Microsoft Power Apps, and Azure Logic Apps. They allow
users to link their accounts and use a collection of prebuilt actions and triggers to create
their apps and workflows.

Connections
Connectors require connections. In Power Automate, a connection refers to the
authenticated link between Power Automate and an external service. This connection
allows Power Automate to access and perform actions on data from various services,
such as Microsoft 365, SharePoint, SQL Server, and many others. Each connection is
specific to a user and requires authentication to ensure secure access to data and
services. This authentication is typically done using OAuth, API keys, or other
authentication methods provided by the external service.

Connection references
Desktop flows utilize connection references. In Power Automate, a connection reference
is an abstraction layer that points to a specific connection used by actions within your
flows. Instead of hardcoding connections directly into each action, connection
references allow for a more modular and reusable approach, enabling easier
management and sharing of flows, especially within Power Platform solutions.

Key concepts
The following are some key concepts of connection references:

Abstraction: A connection reference abstracts the connection details from the
actions, allowing you to manage connections separately from the logic of the flow.

Reusability: Connection references can be reused across multiple flows and
environments, simplifying the process of updating connections if credentials or
endpoints change.



Portability: Using connection references makes it easier to move flows between
different environments (for example development, testing, production) because
the connection reference remains consistent, even if the actual connection details
are different between environments.

Simplified management: By centralizing connection details, it becomes easier to
update or replace connections without needing to modify each individual action
that uses the connection.

Use a connector action in desktop flows
In Power Automate for desktop, you can find some of the most popular connectors (for
example, SharePoint, Office 365 Outlook, and OneDrive) in the standard library of
actions. You can use their actions the same way every other action is utilized. Either
double-click or drag and drop the desired action in the designer canvas.

If there are no compatible connection references available for the connector you want
to use, a prompt appears for you to create a new connection reference.

To select a connection reference, in the action configuration window, select the socket
icon. Once you select it, all the available connection references compatible with the
connector appear.



To create a new connection reference, select the Add new connection reference button.
You can use an existing connection that is compatible with the respective connector and
create a new connection reference for it. Alternatively, you can create a new connection
and include it in a new connection reference.

Once the connection reference is set up, you're all set. You can now access the
underlying data and configure the respective action as desired.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Share desktop flows that contain
connector actions
Article • 03/21/2025

Sharing a desktop flow that uses connectors follows the same principles as any other
desktop flow. However, there are a few more steps required due to the connection
references in the desktop flows.

７ Note

Connectors require connections. In Power Automate, a connection refers to the
authenticated link between Power Automate and an external service. This
connection allows Power Automate to access and perform actions on data from
various services, such as Office 365, SharePoint, SQL Server, and many others. Each
connection is specific to a user and requires authentication to ensure secure access
to data and services. This is typically done using OAuth, API keys, or other
authentication methods provided by the external service.

） Important

Sharing a desktop flow does not automatically provide access to the underlying
connections utilized.

You can share a desktop flow that uses connections with:

users (run-only level access)
co-owners

Run a shared desktop flow that contains
connector actions as a user
Makers with user access on a shared desktop flow must always bring their own
connections when they run the flow. They can only perform attended console initiated
runs.

Once you run a shared desktop flow that contains connector actions through the
console, a prompt appears for you to provide a valid connection to be used.



If there are compatible existing connections available, the first one is selected by default.

Run a shared desktop flow that contains
connector actions as a co-owner
Co-owners have the ability to modify shared desktop flows in addition to running them.
Co-owners have the ability to embed the connection references (and as a result their
underlying connections) to the desktop flows they have access to. By embedding a
connection reference to a desktop flow, you allow other co-owners to have access to the
underlying data provided by it, for both modifying as well as running the desktop flow.

７ Note

You can only embed or remove connection references that you own from a desktop
flow. Connection references added by other co-owners can only be managed by
them.

） Important

Embedded connection references are only available to other co-owners in the
scope of the shared desktop flow.

Cloud initiated runs



To successfully invoke a desktop flow containing connector actions from a cloud flow, it
must meet the following two requirements:

The desktop flow must use the Power Automate v2 schema.
All of its connection references must be marked as embedded.

To embed a connection reference to a flow that you have access to as a co-owner:

1. Select the desktop flow in Power Automate  and then select Details.

2. In the Connection references section, select Manage.

In the Connection references screen, all of the connection references used in a
flow are displayed.

3. Set the Embed in desktop flow option to Yes to enable it.

4. After you confirm your selection, the connection reference is embedded in the
desktop flow.

Known limitations



Required connection references not automatically included when
importing desktop flows

When importing a desktop flow with embedded connection references in a solution, the
required connection references aren't automatically included. To work around this
current limitation, explicitly include the required connection references in the solution
alongside the desktop flow.

Console runs
Similar to the user use-case, when you run a shared desktop flow with connector actions
through the console, a prompt appears for you to provide a valid connection to be used.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Set screen resolution on unattended
mode
Article • 04/01/2025

In some scenarios, Power Automate might run unattended flows in a lower resolution
than the one used to develop the flows. As a result, some UI elements could be hidden
from the screen, while any images captured might not be identified at runtime under a
different resolution. This might cause flows to fail. In such cases, you can follow one of
the two approaches explained in this article to adjust the screen resolution used for
unattended flows accordingly.

７ Note

The screen resolution can be adjusted per target machine, not per flow. If you need
one of your unattended flows to run in another resolution, a different target
machine needs to be used.

With Windows registry
Set the screen resolution for unattended flows using the Windows registry. This method
can be used with Power Automate flows starting with version 2.35.

） Important

Setting the ScreenResolutionEnabled registry key to 1 overrides the settings in the
UIFlowService.exe.config file. The registry settings for screen resolution persist after
an upgrade of Power Automate Desktop, the UIFlowService.exe.config file is
overwritten with default values during upgrades.

1. This task explains how to modify the Windows registry. We recommend that you
first back up any registry keys you modify, such as the Power Automate Desktop
key. More information: How to back up and restore the registry in Windows

2. Open the registry editor (Windows key + R, and type 'regedit') and expand the
HKEY_LOCAL_MACHINE hive.

3. Locate the Screen key in SOFTWARE\WOW6432Node\Microsoft\Power Automate
Desktop\Global. If it doesn't exist, create it: right-click the Global key, select New >



Key, type Screen, and press Enter.

4. Locate the following values in SOFTWARE\WOW6432Node\Microsoft\Power
Automate Desktop\Global\Screen and set the corresponding values. If the value
names don’t exist, create them. To create them, right-click the Screen key, select
New > DWORD (32-bit) Value, type ScreenResolutionEnabled, and press Enter.
Double-click ScreenResolutionEnabled, enter 1, select Decimal, and then select
OK. Repeat these steps for each value in the following table.

When editing DWORD values, be sure to select the Decimal base (hexadecimal is
selected by default), to avoid having your values interpreted as hexadecimal which
results in incorrect resolution settings.

） Important

The registry keys are in the 32-bit registry because the Power Automate installer
writes its registry settings there. However, if the screen resolution keys are set in
the 64-bit registry (for example, SOFTWARE\Microsoft\Power Automate
Desktop\Global\Screen), they take precedence. If the settings don't work as
expected, check both locations and use only one.

ﾉ Expand table

Key Name Type Value

SOFTWARE\WOW6432Node\Microsoft\Power ScreenResolutionEnabled DWORD If set to
Automate Desktop\Global\Screen '1', will

enable the
custom
resolution
settings.

SOFTWARE\WOW6432Node\Microsoft\Power Width DWORD Set the
Automate Desktop\Global\Screen screen

resolution



Key Name Type Value

width,
such as
1920.

SOFTWARE\WOW6432Node\Microsoft\Power Height DWORD Set the
Automate Desktop\Global\Screen screen

resolution
height,
such as
1080.

SOFTWARE\WOW6432Node\Microsoft\Power Scale DWORD Set the
Automate Desktop\Global\Screen screen

resolution
scale, such
as 100.

With UIFlowService.exe.config file (deprecated)
） Important

The UIFlowService.exe.config file is overwritten with default values during
upgrades and screen resolution settings will therefore be reset. We recommend
setting the resolution with Windows registry settings instead.

To change the resolution in which unattended flows are run by editing the
UIFlowService.exe.config:

1. Go to C:\Program Files (x86)\Power Automate Desktop, and then open the
UIFlowService.exe.config file.

2. Set the value of the
Microsoft.Flow.RPA.UIFlowService.ScreenDefaultResolutionEnabled element to
true.

XML

<add 
key="Microsoft.Flow.RPA.UIFlowService.ScreenDefaultResolutionEnabled" 
value="true" />

3. Change the values of the following elements to the proper screen resolution width,
height, and scale, respectively. The following code sets the default resolution to



1920 x 1,080 pixels.

XML

<add 
key="Microsoft.Flow.RPA.UIFlowService.ScreenDefaultResolutionWidth" 
value="1920" />
<add 
key="Microsoft.Flow.RPA.UIFlowService.ScreenDefaultResolutionHeight" 
value="1080" />
<add 
key="Microsoft.Flow.RPA.UIFlowService.ScreenDefaultResolutionScale" 
value="100" />

4. Restart the UIFlowService service.

To restart the service, start Windows Task Manager, select the Services tab, right-
click the UIFlowService service, and then select Restart.



７ Note

An alternative to restarting the UIFlowService is to restart your machine.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Run Power Automate with elevated
rights
Article • 02/24/2023

During desktop flow development, some actions may need to access resources with
elevated rights, such as files and applications. To run these actions successfully, launch
Power Automate as administrator:

） Important

To run desktop flows through the flow designer or the console to interact with
applications running with elevated rights, launch Power Automate as an
administrator.
When a desktop flow is triggered by a cloud flow, the actions contained in the
desktop flow that require elevated privileges won't have any effect. Therefore,
Power Automate won't be able to access applications that run with elevated
rights.

1. Before launching Power Automate, ensure that the application is closed, and
doesn't appear on the Windows system tray.

2. Right-click on the Power Automate icon and select Run as administrator.

3. To confirm that Power Automate is launched with administrator rights, open
Windows Task Manager, navigate to the Details tab, and check that Power
Automate runs with elevated privileges.






Extract text from a Word document
using VBScript
Article • 02/24/2023

Although you can use optical character recognition (OCR) to extract text from Word
documents, this approach can become complicated for multi-page documents that
require scrolling.

A more efficient way to extract text from Word documents is the use of VBScript. Power
Automate provides the Run VBScript action that enables you to run scripts on your
desktop.

To extract text from a Word document, deploy the Run VBScript action and paste the
following code in the VBScript to run field.

VBScript

Dim Word

Dim WordDoc

Dim var

Set Word = CreateObject("Word.Application")


'Open the document

Set WordDoc = Word.Documents.open("%FilePath%")


'Read the document

NumberOfWords = WordDoc.Sentences.count

For i = 1 to NumberOfWords

WScript.Echo WordDoc.Sentences(i)
Next


'Close the document

WordDoc.Save

Word.Quit


'Release the object variables

Set WordDoc = Nothing

Set Word = Nothing




The script contains a variable named FilePath that specifies the file path of the Word
document. You can initialize this variable using a Set variable action before the Run
VBScript action or replace it with a hardcoded value.



The Run VBScript action stores the extracted text by default in a variable named
VBScriptOutput. You can use this variable as an input in the available Text actions to
manipulate the retrieved text.



Pass a datatable from a cloud flow to a
desktop flow
Article • 02/24/2023

Some automation scenarios require users to pass data in tabular form from a cloud flow
to a desktop flow. To implement this functionality, replicate the following steps:

1. Create a new input variable of a datatable datatype. In this example, the input
variable is named DataInput.

2. Inside your cloud flow, initialize a new variable of type array with an array of
objects (JSON) representing your datatable. Then, use it as an input value in the
Run a flow built with Power Automate for desktop action.



In the following example, you can see the structure of a JSON block:

JSON

[

 {

 "Name": "Tania",

 "Last Name": "Agius",

 "Email": "taniaagius@contoso.com"

 },

 {

 "Name": "Ditiro",




 "Last Name": "Kgosi",

 "Email": "ditirokgosi@contoso.com"

 },

 {

 "Name": "Zoltan",

 "Last Name": "Gal",

 "Email": "zoltangal@contoso.com"

 }

]


To find more information regarding passing data from cloud flows to desktop flows,
refer to Trigger desktop flows from cloud flows.



Delete desktop flow run history data
Article • 04/11/2023

Effective management of historical data generated by Microsoft Power Automate  can
be important to ensure that your Microsoft Dataverse environments remain efficient and
cost-effective. By implementing data retention policies and utilizing features like Bulk
Record Deletion of Microsoft Dataverse and the Power Platform admin center, you can
proactively manage the accumulation of historical data.

In the following sections, we'll walk you through the steps on how to purge historical
desktop flow data from your environment using Dataverse's built-in bulk-delete feature.
This feature allows you to quickly and easily remove large amounts of data from your
environment in compliance with your specific data retention policies, ensuring efficient
data storage and performance management. In addition to ad-hoc bulk-delete jobs, you
could also schedule recurrent bulk-delete jobs that will find and delete records in a table
that are, for example, OlderThanXDays.

We'll cover how to identify the desktop flow data that could be purged, how to create a
bulk delete job to delete the data, and how to monitor the progress of the job.

Ｕ Caution

Before deleting Dataverse data, it is important to understand that the data is
permanently deleted from your environment, and there's no way to recover
individual records once they've been deleted.

７ Note

To create bulk-delete jobs in Dataverse, you need to have the Bulk Delete privilege
in at least one of the roles that have been assigned to you.

Desktop flow tables with potentially large data
volumes

Display System name Details
name



Display System name Details
name

Flow flowsession The Flow Session table stores metadata about desktop flow runs,
Session such as the start time, completion time, context, detailed action

logs and status of the run. The Regarding field in this table is
referencing a desktop flow ID (workflowid) for which the flow
session record has been created for.

Workflow workflowbinary The Workflow Binary table stores binary data for all types of
Binary workflow runs, such as the input and output data and exceptions

screenshots if there's desktop flow runs.

） Important

The Flow Session and Workflow Binary tables in Dataverse have a cascade
relationship. The cascade relationship between these two tables ensures that when
a desktop flow run is deleted from the Flow Session table, all associated Workflow
Binary records are also deleted. This helps to keep the Dataverse database clean
and avoids orphaned records.

Creating a bulk-delete job to delete desktop flow runs
To bulk-delete data in Dataverse, follow the detailed steps below.

） Important

Before performing any bulk delete operations, it is important to thoroughly test
and review your filter results since bulk-delete operations are irreversible.

1. Sign in to the Power Platform admin center.

2. Select Environments in the left navigation pane, select your environment, and
then select Settings on the top menu bar.

3. Select Data management > Bulk deletion.

4. From the Bulk Record Deletion grid, select New on the command bar. This will
open the Bulk Deletion wizard that allows you to define a query for the records
you want deleted.

5. In the Look for list, select the Flow Sessions table from the list.



6. In the search criteria area, add desired filter that should return the records that you
want to be deleted. Here’s an example that will find all desktop flow runs that are
older than 6 months (format: Field | Filter Type | Value):

Completed On | Older Than X Months | 6

7. Select Next.

8. In the Name text box, type a name for the bulk deletion job for example “Bulk-
delete of desktop flow sessions older than 6 months”.

9. Select a date and time for the job start time (preferably a time when users are
typically not online).

10. Select the Run this job after every check box, and then in the days list, select the
frequency you want the job to run.

11. If you want a notification e-mail sent, select the Send an email to me
(email@domain.com) when this job is finished check box.

12. Select Next, review the bulk deletion job, and then select Submit to create the
recurring job.

Advanced record filtering
Using Dataverse's Bulk Deletion Wizard, you can create more advanced queries to filter
your records using more complex filter criteria options. For instance, you could use
grouping features such as AND and OR and even search for data in related tables to
combine multiple conditions into a single query.

In the following filter example screen we're searching for all Flow Session records that
are older than six months, with a status of Canceled, Failed or Succeeded, and
associated with a specific flow type and user who initially created the flow. To achieve
this, we've applied multiple Group AND options and used the Regarding (Process)
fields of the related Process table to filter based on Desktop Flow Type and Created By
a specific user.



Monitoring bulk-delete jobs
To monitor Dataverse bulk-delete jobs, please follow these steps:

1. Sign in to the Power Platform admin center.

2. Select Environments in the left navigation pane, select your environment, and
then select Settings on the top menu bar.

3. Select Data management > Bulk deletion.

4. From the Bulk Record Deletion grid, you can use the view selector to view the
completed, in-progress, pending, and recurring bulk deletion system jobs.

5. The Recurring Bulk Deletion System Jobs view shows the job definitions for the
bulk deletion system jobs that you've created together with the ones that are
included out of the box. If you open one of these recurring bulk deletion system
job records, you can see the query the job uses to identify which records to delete
and the schedule the job runs on. For these out-of-the-box system jobs, you can't
modify the query used by the system job, but you can modify the schedule the job
runs on.



6. If you update the view selector to show jobs that have already been scheduled, are
in progress, or executed, you can cancel, resume, or postpone the job. You can find
these options in the Actions menu when you open the record.

Learn more
Delete data in bulk
Remove a large amount of specific, targeted data with bulk deletion
View and take action on bulk deletion jobs



Timeout configuration for UI and
browser automation
Article • 12/04/2024

Power Automate for desktop provides various components, including the designer,
recorder, Power Automate agent for virtual desktops, and actions from UI automation
and browser automation groups. However, in some cases, these components might fail
due to time-out constraints. To overcome this issue, users can adjust the time-out
settings for distinct desktop and web automation scenarios. When you modify a
configuration file and add the appropriate key or value pairs for the desired scenarios,
users can customize the timeout duration for specific operations based on the specified
configuration value.

Before creating the configuration file
Before creating the configuration file, it's crucial to make sure that Power Automate for
desktop and all its components aren't running. To do this, open Task Manager, go to the
Details tab, and sort the processes by name. Check that no process related to Power
Automate is currently active.

If you need to stop the 'PAD.BrowserNativeMessageHost' process, you should first
deactivate the Power Automate web extension and close all browser windows. Once you
have finished configuring the settings, you can re-enable the Power Automate web
extension.

How to create the configuration file
1. In File Explorer, go to the %LOCALAPPDATA%\Microsoft\Power Automate Desktop

folder.
2. Check if a folder named Configurations exists. If not, create it.
3. Create a new file with name UIAutomationTimeOut.config inside the

Configurations folder.
4. The template of the XML code to be copied inside the file can be viewed in the

following XML snippet. Add the key and value pairs you need, inside the
appSettings  section. Replace everything between <appSettings>  and
</appSettings> .

７ Note



The provided sample is only a template and is non-functional. Populate it with the
required key-value pairs to make it functional.

XML

<?xml version="1.0" encoding="utf-8" ?> 

<configuration> 

      <appSettings> 

          <!-- Please add here the key values for the configuration. See 
examples below: 

          <add key="AutomationServerEndpoint.DesignTime.ConnectionTimeout" 
value="00:01:00" /> 

          <add key="AutomationServerEndpoint.DesignTime.CallTimeout" 
value="00:00:30" /> 

           --> 

      </appSettings> 

</configuration>

5. Save the file.
6. Open Power Automate for desktop.

Key values editing
Each XML configuration item follows these rules:

key : The name of the configuration item. This is a reserved word and should be
listed in the XML configuration file for the elements that follow:

Automation Server : This is a Power Automate for desktop unit, where several
other Power Automate for desktop components such as designer, robot,
recorder, and so on, that utilize desktop and web automation capabilities,
communicate with to perform various operations either at design or run time:

AutomationServerEndpoint.DesignTime.ConnectionTimeout : The timeout period
for designer or recorder to establish a connection with the Automation
Server. This configuration might be useful when an error that indicates that a
connection couldn't be successfully established at a specific period of time is
shown. Increasing the default timeout value of this setting could resolve the
issue.



AutomationServerEndpoint.DesignTime.CallTimeout : The timeout period for
designer or recorder to send and receive messages with the Automation
Server through an already established connection. This setting can be useful
in cases when capturing an element, either using the UI element picker
(designer) or the recorder, takes too long without capturing the element.
Increasing the timeout value to a greater value than the default might resolve
the issue.
AutomationServerEndpoint.Runtime.ConnectionTimeout : The timeout period
for the Power Automate for desktop robot to establish a connection with the
Automation Server when a UI automation or a browser automation action is
executed. This configuration might be useful when an error that indicates
that a connection couldn't be successfully established at a specific period of
time is shown.
AutomationServerEndpoint.Runtime.CallTimeout : The timeout period for the
robot to send and receive messages with the Automation Server through an
already established connection, when a UI automation or browser
automation action is executed. This configuration can be useful in cases
where the execution of a UI or browser automation action might take too
much time and fails due to timeout.
AutomationServerEndpoint.ExtractDataFromWeb.ConnectTimeout : The timeout
period for the ExtractDataFromWeb  module to establish a connection with the
Automation Server. This setting might be useful when an error that indicates
that a connection couldn't be successfully established at a specific period of
time when trying to capture the data to be extracted at design time.
Increasing the default timeout value of this setting might resolve the issue.
AutomationServerEndpoint.ExtractDataFromWeb.CallTimeout : The timeout
period for the ExtractDataFromWeb  module to send and receive messages
through the connection established with the Automation Server. This setting
might be useful during the design time when trying to capture the data to be
extracted at design time but the elements aren't captured without any
specific error.

SAP Bridge : This is the Power Automate for desktop module where several UI
automation modules communicate with SAP bridge to perform various
operations related to SAP applications:

Sap.Bridge.Client.OpenTimeout : The timeout period for a Power Automate
for desktop client module (designer, robot, recorder) to open a connection
with the SAP bridge. This setting might be useful during runtime or design
time, when an error that indicates that a connection couldn't be successfully
established at a specific period of time with the SAP bridge is shown.
Increasing the default timeout value of this setting might resolve the issue.



Sap.Bridge.Client.SendTimeout : The timeout period for a Power Automate
for desktop client module (designer, robot, recorder) to send a message over
a connection established with the SAP bridge. This setting might be useful
during runtime or design time, when an error that indicates that a message
couldn't be sent at a specific period of time to the SAP bridge is shown.
Increasing the default timeout value of this setting might resolve the issue.

** Java Bridge : This is the Power Automate for desktop module where several UI
automation modules communicate with the Java bridge to perform various
operations related to Java applications.

Java.Bridge.Client.ConnectTimeout : The timeout period for a Power
Automate for desktop client module (designer, robot, recorder) to connect
with the Java bridge. This setting might be useful during runtime or design
time when an error that indicates a connection couldn't be successfully
established at a specific period of time with the Java bridge is shown.
Increasing the default timeout value of this setting might resolve the issue.
Java.Bridge.Client.ReadWriteTimeout : The timeout period for a Power
Automate for desktop client module (designer, robot, recorder) to send or
receive messages through a connection established with the Java bridge. This
setting might be useful during runtime or design time, when an error that
indicates that a message couldn't be sent, or a response couldn't be received
at a specific period of time when communicating with the Java bridge is
shown. Increasing the default timeout value of this setting might resolve the
issue.

Web Extensions Message Proxy :
WebExtensionsMessageProxy.OpenTimeout : The timeout period for Power
Automate for desktop to open a connection with the browser web extension
message host. This setting might be useful during runtime or design time,
when an error is shown indicating that a connection couldn't be successfully
established at a specific period of time with the browser native message host.
Increasing the default timeout value of this setting might resolve the issue.
WebExtensionsMessageProxy.SendTimeout : The timeout period for Power
Automate for desktop to send a message through an established connection
with the browser web extension message host. This setting might be useful
during runtime or design time when an error that indicates that a message
couldn't be sent at a specific period of time to browser native message host.
Increasing the default timeout value of this setting might resolve the issue.

RDP.Client.ConnectTimeOut : The timeout period for a Power Automate for
desktop client module, running on the host, such as the designer or robot, to
establish a connection with the Remote Desktop agent that is running on the
remote machine. This setting might be useful in case a Remote Desktop



automation is performed and an error that indicates that a connection with the
Remote Desktop Agent couldn't be established for a specific period of time.
Increasing the default timeout value of this setting might resolve the issue.
RDP.Client.CallTimeOut : The timeout period for a Power Automate for desktop
client module, running on the host, such as the designer or robot, to send or
receive messages through a connection with the Remote Desktop agent that is
running on the remote machine. This setting might be useful in case a Remote
Desktop automation is performed and an error that indicates a connection with
the Remote Desktop Agent that a message couldn't be sent or received for a
specific period of time. Increasing the default timeout value of this setting might
resolve the issue.
Recorder.LaunchBrowserTimeout : The timeout period for the launch browser
option inside the recorder. Increasing this might avoid issues with extension
installation popup windows appearing when choosing the option in the
recorder.

value : The timeout value. The value should be in the format HH:MM:SS. For
example, if you want to set the timeout to five seconds then use 00:00:05 as value.

Sample XML configuration file
XML

<?xml version="1.0" encoding="utf-8" ?> 

    <configuration> 

        <appSettings> 

            <!--Automation Server Endpoint Configuration for Designer --> 

            <add key="AutomationServerEndpoint.DesignTime.ConnectionTimeout" 
value="00:01:00" /> 

            <add key="AutomationServerEndpoint.DesignTime.CallTimeout" 
value="00:00:30" /> 

     

            <!--Automation Server Endpoint Configuration for Runtime --> 

            <add key="AutomationServerEndpoint.Runtime.ConnectionTimeout" 
value="00:05:00" /> 

            <add key="AutomationServerEndpoint.Runtime.CallTimeout" 
value="00:05:00" /> 



     

        <!--Automation Server Endpoint Configuration for ExtractFromWeb 
--> 

            <add 
key="AutomationServerEndpoint.ExtractDataFromWeb.ConnectTimeout"  
value="00:01:00" /> 

            <add 
key="AutomationServerEndpoint.ExtractDataFromWeb.CallTimeout"  
value="00:00:30" /> 

     

     

            <!--SAP Bridge Client Configuration --> 

            <add key="Sap.Bridge.Client.SendTimeout" value="00:10:00"/> 

            <add key="Sap.Bridge.Client.OpenTimeout" value="00:01:00"/> 

  

    <!--Java Bridge Configuration --> 

            <add key="Java.Bridge.Client.ConnectTimeout" value="00:00:05"/> 

            <add key="Java.Bridge.Client.ReadWriteTimeout" 
value="00:01:00"/> 

  

            <!-- Web Extensions Message Proxy--> 

            <add key="WebExtensionsMessageProxy.SendTimeout" 
value="00:01:00"/> 

            <add key="WebExtensionsMessageProxy.OpenTimeout" 
value="00:01:00" /> 

  

            <!--RDP Client Configuration--> 

            <add key="RDP.Client.ConnectTimeOut" value="00:00:10" /> 

            <add key="RDP.Client.CallTimeOut" value="00:00:15" /> 

  

    <!-- Recorder Configuration--> 

            <add key="Recorder.LaunchBrowserTimeout" value="00:00:10" /> 



 

       </appSettings> 

    </configuration>

Feedback
Was this page helpful?  Yes  No

Provide product feedback



How to configure the open terminal
session action
Article • 11/26/2024

This guide shows you how to configure the open terminal session action in Power
Automate for desktop. This action lets you interact with terminal emulation providers,
specifically Micro Focus Reflection Desktop and HLLAPI. Follow the steps to set up and
use terminal sessions efficiently, using these providers to automate your workflows.

Micro focus reflection
Micro Focus Reflection Desktop is a terminal emulation software by Micro Focus. To use
this provider, select the corresponding option in the Provider parameter of the Open
Terminal Session action. This option integrates exclusively with this specific terminal
emulation software, supporting versions 2011, 2014, 2016, and 2018.

Prerequisites
When installing Micro Focus Reflection Desktop, ensure the Application Programmer
Interface (API) is also installed.



Configuration
The configuration allows for two distinct connection methods:

Existing profile
Specify connection

Existing profile
This option starts a terminal session using a saved profile file with predefined settings.
It's an efficient way to start a session without specifying connection preferences.

Specify connection
Add all connection parameters in the action configuration, including the terminal host
type (IBM3270 or IBM5250), the host address, and the port.

７ Note



Launching a terminal emulation session using the Micro Focus Reflection provider
also initiates the terminal emulation software itself.

HLLAPI
HLLAPI is a terminal emulation communication protocol supported by nearly all terminal
emulation software. Power Automate for desktop provides a mechanism to locate the
terminal's HLLAPI implementation for use in flow execution. Since HLLAPI is widely
implemented, Power Automate for desktop can theoretically integrate with virtually any
terminal emulation software available on the market.

Configuration
The HLLAPI DLL path points to the DLL file location for the terminal emulation software.
This DLL contains the HLLAPI implementation from each vendor and is usually in the
product's installation directory. Common DLL files are HLLAPI32.dll or ehlapi32.dll.
Whlapi32.dll isn't supported.

The session name is a letter that corresponds to the active session and can be
configured in the terminal emulation software's options or preferences.



Both the short and long names must match the letter used as the session name in the
action configuration.

７ Note

Using the HLLAPI provider doesn't automatically start the terminal emulation
software. Manually launch the software first, for example, by using a Run
Application action.

Usage example
Launch the terminal with your connection preferences, save the configuration in an .rd3x
file, and use that file with a Run Application action to start the application.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Overview for configuring ALM for
desktop flows
Article • 09/07/2023

This article provides an overview for the tasks involved in how to set up a healthy
application lifecycle management (ALM) strategy for your Power Automate desktop
flows. For information about ALM in the Power Platform, go to Power Platform ALM
resources.

Follow the list of tasks described in this article to set up your ALM strategy for cloud
flows and desktop flows. To benefit from the latest features of desktop flows, we
recommend following those steps in an environment with schema v2 activated.

Task Description More information

1. Set up your DevOps Create your Azure DevOps or GitHub Continuous integration
project repository Create a project

2. Create and configure a How to create a Service Principal in Create a Service Principal
service principal Azure and link it to your environment Configure service

as an Application User connection using Service
Principal

3. Create a solution with Learn how to create and add your Create a solution and a
cloud flow, desktop flow cloud flow, desktop flow and publisher
and connection reference connection reference to your solution. Add desktop flow, cloud

flow and connection
reference

4. Configure an ADO Learn how to set up your ADO pipeline Build pipeline
pipeline to export and to export and commit changes into
commit into your your repository.
repository

5. Review your changes Learn how to compare changes Use Azure DevOps to see
between two versions of your solution diff

6. Share a machine with a Learn how to share a machine with a Share a machine with a
Service Principal and create Service Principal and create a Service Principal and
a connection connection to the machine create a connection

7. Create a setting file and Learn how to create a setting file for Prepopulate connection
configure connection your deployment and set the references for automated
references connection ID used by the connection deployment

reference.



Task Description More information

8. Build and deploy Learn how to build your application Build your solution
and deploy it Deploy your solution



Add a cloud flow, desktop flow and
connection reference to a solution
Article • 01/16/2025

If you've followed the article for configuring ALM for desktop flows, at this point you've
created a solution. Now, add a desktop flow and a cloud flow to this solution. If you
haven't created a solution yet, create a publisher and a solution

） Important

In order for a cloud flow to be added to a solution, the cloud flow has to be created
in the solution. You can't add a cloud flow to a solution after it's been created.

Create a desktop flow
1. Sign in to Power Automate , and then go to Solutions, and then open the

unmanaged solution you want or select New solution to create a solution.
2. Select New > Automation > Desktop flow.

You're redirected to Power Automate desktop, once you have finished editing your
desktop flow, go back to the solution page to see your desktop flow appear.

(Optional) Add your desktop flow connection
references



You might use connections inside your desktop flow. To easily export your desktop flow
to another environment, ensure that the connection references are added.

1. Select Add existing > More > Connection Reference.
2. Search for the connection reference that matches the one used in your desktop

flow.

If you export as a managed solution, you need this step to map your connection
reference to your connection used in Production.

Create a cloud flow
From within the solution, select New > Automation > Cloud flow > Scheduled.

You're redirected to the cloud flow designer. Edit to add an action with a desktop flow,
and if needed, create a connection. You need to use the Unattended run mode.

The connection you use won't be the connection that is used in your production
environment.



You see the cloud flow and its connection reference in your solution. Map the
connection when importing to the production environment.

Next steps
Configure your build pipeline to export your solution

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Compare your desktop flow changes
Article • 01/16/2025

When you commit a change to your repository by running your export pipeline, you can
see the differences between two versions of your solutions by going to Azure DevOps.

Compare the desktop flow definition
The desktop flow definition is stored in the Workflow folder in a file with the extension
.json.data.xml . From Azure DevOps , you can open the file on the History tab to
observe the difference.

New image or control added to the desktop
flow
When you add a new image or control to your desktop flow, a new folder is created in
the desktopflowbinaries folder. Each image has its own folder with a subfolder
containing the screenshot.

The image is stored so you can easily compare which control was removed or added
while authoring your desktop flow.



Related information
Overview for configuring ALM for desktop flows

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create a connection with a service
principal
Article • 03/18/2025

There are two solutions to use a connection with a service principal:

1. Create a connection using the service principal. This article details this solution.
2. Create a connection with a user principal and share it to a service principal. Learn

more in Set a run owner on a Desktop Flow connection.

To create a connection with a service principal, the best approach is to register the
machine using a service principal with silent registration. Alternatively, you can give
permissions to the service principal on the machine or the machine group and then
create a connection using the service principal.

Give permissions on the machine or machine
group
To give permissions on the machine:

1. Sign into Power Automate , and then select Machines on the left navigation
pane. If the item isn’t in the left navigation pane, select … More and then select the
item you want.

2. Select the machine or machine group you want to share.
3. Select Share, and then search for and select the Application User AAD in your

Dataverse instance.
4. Select User, and then select Save.



Create the connection using a service principal
Once you have shared the machine with the application user, create the connection. You
need to create the connection as the service principal. Creating a connection as a service
principal isn't supported with the Power Automate web portal. This is currently only
supported with a direct call to the Web API.

Request an access token
First, request an access token to interact with the Power Platform API. More information:
Request an access token.

Get the group ID of the machine or group
To be able to create the connection, get the group ID associated with the machine or
machine group.

If it's a group, you can go to Monitor > Machines > Machine groups and select
the group. You can then get the group ID from the URL.
If it's a machine, go to Data > Tables > All > Flow Machine Group. Search for your
machine in the list and display the column Flow Machine Group, it's the group ID
associated with your machine.

Create a connection using your service principal
To create a connection, send an HTTP PUT  to the Power Apps API to create the
connection, using the access token that you obtained earlier.

HTTP

PUT 
https://{ENVIRONMENT_ID_URL}.environment.api.powerplatform.com/connectivity/
connectors/shared_uiflow/connections/{CONNECTION_ID}?api-version=1
Content-Type: application/json
Host: {ENVIRONMENT_ID_URL}.environment.api.powerplatform.com
Accept: application/json
Authorization: Bearer eyJ0eXAiOiJKV1QiLCJu...
BODY:
{
    "properties":
    {
        "environment":
        {
            "id": 
"/providers/Microsoft.PowerApps/environments/{ENVIRONMENT_ID}",



            "name":"{ENVIRONMENT_ID}"
        },
        "connectionParametersSet":
        {
            "name":"azureRelay",
            "values":
            {
                "username":{"value":"{MACHINE_ACCOUNT}"},
                "password":{"value":"{MACHINE_PASSWORD}"},
                "targetId":{"value":"{GROUP_ID}"}
            }
        }
    }
}

The above example contains placeholders:

ENVIRONMENT_ID_URL : The environment ID, with all separators removed, and the last
two characters separated by a period. (Example: 37520647-dbdf-49fa-ba01-
6134c14680c4 -> 37520647dbdf49faba016134c14680.c4).
ENVIRONMENT_ID : The environment ID.
CONNECTION_ID: The connection ID used to create the connection. It needs to be
a valid GUID. (You can use the New-Guid  PowerShell command to get this).
MACHINE_ACCOUNT : The username of the account used to open a Windows session.
For a local account, use <MACHINENAME\\User>  or <local\\User> . For a Microsoft
Entra ID account, use <DOMAIN\\User>  or <username@domain.com> . Note that
backslashes need to be escaped, for example, CONTOSO\\accountName .
MACHINE_PASSWORD : The password for the account.
GROUP_ID : The group ID you want to create the connection for. More information:
Get the group ID of the machine or group

Once the request is completed, save the connection ID that you used in your request.
You'll use it in the next step to Prepopulate connection references for automated
deployment.

Next steps
Prepopulate connection references for automated deployment

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Reserved keywords in desktop flows
Article • 07/26/2024

Reserved keywords for the Power Automate for desktop's engine can't be used for the
following items:

Variable names.
Custom object properties.
Action names and property names in custom actions.

List of reserved keywords
） Important

Keywords are case insensitive. For example, ACTION is the same as action.

ACTION
AND
AS
BLOCK
CALL
CASE
DEFAULT
DISABLE
ELSE
END
ERROR
EXIT
FALSE
FOR
FOREACH
FROM
FUNCTION
GLOBAL
GOTO
IF
IMPORT
IN
INPUT



LABEL
LOOP
MAIN
MOD
NEXT
NO
NOT
ON
OR
OUTPUT
REPEAT
SET
STEP
SWITCH
THEN
THROW
TIMES
TO
TRUE
WAIT
WHILE
XOR
YES

Related information
Variables
Custom objects
Custom actions

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Actions reference
Article • 10/31/2024

In this section, you can find a reference to all actions of the Power Automate.

Select on any of the action groups and the list of actions appear along with their
parameters to assist you configure them.

ﾉ Expand table

A - C D - H I - R S - Z

Active Directory Database IBM Cognitive SAP automation

AI Builder Date time Logging Scripting
(Preview)

AWS Email Loops SharePoint

Azure Excel Message boxes System

Browser Exchange Microsoft Cognitive Terminal
automation Server emulation

Clipboard File Mouse and keyboard Text

Cloud connectors Flow control OCR UI automation

CMD session Folder Outlook Variables

Compression FTP Power Automate secret variables Windows services
(Preview)

Conditionals Google PDF Workstation
Cognitive

Custom actions HTTP Run flow Workqueues

Cryptography XML

CyberArk Word

Feedback
Was this page helpful?  Yes  No



Provide product feedback



Variables actions
Article • 06/20/2024

To manually create a variable in a desktop flow, deploy the Set variable action. This
action requires you to provide a name and a value for the new variable.

） Important

Reserved keywords can't be used as variable names. For the full list of reserved
keywords go to Reserved keywords in desktop flows.

To increase or decrease the value of a numeric variable, use the Increase variable and
Decrease variable actions, respectively.



Most actions output their result into a variable. For example, the Create new list action
produces an empty list.

Similarly, the Generate random number action produces a random numeric value. If you
enable Generate multiple numbers in this action, you create a list variable containing
multiple random numeric values.



To add items to an existing list, deploy the Add item to list action, and populate a hard-
coded value or a variable to define the item to add. Likewise, you can remove items
from a list with the Remove item from list action.

７ Note

List indexes start from 0, meaning that the first item in the list always has an index
of 0. Use the notation %ListName[0]% to refer to the first item in the list,
%ListName[1]% to the second, and so on.

If you want to create a data table variable, deploy the Create new data table action and
specify the initial items of it using the visual builder.

To manipulate a data table variable, use the actions of the respective action subgroup,
such as the Find or replace in data table and Update data table item actions.

Create new data table
Creates a new data table variable.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

New table No Datatable The input data table



Variables produced

ﾉ Expand table

Argument Type Description

DataTable Datatable The new data table

Exceptions
This action doesn't include any exceptions.

Insert row into data table
Inserts a row at the end or before a specific index value.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Data table No Datatable The data table variable to work with. This
variable must have been previously
specified by an action that produces a
data table variable

Into N/A End of data End of Specify whether to insert the new row at
location table, Before data table the end of the data table or before a

row index specified row index

Row index No Numeric value Insert the row index value to be used
when before row index is specified as the
into location parameter

New No List, Datarow This parameter accepts a list or datarow
value(s) variable where the column count should

match the column count in the data table

Variables produced
This action doesn't produce any variables.



Exceptions

ﾉ Expand table

Exception Description

Item index is out of range Indicates that the provided item index is out of range

Invalid input arguments Indicates that there's an invalid input parameter

Incompatible type error Indicates that an input parameter of an incompatible type is provided

Delete row from data table
Delete a data table row at the corresponding row index.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Data table No Datatable The data table variable to work with. This
variable must be specified by an action that
produces a data table variable

Row index No Numeric The row index within a data table that should
value be deleted

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Item index is out of range Indicates that the specified data table item is out of range



Update data table item
Update a data table row item on a defined column.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Data table No Datatable The data table variable to work with. This
variable must have been previously specified
by an action that produces a data table
variable.

Column No Text value The column name or index of the item to
update.

Row No Numeric The row index of the item to update.
value

New value No Text value The new value to update at the specified row
index and column.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Item index is out of range Indicates that the specified data table item is out of range

Column name doesn't exist Indicates that the provided column name doesn't exist

Column index is out of Indicates that the provided column index is out of range
range

Incompatible type error Indicates that an input parameter of an incompatible type was
provided



Find or replace in data table
Finds and/or replaces data table values.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Data table No Datatable The data table variable to work with.
This variable must have been
previously specified by an action that
produces a data table variable

Search mode N/A Find, Find and Find The mode to search with (find or find
replace and replace)

All matches N/A Boolean value True Specify whether to find or replace
text in all the matching cells found or
the first matching cell only

Text to find No Text value The text to find in the data table

Find using a N/A Boolean value False Specify whether to use a regular
regular expression to match the cell contents
expression with the text to find

Match case N/A Boolean value False Specify whether to search for case-
sensitive data

Match entire N/A Boolean value False Specify whether to search for cells
cell contents that contain just the specified text

Text to replace No Text value The text used to replace the
with matching cells

Search by N/A Everywhere, Everywhere The order in which to search for the
On column text (everywhere, or on column)

Column index No Text value The column header or index value
or name

Variables produced
ﾉ Expand table



Argument Type Description

DataTableMatches Datatable The data table containing the row and column indexes for
matches

Exceptions

ﾉ Expand table

Exception Description

Provided regular expression is Indicates that the provided regular expression is invalid
invalid

Column name doesn't exist Indicates that the provided column name doesn't exist

Column index is out of range Indicates that the provided column index is out of range

Incompatible type error Indicates that an input parameter of an incompatible type is
provided

Insert column into data table
Inserts a column at the end or before a specific index value.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Data table No Datatable The data table variable to work with.
This variable must be specified by an
action that produces a data table
variable.

Into N/A End of data End of Specify whether to insert the new
location table, Before data table column at the end of the data table or

column index before a specified column index.

Column No Text value Specify the header of the new column.
name

Column No Numeric value Specify the column index value that is
index utilized when the Before column index



Argument Optional Accepts Default Description
Value

option is selected for the Into location
parameter.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Column index is out of range Indicates that the provided column index is out of range.

Duplicate column name Indicates that the provided column name already exists.

Delete column from data table
Delete a data table column at the specified column index or column name.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Data table No Datatable The data table variable to work with. This
variable must be specified by an action that
produces a data table variable.

Specify N/A Name, Name Specify whether to find the column by
column with Index name or index.

Column No Text value The name of the column that should be
name deleted.

Column No Numeric The index of the column that should be
index value deleted. Column indexes start from 0.



Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Column name doesn't exist Indicates that the provided column name doesn't exist

Column index is out of range Indicates that the provided column index is out of range

Delete empty rows from data table
Deletes the rows of the data table that have all of their cells empty.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Data table No Datatable The data table variable to work with. This
variable must have been previously specified by
an action that produces a data table variable

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Delete duplicate rows from data table
Deletes all the rows that are duplicate from the data table, if the values have the same
data type in each column.



Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Data table No Datatable The data table variable to work with. The
specified variable must be defined through an
action that generates a data table variable.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Type mismatch in the cells of a ​Indicates that two or more values in a single column are of
column different data type

Clear data table
Deletes all the rows of the data table, keeping table headers unaffected.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Data table No Datatable The data table variable to work with. The
specified variable must be defined through an
action that generates a data table variable.

Variables produced
This action doesn't produce any variables.



Exceptions
This action doesn't include any exceptions.

Sort data table
Sorts the data table rows in ascending or descending order by the specified column, if
all its values have the same data type.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Data table No Datatable The data table variable to work with.
The specified variable must be defined
through an action that generates a
data table variable.

Specify N/A Name, Index Name Specify whether to find the column by
column with name or index.

Column No Text value The name of the column that should be
name sorted.

Column No Numeric value The index of the column that should be
index sorted. Column indexes start from 0.

Order N/A Ascending, Ascending The order to sort the data table.
Descending

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Column name doesn't exist ​Indicates that the provided column name doesn't exist



Exception Description

Column index is out of range ​Indicates that the provided column index is out of range

Type mismatch in the cells of a ​Indicates that two or more values in a single column are of
column different data type

Filter data table
Filters the data table rows based on the applied rules.

In the action's built-in wizard that helps you create the filters needed, you can apply
multiple filters to different columns that are defined by name or index. Every filter is
composed of a specific column it targets, an operator that is selected, and the value that
is assigned to it.

In addition, multiple filters are applied together via AND and/or OR rules. AND rules are
resolved first in the resulting filter expression, followed by the OR rules.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Data table No Datatable The data table variable to work with. The
specified variable must be defined
through an action that generates a data
table variable.

Filters to No Filtering rules N/A Filtering rules applied to the defined
apply as defined by columns

the user

Variables produced

ﾉ Expand table

Argument Type Description

FilteredDataTable Datatable The generated data table after applying the filters



Exceptions

ﾉ Expand table

Exception Description

Column name doesn't exist ​Indicates that the provided column name doesn't exist

Column index is out of range ​Indicates that the provided column index is out of range

Type mismatch in the cells of a ​Indicates that two or more values in a single column are of
column different data type

Merge data tables
Merges two data tables together, specifying the merging behavior in case their number
of columns is different.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

First data No Datatable The first data table variable to
table work with. This is also the action's

produced variable that holds the
merged data table

Second No Datatable The second data table that is
data table merged into the first data table

Merge N/A Add extra columns, Add extra The merging behavior that is
mode Ignore extra columns applied when the tables don't

columns, Error on have the same number of
extra columns columns

Variables produced
This action doesn't produce any variables.

Exceptions



ﾉ Expand table

Exception Description

Missing Schema ​​Indicates that the data tables don't have the same number of columns

Join data tables
Joins two data tables based on the specified join rule.

In the action's built-in wizard that helps you create the join rules needed, you can set
multiple rules by specifying the column from the first and the second datatable
accordingly, and the comparison operator that applies between them.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

First data No Datatable The first data table variable to work with.
table The specified variable must be defined

through an action that generates a data
table variable.

Second data No Datatable The second data table variable to work
table with. The specified variable must be

defined through an action that generates
a data table variable.

Join N/A Inner, Left, Full Inner The join operation that is used to join the
operation two tables

Join rules No Join rules as N/A Define the columns and the operation to
defined by the be used for joining the two data tables
user

Variables produced
ﾉ Expand table

Argument Type Description

JoinedDataTable Datatable The generated data table after the join operation



Exceptions

ﾉ Expand table

Exception Description

Column name doesn't exist ​Indicates that the provided column name doesn't exist

Column index is out of range ​Indicates that the provided column index is out of range

Read from CSV text variable
Generates a data table from a CSV text.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

CSV text No Text value The CSV text variable to read.

Trim fields N/A Boolean value True Specifies whether to automatically trim
off the leading and trailing whitespaces
of the extracted cells.

First line N/A Boolean value False Specifies whether to use the first row of
contains the CSV text to set the column names
column of the resulting data table. Enable this
names option to avoid reading the names as

data into the table. Subsequent actions
might access the data held by the data
table using column names (instead of
column numbers).

Get CSV N/A Boolean value False Specify whether to retrieve the content
fields as text of the CSV text fields purely as text or

as the closest matching type. For
example, Date Time for dates and
Numeric for numbers.

Columns N/A Predefined, Predefined Specifies whether to use a predefined
separator Custom, Fixed columns separator, a custom separator,

Column or fixed column widths.
Widths



Argument Optional Accepts Default Description
Value

Separator N/A System System The column-separator to parse the CSV
default, default text.
Comma,
Semicolon,
Tab

Custom No Text value The custom column-separator to use
separator for parsing the CSV text.

Fixed No Text value The fixed column-widths to use for
column parsing the CSV text. Separate the
widths widths using commas, spaces, tabs, or

newlines.

Variables produced

ﾉ Expand table

Argument Type Description

CSVTable Datatable The contents of the CSV text as a data table

Exceptions

ﾉ Expand table

Exception Description

CSV parsing failed ​Indicates a problem parsing the CSV text

Convert data table to text
Converts a data table to a CSV text.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Data table No Datatable The data table variable to work with.
The specified variable must be
defined through an action that
generates a data table variable.

Include N/A Boolean value False Specifies whether the column names
column names of the variant specified should

become the first row of the CSV text.

Use custom N/A Boolean value False Specifies whether to use a custom
columns column separator or a predefined
separator column separator.

Separator N/A System default, System The column separator to use in the
Comma, default specified CSV text.
Semicolon, Tab

Custom No Text value The custom column separator to use
columns in the specified CSV text.
separator

Variables produced

ﾉ Expand table

Argument Type Description

CSVText Text value The variable in which the CSV result is stored

Exceptions

ﾉ Expand table

Exception Description

Conversion failed ​Indicates a problem converting the data table to CSV text

Truncate number
Get the integral or fractional digits of a numeric value, or round up the value to a
specified number of decimal places.



Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Number to No Numeric value The number or variable that holds
truncate the numeric value to truncate/round

up

Operation N/A Get integer part, Get Specifies the operation to perform
Get decimal part, integer on the given number
Round number part

Decimal Yes Numeric value 3 The number of decimal places to
places round the given number up to. Enter

0 to return an integer as a result

Variables produced

ﾉ Expand table

Argument Type Description

TruncatedValue Numeric value The truncated or rounded number

Exceptions
This action doesn't include any exceptions.

Generate random number
Generate a random number or a list of random numbers that fall between a minimum
and maximum value.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Minimum value Yes Numeric 0 The lower boundary for the random
value number(s) to generate

Maximum Yes Numeric 100 The upper boundary for the random
value value number(s) to generate

Generate N/A Boolean False Specifies whether to generate a single
multiple value random number or a list of random
numbers numbers

How many Yes Numeric 10 Specifies how many random numbers to
numbers value generate

Allow N/A Boolean False Specifies whether to permit or prevent the
duplicates value same number from appearing more than

once in the random numbers list

Variables produced

ﾉ Expand table

Argument Type Description

RandomNumber Numeric value The newly generated random number

RandomNumbers List of Numeric values The newly generated list of random numbers

Exceptions

ﾉ Expand table

Exception Description

Failed to generate random number Indicates that there's an error generating a random number

Clear list
Remove all items from a list.

Input parameters



ﾉ Expand table

Argument Optional Accepts Default Description
Value

List to No List of General A list variable to remove its
clear values elements

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Remove item from list
Remove one or multiple items from a list.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Remove item by N/A Index, Value Index Specifies whether to remove the item
at a specified index or the item(s) with
a specific value

At index No Numeric The index number of the item to
value remove

With value No General The item to remove
value

Remove all item N/A Boolean False Removes all the occurrences that
occurrences value match the item specified

From list No List of The list with items to remove
General
values



Variables produced

This action doesn't produce any variables.

Exceptions
ﾉ Expand table

Exception Description

Item index is out of range Indicates that item index is out of range

Item not found Indicates that item doesn't exist in the list

Sort list
Sort the items of a list. Use items of the same type.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

List to sort No List of The variable that holds the list to sort
General
values

Sort by list N/A Boolean False If the list items are objects (such are files,
item's value folders, etc.), enable this option to sort
properties the item by a specific property. Leave

this option disabled to sort the elements
by their default property (for example,
file objects are sorted by their full path)

First Yes Text value The name of an item's property to sort
property to the list by. Refer to the help file for the
sort by property names of each object

Sort N/A Ascending, Ascending Specifies whether to sort by the first
Descending property ascending or descending

Second Yes Text value The name of a second property to sort
property to the list by
sort by



Argument Optional Accepts Default Description
Value

Sort N/A Ascending, Ascending Specifies whether to sort by the second
Descending property ascending or descending

Third Yes Text value The name of a third property to sort the
property to list by
sort by

Sort N/A Ascending, Ascending Specifies whether to sort by the third
Descending property ascending or descending

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Shuffle list
Create a random permutation of a list.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

List to No List of General The variable that contains the list
shuffle values to shuffle

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.



Merge lists
Merge two lists into one.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

First list No List of General The first list of items to merge
values

Second list No List of General The second list of items to
values merge

Variables produced
ﾉ Expand table

Argument Type Description

OutputList List of General values The merged list. The initial lists aren't affected

Exceptions

ﾉ Expand table

Exception Description

The lists supplied are of incompatible Indicates that the lists supplied are of incompatible
types types

Reverse list
Reverse the order of the items of a list.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

List to No List of General The list whose items order to
reverse values reverse

Variables produced

This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Remove duplicate items from list
Remove the multiple occurrences of items in a list, so that in the resulting list each item
is unique.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

List to remove No List of The list variable to remove duplicate
duplicate items General items from
from values

Ignore text case N/A Boolean False Specifies whether to perform case
while searching for value insensitive comparison of text while
duplicate items searching for duplicate items (only

applies to lists made of text items)

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.



Find common list items
Compare two lists and create a new list with the items that are common to both.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

First list No List of General The variable that contains the first list
values to compare

Second No List of General The variable that contains the second
list values list to compare

Variables produced
ﾉ Expand table

Argument Type Description

IntersectionList List of General values The new list of common items

Exceptions
This action doesn't include any exceptions.

Subtract lists
Compare two lists and create a new list with the items that are in the first list but not in
the second.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

First list No List of General The variable that holds the first list to
values compare

Second No List of General The variable that holds the second list
list values to compare

Variables produced

ﾉ Expand table

Argument Type Description

ListDifference List of General values The new resulting list

Exceptions
This action doesn't include any exceptions.

Retrieve data table column into list
Convert the contents of a data table column into a list.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Data table No Datatable The data table with the column to convert
into a list

Column name No Text The column name, if column names are
or index value defined, or the index number of the

column to retrieve

Variables produced

ﾉ Expand table



Argument Type Description

ColumnAsList List of General The new list that holds the contents of the specified data
values table

Exceptions

ﾉ Expand table

Exception Description

Column name doesn't exist Indicates that the column name isn't in the data table

Column index is out of range Indicates that the column index is out of range

Convert JSON to custom object
Convert a JSON string to a custom object.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

JSON No Text A JSON text, or a previously created variable
value containing one, to convert it to a custom object

Variables produced

ﾉ Expand table

Argument Type Description

JsonAsCustomObject General value The converted custom object from the provided JSON

Exceptions

ﾉ Expand table



Exception Description

Error parsing the JSON Indicates that there's an error parsing the specified JSON

Convert custom object to JSON
Convert a custom object to a JSON string.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Custom No Custom The custom object to convert to
object object JSON

Variables produced
ﾉ Expand table

Argument Type Description

CustomObjectAsJson Text value The converted JSON from the provided custom object

Exceptions

ﾉ Expand table

Exception Description

Error parsing the custom object Indicates that there's an error parsing the custom object

Add item to list
Append a new item to a list.

Input parameters



ﾉ Expand table

Argument Optional Accepts Default Description
Value

Add item No General A value or a variable to add to the list. Provide
value a list of values to append multiple elements. If

the list has a specific type of elements, the new
element is converted over to that type

Into list No List of A list variable to append the new elements to
General
values

Variables produced
ﾉ Expand table

Argument Type Description

NewList List of General values The new list

Exceptions
This action doesn't include any exceptions.

Create new list
Create a new empty list.

Input parameters
This action doesn't require any input.

Variables produced

ﾉ Expand table

Argument Type Description

List List of General values The new list



Exceptions
This action doesn't include any exceptions.

Increase variable
Increase the value of a variable by a specific amount.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Variable No Numeric The numeric value to increase
name value

Increase by No Numeric A numeric value, or a previously created
value variable containing one, to increase the

variable by

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Decrease variable
Decrease the value of a variable by a specific amount.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Variable No Numeric A numeric value, or a previously created
name value variable containing one, to decrease the

variable by

Decrease by No Numeric A numeric value, or a previously created
value variable containing one, to decrease the

variable by

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Run Power Fx expression
Runs the provided Power Fx expression.

７ Note

This action is only available for Power Fx enabled desktop flows (preview).

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

Expression No * The Power Fx expression to run

Variables produced
This action doesn't produce any variables.

Exceptions



This action doesn't include any exceptions.

Set variable
Set the value of a new or existing variable, create a new variable or overwrite a
previously created variable.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

To No * The value to assign to the variable

Variables produced
ﾉ Expand table

Argument Type Description

NewVar * The name of the variable to set

７ Note

Variable names must start with either a letter or an underscore (_). After the first
character, variable names can contain letters, underscores, and digits (0-9). Names
are not case-sensitive, meaning myVar, myvar, and MYVAR are considered the same
variable. The following reserved keywords cannot be used as variable names: if,
then, else, switch, case, default, loop, from, to, step, foreach, in, while, next, exit,
label, goto, call, output, function, block, end, error, wait, for, set, main, and, or, xor,
not, true, false, yes, no, disable, on, repeat, times, throw, action, mod, global, input,
import

Exceptions

This action doesn't include any exceptions.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Conditional actions
Article • 01/18/2024

Conditional actions allow you to adjust which actions to run based on the outcomes of
conditional statements.

The following list displays some applications and features:

Use If conditionals to evaluate any type of condition.
Use Switch conditionals to compare a single variable with multiple possible values.
Cover multiple scenarios by employing nested conditionals.
Provide default and alternative behaviors to your desktop flows based on the
available data.

To find more information on how to use the conditionals,go to Use conditionals.

Case
An expression that, if met, a block of actions associated with that particular case runs.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Operator N/A Equal to (=), Not equal to (<>), Greater Equal to The comparison
than (>), Greater than or equal to (>=), (=) operator of this
Less than (<), Less than or equal to (<=), case
Contains, Does not contain, Is empty, Is
not empty, Starts with, Does not start
with, Ends with, Does not end with, Is
blank, Is not blank

Value to No * Enter a value to
compare compare with

the switch-block
value

Variables produced
This action doesn't produce any variables.



Exceptions
This action doesn't include any exceptions.

Default case
A block of actions that is run, if no case expression has been met in the switch body.

Input parameters

This action doesn't require any input.

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Else
Marks the beginning of a block of actions that ran if the condition specified in the
preceding 'If' statements aren't met.

Input parameters
This action doesn't require any input.

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Else if



Marks the beginning of a block of actions that run if the conditions specified in the
preceding 'If' statements aren't met, but the condition specified in this statement is met.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Operator N/A Equal to (=), Not equal to (<>), Equal to Choose the
Greater than (>), Greater than or (=) relationship of first
equal to (>=), Less than (<), Less operand to the second
than or equal to (<=), Contains, operand.
Does not contain, Is empty, Is not
empty, Starts with, Does not start
with, Ends with, Does not end with,
Is blank, Is not blank

First No * Enter a value name
operand defined by a previous

action, text, number or
expression to compare
with the second
operand.

Second No * Enter a value name
operand produced by a

previous action, text,
number or expression
to compare with the
first operand.

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

If



Marks the beginning of a block of actions that is run if the condition specified in this
statement is met.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Operator N/A Equal to (=), Not equal to (<>), Equal to Choose the
Greater than (>), Greater than or (=) relationship of first
equal to (>=), Less than (<), Less operand to the second
than or equal to (<=), Contains, operand.
Does not contain, Is empty, Is not
empty, Starts with, Does not start
with, Ends with, Does not end with,
Is blank, Is not blank

First No * Enter a value name
operand defined by a previous

action, text, number or
expression to compare
with the second
operand.

Second No * Enter a value name
operand produced by a

previous action, text,
number or expression
to compare with the
first operand.

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Switch



Dispatches execution to different parts of the switch body based on the value of the
expression.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Value to No * Enter a value name, text, or number to
check compare with the following cases.

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.



Loop actions
Article • 12/16/2022

Use loops to automate repetitive sections of your desktop flows and avoid running the
same actions multiple times.

The following list presents some useful applications and features of loops:

Use simple loops to perform a specific number of repetitions and iterate through
data.
Deploy Loop condition to repeat actions until a condition is met.
Iterate through the items of a list using For each loops.
Explicitly end loops when required.

To find more information on how to use loops, go to Use loops.

Exit loop
Terminates the loop and the flow resumes at the next action or statement following the
loop.

Input parameters
This action doesn't require any input.

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

For each
Iterates over items in a list, data table or data row, allowing a block of actions to be
executed repeatedly.

Input parameters



Argument Optional Accepts Default Description
Value

Value to No * Enter a list, data row, or data table value to
iterate iterate through it.

Variables produced
Argument Type Description

* The value name that will store the current item value in each iteration.

Exceptions
This action doesn't include any exceptions.

Loop
Iterates a block of actions for a specified number of times

Input parameters
Argument Optional Accepts Default Description

Value

Start from No Numeric Set the starting point of the loop counter.
value

Increment No Numeric Set the increment that the loop counter
by value variable is increased by.

End to No Numeric Set the ending point of the loop counter.
value

Variables produced
Argument Type Description

* The value name that will store the current index, starting at the start from
value. The value will change by the increment with each iteration.

Exceptions



This action doesn't include any exceptions.

Loop condition
Iterates a block of actions as long as a specified condition proves to be true.

Input parameters
Argument Optional Accepts Default Description

Value

Operator N/A Equal to (=), Not equal to (<>), Equal Choose the relationship of
Greater than (>), Greater than or to (=) first operand to second
equal to (>=), Less than (<), Less operand.
than or equal to (<=)

First No * Enter a value name
operand defined by a previous

action, text, number or
expression to compare
with the second operand.

Second No * Enter a value name
operand produced by a previous

action, text, number or
expression to compare
with the first operand.

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Next loop
Forces the next iteration of the block to take place, skipping any actions in between.

Input parameters
This action doesn't require any input.



Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.



Flow control actions
Article • 01/20/2025

Flow control is the act of controlling the order in which actions and subflows run. Power
Automate enables you to implement flow control through the flow control actions.

Labels are used to create points of reference for the Go to action that changes the
running point of the desktop flow. The following example directs the flow to a label
earlier in the flow to repeat a series of actions.

The Run subflow action interrupts the subflow in which it's placed and runs another
subflow. When the second subflow completes, the flow reverts to the original subflow to
continue running. The following example runs the Calculate Discount subflow multiple
times throughout the runtime of the flow to avoid repeating the same code.



To visually organize your actions into groups for easier management, enclose them
between a Region and an End region action, and give the region a distinctive name.

These actions don't have any functional effect, but they help group and organize actions
for maintenance and readability purposes. For example, you can collapse and expand a
region to help focus attention where needed.

You can only use the Region and End region actions as pairs, and they must belong to
the same scope to interlock correctly. If one of the two actions belongs to another
group of actions, such as a loop or a conditional, the actions can't form a proper region.

７ Note

If you create multiple regions in a subflow, there's no predetermined mapping
between specific Region and End region actions. Instead, the last Region action will
try to form a pair with the first available End region action that follows.

Comment
User comment.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Value Description

Comment Yes Text value User comment



Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

End
Signifies the end of a block.

Input parameters
This action doesn't require any input.

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

End region
Marks the end of a group of actions.

Input parameters
This action doesn't require any input.

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.



Exit subflow
Exits current subflow and returns to the point it was called from.

Input parameters
This action doesn't require any input.

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Get last error
Retrieves the last error that occurred in the flow.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Clear error N/A Boolean False After the error is stored in the variable, it's
value cleared so that next time the error is retrieved,

it won't retrieve the same error value

Variables produced

ﾉ Expand table

Argument Type Description

LastError Error The details of the error that last occurred in the flow

Exceptions



This action doesn't include any exceptions.

Go to
Transfers the flow of execution to another point, indicated by a label.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Value Description

Go to label No Text value Label in the flow

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Label
Acts as the destination of a 'go to' statement.

From version 2.46 and on, labels can also be used in a different scope than the
corresponding Go to action (for example, in a conditional block), except error blocks,
loops, and/or other subflows.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

Label name No Text value Label in the program

Variables produced



This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

On block error
Marks the beginning of a block to handle actions errors.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Name No Text value The name of the Exception Block for
Visual purposes only.

Retry policy N/A None, Fixed, None The rules based on which retries are
Exponential performed. Delays are estimated in

seconds.

Capture N/A Boolean False Expand the scope of error handling, also
unexpected value capturing logical errors in the flow, for
logic errors example, dividing a number by zero or

trying to access an item from an out of
bounds position.

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Region
Marks the beginning of a group of actions.



Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

Name Yes Text value The name of the region.

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Run subflow
Run a subflow specifying any required arguments.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Subflow No Subflow The name of the subflow to call
name

Input as N/A Boolean False Define whether the input should be handled
expression value as an expression. If enabled, variables and

expressions can be used to dynamically
determine the subflow during runtime.

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.



Stop flow
Terminates the flow.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

End flow No Successfully, With Successfully Terminate the execution of the
error message flow, either successfully or with

an error

Error No Text value The error message to return to
message the flow caller upon exit

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Wait
Suspends the execution of the flow for a specified number of seconds.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Value Description

Duration No Numeric value Time duration in seconds

Variables produced
This action doesn't produce any variables.



Exceptions
This action doesn't include any exceptions.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Run desktop flow action
Article • 01/31/2025

The Run desktop flow action enables you to call other desktop flows while running a
specific desktop flow. To use the action, add it to the workspace and select the desktop
flow you want to call. If the called flow contains input variables, the action will prompt
you to enter their values.

You can disable the toggle property 'Wait for flow to complete', which is enabled by
default. If disabled, the invoked desktop flow runs concurrently with the parent flow.
This configuration is useful for scenarios where unexpected popups in the target
application block the parent flow. By running a child flow in parallel, you can monitor
and manage these popups, ensuring the parent flow continues smoothly. This
improvement provides a workaround given the current concurrency policy, which allows
only one flow per machine at a time.

） Important

Only one parallel flow can run at this time. If a second child flow runs in
parallel, an error occurs during runtime.
If a child flow runs in parallel, its output variables are ignored. The variables
produced from the 'Run desktop flow' action aren't shown in the action
modal.
Child flows can't run another child flow in parallel. A parallel flow run is
allowed only if invoked directly from the parent (root) flow.

To find more information about how to use the Run desktop flow action, go to Run
desktop flow from other desktop flows.

７ Note

A flow's dependencies can't be more than 150 other flows.
Two flows can't directly or indirectly call one-another as this causes a
recursion.
In org tenants, the flows must be under the same environment.



Known limitations
The output variables of a 'Run desktop flow' action don't keep their type during
authoring and appear as 'General values' in the variables pane. Their proper variable
type is resolved during runtime. As a result, output variables of instance type aren't
automatically loaded in the lists of the corresponding actions' instance parameters, so
you need to type or paste them into the parameters.

Run desktop flow
Runs a desktop flow that can receive input variables and might produce output
variables. The parent flow run will be paused until the called desktop flow completes.

Input parameters
ﾉ Expand table



Argument Optional Accepts Default Description
Value

Desktop No Desktop Select the desktop flow to run from within this
flow flow flow. The called flow always runs in the same

Windows session as the parent flow.

Wait for flow N/A Boolean True If enabled, this desktop flow waits for the
to complete value invoked desktop flow to complete before

resuming. The invoked desktop flow's output
variables are available to the current flow. If
disabled, the invoked desktop flow runs
concurrently, and its output variables are
ignored.

Variables produced
This action produces the output variables of the selected flow.

Exceptions

ﾉ Expand table

Exception Description

Run desktop flow failed Indicates a problem while running the desktop flow

Desktop flow timed out Indicates that the desktop flow timed out before completing its run

Feedback
Was this page helpful?  Yes  No

Provide product feedback



System actions
Article • 12/16/2022

７ Note

The System group of actions has been segregated into some new categories. To
find more information about these categories, go to Workstation and Scripting
actions references.

Use the system actions to automate tasks fundamental to the Windows operating
system.

Launch any of your installed applications with the Run application action. You must
enclose any command line arguments in double quotes and separate them by space.
The following example opens a specific Word document in quiet mode.

７ Note

The Application path field has to point to the executable of the application. You can
open certain default Windows applications by entering their name, such as
notepad for Notepad.



Additionally, desktop flows enable you to terminate processes by name or ID through
the Terminate process action, and wait for processes to start or stop through the Wait
for process action.



To handle Windows environment variables, use the Set Windows environment variable,
Get Windows environment variable, and Delete Windows environment variable
actions for the respective tasks.

If process
Marks the beginning of a conditional block of actions depending on whether a process
is running or not.

Input parameters
Argument Optional Accepts Default Description

Value

If process N/A Is running, Isn't Is running State of the process to check
running

Process No Text value The name of the process to
name check

Variables produced
This action doesn't produce any variables.



Exceptions
Exception Description

Can't retrieve list of processes Indicates a problem retrieving the list of processes

Wait for process
Suspends the execution until a process starts or stops.

Input parameters
Argument Optional Accepts Default Description

Value

Process name No Text The name of the process to check
value

Wait for N/A Start, Start Whether to wait until a certain process
process to Stop starts or stops

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Can't retrieve list of processes Indicates a problem retrieving the list of processes

Run application
Executes an application or opens a document by executing the associated application.

） Important

Many applications with advanced functionality require elevated rights to prevent
unauthorized access to system resources. To launch these applications using the
Run application action, run Power Automate with administrator rights. To find more



information regarding running Power Automate as an administrator, go toRun
Power Automate with elevated rights.

Input parameters
Argument Optional Accepts Default Description

Value

Application No File The executable file as a complete
path file path

Command Yes Text value Add extra arguments that would
line go after the executable file name.
arguments For example, enter notepad.exe in

the application path and a specific
text file in the command line
arguments

Working Yes Folder The full path of the folder to work
folder out of, if applicable.

Window N/A Normal, Hidden, Normal Choose the appearance and size of
style Minimized, the application window when it

Maximized opens

After N/A Continue Continue Whether the next action executes
application immediately, Wait immediately immediately, or waits until the
launch for application to program loads or completes

load, Wait for
application to
complete

Timeout Yes Numeric value 0 The maximum wait time, and how
long before forcing a continue

Variables produced
Argument Type Description

AppProcessId Numeric The process ID output
value

AppExitCode Numeric The application exit code
value



Argument Type Description

WindowHandle Numeric The window handle. When opening a new window, this variable will
value catch the value of the window handle, and store it in this variable. A

window handle is useful to specifically identify a window in a later
action

Exceptions
Exception Description

File or application not found Indicates that the specified file or application wasn't found

Access denied for application or Indicates that access was denied for the specified application
File or file

Can't retrieve application's main Indicates a problem retrieving the application's main window
window handle handle

Can't execute application or open Indicates a problem executing the specified application or
file opening the specified file

Terminate process
Immediately stops a running process.

Input parameters
Argument Optional Accepts Default Description

Value

Specify N/A Process Process Specify whether the process to terminate will be
process by ID, name specified by its name, or by its ID

Process
name

Process ID No Numeric The ID of the process to terminate
value

Process No Text The name of the process to terminate. If more
name value than one process with the same name is running,

all of them will be terminated

Variables produced



This action doesn't produce any variables.

Exceptions
Exception Description

Process with specified ID not running Indicates that a process with the specified ID isn't running

Failed to terminate process Indicates a problem terminating the process

Ping
Sends a message to determine whether a remote computer is accessible over the
network.

Input parameters
Argument Optional Accepts Default Description

Value

Host No Text The name of the remote computer or an IP
name value address

Timeout Yes Numeric 5000 The maximum number of milliseconds to wait for
value the Ping reply message

Variables produced
Argument Type Description

PingResult Text value The status of the ping message (success or failure)

RoundTripTime Numeric value The number of milliseconds taken for the Ping to complete

Exceptions
Exception Description

Can't complete ping action Indicates a problem completing the ping action

Set Windows environment variable



Sets an environment variable to a given value.

Input parameters
Argument Optional Accepts Default Description

Value

Environment variable No Text The name of the environment
name value variable

New environment No Text The value that is set to the
variable value value environment variable

Type N/A User, User The type of the environment
System variable

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Indicates a problem setting the Indicates a problem setting the environment
environment variable's value variable's value

Insufficient permissions Indicates that the user has insufficient permissions
to perform this action

Get Windows environment variable
Retrieves the value of an environment variable.

Input parameters
Argument Optional Accepts Default Description

Value

Environment No Text The name of the environment variable
variable name value whose value will be retrieved

Search for variable N/A Boolean False Specify whether to search for the variable
only in scope value only in a specific scope



Argument Optional Accepts Default Description
Value

Scope N/A User, User The scope from which the environment
System variable should be retrieved

Variables produced
Argument Type Description

EnvironmentVariableValue Text value The environment variable's value

Exceptions
Exception Description

Environment variable doesn't Indicates that the specified environment variable doesn't exist
exist

Insufficient permissions Indicates that the user has insufficient permissions to perform
this action

Delete Windows environment variable
Deletes an environment variable from a given scope.

Input parameters
Argument Optional Accepts Default Description

Value

Environment variable No Text The name of the environment
name value variable to delete

Type N/A User, User The type of the environment
System variable to delete

Variables produced
This action doesn't produce any variables.

Exceptions



Exception Description

Failed to delete environment Indicates a problem deleting an environment variable
variable

Insufficient permissions Indicates that the user has insufficient permissions to perform
this action



Workstation actions
Article • 12/16/2022

The workstation group of actions provides a collection of actions that automate some
essential functionalities of your workstation.

To print a document, deploy the Print document action and populate the path of the
file you want to print.

To change the default printer of the workstation, use the Set default printer action. To
check which is the current default printer, use the Get default printer action.

If you want to sign out of your Windows account, use the Log off user action.
Additionally, you can use the Shutdown computer and Lock workstation actions to shut
down or lock your workstation, respectively.

To change the resolution of any of your screens, use the Set screen resolution. This
action requires you to populate the ID number of the screen, the width and height, the
bit count, and the frequency. You can select Available screen resolutions to see all the
available resolutions for each screen. Also, you can retrieve the current values of the
mentioned attributes with the Get screen resolution action.



Print document
Prints a document on the default printer.

Input parameters
Argument Optional Accepts Default Value Description

Document to print No File The path of the document to print

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Document not found Indicates that the specified document wasn't found



Exception Description

Access denied for document Indicates that access was denied for the provided document

Can't print document Indicates a problem printing the specified document

Get default printer
Gets the name of the default printer.

Input parameters
This action doesn't require any input.

Variables produced
Argument Type Description

PrinterName Text value The name of the default printer

Exceptions
Exception Description

Can't get default printer Indicates a problem getting the default printer

Set default printer
Sets a printer as the default printer.

Input parameters
Argument Optional Accepts Default Value Description

Printer name No Text value The name of the printer to set as default

Variables produced
This action doesn't produce any variables.



Exceptions
Exception Description

Can't set default printer Indicates a problem setting the default printer

Show desktop
Shows the desktop.

Input parameters
Argument Optional Accepts Default Description

Value

Operation N/A Minimize all windows Minimize Specify whether to minimize all
(show desktop), all windows to reveal the desktop or
Restore all windows windows restore all windows to their
(undo show desktop) (show original respective states

desktop)

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Lock workstation
Locks the workstation's display to protect it from unauthorized use.

Input parameters
This action doesn't require any input.

Variables produced
This action doesn't produce any variables.



Exceptions
Exception Description

Can't lock the computer in non Indicates a problem locking the computer in non
interactive mode interactive mode

Can't lock the computer Indicates a problem locking the computer in non-
interactive mode

Play sound
Plays a system sound or a wav file.

Input parameters
Argument Optional Accepts Default Description

Value

Play N/A System, WAV file System The type of sound to play
sound
from

Sound to N/A Asterisk, Beep, Exclamation, Asterisk The specific sound to play
play Hand, Question

File to No File The full path of the specific
play WAV file to play

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Can't find sound file Indicates that the sound file couldn't be found

Invalid sound file Indicates an invalid sound file

Empty recycle bin



Deletes all files from the windows recycle bin.

Input parameters
This action doesn't require any input.

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Take screenshot
Takes a screenshot of the foreground window or the specified screen and saves the
image in a file or to the clipboard.

Input parameters
Argument Optional Accepts Default Description

Value

Capture N/A All screens, Primary screen, All The area to capture
Select screen, Foreground screens
window

Screen to No Numeric value Specify which screen to
capture capture

Save N/A Clipboard, File Clipboard The location to save the
screenshot screenshot to
to

Image file No File The full path of the file
name where the captured
image will be saved

Image N/A BMP, EMF, EXIF, GIF, JPG, BMP The format for the image
format PNG, TIFF, WMF file to save

Variables produced



This action doesn't produce any variables.

Exceptions
Exception Description

Failed to take screenshot Indicates a problem taking the screenshot

Failed to save screenshot to file Indicates a problem saving the screenshot to a file

Failed to set screenshot to clipboard Indicates a problem setting the screenshot to the clipboard

Failed to get specified screen Indicates a problem getting the specified screen

Control screen saver
Enables, disables, starts or stops the screensaver.

Input parameters
Argument Optional Accepts Default Description

Value

Screen saver N/A Enable, Disable, Start, Enable The function of the
action Stop screensaver

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Get screen resolution
Gets the width, height, bit count and frequency of a selected monitor.

Input parameters



Argument Optional Accepts Default Description
Value

Monitor No Numeric The number of the monitor to get the
number value resolution of

Variables produced
Argument Type Description

MonitorWidth Numeric value The width of the monitor

MonitorHeight Numeric value The height of the monitor

MonitorBitCount Numeric value The monitor bit count

MonitorFrequency Numeric value The monitor frequency

Exceptions
Exception Description

Failed to get the screen's resolution Indicates a problem getting the screen's resolution

Set screen resolution
Sets the width, height, bit count and frequency of a selected monitor during an
attended desktop flow run.

） Important

To use the Set screen resolution action in flows triggered through cloud flows, you
must be connected to the console session of your machine, where you can
manually change the screen resolution. For example, you can use your machine's
physical screen to connect to the machine. In remote sessions, such as unattended
scenarios that use remote desktop clients, the action has no effect, as users can't
manually change the resolution.

Input parameters



Argument Optional Accepts Default Description
Value

Monitor No Numeric The number of monitor to set the
number value resolution of

Monitor width No Numeric The value to set the monitor width to
value

Monitor height No Numeric The value to set the monitor height to
value

Monitor bit No Numeric The value to set the monitor bit count
count value to

Monitor No Numeric The value to set the monitor frequency
frequency value to

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Failed to set the screen's resolution Indicates a problem setting the screen's resolution

Log off user
Logs off the current user.

７ Note

When you run the Log off user action through the flow designer, the action
prompts you to verify that you want to log off the current user. However, the action
doesn't require confirmation when the flow runs through the console or cloud
flows. In all cases, the action will terminate the flow.

Input parameters



Argument Optional Accepts Default Description
Value

Force log N/A Boolean False Specify whether to force the user account to log
off value off, regardless of unsaved files or programs that

won't close

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Can't log off user in non interactive Indicates a problem logging off the user in non-
mode interactive mode

Can't log off the current user Indicates a problem logging off the current user

Shutdown computer
Instructs the computer to shut down.

） Important

Although a desktop flow containing the Shutdown computer action is set to
shut down the machine, some unrelated factors, such as other running
Windows processes, may prevent it from achieving it.
When you run the Shutdown computer action through the flow designer, the
action prompts you to verify that you want to shut down the computer.
However, the action doesn't require confirmation when the flow is run
through the console or cloud flows. In all cases, the action will terminate the
flow.

Input parameters
Argument Optional Accepts Default Description

Value



Argument Optional Accepts Default Description
Value

Action to N/A Shutdown, Shutdown Specify which shutdown option the
perform Restart, computer will perform

Suspend,
Hibernate

Force N/A Boolean value False Specify whether to force the computer to
shut down, regardless of unsaved files or
programs that won't close

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Can't shut down the computer Indicates a problem shutting down the computer



Scripting actions
Article • 03/21/2025

） Important

To prevent unauthorized access, Windows require administrator rights to access
protected resources. To access protected resources (such as files) using the
scripting actions, run Power Automate with administrator rights. To find more
information regarding running Power Automate as an administrator, go to Run
Power Automate with elevated rights.

Scripting actions enable you to run blocks of code and implement custom behavior in
your desktop flows.

） Important

As announced on October 2023, VBScript is deprecated from Windows. In future
releases of Windows, VBScript will be available as a feature on demand before its
removal from the operating system. For more information, see Resources for
deprecated features.

All scripting actions follow the basic structure of the respective programming or
scripting language: PowerShell, Python, VBScript, JavaScript, and C#/VB.NET.

７ Note

Supported version for C#: v 5.0. For VB.NET: v 11.0

Natural language to script powered by copilot
(preview)
[This topic is prerelease documentation and is subject to change.]

Natural language to code is a new copilot capability added in Power Automate for
desktop. It lets you quickly generate code used in the scripting actions by describing it.
This feature is available in the following scripting actions:

Run PowerShell



Run VBScript
Run DOS command
Run Python
Run JavaScript

） Important

This is a preview feature.
Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.

Availability by region
Currently, copilot in Power Automate for desktop is only available in environments
located in the United States.

Availability by account type
Currently, copilot in Power Automate for desktop is only available for users with a work
or school account.

７ Note

If your environment is in one of the previously listed regions and you still need to
see the copilot in Power Automate for desktop experience, contact your tenant
administrator. They might have turned off the copilot functionality.

How to generate scripts using copilot and natural
language
To generate scripts in one of the supported scripting actions drag and drop the action in
the designer and select Generate script with Copilot.



The create prompt screen opens where you can type your natural language prompt.



To create a script, write your prompt and select Generate. If you need to re-create it, you
can change the prompt and select Regenerate. Otherwise, select Use this script to go
back to the main action window, where you can modify it and add any necessary
variables.

） Important

Make sure that you always review the content generated by the AI model.

Help us improve this feature
Send feedback by selecting the thumb up or thumb down icon underneath the AI-
generated content. Once you do, a feedback dialog appears, which you can use to



submit feedback to Microsoft.

７ Note

If you can't see the dialog, your tenant admin might have turned it off. More
information: Disabling the user feedback functionality

Disabling the user feedback functionality
As a Power Platform admin, prevent users from sending Copilot feedback to Microsoft
by using the "Copilot feedback" tenant setting.

Data subject rights requests on user feedback
Tenant administrators can view, export, and delete the feedback from their users by
signing in to the Microsoft 365 admin center , and then selecting Health > Product
feedback.

AI with Power Automate resources
FAQ for Generating scripts with natural language
Responsible AI FAQs for Power Automate
FAQ for Copilot data security and privacy in Microsoft Power Platform

Working with variables in scripting actions



To declare variables in scripting actions and return results in Power Automate, use the
following commands:

To declare new variables in PowerShell scripts, use the $ notation. To return values
from Run PowerShell script actions to Power Automate, use the Write-Output
command.

PowerShell

$variableName = "variableValue"
Write-Output $variableName

Python scripts don't require any special notation to declare new variables. To
return values from Run Python script actions, use the print function.

Python

variableName = "variableValue"
print variableName

VBScript doesn't require any special notation to declare new variables. Use the
WScript.Echo function to return values from Run VBScript actions to Power
Automate.

VBScript

variableName = "variableValue"
WScript.Echo variableName

In JavaScript scripts, use the var notation to declare new variables and the
WScript.Echo function to return values from Run JavaScript actions.

JavaScript

var variableName = "variableValue";
WScript.Echo(variableName);

For .NET scripts, use the Script Parameters window, accessed through the Run
.NET script action's configuration card. You can set the type of the respective
variable:



In addition, you can set whether it's an input to the .NET script (In option in Direction
dropdown), an output of the script (Out option in Direction dropdown) or both (In-Out
option in Direction dropdown).

To use Power Automate variables in scripting actions, use the percentage notation (%)
and handle the variables the same way as hardcoded values.



Run DOS command
Executes a DOS command or console application in invisible mode and retrieves its
output upon completion.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

DOS No File The name of
command DOS
or command or
application a console

application,
with
arguments if
applicable

Working Yes Folder The full path
folder of the folder

to work out



Argument Optional Accepts Default Description
Value

of, if
applicable

Fail after Yes Boolean value Specify
timeout whether the

DOS
command or
application
will run
indefinitely
or fail after a
set period of
time

Timeout No Numeric value 10 The
maximum
number of
seconds to
wait for the
script to
complete (-1
for
indefinitely)

Change N/A Boolean value False Specifies
code page whether to

change the
session's
current code
page

Encoding No ASMO-708: Arabic (ASMO 708), big5: Chinese utf-8: The
Traditional (Big5), cp1025: IBM EBCDIC Unicode encoding to
(Cyrillic Serbian-Bulgarian), cp866: Cyrillic (UTF-8) use when
(DOS), cp875: IBM EBCDIC (Greek Modern), reading the
csISO2022JP: Japanese (JIS-Allow 1 byte output
Kana), DOS-720: Arabic (DOS), DOS-862:
Hebrew (DOS), EUC-CN: Chinese Simplified
(EUC), EUC-JP: Japanese (JIS 0208-1990 and
0212-1990), euc-jp: Japanese (EUC), euc-kr:
Korean (EUC), GB18030: Chinese Simplified
(GB18030), gb2312: Chinese Simplified
(GB2312), hz-gb-2312: Chinese Simplified
(HZ), IBM-Thai: IBM EBCDIC (Thai), IBM00858:
OEM Multilingual Latin I, IBM00924: IBM
Latin-1, IBM01047: IBM Latin-1, IBM01140:
IBM EBCDIC (US-Canada-Euro), IBM01141:



Argument Optional Accepts Default Description
Value

IBM EBCDIC (Germany-Euro), IBM01142: IBM
EBCDIC (Denmark-Norway-Euro), IBM01143:
IBM EBCDIC (Finland-Sweden-Euro),
IBM01144: IBM EBCDIC (Italy Euro),
IBM01145: IBM EBCDIC (Spain-Euro),
IBM01146: IBM EBCDIC (UK-Euro), IBM01147:
IBM EBCDIC (France-Euro), IBM01148: IBM
EBCDIC (International-Euro), IBM01149: IBM
EBCDIC (Icelandic-Euro), IBM037: IBM EBCDIC
(US-Canada), IBM1026: IBM EBCDIC (Turkish
Latin-5), IBM273: IBM EBCDIC (Germany),
IBM277: IBM EBCDIC (Denmark-Norway),
IBM278: IBM EBCDIC (Finland-Sweden),
IBM280: IBM EBCDIC (Italy), IBM284: IBM
EBCDIC (Spain), IBM285: IBM EBCDIC (UK),
IBM290: IBM EBCDIC (Japanese katakana),
IBM297: IBM EBCDIC (France), IBM420: IBM
EBCDIC (Arabic), IBM423: IBM EBCDIC (Greek),
IBM424: IBM EBCDIC (Hebrew), IBM437: OEM
United States, IBM500: IBM EBCDIC
(International), ibm737: Greek (DOS), ibm775:
Baltic (DOS), ibm850: Western European
(DOS), ibm852: Central European (DOS),
IBM855: OEM Cyrillic, ibm857: Turkish (DOS),
IBM860: Portuguese (DOS), ibm861: Icelandic
(DOS), IBM863: French Canadian (DOS),
IBM864: Arabic (864), IBM865: Nordic (DOS),
ibm869: Greek, Modern (DOS), IBM870: IBM
EBCDIC (Multilingual Latin-2), IBM871: IBM
EBCDIC (Icelandic), IBM880: IBM EBCDIC
(Cyrillic Russian), IBM905: IBM EBCDIC
(Turkish), iso-2022-jp: Japanese (JIS), iso-
2022-jp: Japanese (JIS-Allow 1 byte Kana -
SO/SI), iso-2022-kr: Korean (ISO), iso-8859-1:
Western European (ISO), iso-8859-13:
Estonian (ISO), iso-8859-15: Latin 9 (ISO), iso-
8859-2: Central European (ISO), iso-8859-3:
Latin 3 (ISO), iso-8859-4: Baltic (ISO), iso-
8859-5: Cyrillic (ISO), iso-8859-6: Arabic (ISO),
iso-8859-7: Greek (ISO), iso-8859-8: Hebrew
(ISO-Visual), iso-8859-8-i: Hebrew (ISO-
Logical), iso-8859-9: Turkish (ISO), Johab:
Korean (Johab), koi8-r: Cyrillic (KOI8-R), koi8-
u: Cyrillic (KOI8-U), ks_c_5601-1987: Korean,
macintosh: Western European (Mac), shift_jis:
Japanese (Shift-JIS), us-ascii: US-ASCII, utf-16:
Unicode, utf-16BE: Unicode (Big-Endian), utf-



Argument Optional Accepts Default Description
Value

32: Unicode (UTF-32), utf-32BE: Unicode
(UTF-32 Big-Endian), utf-7: Unicode (UTF-7),
utf-8: Unicode (UTF-8), windows-1250:
Central European (Windows), windows-1251:
Cyrillic (Windows), Windows-1252: Western
European (Windows), windows-1253: Greek
(Windows), windows-1254: Turkish
(Windows), windows-1255: Hebrew
(Windows), windows-1256: Arabic (Windows),
windows-1257: Baltic (Windows), windows-
1258: Vietnamese (Windows), windows-874:
Thai (Windows), x-Chinese-CNS: Chinese
Traditional (CNS), x-Chinese-Eten: Chinese
Traditional (Eten), x-cp20001: TCA Taiwan, x-
cp20003: IBM5550 Taiwan, x-cp20004:
TeleText Taiwan, x-cp20005: Wang Taiwan, x-
cp20261: T.61, x-cp20269: ISO-6937, x-
cp20936: Chinese Simplified (GB2312-80), x-
cp20949: Korean Wansung, x-cp50227:
Chinese Simplified (ISO-2022), x-EBCDIC-
KoreanExtended: IBM EBCDIC (Korean
Extended), x-Europa: Europa, x-IA5: Western
European (IA5), x-IA5-German: German (IA5),
x-IA5-Norwegian: Norwegian (IA5), x-IA5-
Swedish: Swedish (IA5), x-iscii-as: ISCII
Assamese, x-iscii-be: ISCII Bengali, x-iscii-de:
ISCII Devanagari, x-iscii-gu: ISCII Gujarati, x-
iscii-ka: ISCII Kannada, x-iscii-ma: ISCII
Malayalam, x-iscii-or: ISCII Oriya, x-iscii-pa:
ISCII Punjabi, x-iscii-ta: ISCII Tamil, x-iscii-te:
ISCII Telugu, x-mac-arabic: Arabic (Mac), x-
mac-ce: Central European (Mac), x-mac-
chinesesimp: Chinese Simplified (Mac), x-
mac-chinesetrad: Chinese Traditional (Mac), x-
mac-croatian: Croatian (Mac), x-mac-cyrillic:
Cyrillic (Mac), x-mac-greek: Greek (Mac), x-
mac-hebrew: Hebrew (Mac), x-mac-icelandic:
Icelandic (Mac), x-mac-japanese: Japanese
(Mac), x-mac-korean: Korean (Mac), x-mac-
romanian: Romanian (Mac), x-mac-thai: Thai
(Mac), x-mac-turkish: Turkish (Mac), x-mac-
ukrainian: Ukrainian (Mac)`

Variables produced



ﾉ Expand table

Argument Type Description

CommandOutput Text value The text output from the DOS command or application

CommandErrorOutput Text value The text describing the errors occurred (if any) during the
execution of the DOS command or application

CommandExitCode Numeric The command or application exit code. This value is
value numeric

Exceptions
ﾉ Expand table

Exception Description

Can't execute command or console Indicates a problem executing the specified command or
application console application

Failed to run script in the allotted Indicates a problem running the provided script in the
time allotted time

Run VBScript
Executes some custom VBScript code and retrieves its output into a variable.

You can use this action to include your own custom VBScript code in the desktop flow,
while also having the ability to use variables therein, to generate dynamic VBScript
content if needed.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

VBScript to Yes Text value The VBScript code to execute. Variables might
run be included within the script since they

evaluate before the execution of the VBScript

Fail after Yes Boolean N/A Specify whether the VBScript script will run
timeout value indefinitely or fail after a set period of time



Argument Optional Accepts Default Description
Value

Timeout No Numeric 10 The maximum number of seconds to wait for
value the script to complete (-1 for indefinitely)

Variables produced

ﾉ Expand table

Argument Type Description

VBScriptOutput Text The script's output
value

ScriptError Text The errors that might occur during the execution of the VBScript
value code

Exceptions

ﾉ Expand table

Exception Description

Failed to run script in the allotted Indicates a problem running the provided script in the
time allotted time

Run JavaScript
Executes some custom JavaScript code and retrieves its output into a variable.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

JavaScript Yes Text value The JavaScript code to execute. Variables
to run might be included within the script since they

evaluate before the JavaScript code's
execution



Argument Optional Accepts Default Description
Value

Fail after Yes Boolean Specify whether the JavaScript script will run
timeout value indefinitely or fail after a set period of time

Timeout No Numeric 10 The maximum number of seconds to wait for
value the script to complete (-1 for indefinitely)

Variables produced

ﾉ Expand table

Argument Type Description

JavascriptOutput Text The script's output
value

ScriptError Text The errors that might occur during the execution of the JavaScript
value code

Exceptions

ﾉ Expand table

Exception Description

Failed to run script in the allotted Indicates a problem running the provided script in the
time allotted time

Run PowerShell script
Executes some custom PowerShell script and retrieves its output into a variable.

You can use this action to include your own custom PowerShell code in the desktop
flow, while also having the ability to use variables therein, to generate dynamic
PowerShell content if needed.

Input parameters
ﾉ Expand table



Argument Optional Accepts Default Description
Value

PowerShell Yes Text value The PowerShell code to execute. Variables
code to run can be included within the script since they

evaluate before the execution of the
PowerShell code

Fail after Yes Boolean Specify whether the PowerShell script will
timeout value run indefinitely or fail after a set period of

time

Timeout No Numeric 10 The maximum number of seconds to wait for
value the script to complete (-1 for indefinitely)

Variables produced

ﾉ Expand table

Argument Type Description

PowershellOutput Text The script's output
value

ScriptError Text The errors that might occur during the execution of the
value PowerShell code

Exceptions

ﾉ Expand table

Exception Description

Failed to run PowerShell script Indicates a problem running the provided PowerShell script

Failed to run script in the allotted Indicates a problem running the provided script in the
time allotted time

Run Python script
Executes Python script code and retrieves its output.

Input parameters



ﾉ Expand table

Argument Optional Accepts Default Description
Value

Python script No Text value The Python script code to execute
to run

Python version No Python 2.7, Python 2.7 Specify which version of Python to
Python 3.4 use when executing the script

Module folder Yes List of Folders The paths of folders where external
paths Python modules lie

Variables produced
ﾉ Expand table

Argument Type Description

PythonScriptOutput Text The script's output
value

ScriptError Text The errors that might occur during the execution of the Python
value script code

Exceptions

ﾉ Expand table

Exception Description

Failed to run Python script Indicates a problem running the provided Python script

Directory not found Indicates that the directory wasn't found

Run .NET script
Executes .NET (C#/VB.NET) script code and retrieves its output.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Language N/A C#/ VB.NET C# The language of the script

.NET script Yes Text value The .NET script imports to be
imports included in the script

References to Yes Folder The root path where .NET
be loaded dynamic link libraries (.dll files)

references are located

Script Yes Script Parameters Setting the values of the
parameters as defined by the parameters that are defined in

user the script

.NET code to No Text value The .NET code to run
run

Variables produced
This action might produce variables, depending on the configuration made by the user
when using the Script Parameters window.

７ Note

In the case the action is configured to produce output parameters (using the Out
direction when configuring them), you should always ensure that the parameter
inside the script is set to a value other than null. Otherwise, the script execution
results in an error since the output parameter hasn't been set.

Exceptions

ﾉ Expand table

Exception Description

Failed to run the .NET script Indicates a problem running the provided .NET script

Feedback



Was this page helpful?  Yes  No

Provide product feedback



File actions
Article • 10/24/2023

） Important

To prevent unauthorized access, Windows requires administrator rights to access
protected files. To access these resources using the file actions, run Power
Automate with administrator rights. For more information about running Power
Automate as an administrator, go to Run Power Automate with elevated rights.

Handling files and their content is essential for most automation scenarios. You can use
the file actions to manage files, retrieve their properties, read and write data, and
convert them to other types.

Most file actions require paths that specify the files you want to manipulate. These paths
can be hard-coded values or file datatype variables.

７ Note

To provide many files as input, use a list variable with file items. A method to create
a list of files is the Get files in folder action.

Similarly, you can populate a hard-coded value or a folder datatype variable to specify a
destination folder in the actions that need one.



Some file actions provide an extensive configuration, allowing you to automate virtually
any scenario. For example, the Rename file(s) action includes options to set a new name
or add, replace or remove a text string to the existing file name.



To append text content or overwrite text files, deploy the Write text to file action. To
read the content of a text file, use the Read text from file action.

Likewise, if you need to read or write content to CSV files, use the Read from CSV file
and Write to CSV file actions. You can find an example desktop flow that handles CSV
files in Convert a CSV file into an Excel spreadsheet.

If you want to check if a file exists in a specific folder, use the If file exists action. This
action is a conditional and allows you to run different blocks of code depending on
whether the file exists. To find more information about conditionals, go to Use
conditionals.

If file exists
Marks the beginning of a conditional block of actions depending on whether a file exists
or not.

Input parameters



Argument Optional Accepts Default Value Description

If file N/A Exists, Doesn't exist Exists The state of the file to check

File path No File The full path to look for the file

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Wait for file
Suspend the execution of the automation until a file is created or deleted.

Input parameters
Argument Optional Accepts Default Description

Value

Wait for file N/A Created, Created Specifies whether to pause the flow on
to be Deleted the creation or deletion of a certain file

File path No File The full path to look for the file

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Copy file(s)
Copy one or more files into a destination folder.



Input parameters
Argument Optional Accepts Default Description

Value

File(s) to No List of Files The file(s) to copy. This value can be a file
copy path, or a variable containing a file, a list of

files, a text path, or a list of text paths. Use
the 'Get files in folder' action to populate a
variable with a list of files.

Destination No Folder The destination folder for the copied files
folder

If file exists N/A Do nothing, Do Specifies what to do if a file with the same
Overwrite nothing name already exists in the destination folder

Variables produced
Argument Type Description

CopiedFiles List of Files The copied file(s) as a list of files

Exceptions
Exception Description

Source folder doesn't exist Indicates that the source folder doesn't exist

Destination folder doesn't exist Indicates that the destination folder doesn't exist

File not found Indicates that the file doesn't exist

Can't copy file Indicates a problem copying the file

Move file(s)
Move one or more files into a destination folder.

Input parameters



Argument Optional Accepts Default Description
Value

File(s) to No List of Files The file(s) to move. This value can be a file
move path, or a variable containing a file, a list of

files, a textual path, or a list of text paths.
Use the 'Get files in folder' action to
populate a variable with a list of files.

Destination No Folder The destination folder for the moved files
folder

If file exists N/A Do nothing, Do Specifies what to do if a file with the same
Overwrite nothing name already exists in the destination folder

Variables produced
Argument Type Description

MovedFiles List of Files The moved file(s) as a list of files

Exceptions
Exception Description

Source folder doesn't exist Indicates that the source folder doesn't exist

Destination folder doesn't exist Indicates that the destination folder doesn't exist

File not found Indicates that the file doesn't exist

Can't move file Indicates a problem moving the file

Delete file(s)
Delete one or more files.

Input parameters
Argument Optional Accepts Default Description

Value

File(s) to No List of The file(s) to delete. This value can be a file path,
delete Files or a variable containing a file, a list of files, a text



Argument Optional Accepts Default Description
Value

path, or a list of text paths. Use the 'Get files in
folder' to populate a variable with a list of files

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

File path doesn't exist Indicates that the file path doesn't exist

File not found Indicates that the file doesn't exist

Can't delete file Indicates a problem deleting the file

Rename file(s)
Change the name of one or more files.

Input parameters
Argument Optional Accepts Default Description

Value

File to No List of Files The file(s) to rename. This value
rename can be a file path, or a variable

containing a file, a list of files, a
text path, or a list of text paths.
Use the 'Get files in folder'
action to populate a variable
with a list of files.

Add number N/A Boolean value True Specifies whether to add the
to number to the existing file

name(s) or a new name

Rename N/A Set new name, Add Set new Specifies how to rename the
scheme text, Remove text, name file(s)

Replace text, Change
extension, Add



Argument Optional Accepts Default Description
Value

datetime, Make
sequential

New file No Text value The new name of the file(s)
name

New Yes Text value The text to add as the new
extension extension for the file(s)

New file No Text value The new name of the file(s)
name

Add number N/A After name, Before After name Specifies whether to add the
to name number before or after the

original name(s) or a new base
name

Text to add Yes Text value The text to add to the original
file name(s)

Text to Yes Text value The text to remove from the
remove original file name(s). This

rename scheme searches each
file name, and removes the
entered text anywhere in the
name, each time it occurs.

Text to No Text value The text to replace in the
replace original file name(s). This

rename scheme searches each
file name, and replaces the
entered text anywhere in the
name, each time it occurs

Use custom N/A Boolean value False Specifies whether to use a
datetime custom datetime

Datetime to N/A Current datetime, Current Specifies what datetime value to
add Creation time, Last datetime add to the file name(s)

accessed, Last
modified

Keep N/A Boolean value True Specifies whether to include the
extension previous extension with the file

name(s). Disable this option to
add the extension to the file(s)
manually.



Argument Optional Accepts Default Description
Value

Replace with Yes Text value The text to replace the original
text with

Start No Numeric value The starting number value
numbering
at

Add text N/A After name, Before After name Specifies whether to add the text
name before or after the original

name(s)

Custom No Datetime The datetime to add to the file
datetime name(s)

Increment No Numeric value The number to increment the
by starting value by

Add N/A After name, Before After name Specifies whether to add the
datetime name datetime before or after the

original name(s)

Separator N/A Nothing, Space, Space Specifies what to use to separate
Dash, Period, the original file name and the
Underscore number added, including the

option to not use a separator

Separator N/A Nothing, Space, Space Specifies what to use to separate
Dash, Period, the original file name and the
Underscore datetime value added, including

the option to not use a
separator

Use padding N/A Boolean value False Specifies whether to use
padding

Datetime No Text value yyyyMMdd The format of the datetime value
format to add to the file name, such as

MM/dd/yyyy for date, and
hh:mm:sstt for time

Make each Yes Numeric value 3 The minimum length for each
number at number added
least

If file exists N/A Do nothing, Do nothing Specifies what to do if a file with
Overwrite the same name already exists in

the folder



Variables produced
Argument Type Description

RenamedFiles List of Files The renamed file(s) as a list of files

Exceptions
Exception Description

Directory not found Indicates that the directory wasn't found

File not found Indicates that the file doesn't exist

Can't rename file Indicates a problem renaming the file

Read text from file
Read the contents of a text file.

Input parameters
Argument Optional Accepts Default Description

Value

File path No File The file to read

Store N/A Single text value, Single Specifies how to store the text. Choose
content as List (each is a list text 'Single text value' to store the entire

item) value text as a single text value. Choose 'List'
to store each line of the original text as
a text item in a list.

Encoding N/A System default, UTF-8 The encoding to read the specified text
ASCII, Unicode, from the text file with.
Unicode (big-
endian), UTF-8

Variables produced
Argument Type Description

FileContents Text value The contents as a text



Argument Type Description

FileContents List of Text values The contents as a list of texts

Exceptions
Exception Description

Directory not found Indicates that the directory wasn't found

File not found Indicates that the file doesn't exist

Failed to read from file Indicates a problem reading from the file

Write text to file
Write or appends text to a file.

Input parameters
Argument Optional Accepts Default Description

Value

File path No File The file to write the text. This
value can be a file path, or a
variable containing a file or a
textual path.

Text to Yes General value The text to write in the
write specified file

Append N/A Boolean value True Specifies whether to append a
new line new line at the end of the

overall text to write to the file

If file exists N/A Overwrite existing Overwrite Specifies whether to overwrite
content, Append existing the existing content, or to
content content append to the end of the

existing content. If the file
doesn't exist, this action
automatically creates it.

Encoding N/A System default, ASCII, Unicode The encoding to use for the
Unicode, Unicode (big- specified text to write into the
endian), UTF-8, Unicode text file
(without byte order



Argument Optional Accepts Default Description
Value

mask), UTF-8 (without
byte order mask)

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Failed to write text to file Indicates a problem writing to the file

Invalid directory for file Indicates that the directory is invalid

Read from CSV file
Read a CSV file into a data table.

You can use the Read from CSV file action to create a datatable variable with the file's
contents. You need to define the path to the CSV file and the encoding to use for
reading it, while you can also trim any whitespaces from the extracted cells, handle the
first line as column headers, and specify the columns separator.

Input parameters
Argument Optional Accepts Default Description

Value

File path No File The CSV file to read. This value can
be a file path, or a variable
containing a file or a textual path

Encoding N/A UTF-8, Unicode, UTF-8 The encoding to be used for
Unicode (big- reading the specified CSV file
endian), UTF-8 (No
byte order mark),
Unicode (no byte
order mark),
System default,
ASCII



Argument Optional Accepts Default Description
Value

Trim fields N/A Boolean value True Specifies whether to automatically
trim off the leading and trailing
whitespaces of the extracted cells

First line N/A Boolean value False Specifies whether to use the first
contains row of the CSV resource to set the
column column names of the resulting
names data table variant. Enable this

option to avoid reading the names
as data into the table. Subsequent
actions may access the data held
by the data table using column
names (instead of column
numbers).

Columns N/A Predefined, Predefined Specifies whether to use a
separator Custom, Fixed predefined columns separator, a

column widths custom one or fixed column widths

Separator N/A System default, System The column-separator to parse the
Comma, default CSV file
Semicolon, Tab

Custom No Text value The custom column-separator to
separator use for parsing the CSV resource

specified

Fixed No Text value The fixed column-widths to use for
column parsing the CSV resource specified.
widths Separate the widths using

commas, spaces, tabs or newlines.

Variables produced
Argument Type Description

CSVTable Datatable The contents of the CSV file as a data table

Exceptions
Exception Description

Read from CSV failed Indicates a problem reading from the CSV file



Write to CSV file
Write a data table, data row or list to a CSV file.

Use the Write to CSV file action to write a data table, data row or list variable to a target
CSV file. In the File path parameter, specify the file path or variable containing a file or
textual path where the data will be exported to.

Input parameters
Argument Optional Accepts Default Description

Value

Variable to No General value The data table, data row variable
write or list variable to write into the

target CSV file

File path No File The CSV file to export the
variable to. This value can be a
file path, or a variable containing
a file or a textual path.

Encoding N/A UTF-8, Unicode, UTF-8 The encoding to use for writing
Unicode (big- to the specified CSV file
endian), UTF-8 (No
byte order mark),
Unicode (no byte
order mark), System
default, ASCII

Include N/A Boolean value False Specifies whether the column
column names of the variant specified
names should become the first row of

the CSV file. This option takes
effect if and only if the target
CSV file either doesn't initially
exist or exists but is otherwise
empty of text.

If file exists N/A Overwrite existing Overwrite Specifies the desired behavior
content, Append existing when the targeted CSV file
content content already exists in the filesystem

Separator N/A System default, System The column separator to use in
Comma, Semicolon, default the specified CSV file
Tab



Argument Optional Accepts Default Description
Value

Custom No Text value The custom column separator to
columns use in the CSV file
separator

Use custom N/A Boolean value False Specifies whether to use a
columns custom columns separator or a
separator predefined one

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Write failed Indicates a problem writing to the CSV file

Get file path part
Retrieve one or more parts (directory, filename, extension, etc.) from a text that
represents a file path.

Input parameters
Argument Optional Accepts Default Value Description

File path No File The file path to use as the source

Variables produced
Argument Type Description

RootPath File The root path of the source file

Directory Folder The directory of the source file

FileName Text value The name of the source file

FileNameNoExtension Text value The file name (without the extension) of the source file



Argument Type Description

FileExtension Text value The extension (for example, .doc) of the source file

Exceptions
Exception Description

File path contains invalid characters Indicates that the file path doesn't exist

Get temporary file
Create a uniquely named, empty temporary file on disk, and get the file object (which is
a representation, and can access the file and all its information).

Input parameters
This action doesn't require any input.

Variables produced
Argument Type Description

TempFile File The temporary file object

Exceptions
Exception Description

Failed to create temporary file Indicates a problem creating a temporary file

Convert file to Base64
Convert a file to Base64 encoded text.

Input parameters
Argument Optional Accepts Default Value Description

File path No File The file path to read from



Argument Optional Accepts Default Value Description

Variables produced
Argument Type Description

Base64Text Text value The Base64 encoded text

Exceptions
Exception Description

File not found Indicates that the file doesn't exist

Can't convert file to Indicates that the provided file can't be converted into Base64
Base64 encoded text

Convert Base64 to file
Convert a Base64 encoded text to file.

Input parameters
Argument Optional Accepts Default Description

Value

Base64 No Text value The Base64 encoded text
encoded text

File path No File The file to write to

If file exists N/A Do nothing, Do Specifies what to do if a file with the
Overwrite nothing same name already exists in the

destination folder

Variables produced
This action doesn't produce any variables.

Exceptions



Exception Description

Invalid directory for file Indicates that the directory is invalid

Can't convert Base64 to Indicates that the provided Base64 encoded text can't be converted
file into a file

Convert file to binary data
Convert a file to binary data.

Input parameters
Argument Optional Accepts Default Value Description

File path No File The file to read from

Variables produced
Argument Type Description

BinaryData Text value The binary data to write

Exceptions
Exception Description

File not found Indicates that the file doesn't exist

Can't convert file to binary Indicates that the provided file can't be converted to binary
data data

Convert binary data to file
Convert binary data to file.

Input parameters



Argument Optional Accepts Default Description
Value

Binary No Text value The binary data
data

File path No File The file to write to

If file N/A Do nothing, Do Specifies what to do if a file with the same
exists Overwrite nothing name already exists in the destination

folder

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Invalid directory for file Indicates that the directory is invalid

Can't convert binary file to Indicates that the provided binary data can't be converted into a
file file



Folder actions
Article • 10/20/2023

） Important

To prevent unauthorized access, Windows require administrator rights to access
protected folders. To access these resources using the folder actions, run Power
Automate with administrator rights. For more information about running Power
Automate as an administrator, go to Run Power Automate with elevated rights.

Power Automate folder actions enable you to manipulate and organize folders.

The Get special folder action retrieves the paths for commonly used directories that
vary among users and machines. The following example retrieves the desktop directory
and stores it in a variable.

You can now use the %SpecialFolderPath% variable any time it's necessary, regardless
of the user who runs the flow or the computer on which it runs.

Create new folders with the Create folder action.

To get a list of a folder's contents, use the Get subfolders in folder action. This action
retrieves a list of folders located within the specified folder. The following example
retrieves all the subfolders of a specified special folder. In the Advanced section, you can



see that the action sorts the results by creation time in ascending order and name in
descending order.

You can also copy, move, rename, and delete or empty folders using the appropriate
actions.

If folder exists



Mark the beginning of a conditional block of actions depending on whether a folder
exists or not.

Input parameters
Argument Optional Accepts Default Description

Value

If folder N/A Exists, Exists Choose the state of the folder to check
Doesn't
exist

Folder No Folder Enter or choose the full path of the folder,
path or a variable containing the folder, to check

its state

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Get files in folder
Retrieve the list of files in a folder.

To retrieve all files in a specific folder, use the action Get files in folder. Specify the
folder path in the Folder property and then use the * character in the File filter property
(included by default). In case you want to also include all files included in the subfolder
inside the specified folder, enable the Include subfolders toggle. The retrieved filepaths
are then stored in the output of the action.

Input parameters
Argument Optional Accepts Default Description

Value

Folder No Folder Enter or choose the full path of
the folder, or a variable



Argument Optional Accepts Default Description
Value

containing the folder, to
retrieve the list of files from

File filter No Text value * Choose a filter to limit the files
retrieved. This parameter
allows wild cards, for example,
*.txt or document?.doc. To
allow for multiple file filters,
separate the choices with a
semi-colon, for example,
.txt;.exe.

Include N/A Boolean value False Specify whether to look into
subfolders subfolders as well

Fail upon N/A Boolean value True Specify whether to throw an
denied access error when trying to get files of
to any a folder with no access rights
subfolder or ignore those folders

Sort by N/A No sort, Full name, Root No sort Specify whether to sort the
path, Directory, Name, results and by which criterion
Name without
extension, Extension,
Size, Creation time, Last
accessed, Last modified,
Is hidden, Is system, Is
read-only, Is archive,
Exists

Descending N/A Boolean value False Specify whether to sort the
items in descending or
ascending order

Then by N/A No sort, Full name, Root No sort Specify whether to sort the
path, Directory, Name, results by a second criterion
Name without
extension, Extension,
Size, Creation time, Last
accessed, Last modified,
Is hidden, Is system, Is
read-only, Is archive,
Exists

Descending N/A Boolean value False Specify whether to sort the
items in descending or
ascending order



Argument Optional Accepts Default Description
Value

Then by N/A No sort, Full name, Root No sort Specify whether to sort the
path, Directory, Name, results by a third criterion
Name without
extension, Extension,
Size, Creation time, Last
accessed, Last modified,
Is hidden, Is system, Is
read-only, Is archive,
Exists

Descending N/A Boolean value False Specify whether to sort the
items in descending or
ascending order

Variables produced
Argument Type Description

Files List of Files The retrieved files as a list of file objects

Exceptions
Exception Description

Folder doesn't exist Indicates that the folder wasn't found

Can't retrieve list of files Indicates a problem retrieving the list of files

Get subfolders in folder
Retrieve the list of subfolders in a folder.

Input parameters
Argument Optional Accepts Default Description

Value

Folder No Folder Enter or choose the full path
of the folder, or a variable
containing the folder, to



Argument Optional Accepts Default Description
Value

retrieve the list of subfolders
from

Folder filter No Text value * Choose a filter to limit the
subfolders retrieved. This
parameter allows wild cards,
for example, Doc* or
Document?. To allow for
multiple folder filters,
separate the choices with a
semi-colon, for example,
Doc*;*.

Include N/A Boolean value False Specify whether to look into
subfolders the subfolders and retrieve

their subfolders (and so on)
as well

Fail upon N/A Boolean value True Specify whether to throw an
denied access error when trying to get
to any subfolders of a folder with no
subfolder access rights or ignore those

folders

Sort by N/A No sort, Full name, Root No sort Specify whether to sort the
path, Directory, Name, results and by which criterion
Name without extension,
Extension, Size, Creation
time, Last accessed, Last
modified, Is hidden, Is
system, Is read-only, Is
archive, Exists

Descending N/A Boolean value False Specify whether to sort the
items in descending or
ascending order

Then by N/A No sort, Full name, Root No sort Specify whether to sort the
path, Directory, Name, results by a second criterion
Name without extension,
Extension, Size, Creation
time, Last accessed, Last
modified, Is hidden, Is
system, Is read-only, Is
archive, Exists

Descending N/A Boolean value False Specify whether to sort the
items in descending or



Argument Optional Accepts Default Description
Value

ascending order

Then by N/A No sort, Full name, Root No sort Specify whether to sort the
path, Directory, Name, results by a third criterion
Name without extension,
Extension, Size, Creation
time, Last accessed, Last
modified, Is hidden, Is
system, Is read-only, Is
archive, Exists

Descending N/A Boolean value False Specify whether to sort the
items in descending or
ascending order

Variables produced
Argument Type Description

Folders List of Folders The retrieved subfolders as a list of folder objects

Exceptions
Exception Description

Folder doesn't exist Indicates that the folder wasn't found

Can't retrieve list of subfolders Indicates a problem retrieving the list of subfolders

Create folder
Create a new folder.

Input parameters
Argument Optional Accepts Default Description

Value

Create new No Folder Enter or choose the full path of the folder,
folder into or a variable containing the folder, to create

a new folder in



Argument Optional Accepts Default Description
Value

New folder No Text Enter the text, or a text variable, to be the
name value name of the new folder

Variables produced
Argument Type Description

NewFolder Folder The created folder object (which is a representation and can access the
folder and all its information)

Exceptions
Exception Description

Folder doesn't exist Indicates that the folder wasn't found

Can't create folder Indicates a problem creating the folder

New folder path and name are Indicates that both the new folder path and folder name don't
empty have value

Delete folder
Delete an existing folder and its contents (files and subfolders).

Input parameters
Argument Optional Accepts Default Description

Value

Folder to No Folder Enter or choose the full path of the folder, or a
delete variable containing the folder, to delete.

Remember that all contents of that folder and its
subfolders are deleted too.

Variables produced
This action doesn't produce any variables.



Exceptions
Exception Description

Folder doesn't exist Indicates that the folder wasn't found

Can't delete folder Indicates a problem deleting the folder

Empty folder
Delete all the contents of a folder (files and subfolders) without deleting the folder itself.

Input parameters
Argument Optional Accepts Default Description

Value

Folder to No Folder Enter or choose the full path of the folder, or a
empty variable containing the folder, to delete its

contents

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Folder doesn't exist Indicates that the folder wasn't found

Can't delete folder's contents Indicates a problem clearing the folder's contents

Copy folder
Copy a folder into a destination folder.

Input parameters



Argument Optional Accepts Default Description
Value

Folder to No Folder Enter or choose the full path of the folder, or
copy a variable containing the folder, to copy. If the

folder path ends with a \ only the contents of
the folder (files + subfolders) are copied.
Otherwise, the folder itself (along with its
contents) is copied as a subfolder into the
destination folder.

Destination No Folder Enter or choose the full path of the folder, or
folder a variable containing the folder, to be the

destination folder

If folder N/A Do Do Specify whether to overwrite files or not copy
exists nothing, nothing them at all, if the destination folder already

Overwrite exists. If the folder exists, but the files have
different names, the old files still remain in the
folder.

Variables produced
Argument Type Description

CopiedFolder Folder The copied folder object (which is a representation and can access the
folder and all its information)

Exceptions
Exception Description

Folder doesn't exist Indicates that the folder wasn't found

Destination folder doesn't exist Indicates that the destination folder wasn't found

Can't copy folder Indicates a problem copying the folder

Move folder
Move an existing folder into a destination folder.

Input parameters



Argument Optional Accepts Default Description
Value

Folder to No Folder Enter or choose the full path of the folder, or
move a variable containing the folder, to move

Destination No Folder Enter or choose the full path of the folder, or
folder a variable containing the folder, to be the

destination folder

Variables produced
Argument Type Description

MovedFolder Folder The moved folder object (which is a representation and can access the
folder and all its information)

Exceptions
Exception Description

Folder doesn't exist Indicates that the folder wasn't found

Destination folder doesn't exist Indicates that the destination folder wasn't found

Can't move folder Indicates a problem moving the folder

Rename folder
Change the name of a folder.

Input parameters
Argument Optional Accepts Default Description

Value

Folder to No Folder Enter or choose the full path of the folder, or
rename a variable containing the folder, to change its

name

New folder No Text Enter the text, or a text variable, to be the
name value new folder name



Variables produced
Argument Type Description

RenamedFolder Folder The renamed folder object (which is a representation and can access
the folder and all its information)

Exceptions
Exception Description

Folder doesn't exist Indicates that the folder wasn't found

Can't rename folder Indicates a problem renaming the folder

Get special folder
Retrieve the path of a Windows' special folder (such as Desktop, My Pictures, Internet
Cache etc.).

Input parameters
Argument Optional Accepts Default Description

Value

Special N/A Programs, Personal, Favorites, Desktop Choose the name of the
folder Startup, Recent, Send To, Start special folder (like My
name Menu, Music, Desktop, Documents or Desktop).

Templates, Application Data, This option is
Local Application Data, Internet independent of path, to
Cache, Cookies, History, find the special folder on
Common Application Data, any computer regardless
System, Program Files, Pictures, of path specifics.
Common Program Files

Variables produced
Argument Type Description

SpecialFolderPath Folder The special folder object (which is a representation and can access
the folder and all its information)



Exceptions
This action doesn't include any exceptions.



Compression actions
Article • 12/16/2022

To compress (or zip) a file, use the ZIP files action and specify a path to archive. If the
archive already exists, the action will add the selected files.

The following example uses a variable to specify the path to archive. Best compression
ensures maximum file size reduction, and a password adds a layer of security to the
archive.

The Unzip files action works similarly, requiring a path to archive and a destination
folder. The following example uses the Include mask option to only unzip files with the
extensions .txt and .xlsx.



ZIP files
Compress one or more files or folders into a ZIP archive.

Input parameters
Argument Optional Accepts Default Description

Value

Archive path No File The full path of ZIP file to create. If
the file already exists, this action
adds the new zipped files and/or
to the existing ZIP file. If the ZIP
file already contains a file or folder
with the same name, it overwrites
it.

File(s) to zip No List of The full path of the file(s) or
FileSystemObject folder(s) to include in the ZIP file



Argument Optional Accepts Default Description
Value

Compression N/A None, Best Best balance The level of compression to use.
level speed, Best of speed The higher the compression the

balance of speed and smaller the file, though it takes
and compression longer to create or access
compression,
Best
compression

Password Yes Direct encrypted The password to use for protecting
input or Text the ZIP. Leave this attribute blank
value to create a non password-

protected ZIP

Archive Yes Text value The comment to include in the ZIP
comment file as a file property

Variables produced
Argument Type Description

ZipFile File The ZIP file created by this action

Exceptions
Exception Description

File or folder doesn't exist Indicates that the specified file or folder doesn't exist

File or folder name is invalid Indicates that the file or folder name is invalid

Archive already exists but it isn't a valid Indicates that the archive already exists but it isn't a
ZIP archive valid ZIP archive

Failed to zip files Indicates a problem zipping the files

Unzip files
Uncompress one or more files or folders contained in a ZIP archive.

Input parameters



Argument Optional Accepts Default Description
Value

Archive No File The full path of a ZIP file to extract
path

Destination No Folder The full path of the folder to extract the archive
folder to. This action overwrites files in the folder with

the same name as a file in the archive

Password Yes Direct The password, if any, that is used for this archive.
encrypted If the ZIP file isn't password-protected, leave this
input or blank
Text value

Include Yes Text value The filter to limit the files extracted to the files
mask entered here. This parameter allows wild cards,

for example '.txt' or 'document?.doc' (without the
quotes). To allow multiple file filters, separate the
choices with a semi-colon, for instance, '.txt;*.exe'

Exclude Yes Text value The filter to limit the files extracted by excluding
mask the file entered here. This parameter allows wild

cards, for example, '.txt' or 'document?.doc'
(without the quotes). To allow multiple file filters,
separate the choices with a semi-colon, for
instance, '.txt;*.exe'

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Can't create destination folder Indicates that the destination folder couldn't be created

Archive not found Indicates that the archive doesn't exist

Archive isn't a valid ZIP file Indicates that the archive isn't a valid ZIP file

Failed to unzip files Indicates a problem unzipping the files



UI automation actions
Article • 10/14/2024

） Important

To prevent unauthorized access, Power Automate needs to run with the same or
higher privileges as the applications it automates. To use the UI automation actions
(except for the Use desktop action) to interact with applications that run with
elevated privileges, run Power Automate as administrator. To find more information
regarding running Power Automate as an administrator, go to Run Power
Automate with elevated rights.

Power Automate provides various UI automation actions to enable users to interact with
Windows and desktop applications. Some UI automation actions require you to set UI
elements in their properties to indicate the element you want to handle.

To add a new UI element, select Add UI element through the deployed UI automation
action or the UI elements pane of the flow designer.

All UI elements consist of selectors that pinpoint the hierarchical structure of the
components. Selectors use the > notation to indicate that each element is contained
within the element on its left.



When you create a UI element of an application window, its selector always has a root
element named :desktop.

If you create a UI element that pinpoints a component inside an application window,
two UI elements will be created automatically. The parent UI element pinpoints the
application window, while the child shows the hierarchical structure of the specific
component inside the window.

Although selectors are created automatically when adding UI elements, some particular
scenarios need manually created selectors. When a custom selector is needed, you can
edit an existing selector or build one from scratch.



To develop more dynamic flows, replace the Equals to operators with other operators or
regular expressions. Additionally, if the value of a selector's attribute depends on the
results of previous actions, use variables instead of hard-coded values.



For many actions of UI automation there are two modes for executing actions: physical
and simulated. In physical mode, the tool takes control of the machine's mouse and
keyboard to perform the action physically. In simulated mode, the action is performed
programmatically without taking control of the mouse and keyboard and without
requiring the UI element's screen to be brought to the foreground. It's important to
note that the simulated option might not be applicable to every UI element. To perform
an action by simulation, either enable the Simulate action parameter in some actions or
disable the Bring to front parameter in other actions.

７ Note

To find more information about developing UI automation flows and creating
custom selectors, go to Automate desktop flows and Build a custom selector,
respectively.

Get details of window
Gets a property of a window such as its title or its source text.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Window No UI element The window to get details from

Window N/A Get window Get Choose which property of the window to
property title, Get window extract

window text, title
Get window



Argument Optional Accepts Default Description
Value

location and
size, Get
process name

Bring to N/A Boolean value True Specify whether the window containing the
front UI element will be brought to the front

during execution. If this option is disabled,
the action is executed in the background.
Note that not all UI elements are
compatible with having the option
disabled. Additionally, if execution of the
action requires scrolling, disabling this
option might not extract all elements.

Variables produced
ﾉ Expand table

Argument Type Description

WindowProperty General value The retrieved information of the window

Exceptions

ﾉ Expand table

Exception Description

Failed to retrieve property of window Indicates a problem retrieving the window property

Get details of a UI element in window
Gets the value of a UI element's attribute in a window.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

UI element No UI The UI element to get details from
element

Attribute Yes Text Own The attribute whose value will be retrieved
name value Text

Bring to N/A Boolean True Specify whether the window containing the UI
front value element will be brought to the front during

execution. If this option is disabled, the action is
executed in the background. Note that not all UI
elements are compatible with having the option
disabled. Additionally, if execution of the action
requires scrolling, disabling this option might not
extract all elements.

Variables produced

ﾉ Expand table

Argument Type Description

AttributeValue Text value The value of the UI element's text

Exceptions

ﾉ Expand table

Exception Description

Failed to retrieve attribute of UI Indicates a problem retrieving the UI element's
element attribute

Get selected checkboxes in window
Retrieves the names of the selected checkboxes in a checkbox group or the state of a
specific checkbox.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

UI element No UI element The checkbox or checkbox group

Operation N/A Get names of Get names of Specify whether to retrieve the state
selected selected of multiple selected checkboxes or
checkboxes in checkboxes just one
group, Get in group
state of
checkbox

Bring to N/A Boolean value True Specify whether the window
front containing the UI element should be

brought to the front during
execution. If this option is disabled,
the action will be executed in the
background. Note that not all UI
elements might be compatible with
having the option disabled.
Additionally, if execution of the action
requires scrolling, disabling this
option might not extract all elements.

Variables produced

ﾉ Expand table

Argument Type Description

IsChecked Boolean value The state of the selected checkbox

SelectedCheckboxes List of Text The names of selected checkboxes inside the specified
values checkbox group

Exceptions

ﾉ Expand table

Exception Description

Failed to retrieve checkbox state(s) Indicates a problem retrieving the specified checkbox state(s)

Get selected radio button in window



Retrieves the names of the selected radio button in a radio button group or the state of
a specific radio button.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

UI element No UI element The radio button or radio button group

Operation N/A Get selected Get Specify whether to retrieve the name of
radio button selected the radio button that's selected inside a
name in radio group of radio buttons or just the state of
group, Get button a single radio button
state of radio name in
button group

Bring to N/A Boolean True Specify whether the window containing
front value the UI element will be brought to the front

during execution. If this option is disabled,
the action is executed in the background.
Note that not all UI elements are
compatible with having the option
disabled. Additionally, if execution of the
action requires scrolling, disabling this
option might not extract all elements.

Variables produced
ﾉ Expand table

Argument Type Description

IsSelected Boolean value The state of the selected radio button

SelectedRadiobutton Text value The selected radio button inside the specified radio group

Exceptions

ﾉ Expand table



Exception Description

Failed to retrieve radio button Indicates a problem retrieving the specified radio button
state state

Extract data from window
Extracts data from specific parts of a window in the form of single values, lists, or tables.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Window No UI element The window to extract data from

Store N/A an Excel an Excel Specify where to store the extracted
extracted spreadsheet, spreadsheet data
data in A variable

Bring to N/A Boolean value True Specify whether the window containing
front the UI element will be brought to the

front during execution. If this option is
disabled, the action is executed in the
background. Note that not all UI
elements are compatible with having
the option disabled. Additionally, if
execution of the action requires
scrolling, disabling this option might
not extract all elements.

Variables produced
ﾉ Expand table

Argument Type Description

ExcelInstance Excel The Excel instance with the extracted data. Use this instance to
instance manipulate the spreadsheet (or save and close it) by using the

dedicated Excel actions.

DataFromWindow General The extracted data in the form of a datatable
value



Exceptions

ﾉ Expand table

Exception Description

Extraction failed Indicates a problem extracting data from the specified window

Extract data from table
Extracts data from a table in the form of a datatable.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Table No UI element The table or grid to extract data from

Store N/A an Excel an Excel Specify where to store the extracted
extracted spreadsheet, spreadsheet data
data in A variable

Bring to N/A Boolean value True Specify whether the window containing
front the UI element is brought to the front

during execution. If this option is
disabled, the action is executed in the
background. Not all UI elements are
compatible with having the option
disabled. Additionally, if execution of
the action requires scrolling, disabling
this option might not extract all
elements.

Variables produced

ﾉ Expand table

Argument Type Description

ExcelInstance Excel The Excel instance with the extracted data. Use this instance to
instance manipulate the spreadsheet (or save and close it) by using the



Argument Type Description

dedicated Excel actions.

DataFromTable General The extracted data in the form of a datatable
value

Exceptions
ﾉ Expand table

Exception Description

Extraction failed Indicates a problem extracting data from the specified table

Take screenshot of UI element
Takes a screenshot of a UI element in window.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

UI element No UI element The UI element in the window to
capture as screenshot

Save mode N/A Clipboard, File Clipboard Specify whether to save the
image into a file or store it into
the clipboard

Image file No File Set the full path for the file to be
path saved

File format N/A BMP, EMF, EXIF, GIF, BMP The file format of the image file
JPG, PNG, TIFF, WMF

Variables produced

ﾉ Expand table



Argument Type Description

ImageFile File The file path of the generated screenshot image file

Exceptions

ﾉ Expand table

Exception Description

Failed to retrieve UI element Indicates a problem retrieving the UI element

Failed to save image Indicates a problem saving the taken screenshot

Failed to take screenshot of UI Indicates a problem taking a screenshot of the UI
element element

Focus text field in window
Sets the focus on a text box of a window and scrolls it into view.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Value Description

Text field No UI element The text box to focus

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to set input focus in window Indicates a problem setting the focus on the specified web
text box page text field



Populate text field in window
Fills a text box in a window with the specified text.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Text box No UI element The text box to populate

Text to fill No Direct The text to fill in the text field
in encrypted

input or
Text value

Simulate N/A Boolean False Simulate the keystrokes programmatically
action value when populating text to UI text field

elements. This option doesn't require the UI
element's screen to be focused, it will not
automatically bring it to the foreground.
Note this option can be applied only to left-
click action and it might not be applicable to
every UI element.

If field isn't Yes Replace Replace Specify whether to replace existing content,
empty text, text or to append.

Append text

Click before Yes Left-click, Left- Specify whether a left mouse click is
populating Double- click performed before populating the text field or

click, No not.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table



Exception Description

Failed to write in textbox Indicates a problem populating the specified text field

Press button in window
Presses a window button.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

UI element No UI element The button to press

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to press button Indicates a problem pressing the specified button

Select radio button in window
Selects a radio button on a window.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

Radio button No UI element The radio button to select



Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to select radio button UI Indicates a problem selecting the specified radio button UI
element element

Set checkbox state in window
Checks or unchecks a checkbox in a window form.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Checkbox No UI element The checkbox to set the state of

Set checkbox N/A Checked, Checked Specify whether the checkbox will
state to Unchecked become checked or unchecked

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to set checkbox state Indicates a problem setting the specified checkbox state



Set drop-down list value in window
Sets or clears the selected options for a drop-down list in a window form.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Drop-down No UI element The drop-down list whose value to set
list

Operation N/A Clear selected Clear Specify whether you want to select a
options, Select selected value by name or by ordinal position (1
options by options 2 3 ...) or clear the selected value of the
name, Select drop-down list
options by
index

Option No List of Text Enter an option or a list of options to
names values be selected in the drop-down list.

Multiple options make sense only
when working with multi-selection
lists. If the list is single-selection, then
only the first option of the list specified
will be used.

Use regular N/A Boolean value False Specify whether the option names
expressions values to interpret as a regular

expression

Options No List of Numeric Enter an index or a list of indices to be
indices values selected in the drop-down list. Multiple

options make sense only when
working with multi-selection lists. If the
list is single-selection, then only the
first option of the list specified will be
used.

Variables produced
This action doesn't produce any variables.

Exceptions



ﾉ Expand table

Exception Description

Failed to select the specified options in Indicates a problem selecting the specified options
the drop-down list in the drop-down list

Get window
Gets a running window, for automating desktop applications.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Get window N/A Specific window, Specific Specify whether to look using a
Foreground window selector or the foreground window
window

UI element No UI element The selector of the window to get

Bring window N/A Boolean value False Specify whether to bring the window
to front to the foreground automatically

upon acquiring it

Fail if window N/A Boolean value True Specify whether to wait indefinitely
isn't found for the window to appear or to fail if

the window doesn't show up within a
set time period

Timeout No Numeric value The timeout to wait in seconds

Variables produced

ﾉ Expand table

Argument Type Description

WindowTitle Text value The title of the foreground window

AutomationWindow Window The specific window instance for use with later UI
instance Automation actions



Exceptions

ﾉ Expand table

Exception Description

Failed to get window Indicates a problem getting the window

Focus window
Activates and brings to the foreground a specific window.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Find N/A By window UI element, By Specify whether to look for the
window By window window window using a UI element or a
mode instance/handle, By title UI combination of window

and/or class element title/class

Window No UI element The window UI element

Window Yes Text value The window title. Wildcards can
title be used, like '?' or '*'.

Window No Numeric value The instance or handle of the
instance window to focus

Window Yes Text value If there are two windows with
class the same title, window class

might help differentiate
between them. In this case,
enter the class of the window
to use.

Variables produced
This action doesn't produce any variables.

Exceptions



ﾉ Expand table

Exception Description

Window wasn't found Indicates that the specified window wasn't found

Can't focus window Indicates a problem focusing the specified window

Can't perform window-related action in Indicates a problem performing window-related
noninteractive mode action in non-interactive mode

Set window state
Restores, maximizes or minimizes a specific window.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Find N/A By window UI element, By Specify whether to look for the
window By window window UI window using a UI element or
mode instance/handle, By title element a combination of window

and/or class title/class

Window No UI element The window UI element

Window Yes Text value The window title. Wildcards can
title be used, like '?' or '*'.

Window No Numeric value The instance or handle of the
instance window to set the state of

Window Yes Text value If there are two windows with
class the same title, window class

might help differentiate
between them. In this case,
enter the class of the window
to use.

Window N/A Restored, Maximized, Restored Choose in which state to
state Minimized display the window

Variables produced



This action doesn't produce any variables.

Exceptions
ﾉ Expand table

Exception Description

Window wasn't found Indicates that the specified window wasn't found

Can't set window state Indicates a problem setting the window state of the
specified window

Can't perform window-related action in Indicates a problem performing window-related
noninteractive mode action in non-interactive mode

Set window visibility
Shows a hidden window or hides a visible window.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Find N/A By window UI element, By Specify whether to look for the
window By window window window using a UI element or a
mode instance/handle, By title UI combination of window

and/or class element title/class

Window No UI element The window UI element

Window Yes Text value The window title. Wildcards can
title be used, like '?' or '*'.

Window No Numeric value The instance or handle of the
instance window to set the visibility of

Window Yes Text value If there are two windows with
class the same title, window class

might help differentiate
between them. In this case,
enter the class of the window
to use.



Argument Optional Accepts Default Description
Value

Visibility N/A Visible, Hidden Hidden Choose in which state to set the
window visibility to

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Window wasn't found Indicates that the specified window wasn't found

Can't set window visibility Indicates a problem setting the visibility of the
specified window

Can't perform window-related action in Indicates a problem performing window-related
noninteractive mode action in non-interactive mode

Move window
Sets the position of a specific window.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Find N/A By window UI element, By Specify whether to look for the
window By window window Window using a UI element or
mode instance/handle, By title UI a combination of window

and/or class element title/class

Window No UI element The window UI element

Window Yes Text value The window title. Wildcards can
title be used, like '?' or '*'.



Argument Optional Accepts Default Description
Value

Window No Numeric value The instance or handle of the
instance window to move

Window Yes Text value If you have two windows with
class the same title, Window Class

might help differentiate
between them. In this case,
enter the class of the window to
use.

Position X No Numeric value The X position of the window

Position Y No Numeric value The Y position of the window

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Window wasn't found Indicates that the specified window wasn't found

Can't move window Indicates a problem moving the specified window

Can't perform window-related action in Indicates a problem performing window-related
noninteractive mode action in non-interactive mode

Resize window
Sets the size of a specific window.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Find N/A By window UI element, By Specify whether to look for the
window By window window window using a UI element or a
mode instance/handle, By title UI combination of window

and/or class element title/class

Window No UI element The window UI element

Window Yes Text value The window title. Wildcards can
title be used, like '?' or '*'.

Window No Numeric value The instance or handle of the
instance window to resize

Window Yes Text value If there are two windows with
class the same title, window class

might help differentiate
between them. In this case,
enter the class of the window
to use

Width No Numeric value The new width, in pixels

Height No Numeric value The new height, in pixels

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Window wasn't found Indicates that the specified window wasn't found

Can't resize window Indicates a problem resizing the specified window

Can't perform window-related action in Indicates a problem performing window-related
noninteractive mode action in non-interactive mode

Close window
Closes a specific window.



Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Find N/A By window UI element, By Specify whether to look for the
window By window window window using a UI element or a
mode instance/handle, By title UI combination of window

and/or class element title/class

Window No UI element The window UI element

Window Yes Text value The window title. Wildcards can
title be used, like '?' or '*'.

Window No Numeric value The instance or handle of the
instance window to close

Window Yes Text value If there are two windows with
class the same title, window class

might help differentiate
between them. In this case,
enter the class of the window
to use.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Window wasn't found Indicates that the specified window wasn't found

Can't close window Indicates a problem closing the specified window

Can't perform window-related action in Indicates a problem performing window-related
noninteractive mode action in non-interactive mode

If window contains



Marks the beginning of a conditional block of actions depending on whether a specific
piece of text or UI element exists in a window.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Check if N/A Contains UI element, Contains UI Check whether a specific
window Doesn't contain UI element, element text or UI element exists

Contains text, Doesn't in a window
contain text

Check UI N/A Boolean value False Check whether a specific
element state UI element is enabled or

disabled

Text No Text value The text to check for

UI element No UI element The UI element to check
for

Window No UI element The window to check if
the text exists on

State N/A Enabled, Disabled Enabled The UI element state to
check for

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Wait for window content
Suspends the execution of the automation until a specific piece of text or UI element
appears or disappears from a Window.

Input parameters



ﾉ Expand table

Argument Optional Accepts Default Description
Value

Wait until N/A Contains UI element, Contains Whether to wait for a
window Doesn't contain UI UI element specific text or UI element

element, Contains text, to appear in a window
Doesn't contain text

Check UI N/A Boolean value False Check whether a specific
element state UI element is enabled or

disabled

Text No Text value The text to check for

UI element No UI element The UI element to check
for

Window No UI element The window to check if
the text exists on

State N/A Enabled, Disabled Enabled The UI element state to
check for

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Wait for window content failed Indicates that the wait operation failed

If image
This action marks the beginning of a conditional block of actions depending on whether
a selected image is found on the screen or not.

Input parameters



ﾉ Expand table

Argument Optional Accepts Default Value Description

If image N/A exists, doesn't exist exists Whether to check for the
existence or absence of the
selected image

Image No List of Images The image/s that the action
will check if it/they exist

Search for N/A Entire screen, Entire screen Whether to look for the
image on Foreground window specified image in the

only foremost window only or the
entire visible screen. Neither
choice will find the image if
it isn't clearly visible on the
screen

Search N/A Search whole screen Search whole Whether to scan the entire
mode or foreground screen or screen (or window) to find

window, Search on foreground the supplied text or only a
specified subregion window narrowed down subregion
of screen or of it
foreground window

Find all N/A Boolean value False Check whether all images on
images in the list exist or don't exist
the list

X1 Yes Numeric value The start X coordinate of the
subregion to scan for the
supplied text

X2 Yes Numeric value The end X coordinate of the
subregion to scan for the
supplied text

Y1 Yes Numeric value The start Y coordinate of the
subregion to scan for the
supplied text

Y2 Yes Numeric value The end Y coordinate of the
subregion to scan for the
supplied text

Tolerance Yes Numeric value 10 Specify how much the
image(s) searched for can
differ from the originally
chosen image



Argument Optional Accepts Default Value Description

Image N/A Basic, Advanced Basic Which image algorithm to
matching use when searching for
algorithm image

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Can't check image in noninteractive Indicates that an image can't be identified in non-
mode interactive mode

Invalid subregion coordinates Indicates that the coordinates of the given subregion
were invalid

Use desktop
Performs desktop and taskbar related operations.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

UI element No UI element The UI element to perform a click on

Click type N/A Left-click, Left- The kind of click to perform
Right-click, click
Double-
click

Launch new N/A Boolean True When this parameter is set to 'true', it
application value ensures that a new window of an
when left- application will be created when left-

clicking on its icon in the 'quick launch'



Argument Optional Accepts Default Description
Value

clicking on the bar, also known as the taskbar of Windows
taskbar 7 or above. Uncheck this option to bring

an already running instance of the
application to the foreground.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Taskbar operation failed Indicates that the taskbar operation failed

Select tab in window
Selects a tab from a group of tabs.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

Tab No UI element The tab to select

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table



Exception Description

Selecting tab failed Indicates a problem selecting the specified tab

Wait for image
This action waits until a specific image appears on the screen or on the foreground
window.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Wait for N/A Appear, Disappear Appear Check whether to wait for the
image to image(s) to appear or

disappear

Image to No List of Images The image/s that the action will
wait for check if it/they exist

Search for N/A Entire screen, Entire screen Whether to look for the
image on Foreground window specified image in the foremost

only window only or the entire
visible screen. Neither choice
will find the image if it isn't
clearly visible on the screen

Search N/A Search whole Search whole Whether to scan the entire
mode screen or screen or screen (or window) to find the

foreground window, foreground supplied text or only a
Search on specified window narrowed down subregion of it
subregion of screen
or foreground
window

Wait for all N/A Boolean value False Whether to wait for all the
images images on the list to

appear(disappear), or just one
of them

X1 Yes Numeric value The start X coordinate of the
subregion to scan for the
supplied text



Argument Optional Accepts Default Description
Value

X2 Yes Numeric value The end X coordinate of the
subregion to scan for the
supplied text

Y1 Yes Numeric value The start Y coordinate of the
subregion to scan for the
supplied text

Y2 Yes Numeric value The end Y coordinate of the
subregion to scan for the
supplied text

Tolerance Yes Numeric value 10 Specify how much the image(s)
searched for can differ from the
originally chosen image

Image N/A Basic, Advanced Basic Which image algorithm to use
matching when searching for image
algorithm

Fail with N/A Boolean value False Specify whether you want the
timeout action to wait indefinitely or fail
error after a set time period

Variables produced

ﾉ Expand table

Argument Type Description

X Numeric The X coordinate of the point where the text was found on the screen.
value If the text has been search in the foreground window, this value is

relative to the top left corner of the window.

Y Numeric The Y coordinate of the point where the text was found on the screen.
value If the text has been search in the foreground window, this value is

relative to the top left corner of the window.

Exceptions

ﾉ Expand table



Exception Description

Wait for image failed Indicates that the wait operation failed

Can't check image in noninteractive Indicates that an image can't be identified in non-
mode interactive mode

Invalid subregion coordinates Indicates that the coordinates of the given subregion
were invalid

Hover mouse over UI element in window
Hover the mouse over any UI element on window.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

UI element No UI element Select the UI element in window to hover

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to hover over element Indicates that the hover over the element failed

Click UI element in window
Clicks on any UI element of a window.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

UI element No UI element The UI element to click on

Click type N/A Left-click, Right- Left- The kind of click to perform
click, Double- click
click, Middle-
click, Left button
down, Left
button up, Right
button down,
Right button up

Simulate N/A Boolean value False Specify whether to simulate the move
action of the mouse cursor over the element

prior to clicking. This option does not
require the UI element's screen to be
focused, it will not automatically bring
it to the foreground. Note this option
can be applied only to left-click action
and it might not be applicable to every
UI element.

Mouse N/A Top left, Top Middle Specify which section of the UI
position center, Top right, center element the mouse will be moved to
relative to UI Middle left, prior to clicking
element Middle center,

Middle right,
Bottom left,
Bottom center,
Bottom right

Offset X Yes Text value 0 Offset the mouse from the position by
this many pixels to the right

Offset Y Yes Text value 0 Offset the mouse from the position by
this many pixels down

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table



Exception Description

Click failed Indicates that the click failed

Select menu option in window
Selects an option in a menu of a window.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

UI element No UI element The menu option to select

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to select option Indicates a problem selecting the specified menu option

Drag and drop UI element in window
Drags and drops a UI element of a window.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

UI element to No UI element The UI element to drag
drag



Argument Optional Accepts Default Description
Value

UI element to No UI element The UI element to drop over
drop over

Click type N/A Left-click, Right-click Left- Specify which mouse button
click to use for clicking and

holding down, while
dragging the UI element
over to its destination

Mouse down Yes Text value 0 Offset the mouse-down
offset X click, that will be used to

grab the UI element drag,
by this many pixels to the
right

Mouse down Yes Text value 0 Offset the mouse-down
offset Y click, that will be used to

grab the UI element to
drag, by this many pixels
downwards

Mouse down N/A Top left, Top center, Middle Specify which section of the
position relative Top right, Middle left, center UI element to drop the
to drag-target UI Middle center, Middle mouse onto prior to clicking
element right, Bottom left,

Bottom center, Bottom
right

Mouse up offset Yes Text value 0 Offset the mouse-up click,
X that will be used to grab the

UI element to drag, by this
many pixels to the right

Mouse up offset Yes Text value 0 Offset the mouse-up click,
Y that will be used to grab the

UI element to drag, by this
many pixels downwards

Mouse up N/A Top left, Top center, Middle Specify which section of the
position relative Top right, Middle left, center UI element to drag the
to drop-target UI Middle center, Middle mouse onto after clicking
element right, Bottom left,

Bottom center, Bottom
right

Variables produced



This action doesn't produce any variables.

Exceptions
ﾉ Expand table

Exception Description

UI element to drag wasn't found Indicates that the UI element to drag wasn't found

Drop target UI element wasn't Indicates that the drop target UI element wasn't found
found

Drag and drop failed Indicates a problem during drag and drop of the specified UI
element

Expand/collapse tree node in window
Expands or collapses a node of a tree view residing in a window.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

UI element No UI element The tree node to expand/collapse

Folders path Yes Text value A forward slash separated path made out
of folder names leading to the tree node
to expand or collapse

Use regular N/A Boolean False Specify whether each folder name in the
expressions value path to interpret as a regular expression

Operation N/A Expand, Expand Specify whether to expand or collapse the
Collapse tree node

７ Note

Power Automate's regular expression engine is .NET. To find more information
about regular expressions, go to Regular Expression Language - Quick Reference.



Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to set tree node to the specified Indicates a problem setting the tree node to the
state specified state

If window
This action marks the beginning of a conditional block of actions depending on whether
a window is open or not or whether a window is the focused (foreground) window.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Get N/A By window UI element, By Specify whether to look for the
window By window window Window using a UI element or a

instance/handle, By title UI combination of window
and/or class element title/class

Window Yes Text value The window title. Wildcards can
title be used, like '?' or '*'.

Window No UI element The window UI element

Window No Numeric value The instance or handle of the
instance window to check

Window Yes Text value If there are two windows with
class the same title, window class

might help differentiate
between them. In this case,
enter the class of the window to
be used.



Argument Optional Accepts Default Description
Value

Check if N/A Is open, Isn't open, Is Is open The state of the window to be
window focused, Isn't focused checked

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Wait for window
Suspends the execution or the process until a specific window opens, closes, get or loses
the focus.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Find window N/A By window UI element, By Specify whether to look for the
By window window window using a UI element or a
instance/handle, By UI combination of window
title and/or class element title/class

Window title Yes Text value The window title. Wildcards can
be used, like '?' or '*'.

Window No UI element The window UI element

Window No Numeric value The instance or handle of the
instance window to check

Window Yes Text value If there are two windows with
class the same title, window class

might help differentiate
between them. In this case,
enter the class of the window
to be used



Argument Optional Accepts Default Description
Value

Wait for N/A Open, Close, Become Open Whether to wait for a specific
window to focused, Lose focus window to open, close, become

focused (i.e become the
foreground window), or lose
focus (i.e stop being the
foreground window).

Focus N/A Boolean value False Bring the window to the front
window after after it opens, so later actions
it opens are directed at this window

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Can't focus window Indicates a problem focusing the specified window

Wait for window failed Indicates that the wait operation failed

Can't perform window-related action in Indicates a problem performing window-related
noninteractive mode action in non-interactive mode

Feedback
Was this page helpful?  Yes  No

Provide product feedback



HTTP actions
Article • 01/23/2025

HTTP actions enable you to interact with APIs and send web requests that perform
various operations, such as uploading and downloading data and files.

To send an API request, like POST, GET, PUT, or DELETE, use the Invoke web service
action.

In the action's properties, you must populate the service's URL and the appropriate
HTTP method. Additionally, you must choose the request and response content type,
such as XML and JSON.

The Custom headers and Request body fields depend on the API, and you have to
configure them as described in its documentation.



If the web server requires authentication, populate your credentials in the appropriate
fields of the action's Advanced settings.



A variable named WebServiceResponse stores the results of the web service request. If
the results are files, you can select to save them locally on your desktop.

To download text or files from the web, you can use the Download from web action.
This action requires you to populate the URL of the web page or the file and select the
appropriate HTTP method.



If the web server requires authentication, populate your credentials in the appropriate
fields of the action's Advanced settings.



A variable named WebPageText stores the downloaded text is stored. If you use this
action to download files, you can select to save them locally on your desktop.

Users can download a file from the web using the Click download link on web page
action in the Browser automation group.

） Important

The Click download link on web page action only works in the Internet Explorer
web browser, which has reached the end of its product lifecycle. To find more
information about the Click download link on web page action, go to Click
download link on web page.



Besides HTTP actions, Power Automate lets users interact with web applications through
browser automation actions. Learn more about browser automation actions in Browser
automation.

Download from web
Downloads text or a file from the web and stores it.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

URL No Text value The web page
or file's URL

Method N/A GET, POST GET Specify how to
retrieve a
website's
information.
GET should be
used when all
information
needed is in
the URL, and
POST to enter
more
information
(passwords,
etc.)

Post No Datatable The POST
parameters parameters in

the form of a
datatable with
two columns

Save N/A Get text into variable (for web Get text into Specify how
response pages), Save to disk (for files) variable (for web the returned

pages) data will be
saved

File name N/A Keep original file name (specify Keep original file Specify
only destination folder), Specify name (specify whether to
full path (destination folder + only destination keep the
custom file name) folder) original file



Argument Optional Accepts Default Value Description

name of the
downloaded
file or specify a
new name

Destination No Folder The folder
folder where the file

returned from
the web server
will be saved

Destination No File The full path
file path (folder plus

filename)
where the file
returned by the
web server will
be stored

Connection Yes Numeric value 30 The time (in
timeout seconds) that

the agent
should wait for
a connection
to be
established
with the server,
before giving
up

Follow N/A Boolean value True Specify
redirection whether to

allow the web
server to
redirect you to
another web
page or
website

Clear N/A Boolean value False Specify
cookies whether to

clear all
cookies
created by
similar actions
during this
automation



Argument Optional Accepts Default Value Description

User agent Yes Text value Mozilla/5.0 Specify which
(Windows; U; browser
Windows NT 5.1; identity to be
en-US; seen as. Some
rv:1.8.1.21) web servers
Gecko/20100312 won't allow
Firefox/3.6 access unless a

browser
identity is
chosen

Encoding N/A Auto - detect, IBM037: IBM Auto - detect The encoding
EBCDIC (US-Canada), IBM437: used for the
OEM United States, IBM500: IBM web page. If
EBCDIC (International), ASMO- the Auto-
708: Arabic (ASMO 708), DOS- detect option
720: Arabic (DOS), ibm737: Greek is chosen, the
(DOS), ibm775: Baltic (DOS), encoding to be
ibm850: Western European (DOS), used will be
ibm852: Central European (DOS), specified by
IBM855: OEM Cyrillic, ibm857: the web server
Turkish (DOS), IBM00858: OEM
Multilingual Latin I, IBM860:
Portuguese (DOS), ibm861:
Icelandic (DOS), DOS-862:
Hebrew (DOS), IBM863: French
Canadian (DOS), IBM864: Arabic
(864), IBM865: Nordic (DOS),
cp866: Cyrillic (DOS), ibm869:
Greek, Modern (DOS), IBM870:
IBM EBCDIC (Multilingual Latin-2),
windows-874: Thai (Windows),
cp875: IBM EBCDIC (Greek
Modern), shift_jis: Japanese (Shift-
JIS), gb2312: Chinese Simplified
(GB2312), ks_c_5601-1987:
Korean, big5: Chinese Traditional
(Big5), IBM1026: IBM EBCDIC
(Turkish Latin-5), IBM01047: IBM
Latin-1, IBM01140: IBM EBCDIC
(US-Canada-Euro), IBM01141: IBM
EBCDIC (Germany-Euro),
IBM01142: IBM EBCDIC
(Denmark-Norway-Euro),
IBM01143: IBM EBCDIC (Finland-
Sweden-Euro), IBM01144: IBM
EBCDIC (Italy Euro), IBM01145:



Argument Optional Accepts Default Value Description

IBM EBCDIC (Spain-Euro),
IBM01146: IBM EBCDIC (UK-Euro),
IBM01147: IBM EBCDIC (France-
Euro), IBM01148: IBM EBCDIC
(International-Euro), IBM01149:
IBM EBCDIC (Icelandic-Euro), utf-
16: Unicode, utf-16BE: Unicode
(Big-Endian), windows-1250:
Central European (Windows),
windows-1251: Cyrillic (Windows),
Windows-1252: Western
European (Windows), windows-
1253: Greek (Windows), windows-
1254: Turkish (Windows),
windows-1255: Hebrew
(Windows), windows-1256: Arabic
(Windows), windows-1257: Baltic
(Windows), windows-1258:
Vietnamese (Windows), Johab:
Korean (Johab), macintosh:
Western European (Mac), x-mac-
japanese: Japanese (Mac), x-mac-
chinesetrad: Chinese Traditional
(Mac), x-mac-korean: Korean
(Mac), x-mac-arabic: Arabic (Mac),
x-mac-hebrew: Hebrew (Mac), x-
mac-greek: Greek (Mac), x-mac-
cyrillic: Cyrillic (Mac), x-mac-
chinesesimp: Chinese Simplified
(Mac), x-mac-romanian:
Romanian (Mac), x-mac-ukrainian:
Ukrainian (Mac), x-mac-thai: Thai
(Mac), x-mac-ce: Central
European (Mac), x-mac-icelandic:
Icelandic (Mac), x-mac-turkish:
Turkish (Mac), x-mac-croatian:
Croatian (Mac), utf-32: Unicode
(UTF-32), utf-32BE: Unicode (UTF-
32 Big-Endian), x-Chinese-CNS:
Chinese Traditional (CNS), x-
cp20001: TCA Taiwan, x-Chinese-
Eten: Chinese Traditional (Eten), x-
cp20003: IBM5550 Taiwan, x-
cp20004: TeleText Taiwan, x-
cp20005: Wang Taiwan, x-IA5:
Western European (IA5), x-IA5-
German: German (IA5), x-IA5-
Swedish: Swedish (IA5), x-IA5-



Argument Optional Accepts Default Value Description

Norwegian: Norwegian (IA5), us-
ascii: US-ASCII, x-cp20261: T.61, x-
cp20269: ISO-6937, IBM273: IBM
EBCDIC (Germany), IBM277: IBM
EBCDIC (Denmark-Norway),
IBM278: IBM EBCDIC (Finland-
Sweden), IBM280: IBM EBCDIC
(Italy), IBM284: IBM EBCDIC
(Spain), IBM285: IBM EBCDIC (UK),
IBM290: IBM EBCDIC (Japanese
katakana), IBM297: IBM EBCDIC
(France), IBM420: IBM EBCDIC
(Arabic), IBM423: IBM EBCDIC
(Greek), IBM424: IBM EBCDIC
(Hebrew), x-EBCDIC-
KoreanExtended: IBM EBCDIC
(Korean Extended), IBM-Thai: IBM
EBCDIC (Thai), koi8-r: Cyrillic
(KOI8-R), IBM871: IBM EBCDIC
(Icelandic), IBM880: IBM EBCDIC
(Cyrillic Russian), IBM905: IBM
EBCDIC (Turkish), IBM00924: IBM
Latin-1, EUC-JP: Japanese (JIS
0208-1990 and 0212-1990), x-
cp20936: Chinese Simplified
(GB2312-80), x-cp20949: Korean
Wansung, cp1025: IBM EBCDIC
(Cyrillic Serbian-Bulgarian), koi8-
u: Cyrillic (KOI8-U), iso-8859-1:
Western European (ISO), iso-
8859-2: Central European (ISO),
iso-8859-3: Latin 3 (ISO), iso-
8859-4: Baltic (ISO), iso-8859-5:
Cyrillic (ISO), iso-8859-6: Arabic
(ISO), iso-8859-7: Greek (ISO), iso-
8859-8: Hebrew (ISO-Visual), iso-
8859-9: Turkish (ISO), iso-8859-
13: Estonian (ISO), iso-8859-15:
Latin 9 (ISO), x-Europa: Europa,
iso-8859-8-i: Hebrew (ISO-
Logical), iso-2022-jp: Japanese
(JIS), csISO2022JP: Japanese (JIS-
Allow 1 byte Kana), iso-2022-jp:
Japanese (JIS-Allow 1 byte Kana -
SO/SI), iso-2022-kr: Korean (ISO),
x-cp50227: Chinese Simplified
(ISO-2022), euc-jp: Japanese
(EUC), EUC-CN: Chinese Simplified



Argument Optional Accepts Default Value Description

(EUC), euc-kr: Korean (EUC), hz-
gb-2312: Chinese Simplified (HZ),
GB18030: Chinese Simplified
(GB18030), x-iscii-de: ISCII
Devanagari, x-iscii-be: ISCII
Bengali, x-iscii-ta: ISCII Tamil, x-
iscii-te: ISCII Telugu, x-iscii-as:
ISCII Assamese, x-iscii-or: ISCII
Oriya, x-iscii-ka: ISCII Kannada, x-
iscii-ma: ISCII Malayalam, x-iscii-
gu: ISCII Gujarati, x-iscii-pa: ISCII
Punjabi, utf-7: Unicode (UTF-7),
utf-8: Unicode (UTF-8)

Accept N/A Boolean value False Specify
untrusted whether
certificates untrusted

certificates will
be accepted

Use N/A Boolean value False Specify
credentials whether the

web server
requires
authentication.
This property
refers to HTTP
authentication
(that is, when
the browser
displays a
popup window
asking for user
name and
password)

User name No Text value The user name
for the web
server

Password No Direct encrypted input or Text The password
value for the web

server

Variables produced



ﾉ Expand table

Argument Type Description

DownloadedFile File The downloaded file

WebPageText Text value The web page text

Exceptions
ﾉ Expand table

Exception Description

Directory doesn't exist Indicates that a required directory doesn't exist

Download from web error Indicates a problem downloading from web

Known issues
NTLM Authentication is currently not supported for web requests in Power
Automate for desktop.

Invoke SOAP web service
Invokes a method from a SOAP web service.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

Endpoint No Text value The endpoint
of the web
service

Custom Yes Text value The custom
headers headers to be

included in the
request that
will be sent to
the web
service



Argument Optional Accepts Default Value Description

Request body No Text value The body of
the request
that will be
sent to the
web service

Connection No Numeric value 30 The time (in
timeout seconds) that

the agent
should wait for
a connection
to be
established
with the server

Follow N/A Boolean value True Specify
redirection whether to

allow the web
server to
redirect you to
another web
service

Clear cookies N/A Boolean value False Specify
whether to
clear all
cookies
previously
created by
similar actions
during this
flow

Fail on error N/A Boolean value False Specify
status whether the

responses of
the invoked
web service
that denote
errors will be
processed as if
they were
normal
responses
(suppressing
all exceptions)
or will result in



Argument Optional Accepts Default Value Description

the related
exceptions

User agent No Text value Mozilla/5.0 Specify which
(Windows; U; browser
Windows NT 5.1; identity to be
en-US; seen as. Some
rv:1.8.1.21) web servers
Gecko/20100312 won't allow
Firefox/3.6 access unless a

browser
identity is
chosen

User agent Yes Text value Mozilla/5.0 Specify which
(Windows; U; browser
Windows NT 5.1; identity to be
en-US; seen as. Some
rv:1.8.1.21) web servers
Gecko/20100312 won't allow
Firefox/3.6 access unless a

browser
identity is
chosen

Encoding N/A Auto - detect, IBM037: IBM Auto - detect The encoding
EBCDIC (US-Canada), IBM437: used for the
OEM United States, IBM500: web service
IBM EBCDIC (International), response. If
ASMO-708: Arabic (ASMO the auto-
708), DOS-720: Arabic (DOS), detect option
ibm737: Greek (DOS), ibm775: is chosen, the
Baltic (DOS), ibm850: Western encoding to
European (DOS), ibm852: be used will be
Central European (DOS), specified by
IBM855: OEM Cyrillic, ibm857: the web
Turkish (DOS), IBM00858: OEM service
Multilingual Latin I, IBM860:
Portuguese (DOS), ibm861:
Icelandic (DOS), DOS-862:
Hebrew (DOS), IBM863: French
Canadian (DOS), IBM864:
Arabic (864), IBM865: Nordic
(DOS), cp866: Cyrillic (DOS),
ibm869: Greek, Modern (DOS),
IBM870: IBM EBCDIC
(Multilingual Latin-2), windows-
874: Thai (Windows), cp875:



Argument Optional Accepts Default Value Description

IBM EBCDIC (Greek Modern),
shift_jis: Japanese (Shift-JIS),
gb2312: Chinese Simplified
(GB2312), ks_c_5601-1987:
Korean, big5: Chinese
Traditional (Big5), IBM1026:
IBM EBCDIC (Turkish Latin-5),
IBM01047: IBM Latin-1,
IBM01140: IBM EBCDIC (US-
Canada-Euro), IBM01141: IBM
EBCDIC (Germany-Euro),
IBM01142: IBM EBCDIC
(Denmark-Norway-Euro),
IBM01143: IBM EBCDIC
(Finland-Sweden-Euro),
IBM01144: IBM EBCDIC (Italy
Euro), IBM01145: IBM EBCDIC
(Spain-Euro), IBM01146: IBM
EBCDIC (UK-Euro), IBM01147:
IBM EBCDIC (France-Euro),
IBM01148: IBM EBCDIC
(International-Euro), IBM01149:
IBM EBCDIC (Icelandic-Euro),
utf-16: Unicode, utf-16BE:
Unicode (Big-Endian),
windows-1250: Central
European (Windows), windows-
1251: Cyrillic (Windows),
Windows-1252: Western
European (Windows), windows-
1253: Greek (Windows),
windows-1254: Turkish
(Windows), windows-1255:
Hebrew (Windows), windows-
1256: Arabic (Windows),
windows-1257: Baltic
(Windows), windows-1258:
Vietnamese (Windows), Johab:
Korean (Johab), macintosh:
Western European (Mac), x-
mac-japanese: Japanese (Mac),
x-mac-chinesetrad: Chinese
Traditional (Mac), x-mac-
korean: Korean (Mac), x-mac-
arabic: Arabic (Mac), x-mac-
hebrew: Hebrew (Mac), x-mac-
greek: Greek (Mac), x-mac-
cyrillic: Cyrillic (Mac), x-mac-



Argument Optional Accepts Default Value Description

chinesesimp: Chinese
Simplified (Mac), x-mac-
romanian: Romanian (Mac), x-
mac-ukrainian: Ukrainian (Mac),
x-mac-thai: Thai (Mac), x-mac-
ce: Central European (Mac), x-
mac-icelandic: Icelandic (Mac),
x-mac-turkish: Turkish (Mac), x-
mac-croatian: Croatian (Mac),
utf-32: Unicode (UTF-32), utf-
32BE: Unicode (UTF-32 Big-
Endian), x-Chinese-CNS:
Chinese Traditional (CNS), x-
cp20001: TCA Taiwan, x-
Chinese-Eten: Chinese
Traditional (Eten), x-cp20003:
IBM5550 Taiwan, x-cp20004:
TeleText Taiwan, x-cp20005:
Wang Taiwan, x-IA5: Western
European (IA5), x-IA5-German:
German (IA5), x-IA5-Swedish:
Swedish (IA5), x-IA5-
Norwegian: Norwegian (IA5),
us-ascii: US-ASCII, x-cp20261:
T.61, x-cp20269: ISO-6937,
IBM273: IBM EBCDIC
(Germany), IBM277: IBM
EBCDIC (Denmark-Norway),
IBM278: IBM EBCDIC (Finland-
Sweden), IBM280: IBM EBCDIC
(Italy), IBM284: IBM EBCDIC
(Spain), IBM285: IBM EBCDIC
(UK), IBM290: IBM EBCDIC
(Japanese katakana), IBM297:
IBM EBCDIC (France), IBM420:
IBM EBCDIC (Arabic), IBM423:
IBM EBCDIC (Greek), IBM424:
IBM EBCDIC (Hebrew), x-
EBCDIC-KoreanExtended: IBM
EBCDIC (Korean Extended),
IBM-Thai: IBM EBCDIC (Thai),
koi8-r: Cyrillic (KOI8-R),
IBM871: IBM EBCDIC
(Icelandic), IBM880: IBM
EBCDIC (Cyrillic Russian),
IBM905: IBM EBCDIC (Turkish),
IBM00924: IBM Latin-1, EUC-JP:
Japanese (JIS 0208-1990 and



Argument Optional Accepts Default Value Description

0212-1990), x-cp20936:
Chinese Simplified (GB2312-
80), x-cp20949: Korean
Wansung, cp1025: IBM EBCDIC
(Cyrillic Serbian-Bulgarian),
koi8-u: Cyrillic (KOI8-U), iso-
8859-1: Western European
(ISO), iso-8859-2: Central
European (ISO), iso-8859-3:
Latin 3 (ISO), iso-8859-4: Baltic
(ISO), iso-8859-5: Cyrillic (ISO),
iso-8859-6: Arabic (ISO), iso-
8859-7: Greek (ISO), iso-8859-
8: Hebrew (ISO-Visual), iso-
8859-9: Turkish (ISO), iso-8859-
13: Estonian (ISO), iso-8859-15:
Latin 9 (ISO), x-Europa: Europa,
iso-8859-8-i: Hebrew (ISO-
Logical), iso-2022-jp: Japanese
(JIS), csISO2022JP: Japanese
(JIS-Allow 1 byte Kana), iso-
2022-jp: Japanese (JIS-Allow 1
byte Kana - SO/SI), iso-2022-kr:
Korean (ISO), x-cp50227:
Chinese Simplified (ISO-2022),
euc-jp: Japanese (EUC), EUC-
CN: Chinese Simplified (EUC),
euc-kr: Korean (EUC), hz-gb-
2312: Chinese Simplified (HZ),
GB18030: Chinese Simplified
(GB18030), x-iscii-de: ISCII
Devanagari, x-iscii-be: ISCII
Bengali, x-iscii-ta: ISCII Tamil, x-
iscii-te: ISCII Telugu, x-iscii-as:
ISCII Assamese, x-iscii-or: ISCII
Oriya, x-iscii-ka: ISCII Kannada,
x-iscii-ma: ISCII Malayalam, x-
iscii-gu: ISCII Gujarati, x-iscii-
pa: ISCII Punjabi, utf-7: Unicode
(UTF-7), utf-8: Unicode (UTF-8)

Accept N/A Boolean value False Specify
untrusted whether
certificates untrusted

certificates will
be accepted



Argument Optional Accepts Default Value Description

HTTP N/A Boolean value False Specify
Authentication whether the

web server
requires HTTP
authentication
(that is, the
browser
displays a
popup window
asking for a
username and
password)

User name No Text value The user name
for the web
server

Password No Direct encrypted input or Text The password
value for the web

server

Trim N/A Boolean value True Enable this
whitespaces option to trim

the whitespace
at the end of
the request
body of the
web service
response

Request Builder Parameters

ﾉ Expand table

Argument Accepts Description

WSDL File The Web Services Description Language (WSDL) document to build
the request with

Service Text The service to invoke
value

Port Text The port to invoke the service
value

SOAP version Text The version of the SOAP service



Argument Accepts Description

value

Operation Text The operation to invoke the service
value

Request Text The envelope to send in the request to invoke the service
envelope value

Variables produced
ﾉ Expand table

Argument Type Description

SoapServiceResponseHeaders List of Text values The HTTP headers of the response

SoapServiceResponse Text value The web service response text

StatusCode Numeric value The status code returned

Exceptions

ﾉ Expand table

Exception Description

Invoke SOAP service error Indicates a problem invoking the SOAP service

Invalid header in custom headers Indicates that some custom headers were invalid

Known issues
NTLM Authentication is currently not supported for web requests in Power
Automate for desktop.

Invoke web service
Invokes a web service by sending data and stores the response text.

Input parameters



ﾉ Expand table

Argument Optional Accepts Default Value Description

URL No Text value The web
service's URL

Method N/A GET, POST, CONNECT, HEAD, GET The HTTP
PUT, DELETE, OPTIONS, TRACE, method to be
PATCH used to invoke

the web service

Accept Yes Text value application/xml The acceptable
content type
for the
response of
the web service

Custom Yes Text value The custom
headers headers to be

included in the
request that
will be sent to
the web service

Upload N/A Boolean value False Specify
attachments whether the

web service
will include
files to upload

Content type Yes Text value application/xml The content
type of the
request that
will be sent to
the web service

Request body Yes Text value The body of
the request
that will be
sent to the
web service

Attachments N/A Attachments No attachments Select the
selected attachments

that will be
added to the
web request.
You can only
choose one of
the two



Argument Optional Accepts Default Value Description

attachment
types (File or
Binary).

Attach N/A File, Binary File The type of the
attachments
that will be
sent by the
web service

Save response N/A Get text into variable (for web Get text into Specify how
pages), Save to disk (for files) variable (for web the returned

pages) data will be
saved

File name N/A Keep original file name Keep original file Specify
(specify only destination name (specify whether to
folder), Specify full path only destination keep the
(destination folder + custom folder) original file
file name) name of the

downloaded
file or specify a
new name

Destination No Folder The folder
folder where the file

returned by
the web service
will be saved

Destination No File The full path
file path (folder plus

filename)
where the file
returned by
the web service
will be stored

Connection Yes Numeric value 30 The time (in
timeout seconds) that

the agent
should wait for
a connection
to be
established
with the server,
before giving
up



Argument Optional Accepts Default Value Description

Follow N/A Boolean value True Specify
redirection whether to

allow the web
server to
redirect you to
another web
service

Clear cookies N/A Boolean value False Specify
whether to
clear all
cookies
created by
similar actions
during this
automation
before this
action

Fail on error N/A Boolean value False Specify
status whether the

responses of
the invoked
web service
that denote
errors will be
processed as if
they were
normal
responses
(suppressing
all exceptions)
or will result in
the related
exceptions

Encode N/A Boolean value True Specify
request body whether the

body of
request should
be URL-
encoded
before
invoking

User agent Yes Text value Mozilla/5.0 Specify which
(Windows; U; browser
Windows NT 5.1; identity to be



Argument Optional Accepts Default Value Description

en-US; seen as. Some
rv:1.8.1.21) web servers
Gecko/20100312 won't allow
Firefox/3.6 access unless a

browser
identity is
chosen

Encoding N/A Auto - detect, IBM037: IBM Auto - detect The encoding
EBCDIC (US-Canada), IBM437: used for the
OEM United States, IBM500: web service
IBM EBCDIC (International), response. If the
ASMO-708: Arabic (ASMO auto-detect
708), DOS-720: Arabic (DOS), option is
ibm737: Greek (DOS), ibm775: chosen, the
Baltic (DOS), ibm850: Western encoding to be
European (DOS), ibm852: used will be
Central European (DOS), specified by
IBM855: OEM Cyrillic, ibm857: the web service
Turkish (DOS), IBM00858: OEM
Multilingual Latin I, IBM860:
Portuguese (DOS), ibm861:
Icelandic (DOS), DOS-862:
Hebrew (DOS), IBM863: French
Canadian (DOS), IBM864:
Arabic (864), IBM865: Nordic
(DOS), cp866: Cyrillic (DOS),
ibm869: Greek, Modern (DOS),
IBM870: IBM EBCDIC
(Multilingual Latin-2),
windows-874: Thai (Windows),
cp875: IBM EBCDIC (Greek
Modern), shift_jis: Japanese
(Shift-JIS), gb2312: Chinese
Simplified (GB2312),
ks_c_5601-1987: Korean, big5:
Chinese Traditional (Big5),
IBM1026: IBM EBCDIC (Turkish
Latin-5), IBM01047: IBM Latin-
1, IBM01140: IBM EBCDIC (US-
Canada-Euro), IBM01141: IBM
EBCDIC (Germany-Euro),
IBM01142: IBM EBCDIC
(Denmark-Norway-Euro),
IBM01143: IBM EBCDIC
(Finland-Sweden-Euro),
IBM01144: IBM EBCDIC (Italy
Euro), IBM01145: IBM EBCDIC



Argument Optional Accepts Default Value Description

(Spain-Euro), IBM01146: IBM
EBCDIC (UK-Euro), IBM01147:
IBM EBCDIC (France-Euro),
IBM01148: IBM EBCDIC
(International-Euro),
IBM01149: IBM EBCDIC
(Icelandic-Euro), utf-16:
Unicode, utf-16BE: Unicode
(Big-Endian), windows-1250:
Central European (Windows),
windows-1251: Cyrillic
(Windows), Windows-1252:
Western European (Windows),
windows-1253: Greek
(Windows), windows-1254:
Turkish (Windows), windows-
1255: Hebrew (Windows),
windows-1256: Arabic
(Windows), windows-1257:
Baltic (Windows), windows-
1258: Vietnamese (Windows),
Johab: Korean (Johab),
macintosh: Western European
(Mac), x-mac-japanese:
Japanese (Mac), x-mac-
chinesetrad: Chinese
Traditional (Mac), x-mac-
korean: Korean (Mac), x-mac-
arabic: Arabic (Mac), x-mac-
hebrew: Hebrew (Mac), x-mac-
greek: Greek (Mac), x-mac-
cyrillic: Cyrillic (Mac), x-mac-
chinesesimp: Chinese
Simplified (Mac), x-mac-
romanian: Romanian (Mac), x-
mac-ukrainian: Ukrainian
(Mac), x-mac-thai: Thai (Mac),
x-mac-ce: Central European
(Mac), x-mac-icelandic:
Icelandic (Mac), x-mac-turkish:
Turkish (Mac), x-mac-croatian:
Croatian (Mac), utf-32:
Unicode (UTF-32), utf-32BE:
Unicode (UTF-32 Big-Endian),
x-Chinese-CNS: Chinese
Traditional (CNS), x-cp20001:
TCA Taiwan, x-Chinese-Eten:
Chinese Traditional (Eten), x-



Argument Optional Accepts Default Value Description

cp20003: IBM5550 Taiwan, x-
cp20004: TeleText Taiwan, x-
cp20005: Wang Taiwan, x-IA5:
Western European (IA5), x-IA5-
German: German (IA5), x-IA5-
Swedish: Swedish (IA5), x-IA5-
Norwegian: Norwegian (IA5),
us-ascii: US-ASCII, x-cp20261:
T.61, x-cp20269: ISO-6937,
IBM273: IBM EBCDIC
(Germany), IBM277: IBM
EBCDIC (Denmark-Norway),
IBM278: IBM EBCDIC (Finland-
Sweden), IBM280: IBM EBCDIC
(Italy), IBM284: IBM EBCDIC
(Spain), IBM285: IBM EBCDIC
(UK), IBM290: IBM EBCDIC
(Japanese katakana), IBM297:
IBM EBCDIC (France), IBM420:
IBM EBCDIC (Arabic), IBM423:
IBM EBCDIC (Greek), IBM424:
IBM EBCDIC (Hebrew), x-
EBCDIC-KoreanExtended: IBM
EBCDIC (Korean Extended),
IBM-Thai: IBM EBCDIC (Thai),
koi8-r: Cyrillic (KOI8-R),
IBM871: IBM EBCDIC
(Icelandic), IBM880: IBM
EBCDIC (Cyrillic Russian),
IBM905: IBM EBCDIC (Turkish),
IBM00924: IBM Latin-1, EUC-
JP: Japanese (JIS 0208-1990
and 0212-1990), x-cp20936:
Chinese Simplified (GB2312-
80), x-cp20949: Korean
Wansung, cp1025: IBM EBCDIC
(Cyrillic Serbian-Bulgarian),
koi8-u: Cyrillic (KOI8-U), iso-
8859-1: Western European
(ISO), iso-8859-2: Central
European (ISO), iso-8859-3:
Latin 3 (ISO), iso-8859-4: Baltic
(ISO), iso-8859-5: Cyrillic (ISO),
iso-8859-6: Arabic (ISO), iso-
8859-7: Greek (ISO), iso-8859-
8: Hebrew (ISO-Visual), iso-
8859-9: Turkish (ISO), iso-
8859-13: Estonian (ISO), iso-



Argument Optional Accepts Default Value Description

8859-15: Latin 9 (ISO), x-
Europa: Europa, iso-8859-8-i:
Hebrew (ISO-Logical), iso-
2022-jp: Japanese (JIS),
csISO2022JP: Japanese (JIS-
Allow 1 byte Kana), iso-2022-
jp: Japanese (JIS-Allow 1 byte
Kana - SO/SI), iso-2022-kr:
Korean (ISO), x-cp50227:
Chinese Simplified (ISO-2022),
euc-jp: Japanese (EUC), EUC-
CN: Chinese Simplified (EUC),
euc-kr: Korean (EUC), hz-gb-
2312: Chinese Simplified (HZ),
GB18030: Chinese Simplified
(GB18030), x-iscii-de: ISCII
Devanagari, x-iscii-be: ISCII
Bengali, x-iscii-ta: ISCII Tamil,
x-iscii-te: ISCII Telugu, x-iscii-
as: ISCII Assamese, x-iscii-or:
ISCII Oriya, x-iscii-ka: ISCII
Kannada, x-iscii-ma: ISCII
Malayalam, x-iscii-gu: ISCII
Gujarati, x-iscii-pa: ISCII
Punjabi, utf-7: Unicode (UTF-
7), utf-8: Unicode (UTF-8)

Accept N/A Boolean value False Specify
untrusted whether
certificates untrusted

certificates will
be accepted

HTTP N/A Boolean value False Specify
Authentication whether the

web server
requires
authentication.
This property
refers to HTTP
authentication
(that is, when
the browser
displays a
popup window
asking for user
name and
password)



Argument Optional Accepts Default Value Description

User name No Text value The user name
for the web
server

Password No Direct encrypted input or Text The password
value for the web

server

Trim N/A Boolean value True Enable this to
whitespaces trim the

whitespaces at
the end of the
request body
of the web
service
response

Attachments Parameters
Configures the attachments to be added to the web service request. The attachments
option is only available for POST and PUT requests, and only when the 'Upload
attachments' toggle parameter is enabled.

ﾉ Expand table

Argument Accepts Description

Name Text value The name of the attachment

Attachment File The file to be attached

Type File, Name The attachment type

Variables produced

ﾉ Expand table

Argument Type Description

WebServiceResponseHeaders List of Text values The HTTP headers of the response

DownloadedFile File The downloaded file

WebServiceResponse Text value The web service response text



Argument Type Description

StatusCode Numeric value The status code returned

Exceptions

ﾉ Expand table

Exception Description

Invoke web service error Indicates a problem invoking the web service

Directory doesn't exist Indicates that a required directory doesn't exist

Invalid header in custom headers Indicates that some custom headers were invalid

Known issues
NTLM Authentication is currently not supported for web requests in Power
Automate for desktop.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Browser automation actions
Article • 12/04/2024

Browser automation actions enable users to interact with web applications and
components through UI elements. Web UI elements, also called Web elements, describe
uniquely the web components that the action is going to handle.

To perform web automation, you first need to create a new browser instance. You can
achieve this using the Launch Browser actions, which support Microsoft Edge, Google
Chrome, Mozilla Firefox, and Internet Explorer. With the Launch Browser actions, you can
also specify whether the web page should be launched on your local desktop or in a
virtual desktop environment.

７ Note

To launch a browser on a virtual desktop, first capture at least one UI element
within that desktop. This element needs to be available in the UI element repository
of your flow.

To add a new UI element, select Add UI element through the deployed browser
automation action or the UI elements pane of the flow designer.

All web-related UI elements are specified by one or more CSS selectors - web selectors -
that pinpoint the hierarchical structure of the component on the page. Selectors use the



> notation to indicate that each element is contained within the element on its left.

Although web selectors are created automatically when adding UI elements, some
particular scenarios need manually created selectors. When a custom web selector is
needed, you can create your own by either editing an existing selector or building one
from scratch.

To develop more dynamic web flows, replace the Equals to operators with other
operators or regular expressions. Additionally, if the value of a web selector's attribute
depends on the results of previous actions, use variables instead of hard-coded values.



７ Note

To find more information about developing web flows and creating custom web
selectors for Web elemements, go to Automate web flows and Build a custom
selector.

Extract data from web page
Extract data from specific parts of a web page in the form of single values, lists, rows, or
tables.

For more information on how to use this action, go to Web data extraction.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Web No Web browser Enter or choose the variable that
browser instance contains the web browser instance to
instance work with

UI element No UI element Select the UI element on web page to
extract data from

Extraction No Datatable The parameters to use when extracting
parameters data. Depending on the extraction

mode, this parameter accepts different
data.

Max web No Numeric value The maximum number of web pages to
pages to process
process

Send N/A Boolean value False Specify whether to physically move the
physical click mouse cursor over the page prior to
for next clicking. A physical click is required for
page cases where emulated clicks to the

page don't perform the intentional
action on the element. As this option
requires the browser window to be
focused, it will automatically bring it to
the foreground.

Page CSS No Text value The page CSS selector
selector

Extraction N/A Undefined, Single Specify what to extract from the web
mode Single value, value page

Handpicked
values, List,
Table, Entire
HTML table

Use paging N/A Boolean value False Specify whether to use paging

Get all web N/A Boolean value False Specify whether to get all web pages
pages

Process data N/A Boolean value False Specify whether to process extracted
upon data to present them exactly as
extraction displayed in the webpage. Processing

of extracted data includes displaying of
the information nested in iframes and
filtering through hidden or visible
elements. For larger datasets, having



Argument Optional Accepts Default Description
Value

this option enabled isn't recommended
as it will increase the extraction time.

Timeout Yes Numeric value 60 Set the time in seconds that you want
to wait for the extraction to be
completed before the action fails

Store data N/A Variable, Excel Variable Specify whether to store the extracted
mode spreadsheet data in a variable or an Excel

spreadsheet

Variables produced
ﾉ Expand table

Argument Type Description

ExcelInstance Excel The Excel instance with the extracted data. Use this instance to
instance manipulate the spreadsheet (or save and close it) by using the

dedicated Excel actions.

DataFromWebPage Datatable The extracted data in the form of a single value, list, data row,
or data table.

Exceptions

ﾉ Expand table

Exception Description

Failed to extract data Indicates a problem extracting data

Failed to launch Excel instance Indicates a problem launching an Excel instance

Failed to write values to Excel Indicates a problem writing the values to an Excel

Get details of web page
Get a property of a web page, such as its title or its source text.

Input parameters



ﾉ Expand table

Argument Optional Accepts Default Description
Value

Web No Web browser instance Enter or choose the
browser variable that contains
instance the web browser

instance to work with

Get N/A Web page description, Web Web page Select the information
page meta keywords, Web description to retrieve from the
page title, Web page text, web page
Web page source, Web
browser's current URL address

Variables produced
ﾉ Expand table

Argument Type Description

WebPageProperty Text value The details retrieved from the web page

Exceptions

ﾉ Expand table

Exception Description

Failed to get details of web Indicates a problem getting the details of the specified web
page page

Get details of element on web page
Get the value of an element's attribute on a web page.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Web browser No Web browser Enter or choose the variable that
instance instance contains the web browser instance to

work with

UI element No UI element Select the UI element on web page to
get details from

Attribute name No Text value Own Text Enter or select the attribute whose
value to retrieve

Variables produced

ﾉ Expand table

Argument Type Description

AttributeValue Text value The value of the web element's attribute

Exceptions

ﾉ Expand table

Exception Description

Failed to retrieve attribute of UI element on Indicates a problem retrieving attribute of web
web page page element

Take screenshot of web page
Take a screenshot of the web page (or an element of the web page) currently displayed
in the browser and save the image into a file or to the clipboard.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Web browser No Web browser Enter or choose the variable that
instance instance contains the web browser

instance to work with

Capture N/A Entire web page, Entire web Specify whether to capture the
Specific element page entire web page or only a

specific element of it

UI element No UI element Select the UI element on web
page to capture

Save mode N/A Clipboard, File Clipboard Specify whether to save the
image into a file or store it into
the clipboard

Image file No File Set the full path for the file to
save the image capture

File format N/A BMP, EMF, EXIF, BMP Select the format of the image
GIF, JPG, PNG, TIFF, file
WMF

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Element with specified CSS selector Indicates that a web page element with the specified CSS
not found selector wasn't found

Failed to save file Indicates a problem saving the specified file

Failed to save in the clipboard Indicates a problem while saving to the clipboard

Failed to take screenshot Indicates a problem taking a screenshot

Focus text field on web page
Set the focus on an input element of a web page and scroll it into view.



Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Web browser No Web browser Enter or choose the variable that
instance instance contains the web browser instance

to work with

UI element No UI element Select the UI element on web page
to focus

Wait for page to N/A Boolean value True Specify whether to wait for the
load new web page to load completely

before proceeding

Timeout for No Numeric value 60 Set the time in seconds for page
webpage to to load before the action throws
load an error

If a pop-up N/A Close it, Press a Do Specify what to do if a pop-up
dialog appears button, Do nothing dialog appears

nothing

Dialog button to Yes Text value OK Enter the dialog button to press if
press a pop-up dialog appears

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Element with specified CSS selector Indicates that a web page element with the specified CSS
not found selector wasn't found

Failed to set input focus on web Indicates a problem setting input focus on the specified
page text field web page text field

Populate text field on web page



Fill a text field in a web page with the specified text.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Web browser No Web Enter or choose the variable that contains
instance browser the web browser instance to work with

instance

UI element No UI element Select the text field to populate

Text No Direct Enter the text to fill in the text field
encrypted
input or
Text value

If field isn't Yes Replace Replace Specify whether to replace existing content,
empty text, text or to append.

Append text

Populate text N/A Boolean False Emulate using physical keystrokes when
using value populating text to UI text field elements.
physical Physical keystrokes are required for cases
keystrokes that emulated text population doesn't

perform the intentional action on the
element. As this option requires the
browser window to be focused, it will
automatically bring it in the foreground.

Emulate N/A Boolean True Specify whether to fill the text field at once
typing value by setting the value of the text box, or

emulate a user typing by sending
characters one by one. The latter method is
slower, but required in some complex web
pages.

Unfocus text N/A Boolean False Choose whether to unfocus the text box
box after value right after this action fills it with the
filling it specified text. If scraping autocompletion

lists, this parameter should be set to False.

Wait for N/A Boolean True Specify whether to wait for the new web
page to load value page to load completely after populating

the text field



Argument Optional Accepts Default Description
Value

Timeout for No Numeric 60 Set the time in seconds for page to load
webpage to value before the action throws an error
load

If a pop-up N/A Close it, Do Specify what to do if a pop-up dialog
dialog Press a nothing appears after populating the text field
appears button, Do

nothing

Dialog Yes Text value OK Enter the dialog button to press if a pop-up
button to dialog appears
press

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Element with specified CSS selector Indicates that a web page element with the specified CSS
not found selector wasn't found

Failed to write on text field Indicates a problem writing to the specified text field

Set check box state on web page
Check or uncheck a check box in a web form.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Web browser No Web browser Enter or choose the variable that
instance instance contains the web browser instance



Argument Optional Accepts Default Description
Value

to work with

UI element No UI element Select the check box to set the
state of

Check box N/A Checked, Checked Select the check box state
state Unchecked

Wait for page N/A Boolean value True Specify whether to wait for the
to load new web page to load completely

after setting the check box state

Timeout for No Numeric value 60 Set the time in seconds for page to
webpage to load before the action throws an
load error

If a pop-up N/A Close it, Press a Do Specify what to do if a pop-up
dialog appears button, Do nothing dialog appears after setting the

nothing check box state

Dialog button Yes Text value OK Enter the dialog button to press if
to press a pop-up dialog appears

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Element with specified CSS selector Indicates that a web page element with the specified CSS
not found selector wasn't found

Failed to set the state of the Indicates a problem in setting the state of the specified
checkbox check box

Select radio button on web page
Select a radio button on the web page.



Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Web browser No Web browser Enter or choose the variable that
instance instance contains the web browser instance

to work with

UI element No UI element The radio button to select

Wait for page N/A Boolean value True Specify whether to wait for the new
to load web page to load completely after

selecting the radio button

Timeout for No Numeric value 60 Set the time in seconds for page to
webpage to load before the action throws an
load error

If a pop-up N/A Close it, Press a Do Specify what to do if a pop-up
dialog appears button, Do nothing dialog appears after selecting the

nothing radio button

Dialog button Yes Text value OK The dialog button to press if a pop-
to press up dialog appears

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Element with specified CSS selector Indicates that a web page element with the specified CSS
not found selector wasn't found

Failed to select radio button Indicates a problem in selecting the specified radio button

Set drop-down list value on web page
Set or clear the selected options for a drop-down list in a web form.



Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Web browser No Web browser Enter or choose the variable that
instance instance contains the web browser instance to

work with

UI element No UI element Select the drop-down list to set its value

Operation N/A Clear all Clear all Select whether to select a value or clear
options, Select options the selected value of the drop-down list
options by
name, Select
options by
index

Option No List of Text Enter an option or a list of options to be
names values selected in the drop-down list. Multiple

options make sense only when working
with multi-selection lists. If the list is
single-selection, then only the first
option of the list specified will be used.

Use regular N/A Boolean value False Specify whether the option names
expressions values to interpret as a regular

expression

Option No List of Numeric Enter an index or a list of indices to be
indices values selected in the drop-down list. Multiple

options make sense only when working
with multi-selection lists. If the list is
single-selection, then only the first
option of the list specified will be used.

Wait for N/A Boolean value True Specify whether to wait for the new web
page to load page to load completely after setting

the drop-down list value

Timeout for No Numeric value 60 Set the time in seconds for page to load
webpage before the action throws an error
load

If a pop-up N/A Close it, Press a Do Specify what to do if a pop-up dialog
dialog button, Do nothing appears after setting the drop-down list
appears nothing value



Argument Optional Accepts Default Description
Value

Dialog Yes Text value OK Enter the dialog button to press if a
button to pop-up dialog appears
press

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Element with specified CSS selector Indicates that a web page element with the specified CSS
not found selector wasn't found

Failed to set the selected option Indicates a problem setting the selected drop-down list
option

Press button on web page
Press a web page button.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Web browser No Web browser Enter or choose the variable that
instance instance contains the web browser instance

to work with

UI element No UI element Select the button to press

Wait for page to N/A Boolean value True Specify whether to wait for the new
load web page to load completely after

pressing the button



Argument Optional Accepts Default Description
Value

Timeout for No Numeric value 60 Set the time in seconds for page to
webpage to load before the action throws an
load error

If a pop-up N/A Close it, Press a Do Specify what to do if a pop-up
dialog appears button, Do nothing dialog appears after pressing the

nothing button

Dialog button Yes Text value OK Enter the dialog button to press if a
to press pop-up dialog appears

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Element with specified CSS selector Indicates that a web page element with the specified CSS
not found selector wasn't found

Failed to click on web page button Indicates a problem clicking the specified web page button

If web page contains
Mark the beginning of a conditional block of actions, depending on whether a specific
piece of text or element exists in a web page.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Web browser No Web browser instance Enter or choose the variable
instance that contains the web



Argument Optional Accepts Default Description
Value

browser instance to work
with

Check if web N/A Contains element, Contains Check whether a specific
page Doesn't contain element, element text or web page element

Contains text, Doesn't exists in a web page
contain text

UI element No UI element Select the UI element on
web page to check for

Text No Text value Enter the text on web page
to check for

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to communicate with the browser Indicates that an error with the browser occurred

Wait for web page content
Suspend the flow until a specific piece of text or web page element appears or
disappears from a web page.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Web browser No Web browser instance Enter or choose the variable that
instance contains the web browser

instance to work with



Argument Optional Accepts Default Description
Value

Wait for web N/A Contain element, Not Contain Specify whether to wait for a
page to contain element, element specific text or web page

Contain text, Not element to appear or disappear
contain text in a web page

UI element No UI element Select the UI element on web
page to check for

Text No Text value Enter the text on web page to
check for

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Wait for web page content failed Indicates that the wait operation failed

Launch new Internet Explorer
Launch a new instance or attach to a running instance of Internet Explorer for
automating websites and web applications.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Launch N/A Launch automation Launch Specify whether to launch the
mode browser, Launch new automation automation browser or a new

Internet Explorer, browser instance of Internet Explorer or
Attach to running attach to an existing one
Internet Explorer



Argument Optional Accepts Default Description
Value

Attach to N/A By title, By URL, Use By title Specify whether to attach to
Internet foreground window an Internet Explorer tab by its
Explorer tab title, URL, or attach to the

active tab of Internet Explorer
running as the foreground
window

Initial URL No Text value Enter the URL of the web site
to visit when the web browser
is launched

Tab title No Text value Enter the title (or part of it) of
the Internet Explorer tab to
attach to

Tab URL No Text value Enter the URL (or part of it) of
the Internet Explorer tab to
attach to

Window N/A Normal, Maximized, Normal Specify whether to launch the
state Minimized browser window in normal,

minimized, or maximized state

Target N/A Local computer, Any Local Set the connection string of
desktop virtual desktop that computer the target desktop that the

is either currently browser launches
connected or has at
least one UI element
captured

Clear cache N/A Boolean value False Specify whether to clear the
entire cache of the web
browser right after launching it

Clear N/A Boolean value False Specify whether to clear all
cookies stored cookies in the web

browser right after launching it

Wait for N/A Boolean value True Specify whether to wait for the
page to load new web page to load

completely before proceeding

Timeout for No Numeric value 60 Set the time in seconds for
webpage to page to load before the action
load throws an error

If a pop-up N/A Close it, Press a Do nothing Specify what to do if a pop-up
dialog button, Do nothing dialog appears while loading



Argument Optional Accepts Default Description
Value

appears the initial web page

Dialog Yes Text value OK Enter the dialog button to
button to press if a pop-up dialog
press appears

Custom user Yes Text value Specify the custom user agent
agent string string for the runtime web

helper. If this field remains
empty, the runtime web helper
uses by default the user agent
string of Internet Explorer
installed on the machine.

７ Note

The Clear cache and Clear cookies options only work as intended if running in
protected mode is disabled in the Internet options menu.

Variables produced

ﾉ Expand table

Argument Type Description

InternetExplorer Web browser The Internet Explorer instance to use with browser
instance automation actions

Exceptions
ﾉ Expand table

Exception Description

Failed to launch Internet Explorer Indicates a problem launching Internet Explorer

Invalid URL Indicates that the provided URL was invalid

Launch new Firefox



Launch a new instance or attach to a running instance of Firefox for automating
websites and web applications.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Launch N/A Launch new Instance, Launch Specify whether to launch a new
mode Attach to running new instance of Firefox or attach to

instance Instance an existing one

Attach to N/A By title, By URL, Use By title Specify whether to attach to a
Firefox tab foreground window Firefox tab by its title, URL, or

attach to the active tab of Firefox
running as the foreground
window

Initial URL No Text value Enter the URL of the web site to
visit when the web browser is
launched

Tab title No Text value Enter the title (or part of it) of
the Firefox tab to attach to

Tab URL No Text value Enter the URL (or part of it) of
the Firefox tab to attach to

Window N/A Normal, Maximized, Normal Specify whether to launch the
state Minimized browser window in normal,

minimized, or maximized state

Target N/A Local computer, Any Local Set the connection string of the
desktop virtual desktop that computer target desktop that the browser

is either currently launches
connected or has at
least one UI element
captured

Clear cache N/A Boolean value False Specify whether to clear the
entire cache of the web browser
right after launching it

Clear N/A Boolean value False Specify whether to clear all
cookies stored cookies in the web

browser right after launching it



Argument Optional Accepts Default Description
Value

Wait for N/A Boolean value True Specify whether to wait for the
page to new web page to load
load completely before proceeding

Timeout for No Numeric value 60 Set the time in seconds for page
webpage to to load before the action throws
load an error

If a pop-up N/A Close it, Press a Do Specify what to do if a pop-up
dialog button, Do nothing nothing dialog appears while loading the
appears initial web page

Dialog Yes Text value OK Enter the dialog button to press
button to if a pop-up dialog appears
press

Timeout No Numeric value 60 Set the time in seconds that you
want to wait for the browser to
be launched before the action
fails

User data N/A Picture-in-Picture Picture-in- Specify the user data folder the
folder default, Browser Picture browser uses when the flow runs

default, Custom default in Picture-in-Picture. If Browser
default is selected, the browser
can't be opened on both the
desktop and in Picture-in-Picture
at the same time. Learn more

User data No Folder Specify the path of the user data
folder path folder the browser uses when the

flow runs in Picture-in-Picture.
Learn more

Variables produced

ﾉ Expand table

Argument Type Description

Browser Web browser instance The Firefox instance to use with browser automation actions

Exceptions



ﾉ Expand table

Exception Description

Failed to launch Firefox Indicates a problem launching Firefox

Invalid URL Indicates that the provided URL was invalid

Launch new Chrome
Launch a new instance or attach to a running instance of Chrome for automating
websites and web applications.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Launch N/A Launch new Instance, Launch Specify whether to launch a new
mode Attach to running new instance of Chrome or attach to

instance Instance an existing one

Attach to N/A By title, By URL, Use By title Specify whether to attach to a
Chrome tab foreground window Chrome tab by its title, URL, or

attach to the active tab of
Chrome running as the
foreground window

Initial URL No Text value Enter the URL of the web site to
visit when the web browser is
launched

Tab title No Text value Enter the title (or part of it) of
the Chrome tab to attach to

Tab URL No Text value Enter the URL (or part of it) of
the Chrome tab to attach to

Window N/A Normal, Maximized, Normal Specify whether to launch the
state Minimized browser window in normal,

minimized, or maximized state

Target N/A Local computer, Any Local Set the connection string of the
desktop virtual desktop that computer target desktop that the browser

is either currently launches
connected or has at



Argument Optional Accepts Default Description
Value

least one UI element
captured

Clear cache N/A Boolean value False Specify whether to clear the
entire cache of the web browser
right after launching it

Clear N/A Boolean value False Specify whether to clear all
cookies stored cookies in the web

browser right after launching it

Wait for N/A Boolean value True Specify whether to wait for the
page to new web page to load
load completely before proceeding

Timeout for No Numeric value 60 Set the time in seconds for page
webpage to to load before the action throws
load an error

If a pop-up N/A Close it, Press a Do Specify what to do if a pop-up
dialog button, Do nothing nothing dialog appears while loading the
appears initial web page

Dialog Yes Text value OK Enter the dialog button to press
button to if a pop-up dialog appears
press

Timeout No Numeric value 60 Set the time in seconds that you
want to wait for the browser to
be opened before the action fails

User data N/A Picture-in-Picture Picture-in- Specify the user data folder the
folder default, Browser Picture browser uses when the flow runs

default, Custom default in Picture-in-Picture. If Browser
default is selected, the browser
can't be opened on both the
desktop and in Picture-in-Picture
at the same time. Learn more

User data No Folder Specify the path of the user data
folder path folder the browser will use when

the flow runs in Picture-in-
Picture. Learn more

Variables produced



ﾉ Expand table

Argument Type Description

Browser Web browser The Chrome instance to use with browser automation
instance actions

Exceptions
ﾉ Expand table

Exception Description

Failed to launch Chrome Indicates a problem launching Chrome

Invalid URL Indicates that the provided URL was invalid

Launch new Microsoft Edge
Launch a new instance or attach to a running instance of Microsoft Edge for automating
websites and web applications.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Launch N/A Launch new Instance, Launch Specify whether to launch a new
mode Attach to running new instance of Microsoft Edge or

instance Instance attach to an existing one

Attach to N/A By title, By URL, Use By title Specify whether to attach to a
Microsoft foreground window Microsoft Edge tab by its title,
Edge tab URL, or attach to the active tab

of Microsoft Edge running as the
foreground window

Initial URL No Text value Enter the URL of the web site to
visit when the web browser is
launched

Tab title No Text value Enter the title (or part of it) of
the Microsoft Edge tab to attach



Argument Optional Accepts Default Description
Value

to

Tab URL No Text value Enter the URL (or part of it) of
the Microsoft Edge tab to attach
to

Window N/A Normal, Maximized, Normal Specify whether to launch the
state Minimized browser window in normal,

minimized, or maximized state

Target N/A Local computer, Any Local Set the connection string of the
desktop virtual desktop that computer target desktop that the browser

is either currently launches
connected or has at
least one UI element
captured

Clear cache N/A Boolean value False Specify whether to clear the
entire cache of the web browser
right after launching it

Clear N/A Boolean value False Specify whether to clear all
cookies stored cookies in the web

browser right after launching it

Wait for N/A Boolean value True Specify whether to wait for the
page to new web page to load
load completely before proceeding

Timeout for No Numeric value 60 Set the time in seconds for page
webpage to to load before the action throws
load an error

If a pop-up N/A Close it, Press a Do Specify what to do if a pop-up
dialog button, Do nothing nothing dialog appears while loading the
appears initial web page

Dialog Yes Text value OK Enter the dialog button to press
button to if a pop-up dialog appears
press

Timeout No Numeric value 60 Set the time in seconds that you
want to wait for the browser to
be launched before the action
fails



Argument Optional Accepts Default Description
Value

User data N/A Picture-in-Picture Picture-in- Specify the user data folder the
folder default, Browser Picture browser uses when the flow runs

default, Custom default in Picture-in-Picture. If Browser
default is selected, the browser
can't be opened on both the
desktop and in Picture-in-Picture
at the same time. Learn more

User data No Folder Specify the path of the user data
folder path folder the browser uses when the

flow runs in Picture-in-Picture.
Learn more

Variables produced

ﾉ Expand table

Argument Type Description

Browser Web browser The Microsoft Edge instance to use with browser automation
instance actions

Exceptions

ﾉ Expand table

Exception Description

Failed to launch Microsoft Edge Indicates a problem launching Microsoft Edge

Invalid URL Indicates that the provided URL was invalid

Create new tab
Create a new tab and navigate to the given URL (supported in Microsoft Edge, Chrome,
and Firefox).

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Web browser No Web browser Enter or choose the variable that
instance instance contains the web browser instance

to work with

URL to navigate No Text value Enter the URL, or a variable
to containing the URL, to navigate to

Wait for page to N/A Boolean value True Specify whether to wait for the
load new web page to load completely

before proceeding

Timeout for No Numeric value 60 Set the time in seconds for page
webpage to to load before the action throws
load an error

If a pop-up N/A Close it, Press a Do Specify what to do if a pop-up
dialog appears button, Do nothing dialog appears while loading the

nothing web page

Dialog button to Yes Text value OK Enter the dialog button to press if
press a pop-up dialog appears

Variables produced

ﾉ Expand table

Argument Type Description

NewBrowser Web browser The new web browser instance to use with browser
instance automation actions

Exceptions

ﾉ Expand table

Exception Description

Invalid URL Indicates that the provided URL was invalid

Failed to create a new tab Indicates a problem creating a new tab

Go to web page



Navigate the web browser to a new page.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Web browser No Web browser Enter or choose the variable that
instance instance contains the web browser

instance to work with

Navigate N/A To URL, Back, To URL Specify where to navigate to
Forward, Reload
web page

URL No Text value Enter the URL to navigate to

Wait for page to N/A Boolean value True Specify whether to wait for the
load web page to load completely

before proceeding

Timeout for No Numeric value 60 Set the time in seconds for page
webpage to to load before the action throws
load an error

If a pop-up N/A Close it, Press a Do Specify what to do if a pop-up
dialog appears button, Do nothing dialog appears while loading the

nothing web page

Dialog button Yes Text value OK Enter the dialog button to press
to press if a pop-up dialog appears

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to navigate to web page Indicates a problem navigating to the specified web page



Exception Description

Invalid URL Indicates that the provided URL was invalid

Click link on web page
Click on a link or any other element of a web page.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Web No Web browser Enter or choose the variable that
browser instance contains the web browser instance to
instance work with

UI element No UI element Select the UI element on web page to
click

Click type N/A Left click, Right Left The kind of click to perform
click, Double click, click
Left button down,
Left button up,
Right button
down, Right
button up, Middle
click

Send N/A Boolean value False Specify whether to physically move the
physical mouse cursor over the element prior to
click clicking. A physical click is required for

cases where emulated clicks don't
perform the intentional action on the
element. As this option requires the
browser window to be focused, it will
automatically bring it to the
foreground.

Wait for N/A Boolean value True Specify whether to wait for the new
page to web page to load completely after
load clicking the link

Timeout for No Numeric value 60 Set the time in seconds for page to
webpage to load before the action throws an error



Argument Optional Accepts Default Description
Value

load

If a pop-up N/A Close it, Press a Do Specify what to do if a pop-up dialog
dialog button, Do nothing appears after clicking the link
appears nothing

Dialog Yes Text value OK Enter the dialog button to press if a
button to pop-up dialog appears
press

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Element with specified CSS selector Indicates that a web page element with the specified CSS
not found selector wasn't found

Failed to click UI element Indicates a problem clicking the specified element

Click download link on web page
Select a link in a web page that results in downloading a file.

） Important

The Click download link on web page action only works in Internet Explorer, which
has reached the end of its lifecycle. We recommend using HTTP actions instead.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Web browser No Web Enter or choose the variable that
instance browser contains the web browser instance to

instance work with

UI element No UI element Select the UI element on web page to
click

Destination No Folder Enter or choose the full path of the
folder folder, or a variable containing the folder,

to save the downloaded file to

Variables produced

ﾉ Expand table

Argument Type Description

DownloadedFile File The file on the disk where the download is saved. This value is a filepath
that consists of the download folder as specified above plus the name
of the file as provided by the web server.

Exceptions

ﾉ Expand table

Exception Description

Failed to download file Indicates a problem downloading the specified file

Element with specified CSS selector Indicates that a web page element with the specified CSS
not found selector wasn't found

Failed to click UI element Indicates a problem clicking the specified element

Failed to save file Indicates a problem saving the specified file

Run JavaScript function on web page
Run a JavaScript function on the web page and get the returned result.

７ Note



The migration to the Manifest V3 browser extensions affects this action. To find
more information about Manifest V3 and how it affect the Run JavaScript function
on web page action, go to Migration to Manifest V3.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

Web No Web Enter or choose the
browser browser variable that contains the
instance instance web browser instance to

work with

JavaScript Yes Text value function ExecuteScript() { Enter the JavaScript
function /*your code here, return function to run on the

something (optionally); */ } web page

Variables produced

ﾉ Expand table

Argument Type Description

Result Text value The result of the JavaScript function that ran

Exceptions
ﾉ Expand table

Exception Description

Failed to run JavaScript Indicates a problem running JavaScript

Hover mouse over element on web page
Hover the mouse over an element of a web page.

Input parameters



ﾉ Expand table

Argument Optional Accepts Default Description
Value

Web No Web Enter or choose the variable that contains the
browser browser web browser instance to work with
instance instance

UI element No UI Select the UI element on web page to hover
element

Move No Boolean False Specify whether to physically move the mouse
mouse to value cursor over the element in order to hover the UI
hover element. A physical hover is required for cases

where emulated hover doesn't perform the
intentional action on the element. As this
option requires the browser window to be
focused, it automatically brings it to the
foreground.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to hover over element Indicates a problem hovering over the specified element

Close web browser
Close a web browser window.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Web browser No Web browser Enter or choose the variable that
instance instance contains the web browser instance to

close

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to close the web browser Indicates a problem closing the web browser

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Excel actions
Article • 02/10/2025

After setting an Excel instance, either with the Launch Excel or the Attach to running
Excel action, you can further handle your Excel worksheets.

To read and extract data from an Excel document, use the Read from Excel worksheet
action. You can retrieve the value of a single cell or a data table. The following example
reads the cells A1 through E5:

When the flow runs, the action stores the data in a data table variable:



To write data to an Excel spreadsheet, use the Write to Excel worksheet action. This
action can write any static data or variable to a specified cell or multiple cells in an Excel
worksheet.

The following example writes the previously mentioned data table to cell A51:

Each cell in the data table populates the corresponding cell in the workbook. The result
is that the A51 to E55 cell range is filled with the contents of the data table.



Resize columns/rows in Excel worksheet
Resizes a selection of columns or rows in the active worksheet of an Excel instance.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel Specify the Excel instance. This variable
instance instance must have been previously specified in a

Launch Excel action.

Resize N/A Column, Row Column Specify whether to resize columns or rows
target

Selection N/A Single, Single Specify whether to select a single
range Range, All column/row, a range of columns/rows or all

available the available columns/rows in the active
worksheet

Column No Text value The column's index number or letter.
Column numbering starts from index 1.



Argument Optional Accepts Default Description
Value

Start No Text value The index or letter of the first column.
column Column numbering starts from index 1.

End column No Text value The index or letter of the last column.
Column numbering starts from index 1.

Row No Numeric The row's index number. The numbering
value starts from 1.

Start row No Numeric The index or the first row. The numbering
value starts from 1.

End row No Numeric The index or the last row. The numbering
value starts from 1.

Resize type N/A Autofit, Autofit Specify whether to autofit selected
Custom size columns/rows or set a custom size

Width No Numeric The width of the selected columns
value

Height No Numeric The height of the selected rows
value

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to resize columns/rows Indicates a problem while resizing columns/rows

Run Excel macro
Runs a specified macro on the document of an Excel instance.

Input parameters



ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel The Excel instance to work with. This variable
instance instance must have been previously specified in a

Launch Excel action.

Macro No Text value The macro to run. The text should consist of
the name of the macro, followed by any
arguments (optional), all separated by
semicolons.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to run macro Indicates a problem running the specified macro

Get active Excel worksheet
Retrieves an Excel document's active worksheet.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel The Excel instance to work with. This variable
instance instance must have been previously specified in a

Launch Excel action.

Variables produced



ﾉ Expand table

Argument Type Description

SheetName Text value The name of the active worksheet

SheetIndex Numeric value The index of the active worksheet

Exceptions
ﾉ Expand table

Exception Description

Failed to retrieve active worksheet Indicates a problem retrieving the active worksheet

Get all Excel worksheets
Retrieves all worksheet names of an Excel document.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel Specify the Excel instance. This variable must
instance instance have been previously specified in a Launch

Excel action.

Variables produced

ﾉ Expand table

Argument Type Description

SheetNames List of Text values The names of all worksheets

Exceptions



ﾉ Expand table

Exception Description

Failed to retrieve all worksheet Indicates a problem retrieving the names of the Excel
names worksheet

Delete Excel worksheet
Deletes a specific worksheet from an Excel instance.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel The Excel instance to work with. This variable
instance instance must have been previously specified in a

Launch Excel action.

Delete N/A Index, Name Whether to find the worksheet by name or
worksheet Name index
with

Worksheet No Numeric The Index number of the worksheet to delete.
index value The numbering starts from 1, meaning that

the index of the first worksheet is 1, the
second is 2, and so on.

Worksheet No Text value The name of the worksheet to delete
name

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table



Exception Description

Can't find worksheet Indicates that a worksheet with the specified name couldn't be found

Failed to delete worksheet Indicates a problem deleting the specified worksheet

Rename Excel worksheet
Renames a specific worksheet of an Excel instance.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel instance No Excel Specify the Excel instance. This variable must
instance have been previously specified in a Launch

Excel action.

Rename N/A Index, Name Specify whether to find the worksheet by
worksheet Name name or index
with

Worksheet No Numeric The index of the worksheet to rename. The
index value numbering starts from 1, meaning that the

index of the first worksheet is 1, the second
is 2, and so on.

Worksheet No Text value The name of the worksheet to rename
name

Worksheet No Text value The new name of the worksheet
new name

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table



Exception Description

Can't find worksheet Indicates that a worksheet with the specified name couldn't be
found

Failed to rename Indicates a problem renaming the specified worksheet
worksheet

Copy Excel worksheet
Copies a worksheet from an Excel document and paste it to the Excel document of the
same or different Excel instance.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel instance The Excel instance to work with. This
instance variable must be specified in a Launch

Excel action.

Copy N/A Index, Name Name Specify whether to find the worksheet
worksheet by name or index
with

Worksheet No Numeric value The index of the worksheet to copy.
index The numbering starts from 1, meaning

that the index of the first worksheet is
1, the second is 2, and so on.

Worksheet No Text value The name of the worksheet to copy.
name

Target Excel Νο Excel instance The Excel instance of the target file.
instance This variable must be specified in a

Launch Excel action.

Worksheet No Text value The new name of the worksheet
new name

Paste N/A First First Specify whether the copied Excel
worksheet as worksheet, worksheet worksheet will be added before or

Last worksheet after the existing worksheets



Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to copy worksheet Indicates a problem when copying a worksheet in Excel

Can't copy worksheet with this Indicates a problem when trying to set the sheet name after
name copying

Activate cell in Excel worksheet
Activate a cell in the active worksheet of an Excel instance, by providing column, row,
and offset.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel instance Specify the Excel instance to work
instance with. This variable must have been

previously specified in a Launch Excel
action.

Activate N/A Absolutely Absolutely Select whether to specify the cell to
specified cell, specified activate absolutely, or relatively, by
Relatively cell using an offset distance being the
specified cell number of cells between the currently

activated reference cell and the actual
cell activate.

Column No Text value The numeric value or letter of the cell
column.

Direction N/A Left, Right, Left Select offset direction. Select where
Above, Below to look for the cell to activate based



Argument Optional Accepts Default Description
Value

on the position of the currently active
cell.

Offset from No Numeric value The distance in cells between the
active cell currently active cell and the desired

cell. The numbering starts from 0.

Row No Numeric value The numeric value of the cell row. The
numbering starts from 1.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to activate cell Indicates a problem activating an Excel cell

Select cells in Excel worksheet
Selects a range of cells in the active worksheet of an Excel instance.

You have three options when it comes to retrieving a range of cells through Excel with
the Select cells in Excel worksheet action. To begin you need a valid Excel instance,
which you can create by using the Launch Excel action and providing the respective
inputs.

To select a range of cells by explicitly providing the coordinates of the range,
select the option Range of cells in the Select property and then provide a range by
inputting the number or letter of the cells defining its start and end in the
following properties: Start column, Start row, End column, End row.

To select a range of cells, relative to the currently active cell, first select the option
Range of cells relative to active cell in the Select property. Then define the
direction in the X and Y axis based on the position of the currently active cell, as
well as the offset from the active cell in the two axes by modifying the properties
X-axis direction, X-axis offset, Y-axis direction and Y-axis offset.



To select a range of cells using the range's name, select the option Names cells in
the property Select.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel instance The Excel instance to work with.
instance This variable must have been

previously specified in a Launch
Excel action.

Select N/A Absolutely Absolutely Specify whether to select an
specified cell, specified cell explicitly specified range of cells
Relatively or a range of cells relative to the
specified cell currently active cell.

X Axis N/A Left, Right Left The X-axis offset direction. Where
Direction to look along the horizontal axis,

based on currently activated cell's
position.

Start No Text value The index or letter of the first
column column.

X Offset No Numeric value The X-axis offset.

Start row No Numeric value The first row number. The
numbering starts from 1.

End column No Text value The index or letter of the last
column.

Y Axis N/A Above, Below Above The Y-axis offset direction. Where
Direction to look along the vertical axis,

based on the position of the
currently active cell.

End row No Numeric value The last row number. The
numbering starts from 1.

Y Offset No Numeric value The Y-axis offset.

Variables produced



This action doesn't produce any variables.

Exceptions
ﾉ Expand table

Exception Description

Failed to select cells Indicates a problem selecting the specified cells

Get selected cell range from Excel worksheet
Retrieve the selected range of cells in a structure consisting of first column, first row, last
column, and last row.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel The Excel instance to work with. This variable
instance instance must have been previously specified in a

Launch Excel action.

Variables produced

ﾉ Expand table

Argument Type Description

FirstColumnIndex Numeric value The numeric value of the range's first column

FirstRowIndex Numeric value The numeric value of the range's first row

LastColumnIndex Numeric value The numeric value of the range's last column

LastRowIndex Numeric value The numeric value of the range's last row

Exceptions



ﾉ Expand table

Exception Description

Failed to retrieve the selected range of Indicates a problem retrieving the selected range of
cells cells

Copy cells from Excel worksheet
Copies a range of cells from the active worksheet of an Excel instance.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel instance The Excel instance to work with.
instance This variable must have been

previously specified in a Launch
Excel action.

Copy N/A Single Cell's Values, Single Specify whether to copy a single
mode Values from a Range Cell's cell, a range of cells or the

of Cells, Values from Values current selection of cells
Selection

Start No Text value The index or letter of the first
column column

Start row No Numeric value The index of the first row

End No Text value The index or letter of the last
column column

End row No Numeric value The index of the last row

Variables produced
This action doesn't produce any variables.

Exceptions



ﾉ Expand table

Exception Description

Failed to copy cells Indicates a problem copying the cells from the Excel document

Paste cells to Excel worksheet
Pastes a range of cells to the active worksheet of an Excel instance.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel instance Specify the Excel instance. This
instance variable must have been previously

specified in a Launch Excel action.

Paste mode N/A On specified cell, On Specify whether to paste on a
On currently specified specified cell or the currently active
active cell cell cell

Column No Text value The index or letter of the cell column

Row No Numeric value The row number

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to paste cells Indicates a problem pasting the specified cells

Delete from Excel worksheet



Deletes a cell or a range of cells from the active worksheet of an Excel instance.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel instance The Excel instance to work with.
instance This variable must have been

previously specified in a Launch
Excel action.

Retrieve N/A The value of a The value Whether to delete a single cell or a
single cell, Values of a single table from a range of cells
from a range of cell
cells

Start No Text value The cell column (single cell's value)
column or first column as a numeric value

or a letter

Start row No Numeric value The cell row (single cell's value) or
first row number

End No Text value The last column as a numeric value
column or a letter

End row No Numeric value The last row number

Shift N/A Left, Up Left The shift direction
direction

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to delete cells Indicates a problem deleting the specified cells



Insert row to Excel worksheet
Inserts a row above a selected row of an Excel instance.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel The Excel instance to work with. This variable
instance instance must have been previously specified in a

Launch Excel action.

Row index No Numeric The index of the row to add a new row above.
value The numbering starts from 1.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Can't find row Indicates that a row with the specified index couldn't be found

Failed to insert row Indicates a problem inserting a row at the specified Excel instance

Delete row from Excel worksheet
Deletes a selected row from an Excel instance.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Excel No Excel The Excel instance. This variable must have
instance instance been previously specified in a Launch Excel

action.

Delete row No Numeric The Index number of the row to delete. The
value numbering starts from 1.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Can't find row Indicates that a row with the specified index couldn't be found

Failed to delete row Indicates a problem deleting the specified row

Insert column to Excel worksheet
Inserts a column to the left of a selected column of an Excel instance.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel The Excel instance to work with. This variable
instance instance must have been previously specified in a

Launch Excel action.

Column No Text value The column's index number or letter. A new
column will appear on the left side of the
column indicated.



Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Can't find column Indicates that a column with the specified name couldn't be found

Failed to insert column Indicates a problem inserting a column at the specified Excel instance

Delete column from Excel worksheet
Deletes a selected column from an Excel instance.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel The Excel instance to work with. This variable
instance instance must have been previously specified in a

Launch Excel action.

Delete No Text value The index number or letter of the column to
column delete.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table



Exception Description

Can't find column Indicates that a column with the specified name couldn't be found

Failed to delete column Indicates a problem deleting the specified column

Find and replace cells in Excel worksheet
Finds text and replaces it with another in the active worksheet of an Excel instance.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel instance No Excel The Excel instance to work with. This
instance variable must have been previously

specified in a Launch Excel action.

Search mode N/A Find, Find Find The mode to search with
and replace

All matches N/A Boolean False Whether to find/replace text in all the
value matching cells found or in the first

matching cell only

Text to find No Text value The text to find in the worksheet

Text to replace No Text value The text used to replace the matching
with cells

Match case N/A Boolean False Whether to search for case-sensitive
value data

Match entire N/A Boolean False Whether to search for cells that contain
cell contents value just the specified text

Search by N/A Rows, Rows The order in which to search for the text
Columns

Variables produced
ﾉ Expand table



Argument Type Description

FoundColumnIndex Numeric value The index of the column found

FoundRowIndex Numeric value The index of the row found

Cells Datatable The list of cells matching the criteria

Exceptions

ﾉ Expand table

Exception Description

Failed to find and/or replace text Indicates a problem finding and/or replacing the specified text

Get first free row on column from Excel
worksheet
Retrieve the first free row, given the column of the active worksheet.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel Specify the Excel instance. This variable must
instance instance have been previously specified in a Launch

Excel action.

Column No Text value The index or letter that identifies the column.
Column numbering starts from index 1.

Variables produced

ﾉ Expand table

Argument Type Description

FirstFreeRowOnColumn Numeric The numeric value of the given column's first fully
value empty row



Exceptions

ﾉ Expand table

Exception Description

Failed to retrieve first free Indicates a problem retrieving the first free row of an Excel
row instance

Read formula from Excel
Reads the formula inside a cell in Excel.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel instance The Excel instance to work with.
instance This variable must be specified

in a Launch Excel action.

Retrieve N/A The formula of a The formula Specify whether to retrieve the
single cell, The of a single formula from a specified cell or
formula of a named cell a named cell
cell

Start No Text value The cell column (single cell's
column value) or first column as a

numeric value or a letter

Start row No Numeric value The cell row (single cell's value)
or first row number

Name No Text value The name of cells

Variables produced

ﾉ Expand table

Argument Type Description

CellFormula Text value The formula of a single cell



Exceptions

ﾉ Expand table

Exception Description

Failed to read the formula from Indicates a problem when reading the formula from a cell in
cell Excel

Get table range from Excel worksheet
Retrieves the range of a table in the active worksheet of an Excel instance.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel The Excel instance to work with. This variable
instance instance must be specified in a Launch Excel action.

Table name No Text value Specify the name of the table in Excel.

Is pivot N/A Boolean False Determine whether the specified table is a
value pivot table.

Variables produced

ﾉ Expand table

Argument Type Description

FirstColumnIndex Numeric value The numeric value of the table's first column

FirstRowIndex Numeric value The numeric value of the table's first row

LastColumnIndex Numeric value The numeric value of the table's last column

LastRowIndex Numeric value The numeric value of the table's last row

Exceptions



ﾉ Expand table

Exception Description

Failed to get the range from Indicates a problem when getting the range from a table in
table Excel

Auto fill cells in Excel worksheet
Auto fills a range with data, based on the data of another range, in the active worksheet
of an Excel instance.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel instance No Excel The Excel instance to work with. This
instance variable must be specified in a Launch

Excel action.

Ranges N/A Named cells, Named Specify how the ranges are referenced,
format Specific cells either using named cells or absolute

ranges column/row indexes

Source cells No Text value Name representing the source range for
name auto filling

Destination No Text value Name representing the destination range
cells name to auto fill. The source range should begin

from the same cell and should be
included in the destination range

Start column No Text value The index or letter of the first column of
both ranges

Start row No Numeric The first row number of both ranges. The
value numbering starts from 1

Source end No Text value The index or letter of the last column of
column the source range

Source end No Numeric The last row number of the source range.
row value The numbering starts from 1



Argument Optional Accepts Default Description
Value

Destination No Text value The index or letter of the last column of
end column the destination range

Destination No Numeric The last row number of the destination
end row value range. The numbering starts from 1

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to auto fill cells Indicates a problem when auto filling cells in Excel

Append cells in Excel worksheet
Appends a range of cells to the active worksheet of an Excel instance.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel The Excel instance to work with. This
instance instance variable must be specified in a Launch Excel

action.

Append N/A To active To active Specify whether to append to a sheet or
mode sheet, To sheet range of named cells

named cells

Name No Text value The name of the range of cells

First row has N/A Boolean False Indicates that the first row of the destination
headers value contains column headers



Argument Optional Accepts Default Description
Value

Starting Yes Text value The starting column number or letter, where
column the data is appended beginning from the

destination's first empty row. If the field is
left empty, the first column of the specified
destination is used instead.

Starting Yes Text value The header of the starting column, where
column the data is appended beginning from the
header destination's first empty row. If the field is

left empty, the first column of the specified
destination is used instead.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to append cells Indicates a problem when appending cells in Excel

Lookup range in Excel worksheet
Finds and returns the result of Excel's LOOKUP function.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel The Excel instance to work with. This variable
instance instance must be specified in a Launch Excel action.

Lookup No Text value The value to lookup in the specified range of
value cells.



Argument Optional Accepts Default Description
Value

Ranges N/A Named Named Specify how the ranges are referenced, either
format cells, cells using named cells or absolute column/row

Specific indexes.
ranges

Cells name No Text value The name of the cells range to search for the
lookup value.

Start No Text value The index or letter of the first column of the
column range to search for the lookup value.

Start row No Numeric The first row number of the range to search for
value the lookup value. The numbering starts from 1.

End column No Text value The index or letter of the last column of the
range to search for the lookup value.

End row No Numeric The last row number of the range to search for
value the lookup value. The numbering starts from 1.

Array form N/A Boolean False The array form of LOOKUP looks in the first row
value or column of an array for the specified value

and returns a value from the same position in
the last row or column of the array. Use this
form of LOOKUP when the values that you want
to match are in the first row or column of the
array. If this option remains disabled, the vector
form of LOOKUP is used instead, which looks in
a one-row or one-column range (known as a
vector) for a value and returns a value from the
same position in a second one-row or one-
column range.

Cells name Yes Text value The name of the cells range from which the
of results matching value is returned.
source

Start No Text value The index or letter of the first column of the
column of range from which the matching value is
results returned.
source

Start row of No Numeric The first row number of the range from which
results value the matching value is returned. The numbering
source starts from 1.

End column No Text value The index or letter of the last column of the
of results range from which the matching value is



Argument Optional Accepts Default Description
Value

source returned.

End row of No Numeric The last row number of the range from which
results value the matching value is returned. The numbering
source starts from 1.

Variables produced
ﾉ Expand table

Argument Type Description

LookupResult Text value The value returned by the LOOKUP function

Exceptions

ﾉ Expand table

Exception Description

Failed to lookup Indicates a problem when looking up a value in Excel

Set color of cells in Excel worksheet
Fills the background of the selected cells with the specified color, in the active
worksheet of an Excel instance.

You can define the color by entering a hexadecimal code, or you can choose from a
selection of predefined color names provided in the list. Selecting the 'Transparent'
option leaves the cells without any color fill.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel instance No Excel instance The Excel instance to work with.
This variable must be specified in



Argument Optional Accepts Default Description
Value

a Launch Excel action.

Set color of N/A Single cell, Range Single Specify whether to set the
of cells, Named cell background color of a single cell,
cells a range of cells, or named cells.

Start column No Text value The index or letter of the cell
column or range's first column.

Start row No Numeric value The cell row or the range's first
row number. The numbering
starts from 1.

End column No Text value The index or letter of the range's
last column.

End row No Numeric value The range's last row number. The
numbering starts from 1.

Cells name No Text value Name representing the range
that is filled with the specified
color.

Color format N/A Name, Name Select whether to specify a color
Hexadecimal value by its name or its hexadecimal

value.

Color name No Text value Select one of the system defined
colors.

Color No Text value Specify the hexadecimal (RGB)
hexadecimal value of the color.
value

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to set color Indicates a problem when setting the color of cells in Excel



Launch Excel
Launches a new Excel instance or opens an Excel document.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Launch Excel N/A With a blank With a Specify whether to open a New
document, and blank Excel document, or an existing
open the document document
following
document

Document No File The full path of the existing Excel
path document to open

Make N/A Boolean value True Specify whether to make the
instance Excel window visible or hidden
visible

Nest under a N/A Boolean value False Specify whether the Excel
new Excel spreadsheet should be under a
process unique Excel process. Macros and

add-ins from other spreadsheets
won't be accessible.

Password Yes Direct encrypted The password on the Excel
input or Text document, if it's password
value protected

Open as N/A Boolean value False Specify whether to open the
ReadOnly stored document in read-only

mode or not

Load add-ins N/A Boolean value False Specify whether to load add-ins
and macros and macros into the new Excel

instance

Variables produced
ﾉ Expand table



Argument Type Description

ExcelInstance Excel The specific Excel instance for use with later Excel actions. This allows
instance the user to specify which of possibly several Excel spreadsheets to

access

Exceptions

ﾉ Expand table

Exception Description

Failed to launch Excel Indicates a problem launching an Excel instance

Failed to open Excel document Indicates a problem opening the specified Excel document

Attach to running Excel
Attaches to an Excel document that's already open.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Document No File The name or the path of the Excel
name document to attach to

Variables produced

ﾉ Expand table

Argument Type Description

ExcelInstance Excel The Excel instance this action has attached to for use with later
instance Excel actions

Exceptions



ﾉ Expand table

Exception Description

Specified Excel document not Indicates that the specified Excel document couldn't be
found found

Failed to attach to Excel document Indicates a problem attaching to the Excel document

Read from Excel worksheet
Reads the value of a cell or a range of cells from the active worksheet of an Excel
instance.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel instance No Excel instance The Excel instance to work with.
This variable must have been
previously specified in a Launch
Excel action.

Retrieve N/A The value of a single The value Whether to retrieve the value
cell, Values from a of a of a single cell, a table from a
range of cells, Values single cell range of cells or the entire
from selection, All worksheet
available values from
worksheet

Start column No Text value The cell column (single cell's
value) or first column as a
numeric value or a letter

Start row No Numeric value The cell row (single cell's Value)
or first row number

End column No Text value The last column as a numeric
value or a letter

End row No Numeric value The last row number



Argument Optional Accepts Default Description
Value

Get cell N/A Boolean value False Specify whether to retrieve the
contents as content of the cells purely as
text text or as the closest matching

type such as Date Time for
dates, Numeric for numbers,
and so on

First line of N/A Boolean value False Specify whether to consider the
range first row as column names. In
contains this case, the names won't be
column read as data into the table and
names later actions can search the

data by column names.

Variables produced

ﾉ Expand table

Argument Type Description

ExcelData General value The value of the single cell

ExcelData Datatable The value of the range of cells as a DataTable

Exceptions

ﾉ Expand table

Exception Description

Failed to read cell values Indicates a problem reading the value(s) of the specified Excel cells

Get active cell on Excel worksheet
Get the active cell in the active worksheet of the Excel document.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Excel No Excel The Excel instance to work with. This variable
instance instance must have been previously specified in a

Launch Excel action.

Variables produced

ﾉ Expand table

Argument Type Description

ActiveCellColumnIndex Numeric value The numeric value of the active cell's column

ActiveCellRowIndex Numeric value The numeric value of the active cell's row

Exceptions

ﾉ Expand table

Exception Description

Failed to get active cell Indicates a problem getting the active cell

Save Excel
Saves a previously launched Excel instance.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel instance The Excel
instance instance to

save. This
variable must
have been
previously
specified in a



Argument Optional Accepts Default Description
Value

Launch Excel
action.

Save mode N/A Save document, Save document as Save How to save the
document document of

this instance

Document N/A Default (From Extension), Excel Default The format to
format Workbook (.xlsx), Excel Workbook (From save the

Macro Enabled (.xlsm), Excel 97-2003 Extension) document as
Workbook (.xls), Web Page (.htm, .html),
Excel Template (.xltx), Excel Template
Macro Enabled (.xltm), Excel 97-2003
Template (.xlt), Text (.txt), Unicode Text
(.txt), Text Macintosh (.txt), Text DOS
(.txt), XML Spreadsheet (.xml), Excel 95
(.xls), CSV (.csv), DIF (.dif), SYLK (.slk),
Excel add-in (.xlam), Excel 97-2003 add-
In (.xla), Strict Open XML Workbook
(.xlsx), OpenDocument Spreadsheet
(.ods), XML Data (.xml), Excel Binary
Workbook (.xlsb)

Document No File The full path to
path save the

document as

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to save Excel document Indicates a problem saving the Excel document

Write to Excel worksheet
Writes a value into a cell or a range of cells of an Excel instance.



Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel instance The Excel instance to work with. This
instance variable must have been previously

specified in a Launch Excel action.

Value to No General value Enter the text, number, or variable to
write insert. If the variable contains a table, it

will fill in cells to the right and below,
writing over other cell data if need be and
a list will fill in cells below.

Write N/A On specified On Whether to write into a specified cell or
mode cell, On specified the currently active cell

currently cell
active cell

Column No Text value The column number or letter for the cell
to write to

Row No Numeric value The row of the cell to write to. The
numbering starts from 1, meaning that
the index of the first worksheet is 1, the
second is 2, and so on.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to write value to Indicates a problem writing the specified value to the Excel
Excel instance

Close Excel



Closes an Excel instance.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel instance The Excel
instance instance to

close. This
variable must
have been
previously
specified in a
Launch Excel
action.

Before N/A Do not save document, Save document, Don't save Whether and
closing Save document as document how to save the
Excel document of

this instance
before closing
that instance

Document N/A Default (From Extension), Excel Default The format of
format Workbook (.xlsx), Excel Workbook (From the document

Macro Enabled (.xlsm), Excel 97-2003 Extension)
Workbook (.xls), Web Page (.htm, .html),
Excel Template (.xltx), Excel Template
Macro Enabled (.xltm), Excel 97-2003
Template (.xlt), Text (.txt), Unicode Text
(.txt), Text Macintosh (.txt), Text DOS
(.txt), XML Spreadsheet (.xml), Excel 95
(.xls), CSV (.csv), DIF (.dif), SYLK (.slk),
Excel add-in (.xlam), Excel 97-2003 add-
in (.xla), Strict Open XML Workbook
(.xlsx), OpenDocument Spreadsheet
(.ods), XML Data (.xml), Excel Binary
Workbook (.xlsb)

Document No File The full path of
path the document

Variables produced



This action doesn't produce any variables.

Exceptions
ﾉ Expand table

Exception Description

Failed to save Excel document Indicates a problem saving the Excel document

Failed to close Excel instance Indicates a problem closing the Excel instance

Set active Excel worksheet
Activates a specific worksheet of an Excel instance.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel instance No Excel Specify the Excel instance. This variable must
instance have been previously specified in a Launch

Excel action.

Activate N/A Index, Name Specify whether to find the worksheet by
worksheet Name name or index
with

Worksheet No Numeric The index number of the worksheet to
index value activate. The numbering starts from 1,

meaning that the index of the first worksheet
is 1, the second is 2, and so on.

Worksheet No Text value The name of the worksheet to activate
name

Variables produced
This action doesn't produce any variables.

Exceptions



ﾉ Expand table

Exception Description

Can't find worksheet Indicates that a worksheet with the specified name couldn't be
found

Failed to activate Indicates a problem activating the specified worksheet
worksheet

Add new worksheet
Adds a new worksheet to the document of an Excel instance.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel instance Specify the Excel instance. This
instance variable must have been previously

specified in a Launch Excel action.

New No Text value Specify the name of the new
worksheet worksheet
name

Add N/A First worksheet, First Specify whether the new Excel
worksheet as Last worksheet worksheet worksheet will be added before or

after the existing worksheets

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

A worksheet with the same Indicates that the worksheet couldn't be added because a



Exception Description

name already exists worksheet with the same name already exists

Failed to add worksheet Indicates a problem adding the worksheet

Get first free column/row from Excel worksheet
Retrieves the first free column and/or row of the active worksheet. This is useful for
adding new data into a worksheet that already has data in it.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel Specify The Excel instance. This variable must
instance instance have been previously specified in a Launch

Excel action.

Variables produced
ﾉ Expand table

Argument Type Description

FirstFreeColumn Numeric The numeric value of the first fully empty column. For example, if
value column F is the first empty column, it will be stored as '6'.

FirstFreeRow Numeric The numeric value of the first fully empty row. For example, if
value row 7 is the first empty row, it will be stored as '7'.

Exceptions

ﾉ Expand table

Exception Description

Failed to retrieve first free Indicates a problem retrieving the first free column/row of an
column/row Excel instance



Get column name on Excel worksheet
Gets the name of the column.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

Column number No Numeric value The column number

Variables produced
ﾉ Expand table

Argument Type Description

ColumnName Text value The name of the column

Exceptions
This action doesn't include any exceptions.

Clear cells in Excel worksheet
Clears a range of cells or a named cell in the active worksheet of an Excel instance.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel instance The Excel instance to work with. This
instance variable must have been previously

specified in a Launch Excel action.

Clear N/A Range of cells, Range of Specify whether to select an
Range of cells cells explicitly specified range of cells, a
relative to active cell, range of cells relative to the



Argument Optional Accepts Default Description
Value

Named cells, Single currently active cell, named cells, or
cell a single cell.

X Axis N/A Left, Right Left The X-axis offset direction. Where to
Direction look along the horizontal axis, based

on currently activated cell's position.

Start No Text value The index or letter of the first
column column.

X Offset No Numeric value The X-axis offset.

Start row No Numeric value The first row number. The
numbering starts from 1.

End No Text value The index or letter of the last
column column.

Y Axis N/A Above, Below Above The Y-axis offset direction. Where to
Direction look along the vertical axis, based

on the position of the currently
active cell.

End row No Numeric value The last row number. The
numbering starts from 1.

Y Offset No Numeric value The Y-axis offset.

Name No Text value The name of cells.

Column No Text value The index or letter of the column.

Row No Numeric value The row number. Enumeration starts
from 1.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table



Exception Description

Failed to clear Indicates a problem occurred while trying to clear the specified cells in the
cells Excel instance.

Sort cells in Excel worksheet

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel instance The Excel instance to work with. This
instance variable must have been previously

specified in a Launch Excel action.

Sort column N/A Active sheet, Active Specify whether the column to be sorted is
in Table, Range sheet part of a table, a specified range, either by

name or absolute coordinates or if it's part
of the general active worksheet.

Table name No Text value The name of the table.

Range N/A Named cells, Named Specify the range to be sorted, either
Specific cells using named cell or absolute column and
range row index.

Cells name No Text value Name representing the range.

Start No Text value The index or letter of the first column.
column

Start row No Numeric The first row number. The numbering
value starts from 1.

End column No Text value The index or letter of the last column.

End row No Numeric The last row number. The numbering starts
value from 1.

Sort by Yes Sorting rules N/A Sorting rules to apply.
as defined by
the user

First row is Yes Boolean Indicates that the first row of the
header value worksheet is a header.



Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to sort cells in worksheet Indicates a problem sorting cells in the worksheet.

Filter cells in Excel worksheet
Filter cells in Excel worksheet allows makers to create and apply a filter in the active
sheet, table, or range on the values of a specified column. To filter multiple columns in
an active sheet/table/range, multiple Filter cells in Excel worksheet actions must be
used, each one applying the respective filter.

） Important

To apply multiple filters in a specific active sheet/table/range, make sure that all
Filter cells in Excel worksheet actions used target the same source (active
sheet/table/range).

When using the Filter cells in Excel worksheet in an active sheet/range with already
existing/applied filters:

If the targeted range is the same as the one the previous filters were applied on, all
filters are applied.
If the targeted range isn't the same as the range previous filters were applied on,
previous filters are cleared, and only the latest filter is applied.
If the targeted range is a table, all filters are applied.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Excel No Excel instance The Excel instance to work with. This
instance variable must have been previously

specified in a Launch Excel action.

Filter N/A Active sheet, Active Specify whether the column to be filtered
column in Table, Range sheet is part of a table, a specified range, either

by name or absolute coordinates or if it's
part of the general active worksheet

Table name No Text value The name of the table.

Range N/A Named cells, Named Specify the range to be filtered, either
Specific range cells using named cell or absolute column/row

index

Cells name No Text value Name representing the range

Start No Text value The index or letter of the first column.
column

Start row No Numeric The first row number. The numbering
value starts from 1.

End No Text value The index or letter of the last column.
column

End row No Numeric The last row number. The numbering starts
value from 1.

Column to No Text value Name or index of the column to be
filter filtered. If the column is part of a table use

the header name.

Filters to Yes Filtering rules N/A Filtering rules applied to the defined
apply as defined by column

the user

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table



Exception Description

Failed to apply filter on cells in Indicates a problem applying the specified filter on cells in
worksheet the worksheet

Clear filters in Excel worksheet

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel instance No Excel The Excel instance to work with. This
instance variable must have been previously

specified in a Launch Excel action.

Clear filters in N/A Active Active Specify whether to clear filters from the
sheet, sheet entire active worksheet or from a
Table specific table.

Table name No Text value The name of the table.

Clear filters from Yes Boolean Clear filters from specific column.
specific column value

Clear filter in No Text value The column name to clear applied filter.
column

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to clear filter on cells in Indicates a problem applying the specified filter on cells in
worksheet the worksheet



Get empty cell

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Excel No Excel instance The Excel instance to work with. This
instance variable must have been previously

specified in a Launch Excel action.

Operation N/A First empty cell, First First Specify whether to search for the
empty cell in empty first empty cell, the first empty cell
column, First empty cell on column, the first empty cell on
cell in row, All empty row, or all empty cells inside a
cells specific range.

Search N/A By row, By column By row Specify whether to search by rows
direction or columns to find the first empty

cell inside a specific range.

Search in N/A Named cells, Specific Named Search for empty cell in a named
range cells cell or a range defined by start

column/row and end column/row.

Cells name No Text value Name representing the range.

Column No Text value Column.

Row No Numeric value Row.

Start No Text value The index or letter of the first
column column.

Start row No Numeric value The first row number. The
numbering starts from 1.

End No Text value The index or letter of the last
column column.

End row No Numeric value The last row number. The
numbering starts from 1.

Variables produced



ﾉ Expand table

Argument Type Description

EmptyCellColumnIndex Numeric value The index of the column the first empty cell is found.

EmptyCellRowIndex Numeric value The index of the row the first empty cell is found.

EmptyCells Datatable The list of empty cells found.

Exceptions
ﾉ Expand table

Exception Description

Get empty cells failed Indicates a problem retrieving the empty cells from the worksheet.

Known limitations

Using Excel files synchronized through OneDrive or
SharePoint
Interaction with Microsoft Excel files that are contained in folders synchronized in
OneDrive or SharePoint might result in an erroneous flow. Power Automate for desktop
utilizes COM objects for Excel interactions. OneDrive and SharePoint aren't fully
compatible with Excel instances launched through COM.

For this reason, when you try to open an Excel file stored under a OneDrive or
SharePoint directory, you might encounter a file not found error. To resolve this issue,
use one of the following workarounds:

Workaround 1
Make a local copy of the respective Excel file.
Modify the local copy of the Excel file using Power Automate for desktop's Excel
automation actions.
Override the Excel file copy synchronized through OneDrive/ Sharepoint with the
local copy that includes the latest changes.

Workaround 2



７ Note

This workaround can be used in general when the Launch Excel action fails to
execute.

Open a new Excel instance using the Run application action. Make sure that you
provide enough wait time between actions, allowing the Excel process to load
completely, including any add-ins.
Use the action Attach to Excel to attach to the new process.

Case with Read from Excel worksheet
When the Get cell contents as text option is enabled in the Read from Excel worksheet
action, the data is retrieved exactly as it appears in the Excel worksheet. This means that
if the column width is too narrow and the data is displayed as ### in Excel, these
symbols will also appear in the result.

Workaround:

To avoid this, use the Resize columns/rows action. If the Get cell contents as text
option is not used, the data fetched is the raw cell values, regardless of how they are
displayed or formatted in the worksheet. This means there is no need to use the Resize
columns/rows action. For date values, the time will be appended because the date data
type includes time.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Word actions
Article • 01/19/2024

The Word automation feature enables you to seamlessly interact with Word files stored
either locally or in the cloud. To begin, you need to create a Word instance using either
the 'Launch Word' or 'Attach to running Word' action. This instance serves as the input
parameter for the rest of the actions in the group, allowing you to easily perform actions
on the desired Word file.

Currently, the below actions are available:

Launch Word: When this action is triggered in Power Automate for desktop, it
opens a Word document and creates a Word instance that can be used in
subsequent Word actions within the same desktop flow. The user can choose to
open either a new, blank Word document or an existing one located on the local
machine or in the cloud (through OneDrive or SharePoint). Depending on the
action's configuration, the Word application can be launched visibly or invisibly,
and the document can be opened in read-only mode. It's important to note that if
the document is opened in read-only mode, it can't be edited either through
Power Automate for desktop actions or manually.
Attach to running Word: This action provides the capability to attach an existing
Word document that's currently open and creates a Word instance that can be
used in subsequent Word actions within the same desktop flow. The user has the
option to insert a Word document that's already open on the same machine at the
time of design through a drop-down menu, or select an existing Word document
located on the local machine or in the cloud (through OneDrive or SharePoint).
Save Word: This action enables the user to save a Word document in any format
that currently the Word application supports. The default document format is
'Default (From Extension)' which means that the user must set the document
format in the Document path parameter, such as set the value to C:\TestWord.pdf
to save it as PDF.
Close Word: This action closes a Word document and make the specific Word
instance in Power Automate as inactive. The user can save the Word document
before closing it in any format that currently the Word application supports. Note
that the default document format is 'Default (From Extension)' which means that
the user must set the document format in the 'Document path' parameter, such as
set the value to C:\TestWord.pdf to save it as PDF.
Read from Word document: This action enables users to retrieve content from a
Word document and use it in a subsequent action of the flow. You have the
flexibility to read the entire document, specific pages, or the content of a



bookmark. For pages, you can specify a specific page or a list of pages. For
example, you can insert the value 2-5 in the respective Pages parameter to retrieve
the content of pages two to five, for example pages 2, 3, 4, and 5, or insert the
value 3,5,6,7 to retrieve the content of the respective pages or use a combination
of both ways, such as 2-4,6,8,9. It's important to note that the Word document
format can't be retrieved, and the output parameter is in plain text.

Find and replace words in Word document: Users can apply a new functionality
with this action, which is the ability to find and replace specific text within a Word
document. Users have the option to replace only the first occurrence of the text or
all matches. Additionally, the use of wildcards allows for dynamic text finding, with
the wildcard being inserted in the Text to find input parameter. To further refine
the search, configure the tool to match the case of the text or match whole words



only. These settings are available when the Use wildcards parameter is set to off.

Write to Word document: This action enables users to insert text in specific
positions within a Word document. This can be done at the beginning or end of
the file, or before or after a specific bookmark. Additionally, users have the option
to append a new line before the inserted text or not, depending on their



preferences.

Insert image in Word document: This action allows users to insert images in
specific positions within a Word document. This can be done at the beginning or
end of the file, before or after a specific bookmark, or before or after specific text.
Note that no spaces or new lines are added. Users have the option to retrieve the
image either as a file stored in their local machine or as content from the



clipboard.

７ Note

Word actions in Power Automate for desktop are compatible with Microsoft Word
2013 or later versions.

Launch Word
Opens a new Word instance or opens a Word document.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Launch Word N/A With a blank With a blank Specify whether to open a
document, and open document new Word document, or an
the following existing one
document

Document No File The full path of the existing
path Word document to open



Argument Optional Accepts Default Description
Value

Make instance N/A Boolean value True Specify whether to make the
visible Word window visible or hide

it

Open as N/A Boolean value False Specify whether to open the
ReadOnly stored document in read-

only mode or not

Read Yes Direct encrypted The read protection
protection input or Text value password on the Word
password document, if it's password

protected

Write Yes Direct encrypted The write protection
protection input or Text value password on the Word
password document, if it's password

protected

Variables produced

ﾉ Expand table

Argument Type Description

WordInstance Word The specific Word instance for use with later Word actions. This
instance allows the user to specify which of possibly several Word documents

to access

Exceptions

ﾉ Expand table

Exception Description

Failed to launch Word Indicates a problem launching a Word instance

The Word document was not Indicates that the specific Word document could not be found
found in the provided location

Failed to open existing Word Indicates a problem opening the specified Word document
document

Failed to launch Word Indicates that Word application could not be launched due to an
application internal error



Exception Description

Word application is not Indicates that Word application isn't installed on the specific
installed machine

Attach to running Word
Attaches to a Word document that's already open.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Document No File The name or the path of the Word
name document to attach to

Variables produced
ﾉ Expand table

Argument Type Description

WordInstance Word The Word instance this action has attached to for use with later
instance Word actions

Exceptions

ﾉ Expand table

Exception Description

Failed to attach to Word Indicates a problem attaching to the specified Word document
document

Specified Word document Indicates that the specific Word document couldn't be found in
not found the provided location

Failed to launch Word Indicates that Word application couldn't be launched due to an
internal error



Save Word
Saves a previously launched Word instance.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Word No Word instance The Word instance to save. This
instance variable must have been previously

specified in a Launch Word or
Attach to running Word action.

Save mode N/A Save Save How to save the document of this
document, document instance.
Save document
as

Document N/A All available Default The format of the document.
format formats from (From

Word app Extension)

Document No File The full path of the document. Insert
path the desired document file extension

according to the selection in the
Document format parameter.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to save Word Indicates a problem saving the Word document

The Word instance or the Word Indicates that Word instance or Word document
document is not initialized specified in action isn't initialized



Exception Description

The operation cannot be performed on a Indicates that Word document can't be saved
read-only document because it is opened as read-only

Close Word
Closes a Word instance.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Word No Word instance The Word instance to close. This
instance variable must have been

previously specified in a Launch
Word or Attach to running Word
action.

Before N/A Do not save Don't save Specify whether and how to save
closing document, Save document the document of this instance
Word document, Save before closing that instance.

document as

Document N/A All available Default The format of the document.
format formats from (From

Word app Extension)

Document No File The full path of the document.
path Insert the desired document file

extension according to the
selection in the Document format
parameter.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table



Exception Description

Failed to close Word Indicates a problem closing the Word document

Failed to save Word Indicates a problem saving the Word document

The operation cannot be performed on a Indicates that Word document can't be saved
read-only document because it is opened as read-only

Read from Word document
Reads the text content from a document of a Word instance.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Word No Word instance The Word This variable must have
instance instance to been previously specified

work with in a Launch Word or
Attach to running Word
action

Retrieve N/A Whole Whole Whether to retrieve the
document/Pages/Bookmark document content of the whole

document, of specific
pages, or a bookmark

Page No Numeric value 1 The pages of the Word
document to be read. A
range of pages or a list
can be provided as 2-5,
which will retrieve content
from page 2 to page 5 or
2,3,7, retrieve content
from 2,3,7 pages

Bookmark No Text value The bookmark of the
Word document to be
read

Variables produced



ﾉ Expand table

Argument Type Description

WordData Text value The value of the retrieved content

Exceptions
ﾉ Expand table

Exception Description

Failed to read the content from a Word Indicates a problem retrieving the content from the
document specified Word document

The Word instance or the Word Indicates that Word instance or Word document
document is not initialized specified in action isn't initialized

Write to Word document
Write or append text to a Word file.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

Word No Word instance The Word instance This variable must have
instance to work with been previously

specified in a Launch
Word or Attach to
running Word action

Text to Yes General value The text to write in
write the specified Word

document

Append N/A Boolean value True Specifies whether to
new line append a new line at

the start of the overall
text to write to the
document



Argument Optional Accepts Default Value Description

Write text N/A Beginning of Word Beginning of Specifies the position
to file/End of Word Word file of the Word document

file/Before of where the text will be
Bookmark/After of appended
Bookmark

Bookmark No Text value The target This action appends
bookmark in the text before or after of
Word document the specified bookmark
where the text will in the Word document
be appended

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

The Word instance or the Word Indicates that Word instance or Word document
document is not initialized specified in action isn't initialized

The operation cannot be performed on a Indicates that Word document can't be edited
read-only document because it is opened as read-only

The write operation on the Word Indicates a problem writing content in the specified
document instance failed Word document

Insert image in Word document
Insert an image to a Word file.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Value Description

Word No Word instance The Word This variable must
instance instance to work have been previously

with specified in a Launch
Word or Attach to
running Word action

Insert N/A Beginning of Word file/End Beginning of Specifies the position
image to of Word file/Before of Word file of the Word

Bookmark/After of document that image
Bookmark/Before specific will be appended
text /After specific text

Insert N/A File/Clipboard File The location of the
image image to be inserted
from in the specified Word

document

Image path No File The full path of the
image to be inserted

Text to find No Text value The text to find Image will be
in the Word appended before or
document for after any occurrence
inserting image of the specified text

Bookmark No Text value The target
bookmark in the
Word document
where the image
will be appended

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

The Word instance or the Word Indicates that Word instance or Word document
document is not initialized specified in action isn't initialized

The operation cannot be performed on a Indicates that Word document can't be edited



Exception Description

read-only document because it is opened as read-only

Failed to insert image Indicates a problem inserting the image in the
specified Word document

Find and replace words in Word document
Finds text and replaces it with another in the active worksheet of an Excel instance.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Value Description

Word instance No Word The Word This variable must have been
instance instance to previously specified in a Launch Word

work with or Attach to running Word action

All matches N/A Boolean False Whether to find/ and replace text in
value all the matching occurrences found or

in the first matching occurrence only

Text to find No Text value The text to find
in the
worksheet

Text to No Text value The text used to replace the matching
replace with cells

Use wildcards N/A Boolean False Whether to use wildcards for the text
value to find

Match case N/A Boolean False Whether to search for case-sensitive
value data

Match whole N/A Boolean False Whether to search for words that are
words only value the same as the specified text

Variables produced
This action doesn't produce any variables.

Exceptions



ﾉ Expand table

Exception Description

Failed to replace text in Word document Indicates a problem replacing the specified text with
the provided input

The Word instance or the Word Indicates that Word instance or Word document
document is not initialized specified in action isn't initialized

The operation cannot be performed on a Indicates that Word document can't be edited
read-only document because it is opened as read-only

Known limitations

Using Word files synchronized through OneDrive or
SharePoint
Interaction with Microsoft Word files that are contained in folders synchronized in
OneDrive or SharePoint might result in an erroneous flow. Power Automate for desktop
utilizes COM objects for Word interactions. OneDrive and SharePoint aren't fully
compatible with Word instances launched through COM.

For this reason, when you try to open a Word file stored in a OneDrive or SharePoint
directory, you might encounter a file not found error. To resolve this issue, use one of
the following workarounds:

Workaround 1
Make a local copy of the respective Word file.
Modify the local copy of the Word file using Power Automate for desktop Word
automation actions.
Override the Word file copy synchronized through OneDrive or Sharepoint with
the local copy that includes the latest changes.

Workaround 2
Open a new Word instance using the Run application action. Make sure that you
provide enough wait time between actions, allowing the Word process to load
completely, including any add-ins.
Use the action Attach to running Word to attach to the new process.



７ Note

This workaround can be used in general when the Launch Word action fails to
execute.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



AI Builder actions (preview)
Article • 10/19/2023

The AI Builder group contains the Create text with GPT (preview) action that creates
text using the GPT language model.

） Important

This is a preview feature.
Preview features aren’t meant for production use and may have restricted
functionality.
These features are available before an official release so that customers can
get early access and provide feedback.

Further strengthening our commitment to responsible AI  we're introducing
some updates related to the utilization of Create text with GPT (preview) action in
the Power Automate for desktop October 2023 update. Specifically:

A Display input dialog action or Display message action must accompany
each use of the Create text with GPT action
The Display input dialog action or Display message action must contain the
response from the Create text with GPT action in its body so it is clearly
presented to the user

Make sure that flows that utilize the Create text with GPT (preview) action check
those two points. If either of those steps is omitted, the respective flow(s) will result
in an error.

Also note the following:

This capability is in process of rolling out, and may not be available in your
region yet.
This capability may be subject to usage limits or capacity throttling.
The GPT model might make mistakes or have biases and other undesirable
content. Therefore, to ensure that the AI-generated content is accurate,
appropriate, and free from bias, always have humans review it.
This capability is under gated access. Apply for consideration to take part in
the trial. To apply, go to Limited preview request .



After deploying the action, select Create instructions to open the instructions wizard.
The wizard allows you to create instructions using existing templates or start from blank.

Learn more about the Text generation model (preview) in the Text generation model
overview (preview).

） Important

It's mandatory that you add either a Display input dialog or Display message
action and pass either of the generated outputs of the Create text with GPT
(preview) action (PredictV2Response, PredictV2TextResponse) in its body. This will
require a human review of the generated messages. If either of those steps is
omitted, the respective flow(s) will result in an error.

Example approach: Add a Display message action with Yes - No buttons to require a
human review of the generated content. An error appears when this action doesn't exist.
Learn more about the Display message action in Message boxes actions.



Create text with GPT (preview)
Get a response generated by GPT.

Input parameters
Argument Optional Accepts Default Description

Value

Instructions No Text Provide instructions for the GPT model to
value perform a task



Variables produced
Argument Type Description

PredictV2Response Connector object

PredictV2TextResponse Text

Exceptions
Exception Description

Endpoint failure Indicates an endpoint failure



Database actions
Article • 02/21/2025

To connect to a database, use the Open SQL connection action. A connection string
specifies all information necessary to connect to a database, such as the driver, the
database, server names, and the username and password.

The following connection string connects to an Excel database:

Connection

Provider=Microsoft.ACE.OLEDB.12.0;Data 
Source=C:\myFolder\myExcelFile.xlsx;Extended Properties="Excel 12.0 
Xml;HDR=YES";

The following connection string connects to an Access database:

Connection

Provider=Microsoft.ACE.OLEDB.12.0;Data 
Source=C:\myFolder\myAccessFile.accdb; Persist Security Info=False;

７ Note

Power Automate for desktop is a 64-bit application. Only 64-bit installed drivers are
available for selection in the Open SQL connection action.

Configure a connection string manually
To manually build a connection string:

1. Select Build connections string to open the Data Link Properties dialog. The data
link tool helps you compose the required connection string step by step.

2. Once you access the wizard, select the correct driver for the database under
Provider.



3. Next, under the Connection tab, enter the remaining details such as the server
name, the username, password, and database name. Select Test Connection to test
that the connection string connects successfully.

4. Specify a connection timeout and other network settings in the Advanced tab.



Open SQL connection
Open a new connection to a database.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Connection No Text The connection string to use to connect
string value to the database

Variables produced



ﾉ Expand table

Argument Type Description

SQLConnection SQL connection A handle for the new SQL connection

Exceptions
ﾉ Expand table

Exception Description

Can't connect to data source Indicates a problem connecting to the data source

Invalid connection string Indicates that the specified connection string is invalid

Execute SQL statement
Connect to a database and execute a SQL statement.

To execute an SQL query, use the Execute SQL statement action. Begin by providing a
valid connection to the respective database. Select the desired option in the Get
connection by property. You can either provide an SQL connection variable (you can
create one by using the Open SQL connection action) or by providing the Connection
string. Then input the SQL query you want to execute in the SQL statement property.
You can also modify the timeout seconds of the action or leave the default option (30
seconds).

Natural language to script powered by copilot
(preview)
[This topic is prerelease documentation and is subject to change.]

Natural language to script is a new copilot capability added in Power Automate for
desktop. It lets you quickly generate scripts used in the execute SQL statement action by
providing a description in natural language.

） Important

） Important



This is a preview feature.
Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so
that customers can get early access and provide feedback.

Availability by region
Currently, natural language to script in Power Automate for desktop is only available in
environments located in the United States.

Availability by account type
Currently, natural language to script in Power Automate for desktop is only available for
users with a work or school account.

７ Note

If your environment is in the region where this feature is available and you still can't
experience the copilot in Power Automate for desktop experience, contact your
tenant administrator. They might have turned off the copilot functionality.

How to generate scripts using copilot and natural
language
To generate SQL code in the execute SQL statement select Generate script with Copilot.



The create prompt screen opens where you type your natural language prompt.



To create a SQL script, write your prompt and select Generate. If you need to re-create
it, you can change the prompt and select Regenerate. Otherwise, select Use this script
to go back to the main action window, where you can modify your prompt and add any
necessary variables.



） Important

Make sure that you always review the content generated by the AI model.

Help us improve this feature
Send feedback by selecting the thumb up or thumb down icon underneath the AI-
generated content. Once you do, a feedback dialog appears, which you can use to



submit feedback to Microsoft.

７ Note

If you can't see the dialog, your tenant admin might have turned it off. More
information: Disabling the user feedback functionality

Disabling the user feedback functionality
As a tenant admin you can prevent your users from sending feedback to Microsoft by
disabling the disableSurveyFeedback  tenant setting. Find more information about
viewing and setting tenant settings here:

List tenant settings (preview)
Set TenantSettings

Data subject rights requests on user feedback
Tenant administrators can view, export, and delete the feedback provided by their users
by signing in to the Microsoft 365 admin center , and then selecting Health > Product
feedback.

AI with Power Automate resources
FAQ for Generating scripts with natural language
Responsible AI FAQs for Power Automate



FAQ for Copilot data security and privacy in Microsoft Power Platform

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Get N/A Connection string, SQL Specifies whether to create a new
connection [SQL connection connection connection from a given
by variable] variable connection string or select an

already open connection

SQL No SQL connection The handle for the new SQL
connection connection

Connection No Text value The connection string to use to
string connect to the database

SQL No Text value The SQL statement to execute to
statement the database

Timeout Yes Numeric value 30 The maximum amount of time to
wait for a result from the
database

Variables produced

ﾉ Expand table

Argument Type Description

QueryResult Datatable The result from the database in the form of a data table, with rows and
columns

Exceptions

ﾉ Expand table

Exception Description

Can't connect to data source Indicates a problem connecting to the data source

Invalid connection string Indicates that the specified connection string is invalid



Exception Description

Error in SQL statement Indicates there's an error in the given SQL statement

Close SQL connection
Close an open connection to a database.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

SQL No SQL The handle for the new SQL
connection connection connection

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Access actions
Article • 01/17/2025

The Access automation feature lets you interact with locally stored Access databases.
Start by creating an Access instance using the 'Launch Access' action. This instance
serves as the input parameter for the rest of the actions, allowing you to perform actions
on the desired Access database.

The following actions are available:

Launch Access
Close Access
Read Access table
Run Access query
Run Access macro

７ Note

Access actions in Power Automate for desktop are compatible with Microsoft
Access 2013 or later versions.

Launch Access
Launches an Access database.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Database N/A Path of The full path of the Access database to
path database open.

User N/A Boolean False Specify if the Access instance allows user
interaction value interaction. This mode keeps the
mode application running after the flow closes

and permits user interaction alongside
automation but can cause popups and
errors requiring user attention.



Argument Optional Accepts Default Description
Value

Make N/A Boolean True Specify whether to make the Access
instance value window visible or hide it.
visible

Database Yes Direct The encryption password of the database,
password encrypted if it's password-protected

input or Text
value

Exclusive N/A Boolean False Specify whether to open the database in
value exclusive mode. When enabled, the

database can't be shared with others while
it's open.

Variables produced

ﾉ Expand table

Argument Type Description

AccessInstance Access The specific Access instance for use with later Access actions. This
instance allows the user to specify which of potentially several Access

documents to access

Exceptions

ﾉ Expand table

Exception Description

The Access database was not Indicates the specified Access database can't be found.
found

Failed to open existing Access Indicates an issue with opening the specific Access database.
database

Failed to launch Access Indicates an issue with launching the Access application.

Access application is not Indicates that Access application isn't currently installed in the
installed specific machine.

Read Access table



Reads an Access table

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Access N/A Access The Access instance to work with. This
instance instance variable must be specified in a Launch Access

action.

Table name N/A Text The name of the Access table. You must type
the exact name of the table as it is stored in
the specific Access database.

Variables produced

ﾉ Expand table

Argument Type Description

Result Text The result of the read query.

Exceptions

ﾉ Expand table

Exception Description

Failed to read an Access table Indicates an issue with reading the specific Access table.

Run Access query
Runs a stored Access query

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Access N/A Access The Access instance to work with. This
instance instance variable must be specified in a Launch

Access action.

Query name N/A Text The name of the stored Access query. You
must type the exact name of the query as
it is stored in the specific Access database.

Query type N/A Select query, Select Specify whether this query is a Select or
Action query query Action query.

Contains Yes Boolean False Specify the parameters required to run the
parameter query. Ensure the parameter names and

data types match the ones in the query.

Variables produced

ﾉ Expand table

Argument Type Description

QueryResult Text The result of the Select query execution, returning the output of the query
in a datatable.

AffectedRows Text The number of rows that are affected, as a result of executing the Action
query.

Exceptions

ﾉ Expand table

Exception Description

Failed to run an Access query Indicates an issue with executing the specific Access query.

Run Access macro
Runs a stored Access macro

Input parameters



ﾉ Expand table

Argument Optional Accepts Default Description
Value

Access N/A Access The Access instance to work with. This
instance instance variable must be specified in a Launch

Access action.

Macro name N/A Text The name of the stored Access macro. You
must type the exact name of the macro as it
is stored in the specific Access database.

Is VBA Macro No Boolean False Specify if the macro is a VBA macro.

Contains Yes Boolean False Specify the parameters required to run the
parameter macro. Ensure the parameter names and

data types match the ones in the macro.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to run an Access macro Indicates an issue with executing the specific Access macro.

Close Access
Closes an Access instance

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Access N/A Access instance The Access instance to work with.
instance This variable must be specified in a



Argument Optional Accepts Default Description
Value

Launch Access action.

Before N/A Do not save Do not save Specify whether to save the Access
closing changes, Save changes database before closing this
Access changes instance.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to close Access Indicates an issue with closing the specific Access instance.

Known limitations
Read Access table and Run Access query can't retrieve attachment and binary data type
cells.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Email actions
Article • 12/16/2022

Before deploying any email action, you have to configure the server that will handle the
requests. The Retrieve email messages and Process email messages actions require an
IMAP server, while the Send email action requires an SMTP server.

Common IMAP ports:

143 (non-encrypted and TLS)
993 (secure IMAP)

Common IMAP servers:

imap-mail.outlook.com (Outlook.com)
outlook.office365.com (Office365.com)
imap.mail.yahoo.com (Yahoo mail)
imap.gmail.com (Google mail)

Common SMTP ports:

25 (non-encrypted)
587 (non-encrypted and TLS)
465 (SSL)

Common SMTP servers:

smtp-mail.outlook.com (Outlook.com)
smtp.office365.com (Office365.com)
smtp.mail.yahoo.com (Yahoo mail)
smtp.gmail.com (Google mail)



To retrieve emails that meet specific criteria, use the Retrieve email messages action.
The following example retrieves only unread messages from the inbox.

The filter further specifies that the email should be from b.friday, the subject should
contain Report, and the body should contain Tuesday. The action will save locally all
attachments that match the specified criteria.



Manage your emails with the Process email messages action that requires the variable
created by the Retrieve email messages action. You can select whether to move, delete,
or mark email messages as read/unread.

The following Send email action below sends an email from N. Varga to B. Friday, with
invoicing in the BCC field. The subject and body contain the %ReportID% variable, while
the attachment is a file that the flow has processed before.



Retrieve email messages
Retrieves email messages from an IMAP server.

Input parameters
Argument Optional Accepts Default Description

Value



Argument Optional Accepts Default Description
Value

IMAP server No Text value The IMAP server address (e.g.
imap.gmail.com)

Port Yes Numeric value 993 The port to use for the IMAP server.
Usually this port is 993

Enable SSL N/A Boolean value True Specify whether to use a secure
connection to communicate with the
IMAP Server

User name No Text value The username of the email account
to access

Password No Direct The password of the email account
encrypted input to access
or Text value

Accept N/A Boolean value False Specify whether untrusted
untrusted certificates will be accepted
certificates

Mail folder No Text value The name of the IMAP mail-folder
(also known as 'mailBox') to retrieve
messages from

Retrieve N/A All email All email Specify whether to retrieve all
messages, messages messages in the folder or only the
Unread email unread ones
messages only,
Read email
messages only

Mark As N/A Boolean value True Specify whether to mark as read the
read retrieved messages or leave them as

is

"From" field Yes Text value The full email address of the sender
contains whose messages will be retrieved.

Leave this attribute blank to retrieve
all messages regardless of the sender

"To" field Yes Text value The full email address(es) of the
contains recipient(s) (separated by space if

more than one) for the messages
that will be retrieved. Leave this
attribute blank to retrieve all
messages regardless of the
recipient(s)



Argument Optional Accepts Default Description
Value

"Subject" Yes Text value The key phrase to find within the
contains email subject. Leave this attribute

blank to retrieve all emails regardless
of their subject

'Body' Yes Text value The key phrase to find within the
contains email body. Leave this attribute blank

to retrieve all emails regardless of
their content

Save N/A Save Do not save Specify whether to save the
attachments attachments, attachments attachments of the emails retrieved

Do not save or not
attachments

Save No Folder The folder to save the attachments
attachments
into

Variables produced
Argument Type Description

RetrievedEmails List of Mail The retrieved emails for later processing as a list of mail
Messages message objects

Exceptions
Exception Description

Failed to connect to IMAP server Indicates that there was a problem connecting to the IMAP
server

Failed to authenticate to the IMAP Indicates a problem authenticating to the specified IMAP
server server

Specified mail-folder doesn't exist Indicates that the specified mail folder wasn't found

Failed to save attachments Indicates a problem saving the attachments

Failed to retrieve emails Indicates a problem retrieving the emails

Process email messages



Moves, deletes or marks as unread an email (or a list of emails) retrieved by a Retrieve
emails action.

Input parameters
Argument Optional Accepts Default Description

Value

IMAP No Text value The IMAP server address
server (e.g. imap.gmail.com)

Port Yes Numeric value 993 The port to use for the
IMAP server. Usually this
port is 993

Enable SSL N/A Boolean value True Specify whether to use a
secure connection to
communicate with the
IMAP server

Username No Text value The username of the email
account to access

Password No Direct encrypted input or Text The password of the email
value account to access

Accept N/A Boolean value False Specify whether untrusted
Untrusted certificates will be
Certificates accepted

Email(s) to No List of Mail Messages The email or list of emails
process to process. This parameter

should contain a variable
populated by a Retrieve
emails action

Operation N/A Delete emails from server, Mark Move The operation you want to
emails as unread, Move emails emails perform on the specified
to mail folder, Mark emails as to mail email messages
unread and move to mail folder folder

Mail folder No Text value The name of the mail
folder to which the emails
will be moved

Variables produced
This action doesn't produce any variables.



Exceptions
Exception Description

Failed to connect to IMAP server Indicates that there was a problem connecting to the IMAP
server

Specified mail-folder doesn't Indicates that the specified mail folder wasn't found
exist

Failed to process emails Indicates a problem with processing the specified emails

Send email
Creates and sends a new email message.

Input parameters
Argument Optional Accepts Default Description

Value

SMTP server No Text value The SMTP server address

Server port Yes Numeric 25 The port to use for the server. Usually this
value port is 25

Enable SSL N/A Boolean False Specify whether or not to communicate with
value the server through a secure connection

SMTP Server N/A Boolean False Specify whether the server requires
needs value authentication
authentication

User name No Text value The username of the email account to access

Password No Direct The password of the email account to access
encrypted
input or
Text value

Accept N/A Boolean False Specify whether untrusted certificates will be
untrusted value accepted
certificates

From No Text value The sender's email address

Sender Yes Text value The sender's display name
display name



Argument Optional Accepts Default Description
Value

To No Text value The email(s) of the recipient(s). If more than
one email is entered, the list of addresses
should be separated by semi-colons

CC Yes Text value The email(s) of the Cc recipient(s). If more
than one email is entered, the list of
addresses should be separated by semi-
colons

BCC Yes Text value The email(s) of the BCC (hidden) recipient(s).
If more than one email is entered, the list of
addresses should be separated by semi-
colons

Subject Yes Text value The subject of the email

Body Yes Text value The body of the email

Body Is HTML N/A Boolean False Specify whether the body of the email will be
value interpreted as HTML coding

Attachment(s) Yes List of The full path of any attachment(s), or a file or
Files a list of files. Multiple files should be

enclosed in double quotes (") and separated
by a space character

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Invalid email address Indicates that the specified email address is invalid

Failed to send email Indicates a problem sending the email

Attachment not found Indicates that the specified attachment(s) weren't found



Exchange Server actions
Article • 10/24/2023

２ Warning

This group of actions is intended for Exchange Server automation scenarios. To
automate Exchange Online, use the corresponding Office 365 cloud connectors in
cloud flows.

The Exchange Server actions enable you to connect to an Exchange server and manage
your correspondence.

Exchange Server actions require a connection to an Exchange server that you can
establish using the Connect to Exchange server action.

The following example contains a manually populated server address rather than using
auto-discovery. The credentials are set to user defined, so the domain, username, and
password are manually entered. A set timeout in the Advanced section allows the action
to return an error if a connection hasn't been established within the specified time
frame.



To retrieve emails from an exchange server, use the Retrieve Exchange email messages
action. The following example retrieves email messages from a custom folder named
Receipts. The filters contain variables that have been previously defined in the desktop
flow. The action will save all attachments locally to the specified folder.



The Process Exchange email messages action processes email messages retrieved by
the Retrieve Exchange email messages action. Use this action to move, delete, or mark
email messages as read.

Connect to Exchange server



Open a new connection to an Exchange server.

Input parameters
Argument Optional Accepts Default Description

Value

Exchange N/A Exchange 2010, Exchange The version of the Exchange
server Exchange 2010 SP1, 2013 SP1 server
version Exchange 2010 SP2,

Exchange 2013,
Exchange 2013 SP1

Connection N/A Auto discovery, Auto Specifies how to connect to
type Exchange server address discovery the Exchange server

Server No Text value The Exchange server
address address

Email address No Text value The Exchange account email
address

Credentials N/A Exchange default, User Exchange Specifies the way to provide
defined default the user's Exchange

credentials

Domain Yes Text value The Exchange account
domain. To extract the
account domain from the
username, left this field
empty

Username No Text value The Exchange account
username

Password No Direct encrypted input The Exchange account
or Text value password

Timeout Yes Numeric value 30 The time in seconds to wait
for the connection to be
established before the
action fails

Variables produced



Argument Type Description

ExchangeConnection Exchange The specific Exchange connection for use with later
connection Exchange actions

Exceptions
Exception Description

Failed to connect to the Exchange server Indicates a problem connecting to the Exchange server

Retrieve Exchange email messages
Retrieve email messages from the specified Exchange server.

Input parameters
Argument Optional Accepts Default Description

Value

Exchange No Exchange The Exchange connection.
connection connection Create an Exchange connection

with the 'Connect to Exchange
server' action

Mailbox type N/A Personal, Shared Personal The type of the mailbox to
retrieve email messages from

Shared No Text value The address of the shared
mailbox mailbox to retrieve email
address messages from

Retrieve email N/A Boolean value False Specifies whether to retrieve
messages from email messages from a custom
custom folder folder or a predefined

Exchange folder

Exchange N/A Inbox, Deleted Inbox A predefined Exchange folder
folder items, Drafts, to retrieve email messages

Outbox, Sent from
items, Junk email

Mail folder No Text value Inbox The name or path (e.g.
folder1\folder2) of the mail-
folder to retrieve email
messages from



Argument Optional Accepts Default Description
Value

Retrieve N/A All email Unread email Specifies whether to retrieve all
messages, messages email messages in the folder or
Unread email only only the unread ones
messages only,
Read email
messages only

Mark as read N/A Boolean value True Specifies whether to mark as
read the retrieved email
messages or leave them as is

From contains Yes Text value The full email address of the
sender to retrieve messages
from. Leave this attribute blank
to retrieve all messages
regardless of the sender

To contains Yes Text value The full email address(es) of
the recipient(s) (separated by
space if more than one) for the
email messages to retrieve.
Leave this attribute blank to
retrieve all email messages
regardless of the recipient(s)

Subject Yes Text value The key phrase to find within
contains the email subject. Leave this

attribute blank to retrieve all
email messages regardless of
their subject

Body contains Yes Text value The key phrase to find within
the email body. Leave this
attribute blank to retrieve all
email messages regardless of
their content

Attachments N/A Save attachments, Do not save Specifies whether to save the
Do not save attachments attachments of the email
attachments messages retrieved or not

Save No Folder The folder to save the
attachments attachments into
into

Variables produced



Argument Type Description

RetrievedEmails List of Exchange mail The retrieved email messages for later processing as a
messages list of Exchange mail messages objects

Exceptions
Exception Description

Failed to save attachments Indicates a problem saving the attachments

Specified mail-folder doesn't exist Indicates that the specified mail folder doesn't exist

Failed to retrieve email messages Indicates a problem retrieving the email messages

Send Exchange email message
Create and send a new email message.

The Send Exchange email message action creates and sends a new email message
upon connecting to an Exchange server. Before adding this action, add the Connect to
Exchange server action to set up a connection to your Exchange server first. The output
of this action is the %ExchangeConnection% variable that should be used as input to the
Send Exchange email message action.

Input parameters
Argument Optional Accepts Default Description

Value

Exchange No Exchange The Exchange connection. Create an
connection connection Exchange connection with the 'Connect

to Exchange server' action

From No Text value The sender's email address

Sender display Yes Text value The sender's display name
name

To No Text value The email(s) of the recipient(s). To enter
more than one email, separate the list
of addresses by semi-colons

CC Yes Text value The email(s) of the CC recipient(s). To
enter more than one email, separate



Argument Optional Accepts Default Description
Value

the list of addresses by semi-colons

BCC Yes Text value The email(s) of the BCC (hidden)
recipient(s). To enter more than one
email, separate the list of addresses by
semi-colons

Subject Yes Text value The subject of the email

Body Yes Text value The text of the body

Body is HTML N/A Boolean False Specifies whether to interpret the body
value of the email as HTML coding

Attachment(s) Yes List of Files The full path of any attachment(s).
Enclose multiple files in double quotes
(") and separate them by a space
character

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Attachment not found Indicates that the specified attachment(s) don't exist

Failed to send email Indicates a problem sending the email

Process Exchange email messages
Move, delete or mark as unread an email message (or a list of email messages).

Input parameters
Argument Optional Accepts Default Description

Value

Exchange No Exchange connection The Exchange connection.
connection Create an Exchange

connection with the



Argument Optional Accepts Default Description
Value

'Connect to Exchange
server' action

Email No List of Exchange mail The email message(s) to
message(s) messages process. Use a variable
to process populated by a 'Retrieve

Exchange email messages'
action

Operation N/A Delete email messages Move email Specifies which operation
from server, Mark email messages to to perform on the specified
messages as unread, mail folder email messages
Move email messages
to mail folder

Mailbox type N/A Personal, Shared Personal The type of the mailbox to
retrieve email messages
from

Shared No Text value The address of the shared
mailbox mailbox to retrieve email
address messages from

Move to N/A Boolean value False Specifies whether to move
custom email messages to a
folder custom folder or a

predefined Exchange folder

Exchange N/A Inbox, Deleted items, Inbox A predefined Exchange
folder Drafts, Outbox, Sent folder to move email

items, Junk email messages from

Mail folder No Text value Inbox The name or path (e.g.
folder1\folder2) of the
mail-folder to move email
messages to

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Specified mail-folder doesn't exist Indicates that the specified mail folder doesn't exist



EFaxicleedp ttioo nprocess email messages DInedsiccaritpesti oa nproblem processing the specified email messages



Outlook actions
Article • 01/11/2024

For machines with an installation of Outlook, you can manage your mailboxes with the
Outlook actions.

![IMPORTANT] Outlook automation actions don't support the new Outlook for
Windows  application. Make sure you are using the Outlook desktop application.

After creating an Outlook instance with the Launch Outlook action, use the Retrieve
email messages from Outlook action to get the messages from a specified account and
mail folder.

） Important

When you filter the retrieved results by modifying the From contains or To
contains argument in the Retrieve email messages from Outlook action, using
email addresses in plain display format (SMTP) won't yield any data if the email
addresses are stored in x.500 format.

The following example retrieves all the email messages from the folder Tickets, a
subfolder of the Inbox. The specified filters limit the results to messages from a specific
sender that contain particular words in their subject and body.



The Process email messages in Outlook action processes email messages retrieved by
the Retrieve email messages from Outlook action. To use this action, you must provide
an Outlook instance, an account, and a variable with retrieved emails. Then, you can
select whether to move, delete or mark as read the selected messages.

Store Outlook email messages locally using the Save Outlook email messages action.
Specify an Outlook instance, an account, a variable with the messages to save, and the
format and location for the created files.



To close an open Outlook instance, use the Close Outlook action.

Launch Outlook
Launch Outlook and create a new Outlook instance.

Input parameters
This action doesn't require any input.

Variables produced

ﾉ Expand table

Argument Type Description

OutlookInstance Outlook The specific Outlook instance for use with later Outlook
instance actions

Exceptions
ﾉ Expand table

Exception Description

Failed to launch Outlook Indicates a problem launching Outlook

Retrieve email messages from Outlook
Retrieve email messages from an Outlook account.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Outlook No Outlook instance The Outlook instance to work
instance with. Specify this variable in a

'Launch Outlook' action



Argument Optional Accepts Default Description
Value

Account No Text value The name of the Outlook
account (data file name) to
work with

Mail folder No Text value The name of the folder to
retrieve messages from. Enter
the full folder path for
subfolders (ex: Inbox\Work)

Retrieve N/A All email All email Specifies whether to retrieve all
messages, Unread messages messages in the folder or only
email messages the unread ones
only, Read email
messages only

Mark as read N/A Boolean value True Specifies whether to mark as
read all the unread messages
retrieved

From Yes Text value The full email address of the
contains sender whose messages to

retrieve. Leave this attribute
blank to retrieve all messages
regardless of the sender

To contains Yes Text value The full email address(es) of the
recipient(s) (separated by space
or semicolon if more than one)
for the messages to retrieve.
Leave this attribute blank to
retrieve all messages regardless
of the recipient(s)

Subject Yes Text value The key phrase to find within
contains the email subject. Leave this

attribute blank to retrieve all
email messages regardless of
their subject

Body Yes Text value The key phrase to find within
contains the email body. Leave this

attribute blank to retrieve all
email messages regardless of
their content

Attachments N/A Save attachments, Don't save Specifies whether to save the
Don't save attachments attachments of the email



Argument Optional Accepts Default Description
Value

attachments messages retrieved or not

Save No Folder The path to save the
attachments attachments of the retrieved
into emails into

Variables produced
ﾉ Expand table

Argument Type Description

RetrievedEmails List of Outlook mail The retrieved email messages for later processing. The
messages variable contain a list of Outlook message objects

Exceptions

ﾉ Expand table

Exception Description

Failed to find Outlook account Indicates that the specified Outlook account doesn't
exist

Mail-folder specified not valid in Indicates that the specified mail folder isn't valid
Outlook

Directory for saving attachments not Indicates that the directory to save the attachments into
found doesn't exist

Failed to retrieve email messages from Indicates a problem retrieving the email messages from
Outlook Outlook

Send email through Outlook
Create and send a new email message through Outlook.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Outlook No Outlook The Outlook instance to work with.
instance instance Specify this variable in a 'Launch Outlook'

action

Account No Text value The name of the Outlook account (data
file name) to work with

Send email N/A Account, Account Specifies whether to send the email using
from Other the specified account or a different one,

mailbox for example from a shared mailbox

Send from No Text value The name of the Outlook account to send
the email from; for example, a shared
mailbox.

To No Text value The email address(es) of the recipient(s).
To enter more than one email address,
separate the list of addresses by spaces or
semicolons

CC Yes Text value The email address(es) of the CC
recipient(s). To enter more than one email
address, separate the list of addresses by
spaces or semicolons

BCC Yes Text value The email address(es) of the BCC (hidden)
recipient(s). To enter more than one email
address, separate the list of addresses by
spaces or semicolons

Subject Yes Text value The subject of the email

Body Yes Text value The text of the body

Body is HTML N/A Boolean False Specifies whether to interpret the body of
value the email as HTML coding

Attachment(s) Yes List of Files The full path of any attachment(s). Enclose
multiple files in double quotes (") and
separate them by a space character

Variables produced
This action doesn't produce any variables.

Exceptions



ﾉ Expand table

Exception Description

Failed to find Indicates that the specified Outlook account doesn't exist. Power Automate
Outlook account doesn't throw this error for the email addresses populated in the Send from

input parameter

Failed to send Indicates a problem sending the email
email

Attachment not Indicates that the specified attachment(s) don't exist
found

Process email messages in Outlook
Move or deletes an email (or a list of email messages) retrieved by a 'Retrieve emails
from Outlook' action.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Outlook No Outlook instance The Outlook instance to work
instance with. Specify this variable in a

'Launch Outlook' action

Account No Text value The name of the Outlook
account (data file name) to
work with

Email No List of Outlook mail The email message(s) to
messages to messages process. Use a variable
process populated by a 'Retrieve

email messages from
Outlook' action

Operation N/A Delete email Move email Specifies which operation to
messages, Move messages to perform on the specified
email messages to mail folder email messages
mail folder, Mark as
unread



Argument Optional Accepts Default Description
Value

Mail folder No Text value The name of the folder to
retrieve messages from. Enter
the full folder path for
subfolders (for example,
Inbox\Work)

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to find Outlook account Indicates that the specified Outlook account doesn't exist

Specified mail-folder doesn't exist Indicates that the specified mail folder doesn't exist

Failed to process email messages in Indicates a problem processing the specified email
Outlook messages in Outlook

Save Outlook email messages
Save Outlook email messages given an account.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Outlook No Outlook instance The Outlook instance to
instance work with. Specify this

variable in a 'Launch
Outlook' action

Account No Text value The name of the Outlook
account (data file name) to



Argument Optional Accepts Default Description
Value

work with

Email No List of Outlook mail The email message(s) to
message(s) messages save. Use a variable
to save populated by a 'Retrieve

email messages from
Outlook' action

Save format N/A Text only (.txt), Outlook Outlook Specifies the format to
template (.oft), Outlook message save the messages
message format (.msg), format
Outlook message format - (*.msg)
Unicode (.msg), HTML
(.html), MHT files (.mht)

File name N/A Default, Custom Default Specifies whether to save
the messages using the
default name (subject) or
provide another

Save as No Text value Specifies the custom name
for messages' name, which
differs from message to
message by an
automatically added suffix

Save email No Folder The folder to save the
message(s) messages to
to

Variables produced
ﾉ Expand table

Argument Type Description

StoredMessagesFiles List of Text The file paths of the saved email messages for later
values processing

Exceptions

ﾉ Expand table



Exception Description

Failed to find Outlook account Indicates that the specified Outlook account doesn't exist

Directory not found Indicates that the specified email message(s) couldn't be
saved because the directory doesn't exist

Email message is deleted or Indicates that the specified email message(s) couldn't be
moved to another folder saved because they're moved or deleted

Failed to save email message(s) Indicates a problem saving the specified email message(s)

Respond to Outlook mail message
Respond to an Outlook message, by replying, replying to all or forwarding it.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Outlook No Outlook The Outlook instance to work with. Specify
instance instance this variable in a 'Launch Outlook' action

Account No Text value The name of the Outlook account (data
file name) to work with

Mail message No Outlook The mail message to act upon. Use a
mail variable populated by a 'Retrieve email
message messages from Outlook' action

Response N/A Reply, Reply Reply Specifies whether to reply (to sender or
action all, Forward all) with a message or forward the

received message

To No Text value The email address(es) of the recipient(s).
To enter more than one email address,
separate the list of addresses by spaces or
semicolons

CC Yes Text value The email address(es) of the CC
recipient(s). To enter more than one email
address, separate the list of addresses by
spaces or semicolons



Argument Optional Accepts Default Description
Value

BCC Yes Text value The email address(es) of the BCC (hidden)
recipient(s). To enter more than one email
address, separate the list of addresses by
spaces or semicolons

Body Yes Text value The text of the body

Attachment(s) Yes List of Files The full path of any attachment(s). Enclose
multiple files in double quotes (") and
separate them by a space character

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to find Outlook account Indicates that the specified Outlook account doesn't exist

Failed to send email Indicates a problem sending the email

Attachment not found Indicates that the specified attachment(s) don't exist

Close Outlook
Close a previously launched Outlook instance.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Outlook No Outlook The Outlook instance to work with. This
instance instance variable is specified in a 'Launch Outlook'

action



Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Failed to close Outlook instance Indicates a problem closing the Outlook instance



Message boxes actions
Article • 11/11/2024

You can use message boxes in your desktop flows to interact with users, request input,
and provide an output.

To display a message to the user while a flow runs, use the Display message action. You
must specify the title of the message box, its content, the icon and the buttons in the
box to be displayed. Moreover, you might set a default button to be preselected as well
as to indicate if the message box should always be on top of all other windows on your
machine and whether the message box is to be closed automatically after a certain
amount of time.

The example here displays a message box that informs the user that parsing is complete
and asks whether to parse another file. The message box displays a question icon and
always is on top of other windows. The ButtonPressed variable will store the user's
selection.



The created message box should look like the following example:

In addition to this, you might create a custom form for displaying a message as part of
your flow with the use of the Display custom form action. A custom form accepts



multiple elements, and you can create a custom form that contains various input types
and buttons. More information: Create custom forms.

To request input data using a dialog, deploy the Display input dialog action. This action
requires a title for the dialog and a message as a prompt for the user. Optionally, you
can set a default value and an input type (single line, multiline, or password).

Use the Display select file dialog action to prompt users to browse for a file. The
following example prompts you to select an image file. A variable specifies the initial
folder, and the file filter limits the available selections to specific file extensions.



The created file dialog should look like the following example. You can see the specified
filter in the bottom right corner of the dialog.



Display message
Displays a message box.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Message box Yes Text value The text to use as the message
title box title

Message to Yes Text value The text to display as the actual
display message

Message box N/A None, Information, None The icon to display with the
icon Question, Warning, message box

Error

Message box N/A OK, OK - Cancel, Yes OK The buttons to display on the
buttons - No, Yes - No - message box

Cancel, Abort - Retry
- Ignore, Retry -
Cancel

Default button N/A First button, Second First The button to highlight by
button, Third button button default. If the user presses Enter,

this button will be pressed

Keep message N/A Boolean value False Specify whether the message
box always on box should always remain on top
top of all other windows

Close message N/A Boolean value False Specify whether the message
box box closes automatically after a
automatically preset time, as if the default

button was pressed. Otherwise,
the flow will wait until a button is
pressed by the user

Timeout Yes Numeric value 3 The seconds to pause the
automation while waiting for
input, until continuing
automatically

Variables produced



ﾉ Expand table

Argument Type Description

ButtonPressed Text value The text of the button pressed

７ Note

The value of the ButtonPressed variable is always in English, regardless of the
current locale settings in Power Automate for desktop.

Exceptions

ﾉ Expand table

Exception Description

Failed to display message box Indicates a problem displaying the message dialog

Can't display message box in Indicates a problem displaying the message dialog in
noninteractive mode non-interactive mode

Display input dialog
Displays a dialog box that prompts the user to enter text.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Input dialog Yes Text value The dialog title
title

Input dialog Yes Text value The dialog message
message

Default value Yes Text value Specify the text to display by default. If
the user wishes to change this text, they
can type over it. Otherwise, the default
text will be used



Argument Optional Accepts Default Description
Value

Input type N/A Single line, Single The format for the input text. Choose
Password, line Single line - password to hide the text
Multiline or multiline so that a larger display box

makes visible more than one line of text

Keep input N/A Boolean False Specify whether the input dialog should
dialog always value always remain on top of all other
on top windows

Variables produced

ﾉ Expand table

Argument Type Description

UserInput Text The text entered by the user, or the default text
value

ButtonPressed Text The text of the button pressed. The user will automatically be given
value the choice of OK or Cancel

７ Note

The value of the ButtonPressed variable is always in English, regardless of the
current locale settings in Power Automate for desktop.

Exceptions

ﾉ Expand table

Exception Description

Failed to display input dialog Indicates a problem displaying the input dialog

Can't display input dialog in non Indicates a problem displaying the input dialog in non-
interactive mode interactive mode

Display select date dialog
Displays a dialog box that prompts the user to enter a date or date range.



Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Dialog title Yes Text value The dialog title

Dialog message Yes Text value The dialog message

Dialog type N/A Single date, Single Whether the user will enter a
Date range (two date single date or two dates as the
Dates) endpoints of a range of dates

Prompt for N/A Date only, Date Date only Specify whether the user will
and time enter the date only or the date

and time

Default value Yes Datetime The default value for the date

Default value for Yes Datetime The default value for the end
second date date in a range

Keep date N/A Boolean value False Specify whether the date
selection dialog selection dialog should always
always on top remain on top of all other

windows

Variables produced

ﾉ Expand table

Argument Type Description

SelectedDate Datetime The date entered by the user or the default date

SecondSelectedDate Datetime The second date entered by the user or that default date

ButtonPressed Text The text of the button pressed by the user. The user will
value automatically be given the choice of OK or Cancel

７ Note

The value of the ButtonPressed variable is always in English, regardless of the
current locale settings in Power Automate for desktop.



Exceptions

ﾉ Expand table

Exception Description

Failed to display select date dialog Indicates a problem displaying the select date dialog

Can't display select date dialog in non Indicates a problem displaying the input dialog in
interactive mode non-interactive mode

Display select from list dialog
Displays a dialog box with options that lets the user select from a list.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Dialog title Yes Text The dialog title
value

Dialog message Yes Text The dialog message
value

List to choose No General The list to display as a drop-down menu
from value for the user to choose from

Keep select N/A Boolean False Specify whether the select dialog should
dialog always on value always remain on top of all other
top windows

Limit to list N/A Boolean True Whether to allow the user to enter their
value own answer outside of the list being

displayed

Allow empty N/A Boolean False Allow the user to not select anything,
selection value creating an empty selected item output

Allow multiple N/A Boolean False Allow the user to select more than one
selections value choice. The selected item and selected

index variables will hold a list of items



Argument Optional Accepts Default Description
Value

Preselect items N/A Boolean False Specify whether the items with a
starting with a + value prepended '+' sign will appear
sign automatically preselected

Variables produced

ﾉ Expand table

Argument Type Description

SelectedItem Text value The item selected from the list as text

SelectedItems List of Text The items selected from the list as a list of text
values

SelectedIndex Numeric The index number of the item selected from the list. You can
value use the item number instead of the full text of your choice

SelectedIndexes List of The index number of the items selected from the list. This
Numeric parameter allows you to use the item number instead of the
values full text of your choice

ButtonPressed Text value The name of the button pressed by the user (OK or Cancel)

７ Note

The value of the ButtonPressed variable is always in English, regardless of the
current locale settings in Power Automate for desktop.

Exceptions

ﾉ Expand table

Exception Description

Failed to display select dialog Indicates a problem displaying the select dialog

Can't display select dialog in Indicates a problem displaying the input dialog in non-
noninteractive mode interactive mode



Display select file dialog
Displays the select file dialog and prompts the user to select one or more files.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Dialog title Yes Text The dialog title
value

Initial folder Yes Folder The initial folder to open when browsing for a
file. This folder is where the select file dialog
action will start the user looking for the file(s)

File filter Yes Text A filter to limit the files retrieved. This
value parameter allows wild cards, for example

".txt" or "document?.doc" (without the quotes).
To allow the user to choose from multiple file
filters, separate the choices with a semi-colon,
for example ".txt;*.exe"

Keep file N/A Boolean False Whether the file selection dialog should
selection value always remain on top of all other windows
dialog always
on top

Allow multiple N/A Boolean False Whether the user will be able to select more
selections value than one file or not

Check if file N/A Boolean False Whether only files that already exist will be
exists value accepted

Variables produced
ﾉ Expand table

Argument Type Description

SelectedFile File The file that will be selected through the dialog

SelectedFiles List of The file(s) selected
Files



Argument Type Description

ButtonPressed Text The text of the button pressed. The user will automatically be given
value the choice of Open or Cancel

７ Note

The value of the ButtonPressed variable is always in English, regardless of the
current locale settings in Power Automate for desktop.

Exceptions
ﾉ Expand table

Exception Description

Failed to display select file dialog Indicates a problem displaying the select file dialog

Can't display select file dialog in Indicates a problem displaying the input dialog in
noninteractive mode non-interactive mode

Display select folder dialog
Displays the select folder dialog and prompts the user to select a folder.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Dialog description Yes Text The description of the select folder
value dialog For example, "Please select the

folder into which you wish to copy the
files"

Initial folder Yes Folder The initial folder to open. This folder
will be the default folder unless the
user picks a new one

Keep folder N/A Boolean False Whether the folder selection dialog
selection dialog value should always remain on top of all



Argument Optional Accepts Default Description
Value

always on top other windows

Variables produced
ﾉ Expand table

Argument Type Description

SelectedFolder Folder The selected folder

ButtonPressed Text The text of the button pressed. The user will automatically be given
value the choice of OK or Cancel

７ Note

The value of the ButtonPressed variable is always in English, regardless of the
current locale settings in Power Automate for desktop.

Exceptions
ﾉ Expand table

Exception Description

Failed to display select folder dialog Indicates a problem displaying the select folder
dialog

Can't display select folder dialog in Indicates a problem displaying the input dialog in
noninteractive mode non-interactive mode

Display custom form
Display a customized form that can include multiple types of elements, like text, number
or file inputs etc.

Input parameters
Input parameters are configured through the custom form designer.



Variables produced

ﾉ Expand table

Argument Type Description

CustomFormData Custom object A custom object containing the user's input

ButtonPressed Text value The ID of the button pressed

７ Note

The value of the ButtonPressed variable is always in English, regardless of the
current locale settings in Power Automate for desktop.

Exceptions

ﾉ Expand table

Exception Description

Failed to display custom form Indicates a problem displaying the custom form

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Mouse and keyboard actions
Article • 12/16/2022

Simulate keyboard activity with the Send Keys action. To insert special keys, such as the
arrow keys and Caps Lock, and modifies, such as Shift and Control, select Insert special
key.

The following examples add a signature to an email message, starting with two line
breaks. Then, the action sends Ctrl + A and Ctrl + C to select and copy the text to the
clipboard.

７ Note

To use a key as a modifier, use the curly brackets notation for both keys.



To simulate mouse movements, use the Move mouse action. The following example
moves the mouse manually to specific coordinates at normal speed.

Move the mouse to a specific image on the screen with the Move mouse to image
action. The following example moves the cursor to the first occurrence of the search
icon and left-clicks it.



In the Advanced section of the action, you can see that the action waits 30 seconds for
the image to appear in the foreground window, and the mouse will point to the center
of the image.



Block Input
Blocks user mouse and keyboard input, so that the flow can perform mouse and
keyboard actions without interference from the user.

） Important

Because of its critical functionality, the Block input action requires elevated rights
to run. Therefore, before using the action, ensure that Power Automate runs with
administrator rights. To find more information regarding running Power Automate
as an administrator, go to Run Power Automate with elevated rights.



Input parameters
Argument Optional Accepts Default Description

Value

Block it N/A Boolean True Specify whether to block or unblock mouse
value and keyboard input

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Can't block/unblock user input in non Indicates a problem blocking/unblocking input in
interactive mode non-interactive mode

Failed to block/unblock input Indicates a problem blocking/unblocking input

Get mouse position
Retrieves the current position of the mouse cursor on the screen in pixel coordinates.

Input parameters
Argument Optional Accepts Default Description

Value

Relative to N/A Screen, Screen Specify whether to retrieve the mouse position
Foreground in screen coordinates or relative to the top left
window corner of the active window

Variables produced
Argument Type Description

MousePosX Numeric value The horizontal (X) value of the mouse position

MousePosY Numeric value The vertical (Y) value of the mouse position



Exceptions
Exception Description

Can't retrieve the mouse position in Indicates a problem retrieving the mouse cursor
non interactive mode position in non-interactive mode

Move mouse
Moves the mouse to a specific position.

Input parameters
Argument Optional Accepts Default Description

Value

Position X No Numeric value The horizontal (X) value of the
position to send the mouse to

Position Y No Numeric value The vertical (Y) value of the
position to send the mouse to

Relative to N/A Screen, Active window, Screen Specify whether the new mouse
Current mouse position position will be relative to the top

left corner of the screen, the
foremost window, or the current
mouse position

Move N/A Instant, With animation Instant Specify how to move the mouse
mouse (low speed), With
from animation (normal
previous speed), With animation
position (high speed)

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Can't move mouse in non interactive Indicates a problem moving the mouse in non-
mode interactive mode



Exception Description

Failed to move mouse Indicates a problem moving the mouse

Move mouse to image
Moves the mouse over an image found on screen or on the foreground window.

Input parameters
Argument Optional Accepts Default Description

Value

Image to No List of Images The list of Images to move
move the mouse to
mouse to

Mouse N/A Instant, With animation Instant Specify the style of
movement (low speed), With movement in which the
style animation (normal speed), mouse will move from its

With animation (high previous position to the
speed) beginning of the recorded

route (or to its final position)

Occurrence Yes Numeric value 1 The occurrence of the image
found to move the mouse to

Send a N/A Boolean value False Specify whether to send a
click after click after the mouse is
moving positioned over the image
mouse

Click type N/A Left click, Right click, Left click The mouse click to send to
Double click, Middle click, the image
Left button down, Left
button up, Right button
down, Right button up

Wait for N/A Boolean value True Choose whether you want
image to the action to wait if the
appear image isn't found on the

screen or foreground
window

Fail Yes Numeric value 0 The fail timeout in seconds
timeout



Argument Optional Accepts Default Description
Value

Seconds Yes Numeric value 0 The number of seconds to
before click wait before sending the click

Image N/A Basic, Advanced Basic Which image algorithm to
matching use when searching for
algorithm image

Mouse N/A top left corner, top center, center The section of the image the
position top right corner, middle mouse will be moved to
relative to left part, center, middle
image right part, bottom left

corner, bottom center,
bottom right corner

Offset X No Text value 0 The pixels to offset the
mouse from the position to
the right

Offset Y No Text value 0 The pixels to offset the
mouse from the position
down

Tolerance Yes Numeric value 10 Specify how much the
specified image can differ
from the originally chosen
image

Search for N/A Entire screen, Foreground Entire Specify whether to search for
image on window only screen the specified Image in the

foremost window only, or
the entire visible screen.
Neither choice will find the
image if it isn't clearly visible
on the screen

Search N/A Search whole screen or Search Specify whether to scan the
mode foreground window, whole entire screen (or window) to

Search on specified screen or find the supplied image or
subregion of screen or foreground only a subregion of it
foreground window window

X1 Yes Numeric value The starting X of the
subregion to search in

Y1 Yes Numeric value The starting Y of the
subregion to search in



Argument Optional Accepts Default Description
Value

X2 Yes Numeric value The ending X of the
subregion to search in

Y2 Yes Numeric value The ending Y of the
subregion to search in

Variables produced
Argument Type Description

X Numeric The X coordinate of the point where the image is found on the screen. If
value the image is being searched for on the foreground window, the

coordinate returned is relative to the top left corner of the window

Y Numeric The Y coordinate of the point where the image is found on the screen. If
value the image is being searched for on the foreground window, the

coordinate returned is relative to the top left corner of the window

Exceptions
Exception Description

Image not found on screen Indicates that the specified image wasn't found on the screen

Can't move mouse in non Indicates a problem moving the mouse in non-interactive
interactive mode mode

Failed to move mouse Indicates a problem moving the mouse

Invalid subregion coordinates Indicates that the coordinates of the given subregion were
invalid

Not enough Image occurrences Indicates that not enough occurrences of the specified Image
found on screen were found on the screen

Move mouse to text on screen (OCR)
Moves the mouse over a text found on the screen or on the foreground window using
OCR.

Input parameters



Argument Optional Accepts Default Description
Value

OCR engine No OCR engine variable, Tesseract engine OCR The OCR engine
type engine type to use.

variable Select a
peconfigured
OCR engine or
set up a new
one.

OCR engine No OCREngineObject The OCR engine
variable to search for the

text with

Text to find No Text value The text to move
the mouse over

Is regular N/A Boolean value False Whether to use a
expression regular

expression to
look for the text
on screen

Occurrence Yes Numeric value 1 A positive
number that will
be used as the
occurrence of
the input text on
screen

Search for N/A Entire screen, Foreground window only Entire Whether to look
text on screen for the specified

text in the
foremost
window only or
the entire visible
screen. Neither
choice will find
the text if it isn't
clearly visible on
the screen

Search N/A Whole of specified source, Specific Whole Whether to scan
mode subregion only, Subregion relative to of the entire screen

image specified (or window) to
source find the supplied

text or only a
narrows down
subregion of it



Argument Optional Accepts Default Description
Value

Image(s) No List of Images The image(s)
specifying the
subregion
(relative to the
top left corner of
the image) to
scan for the
supplied text

X1 Yes Numeric value The start X
coordinate of the
subregion to
scan for the
supplied text

Tolerance Yes Numeric value 10 Specify how
much the
image(s)
searched for can
differ from the
originally chosen
image

Y1 Yes Numeric value The start Y
coordinate of the
subregion to
scan for the
supplied text

X1 Yes Numeric value The start X
coordinate of the
subregion
relative to the
specified image
to scan for the
supplied text

X2 Yes Numeric value The end X
coordinate of the
subregion to
scan for the
supplied text



Argument Optional Accepts Default Description
Value

Y1 Yes Numeric value The start Y
coordinate of the
subregion
relative to the
specified image
to scan for the
supplied text

Y2 Yes Numeric value The end Y
coordinate of the
subregion to
scan for the
supplied text

X2 Yes Numeric value The end X
coordinate of the
subregion
relative to the
specified image
to scan for the
supplied text

Y2 Yes Numeric value The end Y
coordinate of the
subregion
relative to the
specified image
to scan for the
supplied text

Move N/A Instant, With animation (low speed), Instant The style of
mouse from With animation (normal speed), With movement in
previous animation (high speed) which the mouse
position will move from

its previous
position to its
final position

Windows N/A Chinese (Simplified), Chinese English The language of
OCR (Traditional), Czech, Danish, Dutch, the text that the
language English, Finnish, French, German, Windows OCR

Greek, Hungarian, Italian, Japanese, engine detects
Korean, Norwegian, Polish, Portuguese,
Romanian, Russian, Serbian (Cyrillic),
Serbian (Latin), Slovak, Spanish,
Swedish, Turkish



Argument Optional Accepts Default Description
Value

Use other N/A Boolean value False Specifies
language whether to use a

language not
given in the
'Tesseract
language' field

Tesseract N/A English, German, Spanish, French, English The language of
language Italian the text that the

Tesseract engine
detects

Language No Text value The Tesseract
abbreviation abbreviation of

the language to
use. For example,
if the data is
'eng.traineddata',
set this
parameter to
'eng'

Language No Text value The path of the
data path folder that holds

the specified
language's
Tesseract data

Image width No Numeric value 1 The width
multiplier multiplier of the

image

Image No Numeric value 1 The height
height multiplier of the
multiplier image

Wait for text N/A Boolean value False Specify whether
to appear to wait if the text

isn't found on
the screen or
foreground
window

Fail if text Yes Numeric value 10 The number of
doesn't seconds to wait
appear for the supplied
within text to appear



Argument Optional Accepts Default Description
Value

Send a click N/A Boolean value False Specify whether
after to send a click
moving after the mouse
mouse is positioned

over the text

Click type N/A Left click, Right click, Double click, Left click The mouse click
Middle click, Left button down, Left type to send to
button up, Right button down, Right the text
button up

Wait before Yes Numeric value 1 The number of
clicking for seconds to wait

before clicking

Mouse N/A Top left, Top center, Top right, Middle Middle Specify which
position left, Middle center, Middle right, center section of the
relative to Bottom left, Bottom center, Bottom text the mouse
text right will be moved to

Offset X No Text value 0 Offset the mouse
from the
position by this
many pixels to
the right

Offset Y No Text value 0 Offset the mouse
from the
position by this
many pixels
down

Image N/A Basic, Advanced Basic Which image
matching algorithm to use
algorithm when searching

for image

７ Note

Power Automate's regular expression engine is .NET. To find more information
about regular expressions, go to Regular Expression Language - Quick Reference.

Variables produced



Argument Type Description

LocationOfTextFoundX Numeric The X coordinate of the point where the text is found on the
value screen. If the text is searched for in the foreground window,

this coordinate is relative to the top left corner of the window

LocationOfTextFoundY Numeric The Y coordinate of the point where the text is found on the
value screen. If the text is searched for in the foreground window,

this coordinate is relative to the top left corner of the window

WidthOfTextFound Numeric The width of the area the text was found on
value

HeightOfTextFound Numeric The width of the area the text was found on
value

Exceptions
Exception Description

Text not found on screen Indicates that the specified text couldn't be found on
the screen

Can't move mouse in non interactive Indicates a problem moving the mouse in non-
mode interactive mode

Failed to move mouse Indicates a problem moving the mouse

Invalid subregion coordinates Indicates that the coordinates of the given subregion
were invalid

Failed to create the OCR engine Indicates an error occurred while trying to create the
OCR engine

Data path folder doesn't exist Indicates that the folder specified for the language
data doesn't exist

The selected Windows language pack Indicates that the selected Windows language pack
isn't installed on the machine hasn't been installed on the machine

OCR engine isn't alive Indicates that the OCR engine isn't alive

Send mouse click
Sends a mouse click event.

） Important



To prevent unauthorized access, Power Automate needs to run with the same or
higher privileges as the applications it automates. To use the Send mouse click
action to interact with applications that run with elevated privileges, run Power
Automate as administrator. You can find more information regarding running
Power Automate as an administrator in Run Power Automate with elevated rights.

Input parameters
Argument Optional Accepts Default Description

Value

Mouse N/A Left click, Right click, Double Left Specify what form of mouse
event to click, Middle click, Left click event to send
send button down, Left button up,

Right button down, Right
button up

Wait Yes Numeric value 0 The time to delay before
sending the mouse event in
1/1000 of a second

Move N/A Boolean value False Move mouse
mouse

X No Numeric value The horizontal (X) position of
the mouse in pixel
coordinates

Y No Numeric value The vertical (Y) position of the
mouse in pixel coordinates

Relative to N/A Screen, Active window, Screen Specify whether the new
Current mouse position mouse position will be relative

to the top left corner of the
screen, the foremost window,
or the current mouse position

Mouse N/A Instant, With animation (low Instant The style of movement in
movement speed), With animation which the mouse will move
style (normal speed), With from its previous position to

animation (high speed) the beginning of the recorded
route (or to its final position)

Variables produced
This action doesn't produce any variables.



Exceptions
Exception Description

Can't send mouse click in non Indicates a problem sending a mouse click in non-
interactive mode interactive mode

Mouse click out of screen bounds Indicates that the mouse click was out of the screen
bounds

Failed to send mouse click Indicates a problem sending a mouse click

Send keys
Sends keys to the application that is currently active.

） Important

To prevent unauthorized access, Power Automate needs to run with the same or
higher privileges as the applications it automates. To use the Send keys action to
interact with applications that run with elevated privileges, run Power Automate as
administrator. To find more information regarding running Power Automate as an
administrator, go to Run Power Automate with elevated rights.

Input parameters
Argument Optional Accepts Default Description

Value

Send keys N/A Foreground window, Foreground Specify whether to send the
to By UI element, By window keys to the foreground window

window or to a UI element or to a
instance/handle, By window instance or a
title and/or class combination of window

title/class

Text to No Direct encrypted input The text to send to the
send or Text value application

Delay Yes Numeric value 10 Specify the delay in milliseconds
between between sending keystrokes to
keystrokes avoid input errors



Argument Optional Accepts Default Description
Value

Send Text N/A Boolean value False Emulate the actual keystrokes
as on keyboard when sending
hardware whole Text
keys

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Can't send keystrokes in non interactive Indicates a problem sending keystrokes in non-
mode interactive mode

Text to send doesn't represent valid Indicates that the text given doesn't represent valid
keystrokes keystrokes

There isn't an active application to send Indicates that there isn't an active application to send
keystrokes to keystrokes to

Failed to send keystrokes Indicates a problem sending keystrokes

７ Note

To simulate a physical key being pressed inside a Send keys action, use the curly
brackets {} notation. To use a key as a modifier, use the curly brackets {} notation
for both keys. The Send keys action accepts the Virtual-Key Codes.

Valid keys
Category Keys

Buttons LButton, RButton, Cancel, MButton, XButton1, XButton2

Keyboard Back, Tab, LineFeed, Clear, Enter, Return, ShiftKey, ControlKey,Menu, Pause,
Control CapsLock, Capital, Escape, Space, Prior, PageUp, PageDown, Next, End, Home, Left,

Up, Right, Down, Select, Print, Execute, Snapshot, PrintScreen, Insert, Delete, Help



Category Keys

Buttons HangulMode, HanguelMode, KanaMode, JunjaMode, FinalMode, KanjiMode,
HanjaMode

IME keys IMEConvert, IMENonconvert, IMEAccept, IMEAceept, IMEModeChange

Browser BrowserSearch, BrowserFavorites, BrowserHome
keys

Volume VolumeMute, VolumeDown, VolumeUp
keys

Media MediaNextTrack, MediaPreviousTrack, MediaStop, MediaPlayPause
keys

Buttons LaunchMail, SelectMedia, LaunchApplication1, LaunchApplication2

OEM keys OemSemicolon, Oem1, Oemplus, Oemcomma, OemMinus, OemPeriod, Oem2,
OemQuestion, Oem3, Oemtilde, Oem4, OemOpenBrackets, OemPipe, Oem5,
OemCloseBrackets, Oem6, OemQuotes, Oem7, Oem8, Oem102, OemBackslash,
OemClear

Buttons ProcessKey, Packet, Attn, Crsel, Exsel, EraseEof, Play, Zoom, NoName, Pa1

Buttons KeyCodem, Shift, Control, Alt, Modifiers

D keys D0, D1, D2, D3, D4, D5, D6, D7, D8, D9

Letters A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z

Windows LWin, RWin, Apps, Sleep
keys

NumPad NumPad0, NumPad1, NumPad2, NumPad3, NumPad4, NumPad5, NumPad6,
keys NumPad7, NumPad8, NumPad9

Calculation Multiply, Add, Separator, Subtract, Decimal, Divide
keys

Function F1, F2, F3, F4, F5, F6, F7, F8, F9, F10, F11, F12, F13, F14, F15, F16, F17, F18, F19, F20,
keys F21, F22, F23, F24

Buttons NumLock, Scroll, LShiftKey, RShiftKey, LControlKey, RControlKey, LMenu, RMenu,
BrowserBack, BrowserForward, BrowserRefresh, BrowserStop

Press/release key
Presses (and holds) or releases one or more modifier keys (Alt, Control, or Shift).



Input parameters
Argument Optional Accepts Default Description

Value

Action to N/A Press, Press Specify whether to press or release keys with
perform Release this action

Control N/A Boolean False Specify whether the Ctrl key will be
value pressed/released or not

Alt N/A Boolean False Specify whether the Alt key will be
value pressed/released or not

Shift N/A Boolean False Specify whether the Shift key will be
value pressed/released or not

Win N/A Boolean False Specify whether the Windows key will be
value pressed/released or not

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Can't press or release key in non Indicates a problem pressing or releasing the key in non-
interactive mode interactive mode

Set key state
Sets the state (on or off) for the keys Caps Lock, Num Lock or Scroll Lock

Input parameters
Argument Optional Accepts Default Description

Value

Key N/A Caps Lock, Num Lock, Caps Lock Specify the key to set
Scroll Lock



Argument Optional Accepts Default Description
Value

State N/A Off, On On Whether to set the key state to
on or off

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Can't set key state in non interactive Indicates a problem setting the key state in non
mode interactive mode

Wait for mouse
Suspends the execution of the flow until the mouse pointer changes, usually to or from
the 'wait cursor' or hourglass.

Input parameters
Argument Optional Accepts Default Description

Value

Wait for N/A Become, Become not Become Choose what action of
mouse the mouse cursor to wait
pointer to for.

Mouse N/A Arrow, App starting, Cross, Arrow Specify the mouse
pointer Hand, Help, IBeam, Wait pointer state.

cursor

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.



Get keyboard identifier
Retrieves the active keyboard identifier from the machine's registry.

Input parameters
This action doesn't require any input.

Variables produced
Argument Type Description

KeyboardLayoutId Numeric value The registry key of the active keyboard identifier

Exceptions
Exception Description

Keyboard identifier wasn’t found Indicates an error while retrieving the keyboard identifier

Wait for shortcut key
Pause the flow run until a specific shortcut key is pressed. Shortcut keys must contain at
least one key or a key and one of (ctrl, alt, shift). Multiple shortcut keys can be defined.

Input parameters
Argument Optional Accepts Default Description

Value

Shortcut N/A Keys Ctrl + A Specify the shortcut keys to wait for. Shortcut
keys combination keys must contain exactly one key or a key and

a combination of (ctrl, alt, shift). To add more
than one shortcut key, select 'New shortcut
key'

Continue N/A Boolean False Specify whether the flow run will continue
flow run value anyway when the set period of time waiting
on for the shortcut key expires
timeout



Argument Optional Accepts Default Description
Value

Continue Yes Numeric 10 The time in seconds before continuing the
after value flow run

Variables produced
Argument Type Description

IndexOfShortcutKeyPressed Numeric The index of the shortcut key if the shortcut keys are
value in a list format.

Exceptions
Exception Description

Shortcut key failed to register Indicates that a shortcut key failed to register.



Clipboard actions
Article • 12/16/2022

Use the Clipboard actions to manipulate or extract the contents of your machine's
clipboard.

To retrieve the contents of the clipboard and store them in a variable, use the Get
clipboard text action.

To change the text of the clipboard, use the Set clipboard text action. The following
example uses a variable to set the current date and time on the clipboard.

To clear the clipboard, use the Clear clipboard contents action.

Get clipboard text
Gets clipboard text.

Input parameters
This action doesn't require any input.



Variables produced
Argument Type Description

ClipboardText Text value The text stored in the clipboard

Exceptions
Exception Description

Can't retrieve clipboard contents Indicates a problem retrieving clipboard contents

Set clipboard Text
Sets clipboard text.

Input parameters
Argument Optional Accepts Default Value Description

Clipboard text No Text value The text to set to the clipboard

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Can't set clipboard contents Indicates a problem setting clipboard contents

Clear clipboard contents
Clears clipboard contents.

Input parameters
This action doesn't require any input.



Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.



Text actions
Article • 01/19/2024

Text actions enable you to handle, manipulate, and convert text values in your desktop
flows.

To merge a list of text values and create a single value, use the Join text action. The
action requires you to specify the list and a delimiter.

To split a single text value into a list, deploy the Split text action, and specify the text
value and the delimiters to separate the list items.

To replace a subtext in a text, use the Replace text action. The following example
replaces the text Product Characteristics with Characteristics.

Search a text value inside another text with the Parse text action.



Some text actions allow you to use regular expressions. For example, you can enable Is
regular expression in the Parse text action to search for a text specified by a regular
expression. To find more information about regular expressions, go to Regular
Expression Language - Quick Reference.

Additionally, you can disable First occurrence only to make the action return a list with
the positions of all the matched texts.

The following example searches all the words in Items detected in Stock starting with a
capital letter. The produced list named Matches stores the values Items and Stock. The
Positions list stores the positions in which the values were found (1 and 18).

Besides searching in texts, Power Automate enables you to crop text values from texts
using the Crop text action. You can define the text to crop using flags that are the first
occurring given character or string markers. You can crop values before, after, or
between the specified text flag(s).

The CroppedText variable stores the cropped text, while you can use the IsFlagFound
variable to check if the action found the set flags.



To ensure that numbers are stored as numerical values, use the Convert text to number
action. To perform the reverse conversion, use Convert number to text.

Similarly, you can use the Convert text to datetime and Convert datetime to text
actions to ensure that dates are correctly formatted.

Use the Recognize entities in text action
Desktop flows enable you to extract various entities from texts in natural language, such
as numbers, dates, and measurement units, through the Recognize entities in text
action.



The Recognize entities in text action gets a text or a variable containing text and
returns a data table containing the results. Each entity returns different results based on
its structure, but all the data tables contain an Original text field that stores the entity
part of the input text.

The following table displays various examples of entities that the Recognize entities in
text action can recognize.

ﾉ Expand table

Entity Input text Returned values

Date time I'll go back 04th Jan 2019 Value: 1/4/2019 12:00:00 AM
Original text: 04th Jan 2019

Date time Schedule a meeting tonight at 7pm Value: 9/30/2021 7:00:00 PM
Original text: tonight at 7pm

Dimension You weight 200 lbs Value: 200
Unit: Pound
Original text: 200 lbs

Dimension Α twister roared through an area about Value: 10
10 miles long there Unit: Mile



Entity Input text Returned values

Original text: ten miles

Temperature The temperature outside is 40 deg Value: 40
celsius Unit: C

Original text: 40 deg celsius

Currency Net interest income sank 27 percent in Value: 254000000
the quarter to /$ 254 million Unit: Dollar

Original text: $ 254 million

Number This number is larger than 20 and less or From: 20
range equal than 35 To: 35

Original text: larger than 20 and less
or equal than 35

Number From 5 to 10 From: 5
range To: 10

Original text: From 5 to 10

Number Less than 4.565 From: 0
range To: 4.565

Original text: Less than 4.565

Number A dozen Value: 12
Original text: A dozen

Number Two thirds Value: 0.666666666666667
Original text: Two thirds

Ordinal I like the first two books Value: 1
Original text: first

Ordinal Eleventh Value: 11
Original text: Eleventh

Percentage 100 percent Value: 100
Original text: 100 percent

Phone Tel: +1 209-555-0100 Value: +1 209-555-0100
number Original text: +1 209-555-0100

Email felix@contoso.com Value: felix@contoso.com
Original text: felix@contoso.com

IP address My PC IP address is 1.1.1.1 Value: 1.1.1.1
Original text: 1.1.1.1

Mention @Alice Value: @Alice
Original text: @Alice



Entity Input text Returned values

Hashtag #News Value: #News
Original text: #News

URL www.microsoft.com Value: www.microsoft.com
Original text: www.microsoft.com

GUID 123e4567-e89b-12d3-a456- Value: 123e4567-e89b-12d3-a456-
426655440000 426655440000

Original text: 123e4567-e89b-12d3-
a456-426655440000

Quoted text Enter the value in the "value" field Value: "value"
Original text: "value"

７ Note

The Recognize entities in text action supports 14 different languages. However,
some entities may not be available for specific languages. To find more information
about language restrictions, go to Microsoft Recognizers Text - Supported entities
across cultures .

Append line to text
Appends a new line of text to a text value.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

Original text No Text value The original text

Line to append Yes Text value The text to add on as a new line

Variables produced

ﾉ Expand table



Argument Type Description

Result Text value The new text

Exceptions
This action doesn't include any exceptions.

Get subtext
Retrieve a subtext from a text value.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Original text No Text value The text to retrieve a section of text
from

Start index N/A Start of text, Character Specify how to find the starting point
Character position for text retrieval
position

Character No Numeric value The position of the first character to
position retrieve. This value is a zero-based

index, counting from zero for the first
character

Length N/A End of text, Number of Specify whether the subtext continues
Number of chars to the end of the text, or includes only
chars a certain number of characters

Number of No Numeric value The number of characters to retrieve
chars

Variables produced

ﾉ Expand table



Argument Type Description

Subtext Text value The retrieved subtext

Exceptions

ﾉ Expand table

Exception Description

Start index or length are out of range Indicates that the start index or length are out of range

Crop text
Retrieves a text value that occurs before, after or between the specified text flag(s) in a
given text.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Original No Text value The text to retrieve a
text section of text from

Mode N/A Get text before the Get text Specify whether to
specified flag, Get text after before the retrieve the text before,
the specified flag, Get text specified flag after, or between flags.
between the two specified
flags

Start flag No Text value The retrieved text will be
after this flag. The flag
can be any character or
text

End flag No Text value The retrieved text will be
before this flag. The flag
can be any character or
text

Ignore N/A Boolean value False Specify whether to find
case the flags using case-



Argument Optional Accepts Default Description
Value

sensitive or case-
insensitive matching

Variables produced
ﾉ Expand table

Argument Type Description

CroppedText Text value The new cropped text

IsFlagFound Boolean value Indicates if flag(s) found or not

Exceptions
This action doesn't include any exceptions.

Pad text
Creates a fixed length text by adding characters to the left or to the right of an existing
text.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Text to pad Yes Text value The text to lengthen

Pad N/A Left, Left Specify whether to add characters to the left
Right or right of the existing text

Text for Yes Text value The character or text that will be added to
padding lengthen the original text

Total length Yes Numeric 10 The total character length of the final padded
value text. The text for padding will be repeatedly

added until the final text is of the specified
length



Variables produced

ﾉ Expand table

Argument Type Description

PaddedText Text value The new, padded text

Exceptions
This action doesn't include any exceptions.

Trim text
Removes all occurrences of white space characters (such as space, tab, or new line) from
the beginning and/or end of an existing text.

The Trim text action receives a text value as an input and produces a text output
according to the What to trim parameter. The available options of the What to trim
parameter are the following:

whitespace characters from the beginning
whitespace characters from the end
whitespace characters from the beginning and end

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

Text to Yes Text value Text to trim
trim

What to N/A whitespace characters from whitespace Specify where
trim the beginning, whitespace characters from white space

characters from the end, the beginning characters will be
whitespace characters from and end removed from
the beginning and end

Variables produced



ﾉ Expand table

Argument Type Description

TrimmedText Text value The new trimmed text

Exceptions
This action doesn't include any exceptions.

Reverse text
Reverses the order of letters in a text string.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Value Description

Text to reverse No Text value The text to reverse

Variables produced

ﾉ Expand table

Argument Type Description

ReversedText Text value The new reversed text

Exceptions
This action doesn't include any exceptions.

Change text case
Changes the casing of a text to uppercase, lowercase, title case or sentence case.

Input parameters



ﾉ Expand table

Argument Optional Accepts Default Description
Value

Text to Yes Text value The text to convert
convert

Convert to N/A Upper case, Lower case, Title Upper case Specify the text case
case, Sentence case style to use

Variables produced
ﾉ Expand table

Argument Type Description

TextWithNewCase Text value The new converted text

Exceptions
This action doesn't include any exceptions.

Convert text to number
Converts a text representation of a number to a variable that contains a numeric value.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Text to No Text A text variable containing only a number, to
convert value convert to a numeric value variable. Spaces are

ignored, but non-number text throws an
exception

Variables produced

ﾉ Expand table



Argument Type Description

TextAsNumber Numeric value The new numeric value

Exceptions

ﾉ Expand table

Exception Description

Provided text value can't be converted Indicates that the provided text value can't be
into a valid number converted into a valid number

Convert number to text
Converts a number to text using a specified format.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Number to No Numeric A numeric value to convert to text
convert value

Decimal Yes Numeric 2 The number of decimal places that will be
places value included before truncation. Zeros can also

be added to the end to pad the text in this
way

Use N/A Boolean True Specify whether or not to use punctuation
thousands value as a 1000 separator
separator

Variables produced

ﾉ Expand table

Argument Type Description

FormattedNumber Text value The formatted number as text



Exceptions
This action doesn't include any exceptions.

Convert text to datetime
Converts a text representation of a date and/or time value to a datetime value.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Text to convert No Text The text to convert to a datetime value.
value This text must be in a recognizably

datetime value format

Date is N/A Boolean False Specify whether the text to convert
represented in value contains a representation of the date and
custom format time in a nonstandard, nonrecognizable

format

Custom format No Text The format in which the date is stored in
value the text. A custom format can be

expressed as, for example, yyyyMMdd for
date and hhmmss for time

Variables produced

ﾉ Expand table

Argument Type Description

TextAsDateTime Datetime The datetime value

Exceptions

ﾉ Expand table



Exception Description

Provided text value can't be converted Indicates that the provided text value can't be
into a valid datetime converted into a valid datetime

Convert datetime to text
Converts a datetime value to text using a specified custom format.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Datetime to No Datetime The datetime value to
convert convert to text

Format to N/A Standard, Custom Standard Specify whether to use a
use standard datetime format,

or create a custom one

Custom No Text value The custom format to
Format display the datetime value

in. A datetime can be
expressed as, for example,
MM/dd/yyyy for date and
hh:mm:sstt for time

Standard N/A Short date, Long date, Short Short The standard datetime
format time, Long time, Full date format the action uses to

datetime (short time), Full display the datetime value
datetime (long time),
General datetime (short
time), General datetime
(long time), Sortable
datetime

Variables produced
ﾉ Expand table



Argument Type Description

FormattedDateTime Text value The formatted datetime as a text value

Exceptions
This action doesn't include any exceptions.

Create random text
Generates a text of specified length consisting of random characters. This action can be
useful for generating passwords.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Use uppercase N/A Boolean True Specify whether uppercase characters will
letters (A-Z) value be included in the generated text

Use lowercase N/A Boolean True Specify whether lowercase characters will
letters (a-z) value be included in the generated text

Use digits (0-9) N/A Boolean True Specify whether digits will be included in
value the generated text

Use symbols ( , . N/A Boolean True Specify whether symbols will be included
< > ? ! + - _ # $ value in the generated text
^ )

Minimum length Yes Numeric 6 The minimum length of the random text.
value For a certain length of text, set the

minimum and maximum values to that
number

Maximum length Yes Numeric 10 The maximum length of the random text.
value For a certain length of text, set the

minimum and maximum values to that
number

Variables produced



ﾉ Expand table

Argument Type Description

RandomText Text value The generated random text

Exceptions
This action doesn't include any exceptions.

Join text
Converts a list into a text value by separating its items with a specified delimiter.

To join all contents of a list into a single text value, use the Join text action. Begin by
specifying the respective list to use in the Specify list to join property. You can choose
the delimiters to separate the list items in the joined text by making the respective
choice in the Delimiter to separate list items property dropdown list:

None creates a single, joined literal by combining all the items in the list without
separating them with a delimiter.
Standard allows you to set the delimiter as a space, tab, or new line by selecting
the respective option in the Standard delimiter property dropdown list. You can
also choose how many times the delimiter is presented between each list item by
modifying the Times property.
Custom allows you to set your own delimiter.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Specify the list to No List of Text The list to convert to text
join values

Delimiter to N/A None, None Specify whether to use no
separate list items Standard, delimiter, a standard delimiter or a

Custom custom one

Custom delimiter No Text value The character(s) to use as delimiter



Argument Optional Accepts Default Description
Value

Standard N/A Space, Tab, Space Specify the delimiter to use
delimiter New line

Times Yes Numeric value 1 Specify how many times to use the
specified delimiter

Variables produced

ﾉ Expand table

Argument Type Description

JoinedText Text value The new delimited text

Exceptions
This action doesn't include any exceptions.

Split text
Creates a list containing the substrings of a text that are separated by a specified
delimiter or a regular expression.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

The text to No Text value The text to split
split

Delimiter N/A Standard, Standard Whether the used delimiter is of a standard
type Custom or custom format

Custom No Text value The character(s) that were used as a
delimiter delimiter

Standard N/A Space, Tab, Space The delimiter used
delimiter New line



Argument Optional Accepts Default Description
Value

Times Yes Numeric 1 Specify how many times the delimiter is
value used

Is regular N/A Boolean False Specify whether the delimiter will be a
expression value regular expression. A regular expression

creates a range of possibilities for the
delimiter. For example, '\d' means that the
delimiter could be any digit

７ Note

Power Automate's regular expression engine is .NET. To find more information
about regular expressions, go to Regular Expression Language - Quick Reference.

Variables produced
ﾉ Expand table

Argument Type Description

TextList List of Text values The new list

Exceptions

ﾉ Expand table

Exception Description

Provided regular expression is invalid Indicates that the provided regular expression is invalid

Parse text
Parses a text to find the first or all occurrences of a specified subtext or a regular
expression pattern.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Text to Parse No Text value The text to parse

Text to Find No Text value The subtext or a regular expression to
search for

Is regular N/A Boolean False Specify whether the subtext is a regular
expression value expression. For example \d means that the

subtext could be any digit

Start Parsing No Numeric The position to start looking for the 'Text
at Position value to Find'. The first position is zero, so use 0

to start from the beginning

First N/A Boolean True Specify whether to find the first occurrence
occurrence value only, or each occurrence of the 'Text to
only find'

Ignore case N/A Boolean False Specify whether to find the specified text
value using case-sensitive or case-insensitive

matching

７ Note

Power Automate's regular expression engine is .NET. To find more information
about regular expressions, go to Regular Expression Language - Quick Reference.

Variables produced
ﾉ Expand table

Argument Type Description

Position Numeric value The position of the 'Text to find' into the 'Text to parse'. If the text
isn't found within the original text, this variable will hold the value
-1

Positions List of The positions of the 'Text to find' into the 'Text to parse'. If the text
Numeric isn't found within the original text, this variable will hold the value
values -1

Match Text value The result that matches the given regular expression

Matches List of Text The results that match the given regular expression
values



Exceptions

ﾉ Expand table

Exception Description

Provided regular expression is invalid Indicates that the provided regular expression is invalid

Replace text
Replaces all occurrences of a specified subtext with another text. It can also be used with
regular expressions.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Text to parse No Text The text to parse
value

Text to find No Text The subtext or a regular expression to
value search for

Use regular N/A Boolean False Specify whether the subtexts are regular
expressions for value expressions. A regular expression creates a
find and replace range of possibilities for the subtext. For

example, '\d' means that the subtext could
be any digit

Ignore case N/A Boolean False Specify whether to find the subtext to
value replace using case-sensitive or case-

insensitive matching

Replace with No Text The text or a regular expression to replace
value found text

Activate escape N/A Boolean False Specify whether to use special sequences.
sequences value For example, '\t' in the replacement text

will be interpreted as a tab

７ Note



Power Automate's regular expression engine is .NET. To find more information
about regular expressions, go to Regular Expression Language - Quick Reference.

Variables produced

ﾉ Expand table

Argument Type Description

Replaced Text value The new updated text

Exceptions
This action doesn't include any exceptions.

Escape text for regular expression
Escapes a minimal set of characters (, *, +, ?, |, {, [, (,), ^, $,., #, and white space) by
replacing them with their escape codes.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Value Description

Text to escape No Text value The text to escape

Variables produced

ﾉ Expand table

Argument Type Description

EscapedText Text value The escaped text

Exceptions
This action doesn't include any exceptions.



Recognize entities in text
Recognizes entities in text, such as numbers, units, data/time and others expressed in
natural language across multiple languages.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Text to No Text value The text to
recognize recognize entities
from from

Entity type N/A Date time, Dimension, Temperature, Date The type of entity
Currency, Number range, Number, time to recognize (, Date
Ordinal, Percentage, Phone number, time, Email, URL
Email, IP address, Mention, Hashtag, etc.)
URL, GUID, Quoted text

Language N/A English, Chinese (Simplified), Spanish, English Specify the
Spanish (Mexico), Portuguese, language of the
French, German, Italian, Japanese, text
Dutch, Korean, Swedish, Turkish,
Hindi

Variables produced

ﾉ Expand table

Argument Type Description

RecognizedEntities Datatable The recognized entities

Exceptions
This action doesn't include any exceptions.

Create HTML content
Generates rich HTML content and stores it in a variable.



This action allows users to create HTML content in a formatted and intuitive way, which
is stored in a text variable. This variable can then be used in following actions, where
HTML format is needed.

This functionality primarily serves the email sending actions ‘Send email’, ‘Send
Exchange email message’, and ‘Send email message through Outlook’ regarding their
‘Body’ input parameter. Specifically, the produced variable can be used as is in the
‘Body’ parameter of an email sending action that follows later in the flow, while the
Body is HTML option is enabled.

Input parameters
Input parameters are configured through the embedded HTML editor.

The initial view of the HTML editor allows out-of-the-box editing on the rendered HTML
content, providing a set of formatting options through a toolbar found at the top,
including the ability to insert links, images (via local paths or URLs) and tables, and even
variables for dynamic content.



Enabling the Text editor option switches to the view where HTML language can be used
including the corresponding element tags.

The <head> and <body> elements aren't needed in the text editor for the HTML
content to be rendered.

Variables produced

ﾉ Expand table

Argument Type Description

HtmlContent Text value The HTML code

Exceptions
This action doesn't include any exceptions.



Date time actions
Article • 11/14/2023

Use the Get current date and time action to retrieve the current date and time (or date
only, if selected) and store it in a variable. The date format depends on the Windows
configuration. To find more information about the syntax of date and time values, go to
Variable data types.

To add various time units to date variables, deploy the Add to datetime action.

To calculate the difference between two dates, use the Subtract dates action. You can
retrieve the difference in seconds, minutes, hours, or days.

Add to datetime
Adds (or subtracts) a specific number of seconds, minutes, hours or days to a datetime
value.

Input parameters



Argument Optional Accepts Default Description
Value

Datetime No Datetime The datetime value to alter

Add No Numeric value The numeric value to add. To subtract a
time, the value should be negative. For
example, add -7 days here to go back
one week

Time unit N/A Seconds, Seconds The time unit the time to add
Minutes, Hours, represents
Days, Months,
Years

Variables produced
Argument Type Description

ResultedDate Datetime The new, altered datetime value

Exceptions
This action doesn't include any exceptions.

Subtract dates
Finds the time difference between two given dates in days, hours, minutes, or seconds.

To subtract a given date from another one use the Subtract dates action. Input a valid
date in the From date property to use as a base to subtract the other date from. Then
populate the Subtract date property to calculate the difference. Make sure to use a valid
Datetime  type of variable here (to create one use the Get current date and time action).
You can specify how the returned difference should be represented (in days/ hours/
minutes/ seconds) by selecting the respective option in the Get difference in property.

Input parameters
Argument Optional Accepts Default Description

Value

From date No Datetime The datetime to subtract the first
datetime from. This will be the base



Argument Optional Accepts Default Description
Value

datetime, so generally put the later
date/time in this attribute

Subtract No Datetime The datetime to subtract
date

Get N/A Seconds, Days The unit of time to express the difference
difference Minutes, in
in Hours, Days

Variables produced
Argument Type Description

TimeDifference Numeric value The difference in time as a numeric value

Exceptions
This action doesn't include any exceptions.

Get current date and time
Retrieves the current date or the current date and time.

Input parameters
Argument Optional Accepts Default Value Description

Retrieve N/A Current date and Current date and Specify whether to get
time, Current date time the date and time, or
only just the date. If the

latter is chosen, the
time value will be stored
as midnight (0:00:00)

Time zone N/A System time zone, System time zone Specify whether to use
Specific time zone the system's time zone
(to be or select a specific one
deprecated), or set up a time zone
Windows time manually
zone, Custom
input



Argument Optional Accepts Default Value Description

Country/region No Text value Europe/Bucharest The country/region to
get the time of or add a
numeric value as the
hours that will be added
in the UTC time zone

Windows time No Available Windows (UTC) Coordinated Specify the
zone time zones Universal Time country/region to

obtain the time zone
from

Input Type No Offset, Windows Offset Choose whether to set
time zone the offset via a numeric

value or by providing a
Windows format time
zone

Offset No Numeric value N/A Specify the number of
hours the offset is going
to be. Time format is
UTC.

Time zone No Text value N/A Specify the time zone
(Windows time zone)

Variables produced
Argument Type Description

CurrentDateTime Datetime The current datetime value

Exceptions
Exception Description

Failed to get current date and Indicates that there was a problem retrieving the current date
time and time

Specified country/region not Indicates that the specified country or region wasn't found
found



PDF actions
Article • 10/31/2023

PDF actions enable you to extract images, text, and tables from PDF files, and arrange
pages to create new documents.

To extract text from a PDF file, use the Extract text from PDF action. The following
example extracts text from a specific range of pages of a password-protected file. The
password is specified in the Advanced settings.

To extract texts arranged in a tabular form, enable Optimize for structured data to
improve the results' format and accuracy.

To extract tables from a PDF file, deploy the Extract tables from PDF action, select the
file, and specify the pages to extract from.



The action produces the ExtractedPDFTables variable that contains a list of PDF table
info. To find information about this type of list, go to Advanced data types.

７ Note

The Extract tables from PDF action doesn't use Optical Character Recognition
(OCR), so you can't extract non-copyable text from scanned PDFs.
The library behind the action occasionally extracts additional PDF data that
aren't tables. This functionality minimizes the risk of accidentally omitting a
real table.

Apart from extracting information from PDF files, you can create a new PDF document
from an existing file using the Extract PDF file pages to new PDF file action.

The following example selects a combination of specific pages and a range of pages.



Extract text from PDF
You can extract text from a PDF file by using the "Extract text from PDF" action. In the
action properties you can define the source PDF file and the pages that text should be
extracted from. Under the advanced action properties you can define a password in case
the PDF file is protected and if the engine should optimize for structured data or not.

Input parameters
Argument Optional Accepts Default Description

Value

PDF file No File The PDF file to extract text from.
Enter a file path, a variable
containing a file or a text path

Page(s) to N/A All, Single, Range All Specifies how many pages to
extract extract: All pages, a single page or

a range of pages



Argument Optional Accepts Default Description
Value

Single page No Numeric value The number of the single page to
number extract text from

From page No Numeric value The first page number from the
number range of pages to extract text from

To page No Numeric value The last page number from the
number range of pages to extract text from

Password Yes Direct encrypted The password of the PDF file.
input or Text Leave this blank if the PDF isn't
value password protected

Optimize for N/A Boolean value False Specify whether to detect
structured data formatted layout in the document

and extract text accordingly

Variables produced
Argument Type Description

ExtractedPDFText Text value The extracted text

Exceptions
Exception Description

PDF file doesn't exist File doesn't exist on the given path

Invalid password The given password is invalid

Failed to extract text Error while trying to extract text

Extract tables from PDF
You can extract tables that are contained in a PDF file by using the Extract tables from
PDF action. In the action properties you can define the PDF file and the range of pages
that the tables will be extracted from. Under the advanced action properties you can
define a password in case a the PDF file is protected, define if the table has headers or
not, and finally if tables that cross page margins should be merged or not.



Input parameters
Argument Optional Accepts Default Description

Value

PDF file No File The PDF file to extract tables
from. Enter a file path, a variable
containing a file or a text path

Page(s) to extract N/A All, Single, All Specifies how many pages to
Range extract tables from: all pages, a

single page or a range of pages

Single page No Numeric value The number of the single page to
number extract tables from

From page No Numeric value The first page number from the
number range of pages to extract tables

from

To page number No Numeric value The last page number from the
range of pages to extract tables
from

Password Yes Direct encrypted The password of the PDF file.
input or Text Leave this blank if the PDF isn't
value password protected

Merge tables that N/A Boolean value True Specifies whether to merge tables
cross page that cross page margins in the
margins specified page range

First line contains N/A Boolean value True Specifies whether the first line of
column names table contains column names

Variables produced
Argument Type Description

ExtractedPDFTables List of PDF table info The extracted tables with their info as a list

Exceptions
Exception Description

PDF file doesn't exist File doesn't exist on the given path



Exception Description

Invalid password The given password is invalid

Failed to extract tables Error while trying to extract tables

Extract images from PDF
To extract images from a PDF file you can use the Extract images from PDF action. In
the action parameters you can define the PDF file and the pages to extract images from,
the naming convention of the extacted images and the target location of the saved
images. You can also define a password if the PDF file is protected under the advanced
settings.

Input parameters
Argument Optional Accepts Default Description

Value

PDF file No File The PDF file to extract images from.
Enter a file path, a variable containing
a file or a text path

Password Yes Direct encrypted The password of the PDF file. Leave
input or Text this blank if the PDF isn't password
value protected

Page(s) to N/A All, Single, All Specifies how many pages to extract:
extract Range All pages, a single page or a range of

pages

Single page No Numeric value The number of the single page to
number extract images from

From page No Numeric value The first page number from the range
number of pages to extract images from

To page No Numeric value The last page number from the range
number of pages to extract images from

Image(s) No Text value How the name of the image(s) starts.
name Extracted image(s) name example:

GivenName_1, GivenName_2

Save No Folder The folder to save the extracted
image(s) to images as png files



Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Invalid password The given password is invalid

Failed to extract Indicates that an error occurred while extracting images from the given
images pages of the PDF

Folder doesn't exist Indicates that the folder doesn't exist

PDF file doesn't exist File doesn't exist on the given path

Extract PDF file pages to new PDF file
You can create a new PDF file by extracting pages from an existing PDF file by using the
PDF file pages to a new PDF file action. In the action parameters you can define the
PDF file to extract the pages from, the page(s) to be extracted, the location of the new
PDF file and what should happen if a file with the same name and extension already
exists. Finally, under the advanced properties you can define a password in case the
source PDF is protected.

Input parameters
Argument Optional Accepts Default Description

Value

PDF file No File The PDF file to extract pages
from. Enter a file path, a variable
containing a file or a text path

Password Yes Direct encrypted The password of the PDF file.
input or Text value Leave this blank if the PDF isn't

password protected

Page No Text value The index numbers of the pages
selection to keep (for example, 1,3,17-24)

Extracted No File The path to store the extracted
PDF path PDF file



Argument Optional Accepts Default Description
Value

If file exists N/A Overwrite, Don't Add Specifies what to do in case the
overwrite, Add sequential output PDF file already exists
sequential suffix suffix

Variables produced
Argument Type Description

ExtractedPDF File The new PDF file

Exceptions
Exception Description

Invalid password The given password is invalid

PDF file doesn't exist File doesn't exist on the given path

Page out of bounds Indicates that one or more pages are out of bounds of the PDF file

Invalid page selection Indicates that the given pages aren't valid for the PDF file

Failed to extract new PDF Indicates that an error occurred while trying to extract new PDF

Merge PDF files
Merges multiple PDF files into a new one.

You can use the Merge PDF files action to take two or more PDF files and merge them
into a single file. The files to be merged can be provided either in the form of a list, or
enclosed in double quotes and separated by a delimiter. You can also provide
passwords for the PDF files, in case they are password-protected.

Input parameters
Argument Optional Accepts Default Description

Value

PDF files No List of Files The files to merge. Enclose multiple
files in double quotes (") and



Argument Optional Accepts Default Description
Value

separate them by a delimiter, or use
a list of files

Merged No File The path to store the merged PDF
PDF path

If file exists N/A Overwrite, Don't Add Specifies what to do in case the
overwrite, Add sequential destination file already exists
sequential suffix suffix

Passwords Yes Direct encrypted The delimited passwords. The order
input or Text should be the same as the order of
value the input PDFs. Leave this blank if

the PDFs aren't password protected

Delimiter No Text value , A custom password delimiter. This
delimiter shouldn't be part of any of
the passwords

Variables produced
Argument Type Description

MergedPDF File The merged PDF file

Exceptions
Exception Description

PDF file doesn't exist File doesn't exist on the given path

Invalid password The given password is invalid

Failed to merge PDF files Indicates that an error occurred while merging the files



CMD session actions
Article • 12/16/2022

Use the Open CMD session action to commence a command prompt session. Specify
the working folder, and optionally change the code page in the Advanced section. All
CMD session actions require the produced CMD session variable.

To run a command, deploy the Write to CMD session action, specify a command, and
select to send Enter. The following example creates a new folder in the current working
directory.

To ensure that a specific output appears on the command prompt before proceeding
with subsequent actions, use the Wait for text on CMD session action. Specify the text
to expect or enter a regular expression and enable the appropriate option for regular
expressions.



When all the CMD tasks are complete, use the Close CMD session action to terminate
the CMD session.

Open CMD session
Open a new CMD session.

） Important

To prevent unauthorized access, Windows require administrator rights to access
protected folders. To use a protected folder as a working folder in the Open CMD
session action, run Power Automate with administrator rights. To find more
information regarding running Power Automate as an administrator, go to Run
Power Automate with elevated rights.

Input parameters
Argument Optional Accepts Default Description

Value



Argument Optional Accepts Default Description
Value

Working Yes Folder The full
folder path of the

folder to
start the
CMD
session, if
applicable

Change N/A Boolean value False Specifies
code page whether to

change the
session's
current
code page

Encoding No ASMO-708 : Arabic (ASMO 708), big5 : utf-8 : The
Chinese Traditional (Big5), cp1025 : IBM Unicode encoding to
EBCDIC (Cyrillic Serbian-Bulgarian), cp866 : (UTF-8) use when
Cyrillic (DOS), cp875 : IBM EBCDIC (Greek reading the
Modern), csISO2022JP : Japanese (JIS-Allow 1 output
byte Kana), DOS-720 : Arabic (DOS), DOS-862 :
Hebrew (DOS), EUC-CN : Chinese Simplified
(EUC), EUC-JP : Japanese (JIS 0208-1990 and
0212-1990), euc-jp : Japanese (EUC), euc-kr :
Korean (EUC), GB18030 : Chinese Simplified
(GB18030), gb2312 : Chinese Simplified
(GB2312), hz-gb-2312 : Chinese Simplified
(HZ), IBM-Thai : IBM EBCDIC (Thai), IBM00858 :
OEM Multilingual Latin I, IBM00924 : IBM
Latin-1, IBM01047 : IBM Latin-1, IBM01140 :
IBM EBCDIC (US-Canada-Euro), IBM01141 :
IBM EBCDIC (Germany-Euro), IBM01142 : IBM
EBCDIC (Denmark-Norway-Euro), IBM01143 :
IBM EBCDIC (Finland-Sweden-Euro), IBM01144
: IBM EBCDIC (Italy-Euro), IBM01145 : IBM
EBCDIC (Spain-Euro), IBM01146 : IBM EBCDIC
(UK-Euro), IBM01147 : IBM EBCDIC (France-
Euro), IBM01148 : IBM EBCDIC (International-
Euro), IBM01149 : IBM EBCDIC (Icelandic-
Euro), IBM037 : IBM EBCDIC (US-Canada),
IBM1026 : IBM EBCDIC (Turkish Latin-5),
IBM273 : IBM EBCDIC (Germany), IBM277 : IBM
EBCDIC (Denmark-Norway), IBM278 : IBM
EBCDIC (Finland-Sweden), IBM280 : IBM
EBCDIC (Italy), IBM284 : IBM EBCDIC (Spain),
IBM285 : IBM EBCDIC (UK), IBM290 : IBM
EBCDIC (Japanese katakana), IBM297 : IBM



Argument Optional Accepts Default Description
Value

EBCDIC (France), IBM420 : IBM EBCDIC
(Arabic), IBM423 : IBM EBCDIC (Greek), IBM424
: IBM EBCDIC (Hebrew), IBM437 : OEM United
States, IBM500 : IBM EBCDIC (International),
ibm737 : Greek (DOS), ibm775 : Baltic (DOS),
ibm850 : Western European (DOS), ibm852 :
Central European (DOS), IBM855 : OEM Cyrillic,
ibm857 : Turkish (DOS), IBM860 : Portuguese
(DOS), ibm861 : Icelandic (DOS), IBM863 :
French Canadian (DOS), IBM864 : Arabic (864),
IBM865 : Nordic (DOS), ibm869 : Greek,
Modern (DOS), IBM870 : IBM EBCDIC
(Multilingual Latin-2), IBM871 : IBM EBCDIC
(Icelandic), IBM880 : IBM EBCDIC (Cyrillic
Russian), IBM905 : IBM EBCDIC (Turkish), iso-
2022-jp : Japanese (JIS), iso-2022-jp : Japanese
(JIS-Allow 1 byte Kana - SO/SI), iso-2022-kr :
Korean (ISO), iso-8859-1 : Western European
(ISO), iso-8859-13 : Estonian (ISO), iso-8859-15
: Latin 9 (ISO), iso-8859-2 : Central European
(ISO), iso-8859-3 : Latin 3 (ISO), iso-8859-4 :
Baltic (ISO), iso-8859-5 : Cyrillic (ISO), iso-
8859-6 : Arabic (ISO), iso-8859-7 : Greek (ISO),
iso-8859-8 : Hebrew (ISO-Visual), iso-8859-8-i
: Hebrew (ISO-Logical), iso-8859-9 : Turkish
(ISO), Johab : Korean (Johab), koi8-r : Cyrillic
(KOI8-R), koi8-u : Cyrillic (KOI8-U), ks_c_5601-
1987 : Korean, macintosh : Western European
(Mac), shift_jis : Japanese (Shift-JIS), us-ascii :
US-ASCII, utf-16 : Unicode, utf-16BE : Unicode
(Big-Endian), utf-32 : Unicode (UTF-32), utf-
32BE : Unicode (UTF-32 Big-Endian), utf-7 :
Unicode (UTF-7), utf-8 : Unicode (UTF-8),
windows-1250 : Central European (Windows),
windows-1251 : Cyrillic (Windows), Windows-
1252 : Western European (Windows),
windows-1253 : Greek (Windows), windows-
1254 : Turkish (Windows), windows-1255 :
Hebrew (Windows), windows-1256 : Arabic
(Windows), windows-1257 : Baltic (Windows),
windows-1258 : Vietnamese (Windows),
windows-874 : Thai (Windows), x-Chinese-CNS
: Chinese Traditional (CNS), x-Chinese-Eten :
Chinese Traditional (Eten), x-cp20001 : TCA
Taiwan, x-cp20003 : IBM5550 Taiwan, x-
cp20004 : TeleText Taiwan, x-cp20005 : Wang
Taiwan, x-cp20261 : T.61, x-cp20269 : ISO-



Argument Optional Accepts Default Description
Value

6937, x-cp20936 : Chinese Simplified (GB2312-
80), x-cp20949 : Korean Wansung, x-cp50227 :
Chinese Simplified (ISO-2022), x-EBCDIC-
KoreanExtended : IBM EBCDIC (Korean
Extended), x-Europa : Europa, x-IA5 : Western
European (IA5), x-IA5-German : German (IA5),
x-IA5-Norwegian : Norwegian (IA5), x-IA5-
Swedish : Swedish (IA5), x-iscii-as : ISCII
Assamese, x-iscii-be : ISCII Bengali, x-iscii-de :
ISCII Devanagari, x-iscii-gu : ISCII Gujarati, x-
iscii-ka : ISCII Kannada, x-iscii-ma : ISCII
Malayalam, x-iscii-or : ISCII Oriya, x-iscii-pa :
ISCII Punjabi, x-iscii-ta : ISCII Tamil, x-iscii-te :
ISCII Telugu, x-mac-arabic : Arabic (Mac), x-
mac-ce : Central European (Mac), x-mac-
chinesesimp : Chinese Simplified (Mac), x-mac-
chinesetrad : Chinese Traditional (Mac), x-mac-
croatian : Croatian (Mac), x-mac-cyrillic :
Cyrillic (Mac), x-mac-greek : Greek (Mac), x-
mac-hebrew : Hebrew (Mac), x-mac-icelandic :
Icelandic (Mac), x-mac-japanese : Japanese
(Mac), x-mac-korean : Korean (Mac), x-mac-
romanian : Romanian (Mac), x-mac-thai : Thai
(Mac), x-mac-turkish : Turkish (Mac), x-mac-
ukrainian : Ukrainian (Mac)`

Variables produced
Argument Type Description

CmdSession CMD session The CMD session for use with later CMD actions

Exceptions
Exception Description

Can't start command session Indicates a problem initiating a CMD session

Working directory doesn't Indicates that an error occurred trying to locate the working
exist directory

Read from CMD session



Read the output of a CMD session.

Input parameters
Argument Optional Accepts Default Description

Value

CMD No CMD A previously opened CMD session
session session

Separate N/A Boolean False Specifies whether to store the standard output
output from value and the standard error into different variables or
error combined into one

Variables produced
Argument Type Description

CmdOutput Text value The CMD session's standard output

CmdError Text value The CMD session's standard error

Exceptions
Exception Description

CMD session is closed Indicates that the CMD session specified is closed

Write to CMD session
Execute a command on an open CMD session.

Input parameters
Argument Optional Accepts Default Description

Value

CMD session No CMD A previously opened CMD session
session variable

Command No Text value The name of the command to
execute



Argument Optional Accepts Default Description
Value

Send Enter after N/A Boolean True Specifies whether to send an Enter
command value the command

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Can't write to CMD session Indicates an error writing to a CMD session

CMD session is closed Indicates that the CMD session specified is closed

Wait for text on CMD session
Wait for a specific text on a previously opened CMD session.

Input parameters
Argument Optional Accepts Default Description

Value

CMD No CMD An open CMD session variable
session session

Text to No Text The text or regular expression to wait to appear on
wait value standard output or on standard error

Is regular N/A Boolean False Specifies whether to wait for a regular expression
expression value instead of plain text

Ignore N/A Boolean True Specifies whether the text to wait should match
case value with standard output or standard error without

taking into account the case of the text

Timeout Yes Numeric 0 Specifies whether to wait indefinitely for the text to
value appear or to fail if the text doesn't show up within

a set time period



７ Note

Power Automate's regular expression engine is .NET. To find more information
about regular expressions, go to Regular Expression Language - Quick Reference.

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

CMD session is closed Indicates that the CMD session specified is closed

Timeout occurred while Indicates that the specified timeout period has elapsed before the
waiting for text text appeared in the command session

Close CMD session
Close a previously opened CMD session.

Input parameters
Argument Optional Accepts Default Description

Value

CMD No CMD The CMD session to close. Specify this variable in
session session an open CMD session action

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.



Terminal emulation actions
Article • 11/21/2024

Power Automate provides integration with terminal emulators through the Terminal
emulation actions. These actions enable you to handle terminals and mainframes, and
perform operations such as moving the cursor, setting and getting text, and sending
keys.

Before deploying any terminal actions, use the Open terminal session action to open a
new connection with the installed provider.

） Important

Before trying to connect to a terminal session, make sure that the actual terminal
session is already open on your machine.

If you've installed Micro Focus Reflection on your machine, choose the respective option
in the Provider parameter of the action and populate the required configuration.



If you've installed another provider, select HLLAPI that works with most terminal
emulation providers.

Depending on the provider you're using, select the appropriate HLLAPI DLL file located
in its installation folder. In the following list, you can see the HLLAPI DLL file names of
some popular terminal emulation providers:

RocketSoftware BlueZone: ehlapi64.dll
IBM Personal Communications: EHLAPI32.dll
MicroFocus Rumba: System/ehlapi32.Dll
Cybelesoft zScope: zHllap32.dll

７ Note

The Windows HLLAPI DLL (WinHLLAPI) is not currently supported.

After opening a terminal session and completing all the wanted operations, terminate
the connection using the Close terminal session action. If you don't close the
connection, some providers won't let you connect again to the already open session
without restarting the software or the connection.



Open terminal session
Open a new terminal session.

７ Note

Learn more about configuring the action in How to configure the open terminal
session action.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Provider N/A Micro focus Micro The terminal emulation to use
reflection, focus
HLLAPI reflection

HLLAPI DLL No File The HLLAPI DLL of the provider.
path RocketSoftware BlueZone default name:

'ehlapi64.dll'. IBM Personal
Communications default name:



Argument Optional Accepts Default Description
Value

'EHLAPI32.dll'. MicroFocus Rumba
default path: 'System/ehlapi32.Dll'.
Cybelesoft zScope default name:
'zHllap32.dll'. Any other provider that
offers an HLLAPI DLL in its installation
folder.

Installation No Folder The installation path of the provider's
path application on the user's file system

Configuration N/A Existing Existing Choose 'Existing profile' to select a file
profile, profile containing a preconfigured terminal
Specify emulation connection. Choose 'Specify
connection connection' to specify the type of the

connection, the host address and the
port.

Session name No Text value The session name to connect to. The
HLLAPI short name, and it's a unique
identifier for the host session. It can be
found in the Terminal emulator's
configuration settings.

Host type N/A IBM 3270, IBM 3270 The host type of the connection
IBM 5250

Profile No File The file that contains the preconfigured
connection

Host address No Text value The host's address to connect to

Port No Numeric The port to be used for this connection
value

Attach to N/A Boolean False Specifies whether to attach to a currently
running value open/running terminal session
session

Variables produced
ﾉ Expand table

Argument Type Description

TerminalSession Terminal The specific terminal session for use with later terminal
session emulation commands



Exceptions

ﾉ Expand table

Exception Description

Error communicating with the emulator Indicates a problem connecting to the emulator

Profile error Profile error

Close terminal session
Close an open terminal session.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Terminal session to No Terminal The previously opened
close session terminal session

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Error communicating with the emulator Indicates a problem connecting to the emulator

Move cursor on terminal session
Move the terminal's cursor on the specified position.

Input parameters



ﾉ Expand table

Argument Optional Accepts Default Description
Value

Terminal No Terminal The terminal session to work with
session session

Row No Numeric The vertical position of the cursor on
value the screen

Column No Numeric The horizontal position of the cursor
value on the screen

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Screen position out of bounds Indicates that the screen position is out of bounds

Position commands aren't supported by Indicates that position commands used aren't
the emulator supported by the emulator

Operation is unavailable for this session Indicates that the operation is unavailable for this
type session type

Error communicating with the emulator Indicates a problem connecting to the emulator

Get text from terminal session
Get text from a terminal session.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Terminal No Terminal session The terminal session to
session work with

Get text N/A Field, Entire screen, Cursor Field The location to get the text
from position, Specific position from

Get field by N/A Label, Index, Position Label Specifies how to look for
the field

Label No Text value The label of the field to
look for

Index No Numeric value The index of the field to
look for

Text length No Numeric value The length of the text to
receive

Row No Numeric value The vertical position of the
field on the screen

Column No Numeric value The horizontal position of
the field on the screen

Variables produced

ﾉ Expand table

Argument Type Description

TerminalText Text value The text retrieved from the terminal session

Exceptions

ﾉ Expand table

Exception Description

Error communicating with the emulator Indicates a problem connecting to the emulator

Field index out of bounds Indicates that the field index is out of bounds

Field label not found Indicates that the field label doesn't exist

Screen position out of bounds Indicates that the screen position is out of bounds



Exception Description

No field found at the given position Indicates that no field exists at the given position

Terminal screen is unformatted Indicates that the terminal screen is unformatted

Position commands aren't supported by Indicates that position commands used aren't
the emulator supported by the emulator

Operation is unavailable for this session Indicates that the operation is unavailable for this
type session type

Set text on terminal session
Set text on a terminal session.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Terminal No Terminal session The terminal session to work with
session

Text No Direct encrypted The text to set on the specified
input or Text location
value

Set text N/A Cursor position, Field The location to set the text to
Field

Get field by N/A Label, Index, Label Specifies the way by which to look
Position for the field

Label No Text value The label of the field to look for

Index No Numeric value The index of the field on the screen

Row No Numeric value The vertical position of the field on
the screen

Column No Numeric value The horizontal position of the field
on the screen

Treat @ N/A Boolean value False Check this box to send the '@'
character as character literally. Leave this option



Argument Optional Accepts Default Description
Value

literal disabled to sent it as a special
character

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Error communicating with the emulator Indicates a problem connecting to the emulator

Field index out of bounds Indicates that the field index is out of bounds

Field label not found Indicates that the field label doesn't exist

Screen position out of bounds Indicates that the screen position is out of bounds

No field found at the given position Indicates that no field exists at the given position

Terminal screen is unformatted Indicates that the terminal screen is unformatted

Position commands aren't supported by Indicates that position commands used aren't
the emulator supported by the emulator

Operation is unavailable for this session Indicates that the operation is unavailable for this
type session type

Input text was rejected Indicates that the input text was rejected

Send key to terminal session
Send a control key to a terminal session.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Terminal No Terminal session The
session terminal

session to
work with

Control N/A Transmit, Alt cursor, Attention, Backspace, Transmit The key to
key Back tab, Block toggle, Break, Cancel, Center, submit to

Clear, Clear comm, Clear display, Clear line, the session
Clear page, Clear partition, Comma, Command
line, Command window, Compose, Ctrl+F1,
Ctrl+F2, Ctrl+F3, Ctrl+F4, Ctrl+F5, Ctrl+F6,
Ctrl+F7, Ctrl+F8, Ctrl+F9, Ctrl+F10, Ctrl+F11,
Ctrl+F12, Ctrl+Shift+F1, Ctrl+Shift+F2,
Ctrl+Shift+F3, Ctrl+Shift+F4, Ctrl+Shift+F5,
Ctrl+Shift+F6, Ctrl+Shift+F7, Ctrl+Shift+F8,
Ctrl+Shift+F9, Ctrl+Shift+F10, Ctrl+Shift+F11,
Ctrl+Shift+F12, Cursor blink, Cursor select,
Decimal, Delete, Delete char, Delete line,
Delete word, Destructive back space,
Disconnect, Do, Down, Down double, Dup,
Duplicate, Edit script, Key end, End of field,
Erase EOF, Erase EOL, Erase EOP, Erase input,
Escape, ExtGr, F1, F2, F3, F4, F5, F6, F7, F8, F9,
F10, F11, F12, F13, F14, F15, F16, F17, F18, F19,
F20, F21, F22, F23, F24, F25, F26, F27, F28, F29,
F30, F31, F32, F33, F34, F35, F36, F37, F38, F39,
F40, F41, F42, F43, F44, F45, F46, F47, F48,
Field delimiter, Field exit, Field mark, Field
minus, Field plus, Find, Hard reset, Help, Hex,
Hex 00, Hex 01, Hex 02, Hex 03, Hex 04, Hex
05, Hex 06, Hex 07, Hex 08, Hex 09, Hex 0A,
Hex 0B, Hex 0C, Hex 0D, Hex 0E, Hex 0F, Hex
10, Hex 11, Hex 12, Hex 13, Hex 14, Hex 15,
Hex 16, Hex 17, Hex 18, Hex 19, Hex 1A, Hex
1B, Hex 1C, Hex 1D, Hex 1E, Hex 1F, Hex 7F,
Hold, Hold clear, Hold set, Home, Home down,
Home up, Insert, Insert char, Insert here, Insert
line, Insert mode, Invalid key, KeyPad0,
KeyPad1, KeyPad2, KeyPad3, KeyPad4,
KeyPad5, KeyPad6, KeyPad7, KeyPad8,
KeyPad9, Left, Left double, Line feed, Minus,
Monitor toggle, New line, Next page, Next
screen, Next word, Nul, NumLock, PA1, PA2,
PA3, Page, Page down, Page up, Pan left, Pan
right, Partition jump, PF1, PF2, PF3, PF4, Plus
Cr, Previous word, PrevPage, PrevScreen, Print,



Argument Optional Accepts Default Description
Value

Print line, Print Msg, Prent screen, Remove,
Replace, Reset, Return, Reserve field, Right,
Right double, Roll down, Roll up, Rile line, Run
script, Scroll down, Scroll left, Scroll right,
Scroll up, Select, Send, Send answer back,
Send delete, Send line, Send Msg,
Shift+Backspace, Shift+Delete, Shift+Down,
Shift+F1, Shift+F2, Shift+F3, Shift+F4,
Shift+F5, Shift+F6, Shift+F7, Shift+F8,
Shift+F9, Shift+F10, Shift+F11, Shift+F12,
Shift+F13, Shift+F14, Shift+F15, Shift F16,
Shift+F17, Shift+F18, Shift+F19, Shift+F20,
Shift+Home, Shift+Insert, Shift+Left,
Shift+Print screen, Shift+Right, Shift+Up, Soft
reset, System request, Tab, Tek zoom, Term
next page, Term prev page, Test, Text assist
begin bold, Text assist begin of line, Text assist
begin underline, Text assist bottom of page,
Text assist carrier return, Text assist center, Text
assist end bold, Text assist end of line, Text
assist half index down, Text assist half index
up, Text assist insert symbols, Text assist next
stop, Text assist next text column, Text assist
page end, Text assist required space, Text
assist required tab, Text assist stop, Text assist
text tab advance, Text assist top of page, Text
assist word underline, Trace Toggle, Udk 10,
Udk 6, Udk 7, Udk 8, Udk 9, Udk 11, Udk 12,
Udk 13, Udk 14, Udk 15, Udk 16, Udk 17, Udk
18, Udk 19, Udk 20, Up, Up double

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Error communicating with the emulator Indicates a problem connecting to the emulator

Key not supported Indicates that the key isn't supported



Wait for text on terminal session
Wait for a specific text to appear on a terminal session.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Terminal No Terminal The previously opened terminal session
session session

Text to wait No Text value The text or regular expression to wait to
for appear on the terminal screen or on a

specified field

Regular N/A Boolean False Specifies whether to wait for a regular
expression value expression instead of plain text

Wait for text N/A Screen, Field Screen The location to wait for the text to
location appear on

Get field by N/A Label, Index, Label Specifies the way by which to look for
Position the field

Label No Text value The label of the field to look for

Index No Numeric The index of the field to look for
value

Row No Numeric The vertical position of the field on the
value screen

Column No Numeric The horizontal position of the field on
value the screen

Timeout Yes Numeric 0 The maximum amount of time to wait
value

７ Note

Power Automate's regular expression engine is .NET. To find more information
about regular expressions, go to Regular Expression Language - Quick Reference.



Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Error communicating with the emulator Indicates a problem connecting to the emulator

Field index out of bounds Indicates that the field index is out of bounds

Field label not found Indicates that the field label doesn't exist

Screen position out of bounds Indicates that the screen position is out of bounds

No field found at the given position Indicates that no field exists at the given position

Terminal screen is unformatted Indicates that the terminal screen is unformatted

Position commands aren't supported by Indicates that position commands used aren't
the emulator supported by the emulator

Operation is unavailable for this session Indicates that the operation is unavailable for this
type session type

Timeout expired Indicates that the timeout has been expired

Search for text on terminal session
Search for all occurrences of a specific text on a terminal session

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Terminal No Terminal The previously opened terminal session
session session

Text to search No Text value The text or regular expression to search
for for on the terminal screen



Argument Optional Accepts Default Description
Value

Regular N/A Boolean False Specifies whether to search for a regular
expression value expression instead of plain text

Column size No Numeric 80 The number of the columns on the
value terminal screen

７ Note

Power Automate's regular expression engine is .NET. To find more information
about regular expressions, go to Regular Expression Language - Quick Reference.

Variables produced
ﾉ Expand table

Argument Type Description

FindResults Datatable The search results retrieved from the terminal session screen

Exceptions

ﾉ Expand table

Exception Description

Error communicating with the emulator Indicates a problem connecting to the emulator

Text not found Indicates that the text searching for was not found

Invalid regex expression Indicates that the Regular Expression used is invalid

Feedback
Was this page helpful?  Yes  No

Provide product feedback



OCR actions
Article • 12/16/2022

Power Automate enables users to read, extract, and manage data within files through
optical character recognition (OCR).

To create an OCR engine and extract text from images and documents, use the Extract
text with OCR action. The following example extracts text from the entire specified
image.



All OCR actions can create a new OCR engine variable or use an existing one. You can
use existing OCR engine variables in any action that offers OCR capabilities.

Power Automate supports the Windows OCR and Tesseract engines. To configure the
selected OCR engine, navigate to the OCR engine settings of the appropriate action.
The available options include the language and the image width and height multipliers.

７ Note

All the available OCR engines are pre-installed in Power Automate and work
locally without connecting to the cloud. However, you may need to download
language packs or data files to extract texts in specific languages.
Image multipliers increase the image size to make searching and text
extraction more effective. Setting values greater than three may lead to
erroneous results.

Use the Windows OCR engine
The default OCR engine in Power Automate is the Windows OCR engine. To extract texts
using the Windows OCR engine, you must install the appropriate language pack for the
language you want to extract.

If the appropriate language pack isn't installed, Power Automate throws an error,
prompting you to install it. To find more information regarding downloading and
installing language packs, go to Language packs for Windows .

After installing the appropriate language pack, extend the OCR engine settings of the
OCR action and select the language you want. The Windows OCR engine supports 25
languages, including Chinese (Simplified and Traditional), Czech, Danish, Dutch, English,
Finnish, French, German, Greek, Hungarian, Italian, Japanese, Korean, Norwegian, Polish,
Portuguese, Romanian, Russian, Serbian (Cyrillic and Latin), Slovak, Spanish, Swedish,
and Turkish.

Use the Tesseract OCR engine
７ Note

To make use of the Tesseract OCR engine, make sure the machine's CPU supports
AVX2 instruction set.



Apart from the Windows OCR engine, Power Automate supports the Tesseract engine.
This engine can extract text in five languages without further configuration: English,
German, Spanish, French, and Italian.

To extract text in a language outside the mentioned list, enable the Use other languages
option in the OCR engine settings of the OCR action. When this option is enabled, the
action displays two more parameters: Language abbreviation and Language data path.

The Language abbreviation field indicates to the engine which language to look for
during OCR. The Language data path field contains the language data files
(.traineddata) used to train the OCR engine. You can find the language data files for all
the available languages in this GitHub repository .

You can also use the Tesseract engine to extract text from multilingual documents. To
find more information regarding extracting text from multilingual documents, go to
Perform OCR on multilingual documents.

If text on screen (OCR)
Marks the beginning of a conditional block of actions depending on whether a given
text appears on the screen or not, using OCR.

Input parameters
Argument Optional Accepts Default Description

Value

If text N/A Exists, Doesn't exist Exists Specifies
whether to check
if the text exists
or not on the
given source to
analyze

OCR engine No Windows OCR engine, Tesseract OCR The OCR engine
type engine, OCR engine variable engine type to use.

variable Select a
preconfigured
OCR engine or
set up a new
one.

OCR engine No OCREngineObject The engine to
variable use for the OCR

operation



Argument Optional Accepts Default Description
Value

Text to find No Text value The text to
search for in the
specified source

Is regular N/A Boolean value False Specifies
expression whether to use a

regular
expression to
find the specified
text

Search for N/A Entire screen, Foreground window Entire Specifies
text on screen whether to

search for the
specified text on
the entire visible
screen or just the
foreground
window

Search N/A Whole of specified source, Specific Whole Specifies
mode subregion only, Subregion relative to of whether to scan

image specified the entire screen
source (or window) or a

narrowed down
subregion of it

Image(s) No List of Images The image(s)
specifying the
subregion
(relative to the
top left corner of
the image) to
scan for the
supplied text

X1 Yes Numeric value The start X
coordinate of the
subregion to
scan for the
supplied text



Argument Optional Accepts Default Description
Value

Tolerance Yes Numeric value 10 Specifies how
much the
image(s)
searched for can
differ from the
originally chosen
image

Y1 Yes Numeric value The start Y
coordinate of the
subregion to
scan for the
supplied text

X1 Yes Numeric value The start X
coordinate of the
subregion
relative to the
specified image
to scan for the
supplied text

X2 Yes Numeric value The end X
coordinate of the
subregion to
scan for the
supplied text

Y1 Yes Numeric value The start Y
coordinate of the
subregion
relative to the
specified image
to scan for the
supplied text

Y2 Yes Numeric value The end Y
coordinate of the
subregion to
scan for the
supplied text



Argument Optional Accepts Default Description
Value

X2 Yes Numeric value The end X
coordinate of the
subregion
relative to the
specified image
to scan for the
supplied text

Y2 Yes Numeric value The end Y
coordinate of the
subregion
relative to the
specified image
to scan for the
supplied text

Windows N/A Chinese (Simplified), Chinese English The language of
OCR (Traditional), Czech, Danish, Dutch, the text that the
language English, Finnish, French, German, Windows OCR

Greek, Hungarian, Italian, Japanese, engine detects
Korean, Norwegian, Polish, Portuguese,
Romanian, Russian, Serbian (Cyrillic),
Serbian (Latin), Slovak, Spanish,
Swedish, Turkish

Use other N/A Boolean value False Specifies
language whether to use a

language not
given in the
'Tesseract
language' field

Tesseract N/A English, German, Spanish, French, English The language of
language Italian the text that the

Tesseract engine
detects

Language No Text value The Tesseract
abbreviation abbreviation of

the language to
use. For example,
if the data is
'eng.traineddata',
set this
parameter to
'eng'



Argument Optional Accepts Default Description
Value

Language No Text value The path of the
data path folder that holds

the specified
language's
Tesseract data

Image width No Numeric value 1 The width
multiplier multiplier of the

image

Image No Numeric value 1 The height
height multiplier of the
multiplier image

Image N/A Basic, Advanced Basic Which image
matching algorithm to use
algorithm when searching

for image

７ Note

Power Automate's regular expression engine is .NET. To find more information
about regular expressions, go to Regular Expression Language - Quick
Reference.
The OCR engine variable option is planned for deprecation.

Variables produced
Argument Type Description

LocationOfTextFoundX Numeric The X coordinate of the point where the text appears on the
value screen. If the search is performed in the foreground window,

the coordinate returned is relative to the top left corner of
the window

LocationOfTextFoundY Numeric The X coordinate of the point where the text appears on the
value screen. If the search is performed in the foreground window,

the coordinate returned is relative to the top left corner of
the window

Exceptions



Exception Description

Can't check if text exists in non- Indicates that it isn't possible to check for the text on
interactive mode the screen when in non-interactive mode

Invalid subregion coordinates Indicates that the specified subregion coordinates are
invalid

Failed to analyze text with OCR Indicates an error occurred while trying to analyze the
text using OCR

Failed to create the OCR engine Indicates an error occurred while trying to create the
OCR engine

Data path folder doesn't exist Indicates that the folder specified for the language data
doesn't exist

The selected Windows language pack Indicates that the selected Windows language pack
isn't installed on the machine hasn't been installed on the machine

OCR engine not alive Indicates that the OCR engine isn't alive

Wait for text on screen (OCR)
Wait until a specific text appears/disappears on the screen, on the foreground window,
or relative to an image on the screen or foreground window using OCR.

Input parameters
Argument Optional Accepts Default Description

Value

Wait for text N/A Appear, Disappear Appear Specifies
to whether to wait

for the text to
appear or
disappear

OCR engine No Windows OCR engine, Tesseract OCR The OCR engine
type engine, OCR engine variable engine type to use.

variable Select a
preconfigured
OCR engine or
set up a new
one.



Argument Optional Accepts Default Description
Value

OCR engine No OCREngineObject The engine to
variable use for the OCR

operation

Text to find No Text value The text to
search for in the
specified source

Is regular N/A Boolean value False Specifies
expression whether to use a

regular
expression to
find the specified
text

Search for N/A Entire screen, Foreground window Entire Specifies
text on screen whether to

search for the
specified text on
the entire visible
screen or just the
foreground
window

Search N/A Whole of specified source, Specific Whole Specifies
mode subregion only, Subregion relative to of whether to scan

image specified the entire screen
source (or window) or a

narrowed down
subregion of it

Image(s) No List of Images The image(s)
specifying the
subregion
(relative to the
top left corner of
the image) to
scan for the
supplied text

X1 Yes Numeric value The start X
coordinate of the
subregion to
scan for the
supplied text



Argument Optional Accepts Default Description
Value

Tolerance Yes Numeric value 10 Specifies how
much the
image(s)
searched for can
differ from the
originally chosen
image

Y1 Yes Numeric value The start Y
coordinate of the
subregion to
scan for the
supplied text

X1 Yes Numeric value The start X
coordinate of the
subregion
relative to the
specified image
to scan for the
supplied text

X2 Yes Numeric value The end X
coordinate of the
subregion to
scan for the
supplied text

Y1 Yes Numeric value The start Y
coordinate of the
subregion
relative to the
specified image
to scan for the
supplied text

Y2 Yes Numeric value The end Y
coordinate of the
subregion to
scan for the
supplied text



Argument Optional Accepts Default Description
Value

X2 Yes Numeric value The end X
coordinate of the
subregion
relative to the
specified image
to scan for the
supplied text

Y2 Yes Numeric value The end Y
coordinate of the
subregion
relative to the
specified image
to scan for the
supplied text

Windows N/A Chinese (Simplified), Chinese English The language of
OCR (Traditional), Czech, Danish, Dutch, the text that the
language English, Finnish, French, German, Windows OCR

Greek, Hungarian, Italian, Japanese, engine detects
Korean, Norwegian, Polish, Portuguese,
Romanian, Russian, Serbian (Cyrillic),
Serbian (Latin), Slovak, Spanish,
Swedish, Turkish

Use other N/A Boolean value False Specifies
language whether to use a

language not
given in the
'Tesseract
language' field

Tesseract N/A English, German, Spanish, French, English The language of
language Italian the text that the

Tesseract engine
detects

Language No Text value The Tesseract
abbreviation abbreviation of

the language to
use. For example,
if the data is
'eng.traineddata',
set this
parameter to
'eng'



Argument Optional Accepts Default Description
Value

Language No Text value The path of the
data path folder that holds

the specified
language's
Tesseract data

Image width No Numeric value 1 The width
multiplier multiplier of the

image

Image No Numeric value 1 The height
height multiplier of the
multiplier image

Image N/A Basic, Advanced Basic Which image
matching algorithm to use
algorithm when searching

for image

Fail with N/A Boolean value False Specify whether
timeout you want the
error action to wait

indefinitely or
fail after a set
time period

７ Note

Power Automate's regular expression engine is .NET. To find more information
about regular expressions, go to Regular Expression Language - Quick
Reference.
The OCR engine variable option is planned for deprecation.

Variables produced
Argument Type Description

LocationOfTextFoundX Numeric The X coordinate of the point where the text appears on the
value screen. If the search is performed in the foreground window,

the coordinate returned is relative to the top left corner of
the window



Argument Type Description

LocationOfTextFoundY Numeric The X coordinate of the point where the text appears on the
value screen. If the search is performed in the foreground window,

the coordinate returned is relative to the top left corner of
the window

Exceptions
Exception Description

Can't check if text exists in non- Indicates that it isn't possible to check for the text on
interactive mode the screen when in non-interactive mode

Invalid subregion coordinates Indicates that the specified subregion coordinates are
invalid

Failed to analyze text with OCR Indicates an error occurred while trying to analyze the
text using OCR

Failed to create the OCR engine Indicates an error occurred while trying to create the
OCR engine

Data path folder doesn't exist Indicates that the folder specified for the language data
doesn't exist

The selected Windows language pack Indicates that the selected Windows language pack
isn't installed on the machine hasn't been installed on the machine

OCR engine not alive Indicates that the OCR engine isn't alive

Timeout error Indicates that the action failed after a set time period

Extract text with OCR
Extract text from a given source using the given OCR engine.

Input parameters
Argument Optional Accepts Default Description

Value



Argument Optional Accepts Default Description
Value

OCR engine No Windows OCR engine, Tesseract OCR The OCR engine
engine, OCR engine variable engine type to use.

variable Select a
preconfigured
OCR engine or
set up a new one

OCR engine No OCREngineObject The engine to
variable use for the OCR

operation

OCR source N/A Screen, Foreground window, Image on Screen The source of
disk the image to

perform the OCR
operation on

Image file No File The path of the
path image to

perform the OCR
operation on

Search N/A Whole of specified source, Specific Whole The selected
mode subregion only, Subregion relative to of mode for the

image specified OCR operation
source

Image No List of Images The image to use
for narrowing
down the scan to
a subregion that
is relative to the
specified image

Tolerance Yes Numeric value 10 Specifies how
much the image
can differ from
the originally
chosen image

X1 Yes Numeric value The start X
coordinate of the
subregion to
narrow down the
scan



Argument Optional Accepts Default Description
Value

X2 Yes Numeric value The end X
coordinate of the
subregion to
narrow down the
scan

Y1 Yes Numeric value The start Y
coordinate of the
subregion to
narrow down the
scan

Y2 Yes Numeric value The end Y
coordinate of the
subregion to
narrow down the
scan

Windows N/A Chinese (Simplified), Chinese English The language of
OCR (Traditional), Czech, Danish, Dutch, the text that the
language English, Finnish, French, German, Windows OCR

Greek, Hungarian, Italian, Japanese, engine detects
Korean, Norwegian, Polish, Portuguese,
Romanian, Russian, Serbian (Cyrillic),
Serbian (Latin), Slovak, Spanish,
Swedish, Turkish

Use other N/A Boolean value False Specifies
language whether to use a

language not
given in the
'Tesseract
language' field

Tesseract N/A English, German, Spanish, French, English The language of
language Italian the text that the

Tesseract engine
detects



Argument Optional Accepts Default Description
Value

Language No Text value The Tesseract
abbreviation abbreviation of

the language to
use. For example,
if the data is
'eng.traineddata',
set this
parameter to
'eng'

Language No Text value The path of the
data path folder that holds

the specified
language's
Tesseract data

Image width No Numeric value 1 The width
multiplier multiplier of the

image

Image No Numeric value 1 The height
height multiplier of the
multiplier image

Wait for N/A Boolean value True Specifies
image to whether to wait
appear or not for the

image to appear
on the screen or
foreground
window

Timeout No Numeric value 5 Specifies the
time to wait for
the operation to
complete before
the action fails

Image N/A Basic, Advanced Basic Which image
matching algorithm to use
algorithm when searching

for image

７ Note

The OCR engine variable option is planned for deprecation.



Variables produced
Argument Type Description

OcrText Text value The result after the text extraction

Exceptions
Exception Description

Failed to extract text with OCR Indicates an error occurred while trying to extract text
with OCR from the given source

Image file not found Indicates that the file doesn't exist on the given path

Landmark image not found Indicates that the landmark image doesn't exist

Can't get text from screen in non- Indicates that it isn't possible to get text from screen
interactive mode when in non-interactive mode

Failed to create the OCR engine Indicates an error occurred while trying to create the
OCR engine

Data path folder doesn't exist Indicates that the folder specified for the language
data doesn't exist

The selected Windows language pack Indicates that the selected Windows language pack
isn't installed on the machine hasn't been installed on the machine

OCR engine not alive Indicates that the OCR engine isn't alive



Cryptography actions
Article • 07/09/2024

Cryptography actions enable you to encrypt and decrypt plain text and text from files
providing a key and an encoding format.

The Encrypt text with AES action encrypts a text using the AES algorithm and a user-
specified encryption key. You can provide the encryption key directly or through a
variable.

To encrypt the text of a file directly, use the Encrypt from file with AES action. This
action works similarly to the Encrypt text with AES action but requires a source file
instead of a text value.

To decrypt a text, use the Decrypt text with AES, and enter the encrypted text and the
encryption key previously used to encrypt it. To decrypt and store a text in a file, deploy
the Decrypt to file with AES and specify a destination path.



Apart from encryption and decryption, the Cryptography group of actions provides
actions to hash values with and without a key. Like the encryption actions, you can hash
values from files using the Hash from file and Hash from file with key actions.



） Important

Passwords entered in designated fields only work on the machine where they were
initially set. This is due to the machine-specific encryption used for direct password
inputs. If the flow is opened on a different machine, these passwords will not be
valid and will need to be re-entered.

Encrypt text with AES
Encrypt a string with AES, using a key and a specified encoding format.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Encoding N/A System default, Unicode The encoding of the text to encrypt
ASCII, Unicode,



Argument Optional Accepts Default Description
Value

Big-endian
Unicode, UTF-8

Text to No Text value The text to encrypt
encrypt

Encryption No Direct encrypted The encryption key to use
key input or Text

value

Padding N/A None, PKCS7, PKCS7 The padding to use for the selected
Zeros, ANSIX923, encryption algorithm
ISO10126

Key size N/A 128 bits, 192 bits, 256 bits The size of the key in bits to use for
256 bits the encryption

Use salt N/A Boolean value False Specifies whether to use salt for
encryption. When this option is
enabled, the randomly generated
salt becomes an output in the form
of a base64 string.

Use N/A Boolean value False Specifies whether to use an
initialization initialization vector. When this option
vector is enabled, the randomly generated

initialization vector becomes an
output in the form of a base64 string

Variables produced
ﾉ Expand table

Argument Type Description

EncryptedText Text The encrypted text for later processing
value

Salt Text The randomly generated salt value for later processing
value

InitializationVector Text The randomly generated initialization vector value for later
value processing

Exceptions



ﾉ Expand table

Exception Description

Failed to encrypt text Indicates that an error occurred during encryption

Decrypt text with AES
Decrypt a string with AES based on a specified key and an encoding format.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Encoding N/A System default, ASCII, Unicode The encoding for the
Unicode, Big-endian decrypted text
Unicode, UTF-8

Text to decrypt No Text value The text to decrypt in the
form of a base64 string

Decryption key No Direct encrypted input The decryption key to use
or Text value

Padding N/A None, PKCS7, Zeros, PKCS7 The padding to use for the
ANSIX923, ISO10126 selected decryption

algorithm

Key size N/A 128 bits, 192 bits, 256 256 bits The size of the key in bits to
bits use for the decryption

Use salt N/A Boolean value False Specifies whether to use salt
for the decryption

Salt No Text value The salt to use for decryption
in the form of a base64 string

Use N/A Boolean value False Specifies whether to use an
initialization initialization vector
vector

Initialization No Text value The initialization vector to
vector use for decryption in the

form of a base64 string



Variables produced

ﾉ Expand table

Argument Type Description

DecryptedText Text value The decrypted text for later processing

Exceptions

ﾉ Expand table

Exception Description

Failed to decrypt text Indicates that an error occurred during decryption

Encrypt from file with AES
Encrypt the contents of a file with AES, using a key and a specified encoding format.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Encoding N/A System default, Unicode The encoding of the file to encrypt
ASCII, Unicode,
Big-endian
Unicode, UTF-8

File to No File The text file that stores the contents
encrypt to encrypt

Encryption No Direct encrypted The encryption key to use
key input or Text

value

Padding N/A None, PKCS7, PKCS7 The padding to use for the selected
Zeros, ANSIX923, encryption algorithm
ISO10126

Key size N/A 128 bits, 192 bits, 256 bits The size of the key in bits to use for
256 bits the encryption



Argument Optional Accepts Default Description
Value

Use salt N/A Boolean value False Specifies whether to use salt for
encryption. When this option is
enabled, the randomly generated
salt becomes an output in the form
of a base64 string.

Use N/A Boolean value False Specifies whether to use an
initialization initialization vector. When this option
vector is enabled, the randomly generated

initialization vector becomes an
output in the form of a base64 string

Variables produced

ﾉ Expand table

Argument Type Description

EncryptedText Text The text of the encrypted file for later processing
value

Salt Text The randomly generated salt value for later processing
value

InitializationVector Text The randomly generated initialization vector value for later
value processing

Exceptions

ﾉ Expand table

Exception Description

File not found Indicates that the file doesn't exist

Failed to encrypt the contents of Indicates that an error occurred while encrypting the
the file contents of the file

Decrypt to file with AES
Decrypt a string to a file with AES based on a specified key and an encoding format.



Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Encoding N/A System default, Unicode The encoding of the text to
ASCII, Unicode, Big- decrypt
endian Unicode,
UTF-8

Text to No Text value The text to decrypt in the form
decrypt of a base64 string

Decryption No Direct encrypted The decryption key to use
key input or Text value

Decrypt to file No File The file to save the decrypted
text into

If file exists N/A Overwrite, Don't Add Specifies what to do in case
decrypt to file, Add sequential the destination file already
sequential suffix suffix exists

Padding N/A None, PKCS7, Zeros, PKCS7 The padding to use for the
ANSIX923, selected decryption algorithm
ISO10126

Key size N/A 128 bits, 192 bits, 256 bits The size of the key in bits to
256 bits use for decryption

Use salt N/A Boolean value False Specifies whether to use salt
for decryption

Salt No Text value The salt to use for decryption
in the form of a base64 string

Use N/A Boolean value False Specifies whether to use an
initialization initialization vector. Enter the
vector initialization vector in the form

of a base64 string

Initialization No Text value The initialization vector to use
vector for decryption

Variables produced



ﾉ Expand table

Argument Type Description

DecryptedFile File The decrypted file for later processing

Exceptions
ﾉ Expand table

Exception Description

Failed to decrypt and store the Indicates that an error occurred while decrypting or storing
contents to a file the contents to the specified file

Hash text
Hash a string, using a specified algorithm and an encoding format.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Hash N/A SHA256, SHA384, SHA512 SHA256 The algorithm to use
algorithm for hashing

Encoding N/A System default, ASCII, Unicode, Unicode The encoding of the
Big-endian Unicode, UTF-8 text to hash

Text to hash No Text value The text to hash

Variables produced

ﾉ Expand table

Argument Type Description

HashedText Text value The hashed text for later processing



Exceptions

ﾉ Expand table

Exception Description

Failed to hash text Indicates that an error occurred during hashing

Hash from file
Hash the contents of a file, using a specified algorithm and an encoding format.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Hash N/A SHA256, SHA384, SHA512 SHA256 The algorithm to use
algorithm for hashing

Encoding N/A System default, ASCII, Unicode, Unicode The encoding of the
Big-endian Unicode, UTF-8 file to hash

File to hash No File The file to hash the
contents of

Variables produced

ﾉ Expand table

Argument Type Description

HashedText Text value The hashed text for later processing

Exceptions

ﾉ Expand table

Exception Description

File not found Indicates that the file doesn't exist



Exception Description

Failed to hash the file Indicates that an error occurred while hashing the contents of the file

Hash text with key
Hash a string with a key, using a specified algorithm and an encoding format.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Hash N/A HMAC SHA256, HMAC SHA384, HMAC The algorithm to use
algorithm HMAC SHA512 SHA256 for hashing

Encoding N/A System default, ASCII, Unicode, Unicode The encoding of the
Big-endian Unicode, UTF-8 text to hash

Text to hash No Text value The text to hash

Hash key No Direct encrypted input or Text The key to hash the
value text with

Variables produced
ﾉ Expand table

Argument Type Description

HashedText Text value The hashed text for later processing

Exceptions

ﾉ Expand table

Exception Description

Failed to hash text with key Indicates that an error occurred during hashing with key



Hash from file with key
Hash the contents of a file with a key, using a specified algorithm and an encoding
format.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Hash N/A HMAC SHA256, HMAC SHA384, HMAC The algorithm to use
algorithm HMAC SHA512 SHA256 for hashing

Encoding N/A System default, ASCII, Unicode, Unicode The encoding of the
Big-endian Unicode, UTF-8 file to hash

File to hash No File The file to hash the
contents of

Hash key No Direct encrypted input or Text The hash key to hash
value the text with

Variables produced

ﾉ Expand table

Argument Type Description

HashedText Text value The hashed text for later processing

Exceptions

ﾉ Expand table

Exception Description

File not found Indicates that the file doesn't exist

Failed to hash the file Indicates that an error occurred while hashing the contents of the file
with key with the specified key



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Windows services actions
Article • 12/16/2022

） Important

To prevent unauthorized access, Windows require administrator rights to manage
services. To handle services using the Windows services actions, run Power
Automate with administrator rights. To find more information regarding running
Power Automate as an administrator, go to Run Power Automate with elevated
rights.

Power Automate allows you to handle Windows services via the available Windows
services actions. With these actions, you can maintain complete control of the operating
system and limit the running services.

These actions allow desktop flows to start, stop, pause, and resume Windows services.
To use any action of this group, you need to enter only the service name.

The following example starts the UIFlowService service.

２ Warning



Windows services are essential to the smooth operation of the operating system.
Managing Windows services incorrectly could adversely affect your machine.

If service
Marks the beginning of a conditional block of actions depending on whether a service is
running, paused, stopped or installed on the computer.

Input parameters
Argument Optional Accepts Default Description

Value

If service N/A Is stopped, Is installed, Isn't installed, Is The state of the
Is running, Is paused running service to check

Service No Text value The name of the
name service to check

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Service not found Indicates that the service can't be found

Can't retrieve status for Indicates that there's a problem retrieving the status of the
service service

Wait for service
Suspend the execution of the automation until a service is running, paused or stopped
on the computer.

Input parameters



Argument Optional Accepts Default Description
Value

Wait for N/A Stop, Start Specifies whether the flow pauses until a certain
service to Start, service starts, stops or pauses

Pause

Service No Text value The name of the service to check
name

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Service not found Indicates that the service can't be found

Can't retrieve status for Indicates that there's a problem retrieving the status of the
service service

Start service
Start a stopped Windows service.

Input parameters
Argument Optional Accepts Default Value Description

Service to start No Text value The name of the service to start

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Service not found Indicates that the service can't be found



Exception Description

Service is already running Indicates that the service is already running

Can't start service Indicates that there's a problem starting the service

Stop service
Stop a running Windows service.

Input parameters
Argument Optional Accepts Default Value Description

Service to stop No Text value The name of the service to stop

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Service not found Indicates that the service can't be found

Service isn't running Indicates that the service isn't running

Can't stop service Indicates that there's a problem stopping the service

Pause service
Pause a running Windows service.

Input parameters
Argument Optional Accepts Default Value Description

Service to pause No Text value The name of the service to pause

Variables produced



This action doesn't produce any variables.

Exceptions
Exception Description

Service not found Indicates that the service can't be found

Service isn't running Indicates that the service isn't running

Can't pause service Indicates that there's a problem pausing the service

Resume service
Resume a paused Windows service.

Input parameters
Argument Optional Accepts Default Value Description

Service to resume No Text value The name of the service to resume

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Service not found Indicates that the service can't be found

Service isn't running Indicates that the service isn't running

Can't resume service Indicates that there's a problem resuming the service



XML actions
Article • 12/16/2022

Power Automate provides the capability to use desktop flows to manage XML attributes
and elements.

To read an XML file, use the Read XML from file action. Specify the path or browse for
the file, and select one of the encoding options.

After selecting a file, use the Execute XPath expression action to run an Xpath query.
The following example uses a produced variable from the Read XML from file action to
specify the document.

To retrieve an attribute from an XML file, use the Get XML attribute action. In the
following example, status is an attribute of client, which is an element of clientlist. The
value will be obtained as a text value.



Similarly, to retrieve element values, use the Get XML element value action. You can
manage elements and attributes using the respective action to get, set or remove XML
attributes or elements.

Read XML from file
Read the contents of an XML file into a variable.

Input parameters
Argument Optional Accepts Default Description

Value

File path No File The file that contains the
XML document to read

Encoding N/A System default, ASCII, Unicode, System The encoding used for the
Unicode big endian, UTF-8 default specified file

Variables produced



Argument Type Description

XmlDocument XML node The variable that holds the read XML document

Exceptions
Exception Description

Directory not found Indicates that the directory doesn't exist

File not found Indicates that the file doesn't exist

Failed to read from file Indicates a problem reading from file

File doesn't contain a valid XML Indicates that the file doesn't contain a valid XML
document document

Write XML to file
Write the contents of an XML node variable into a file.

Input parameters
Argument Optional Accepts Default Description

Value

File path No File The file to write the XML
document into

XML to No Text value The XML node or document
write to write into the file

Encoding N/A System default, ASCII, System The encoding used for the
Unicode, Unicode big default specified file
endian, UTF-8

Format N/A Boolean value True Specifies whether to format
XML the XML

Indentation Yes Numeric value 2 Specifies by how many
per level spaces to indent each level of

the XML

Variables produced



This action doesn't produce any variables.

Exceptions
Exception Description

Invalid directory specified Indicates that the specified directory is invalid

Failed to write XML to file Indicates a problem writing XML to file

Execute XPath expression
Extract values from an XML document based on the provided XPath query.

Input parameters
Argument Optional Accepts Default Description

Value

XML No Text The XML as text or a previously defined variable
document value that contains the XML document to parse
to parse

XPath No Text The XPath expression to execute against the XML
query value document

Get first N/A Boolean False Specifies whether to retrieve a single value (the
value only value first value only) or all the values that match the

provided XPath expression

Variables produced
Argument Type Description

XPathResult XML node The extracted node(s) as an XML node

XPathResults List of XML nodes The extracted node(s) as a list of XML nodes

Exceptions
Exception Description

Invalid XML document provided Indicates that the XML document provided is invalid



Exception Description

Invalid XPath expression provided Indicates that the XPath expression provided is invalid

Get XML element attribute
Get the value of an attribute of an XML element.

Input parameters
Argument Optional Accepts Default Description

Value

XML No XML node The XML document or XML
document element to retrieve its attribute

XPath Yes Text value The XPath expression to locate
query the subelement and retrieve its

attribute

Attribute No Text value The name of the attribute to
name retrieve its value

Get value N/A Text value, Numeric value, Text Specifies the data type for the
as Datetime value, Boolean value attribute value

value

Variables produced
Argument Type Description

XmlAttributeValue Boolean value The retrieved value of the XML attribute

XmlAttributeValue Datetime The retrieved value of the XML attribute

XmlAttributeValue Numeric value The retrieved value of the XML attribute

XmlAttributeValue Text value The retrieved value of the XML attribute

Exceptions
Exception Description

Invalid XPath expression provided Indicates that the XPath expression provided is invalid



Exception Description

XPath expression returns no element Indicates that the XPath expression returns no
element

Attribute not found in element Indicates that the attribute doesn't exist in the
element

Failed to convert attribute value to the Indicates a problem converting the attribute value to
requested data type the requested data type

Set XML element attribute
Set the value of an attribute of an XML element.

Input parameters
Argument Optional Accepts Default Description

Value

XML No XML The XML document or XML element to set its
document node attribute

XPath Yes Text The XPath expression to locate the subelement
query value and set its attribute

Attribute No Text The name of the attribute to set its value
name value

Attribute No Text The new value for the attribute
value value

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Invalid XPath expression provided Indicates that the XPath expression provided is invalid

XPath expression returns no element Indicates that the XPath expression returns no element

Failed to set XML attribute Indicates a problem setting the XML attribute



Remove XML element attribute
Remove an attribute from an XML element.

Input parameters
Argument Optional Accepts Default Description

Value

XML No XML The XML document or XML element to remove
document node its attribute

XPath Yes Text The XPath expression to locate the subelement
query value and remove its attribute

Attribute No Text The name of the attribute to remove
name value

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Invalid XPath expression provided Indicates that the XPath expression provided is invalid

XPath expression returns no element Indicates that the XPath expression returns no element

Attribute not found in element Indicates that the attribute doesn't exist in the element

Failed to remove XML attribute Indicates a problem removing the XML attribute

Get XML element value
Get the value of an XML element.

Input parameters
Argument Optional Accepts Default Description

Value



Argument Optional Accepts Default Description
Value

XML No XML node The XML document or XML
document element to retrieve its value

XPath Yes Text value The XPath expression to locate
query the subelement and retrieve its

value

Get value N/A Text value, Numeric value, Text Specifies the data type for the
as Datetime value, Boolean value XML element value

value

Variables produced
Argument Type Description

XmlElementValue Boolean value The XML element value

XmlElementValue Datetime The XML element value

XmlElementValue Numeric value The XML element value

XmlElementValue Text value The XML element value

Exceptions
Exception Description

Invalid XPath expression provided Indicates that the XPath expression provided is invalid

XPath expression returns no element Indicates that the XPath expression returns no
element

Failed to convert element value to the Indicates a problem converting the element value to
requested data type the requested data type

Set XML element value
Set the value of an XML element.

Input parameters



Argument Optional Accepts Default Description
Value

XML No XML The XML document or XML element to retrieve
document node it value

XPath query Yes Text The XPath expression to locate the subelement
value and retrieve its value

XML element No Text The new value for the XML element
value value

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Invalid XPath expression provided Indicates that the XPath expression provided is invalid

XPath expression returns no element Indicates that the XPath expression returns no element

Failed to set element value Indicates a problem setting the element value

Insert XML element
Insert a new XML element into an XML document.

Input parameters
Argument Optional Accepts Default Description

Value

XML No XML The XML document to insert the new XML
document node element

XPath query No Text The XPath expression to locate the parent XML
value element and insert the new element into it

XML No XML The new XML element to insert into the XML
element to node document
insert



Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Invalid XPath expression provided Indicates that the XPath expression provided is invalid

XPath expression returns no element Indicates that the XPath expression returns no element

Failed to insert XML element Indicates a problem inserting the XML element

Remove XML element
Remove one or more XML elements from an XML document.

Input parameters
Argument Optional Accepts Default Description

Value

XML No XML The XML document that contains the XML
document node element(s) to remove

XPath No Text The XPath expression to locate the element(s)
query value to remove

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Invalid XPath expression provided Indicates that the XPath expression provided is invalid

Failed to remove XML element Indicates a problem removing the XML element



FTP
Article • 12/16/2022

Use the FTP action group to upload and download files and manipulate directories on
FTP servers.

To establish an FTP connection, use the Open FTP connection action. The following
example has a specified host, port, and credentials. Additionally, the set timeout makes
the action fail if the connection isn't established on time.

Download files using the Download file(s) from FTP action. The following example
shows the connection variable in use and the selected destination folder. The remote file
has also been specified and set to overwrite existing files in the same location.



Upload files using the Upload file(s) to FTP action and specifying the file and the
remote location.

Open FTP connection
This action establishes a specific connection to a remote FTP server, and stores that
connection as a variable for later use.

Input parameters
Argument Optional Accepts Default Description

Value

Host No Text value Enter the FTP server address here.

Port Yes Numeric value 21 Enter the FTP server port here.

Active N/A Boolean value False Specify the mode of the connection
mode

Username No Text value Specify the username of the FTP account to
use



Argument Optional Accepts Default Description
Value

Password Yes Direct Specify the password of the FTP account to
encrypted use
input or Text
value

Timeout Yes Numeric value 10 Set the time in seconds that you want to
wait for the connection to be established
before the action fails

Variables produced
Argument Type Description

FTPConnection FTP connection The FTP connection

Exceptions
Exception Description

Login failure error Indicated that the login failed

Connection error Indicates that there's a problem with the connection

List FTP directory
This action returns the subdirectories and files contained in the current directory of an
FTP connection.

Input parameters
Argument Optional Accepts Default Value Description

Connection No FTP connection The FTP connection

Path Yes Text value The path that you want to list.

Variables produced
Argument Type Description



Argument Type Description

Directories List of FTP directories The listed directories

Files List of FTP files The listed files

Exceptions
Exception Description

Listing error Indicates that the listing of the folder couldn't be performed

Not connected error Indicates that there's no open connection with the FTP server

Directory doesn't exist error Indicates that the directory couldn't be found

Open secure FTP connection
This action establishes a specific secure connection to a remote FTP server, and stores
that connection as a variable for later use.

Input parameters
Argument Optional Accepts Default Description

Value

Host No Text value Enter the FTP server address
here.

Port Yes Numeric value 22 Enter the FTP server port here.

Active mode N/A Boolean value True Specify the mode of the
connection

Secure FTP N/A SFTP, FTPS explicit, SFTP Choose the FTP protocol you
Protocol FTPS implicit wish to use to encrypt your

connection

Authentication N/A Username and Username Choose the method you wish to
method password, Private and use to authenticate yourself on

key, Private key and password the FTP server
passphrase

User name No Text value Specify the username of the FTP
account to use



Argument Optional Accepts Default Description
Value

Password Yes Direct encrypted Specify the password of the FTP
input or Text value account you wish to use

Path to private No Text value Enter the file path to the
key private-key to be used for

authentication

Private key Yes Direct encrypted Enter a variable containing the
pass phrase input or Text value private-key pass phrase here

Timeout Yes Numeric value 10 Set the time in seconds that you
want to wait for the connection
to be established before the
action fails

Variables produced
Argument Type Description

SftpConnection FTP connection SFTP connection

Exceptions
Exception Description

Login failure error Indicated that the login failed

Connection error Indicates that there's a problem with the connection

Close connection
This action closes an open FTP connection.

Input parameters
Argument Optional Accepts Default Value Description

Connection No FTP connection The FTP connection

Variables produced



This action doesn't produce any variables.

Exceptions
Exception Description

Not connected error Indicates that there's no open connection with the FTP server

Change working directory
This action sets the current working directory for an FTP connection.

Input parameters
Argument Optional Accepts Default Description

Value

Connection No FTP The FTP connection
connection

Set working No Text value Set the path to be set as the
directory to working directory

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Not connected error Indicates that there's no open connection with the FTP
server

Directory doesn't exist error Indicates that the directory couldn't be found

Can't change working directory Indicates that it isn't possible to change the working
error directory

Download file(s) from FTP
Downloads one or more files from an FTP server.



Input parameters
Argument Optional Accepts Default Description

Value

FTP No FTP The FTP connection to work with. This
connection connection variable must have been previously

specified in an Open FTP connection action

Download No Folder The folder to be the destination of the
into folder file(s) that will be downloaded

File(s) to No List of FTP The file(s) to download
download files

Transfer N/A Auto, Binary, Auto Enter ASCII or binary to specify the method
type ASCII for downloading a single file. If the file type

is uncertain, or more than one is
downloaded, choose Auto to follow the
transfer rules specified in options

If file exists N/A Overwrite, Overwrite Specify what to do if the file already exists.
Do not Overwrite writes over the original file so
download, you can't access it anymore, and download
Download with unique name adds an underscore and
with unique a sequential number to the end
name

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Not connected error Indicates that there's no open connection with the FTP server

Remote file doesn't exist error Indicates that the file doesn't exist on the FTP server

Directory doesn't exist error Indicates that the directory couldn't be found

FTP connection aborted error Indicates that the FTP connection was aborted

Can't download file error Indicates that it wasn't possible to download the file



Download folder(s) from FTP
Downloads one or more folders from an FTP server.

Input parameters
Argument Optional Accepts Default Description

Value

FTP No FTP The FTP connection to work with. This variable
connection connection must have been previously specified in an

Open FTP connection action

Folder(s) to No List of FTP The name of the folder path(s), or FTP folder(s)
download directories to download

Download No Folder The full path of the destination of the FTP
into local folder(s) you're downloading
folder

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Not connected error Indicates that there's no open connection with the FTP
server

Remote directory doesn't exist Indicates that the directory doesn't exist on the FTP server
error

Directory doesn't exist error Indicates that the directory couldn't be found

FTP connection aborted error Indicates that the FTP connection was aborted

Can't download directory error Indicates that it wasn't possible to download the directory

Upload File(s) to FTP
Uploads one or more files to an FTP server.



Input parameters
Argument Optional Accepts Default Description

Value

FTP No FTP The FTP connection to work with. This
connection connection variable must have been previously specified

in an Open FTP connection action

File(s) to No List of Files The file(s) to upload
upload

Remote Yes Text value The location where the files should be
location uploaded

Transfer N/A Auto, Binary, Auto Enter ASCII or binary to specify the method
type ASCII for downloading a single file. If you're not

sure what type the file will be, or if you're
downloading more than one, choose Auto
to follow the transfer rules specified in
Options

If file exists N/A Overwrite, Overwrite Specify what to do if the file already exists.
Do not Overwrite writes over the original file so you
download, can't access it anymore, and Download with
Download Unique Name adds an underscore and a
with unique sequential number to the end
name

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Not connected error Indicates that there's no open connection with the FTP server

File not found error Indicates that the file wasn't found

FTP connection aborted error Indicates that the FTP connection was aborted

Upload file error Indicates that the file couldn't be uploaded

Upload folder(s) to FTP



Uploads one or more folders to an FTP server.

Input parameters
Argument Optional Accepts Default Description

Value

FTP No FTP The FTP connection to work with. This variable
connection connection must have been previously specified in an Open

FTP connection action

Folder(s) No List of The folder(s) to upload. The folders being
to upload Folders uploaded shouldn't already exist within the

active directory of the FTP server

Remote No Text value The location where the folders should be
location uploaded

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Not connected error Indicates that there's no open connection with the FTP
server

Remote directory doesn't exist Indicates that the directory doesn't exist on the FTP server
error

FTP connection aborted error Indicates that the FTP connection was aborted

Upload directory error Indicates that the directory couldn't be uploaded

Delete FTP file
Deletes one or more files from an FTP server.

Input parameters
Argument Optional Accepts Default Description

Value



Argument Optional Accepts Default Description
Value

FTP No FTP The FTP connection to work with. This variable
connection connection must have been previously specified in an Open

FTP connection action

Files to No List of FTP The files to delete
delete files

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Not connected error Indicates that there's no open connection with the FTP server

File not found error Indicates that the file wasn't found

Can't delete file error Indicates that the deletion of the file wasn't possible

Rename FTP File
Renames a file that resides on an FTP server.

Input parameters
Argument Optional Accepts Default Description

Value

FTP No FTP The FTP connection to work with. This variable
connection connection must have been previously specified in an Open

FTP connection action

File to No FTP file The file to rename
rename

New file No Text value The new name for the file. If you enter a name
name with a path, the file will also be moved to that

location. If the location doesn't exist, it will
throw an exception



Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Not connected error Indicates that there's no open connection with the FTP server

Can't rename file error Indicates that it wasn't possible to rename the file

File not found error Indicates that the file wasn't found

Create FTP directory
Creates a directory on an FTP server.

Input parameters
Argument Optional Accepts Default Description

Value

FTP No FTP The FTP connection to work with. This variable
connection connection must have been previously specified in an Open

FTP connection action

New No FTP The new directory. If a path is specified, all of
directory directory the new folders leading to the new directory

will be created

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Access denied error Indicates that this account doesn't have access for an operation

File exists error Indicates that the file already exists



Exception Description

Create directory error Indicates that it wasn't possible creating the directory

Directory doesn't exist error Indicates that the directory couldn't be found

Not connected error Indicates that there's no open connection with the FTP server

Delete FTP directory
Deletes a directory from an FTP server.

Input parameters
Argument Optional Accepts Default Description

Value

FTP No FTP The FTP connection to work with. This variable
connection connection must have been previously specified in an Open

FTP connection action

Directory No FTP The folder to be deleted. Everything in the
to delete directory folder will be deleted as well

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Delete directory error Indicates that it wasn't possible to delete the directory

Remote directory doesn't exist Indicates that the directory doesn't exist on the FTP server
error

Working directory change error Indicates that the working directory couldn't be changed

Not connected error Indicates that there's no open connection with the FTP
server

Invoke FTP command



Invokes the given literal FTP command on the server.

Input parameters
Argument Optional Accepts Default Description

Value

FTP No FTP The FTP connection to work with. This variable
connection connection must have been previously specified in an open

FTP connection action

FTP No Text value The command to run along with any
command arguments. For example, you could run FEAT, or

CHMOD here

Valid reply Yes Text value The code(s) that could be returned by the
code(s) command, separated by semi-colon. If the FTP

command returns a code that wasn't entered
here, this action will throw an exception. Only
applies over simple FTP or FTPS connections

Variables produced
Argument Type Description

ReplyCode Text The actual code that was returned. Only applies over simple FTP or FTPS
value connections

ReplyText Text The text returned by the FTP server
value

Exceptions
Exception Description

Invoke command error Indicates that an error occurred while invoking an FTP command

Not connected error Indicates that there's no open connection with the FTP server

Synchronize directories
Synchronize the files and subdirectories of a given Folder with a given remote FTP
directory.



Input parameters
Argument Optional Accepts Default Description

Value

FTP connection No FTP The FTP connection to work with.
connection This variable must have been

previously specified in an Open FTP
connection action

Synchronization N/A Remote -> Remote -> Direction of the Synchronization
direction local local method. Whether the local folder

(Download), (Download) will be synchronized to the remote
Local -> directory (DOWNLOAD) or the
remote remote directory will be
(Upload) synchronized to the local folder

(UPLOAD)

Files to sync N/A All files, Only All files Choose whether you want to
files synchronize all files, or you want to
matching the use a file filter to include or exclude
file filter, Only a specific set of files
files not
matching the
file filter

File filter No Text value * File-name pattern that controls
which files will be included or
excluded. This option allows
wildcards such as ".txt",
"document?.doc". The option also
allows for multiple filters by using
coma as a separator,
".txt,*.pdf,document?"

Local folder No Folder Name of the local folder to be
synchronized

FTP directory Yes FTP directory / Name of the FTP directory to be
synchronized

Delete if source N/A Boolean False This option will delete a file or folder
is absent value that exists in the target directory

and not the source.

Include N/A Boolean True This option will include
subdirectories value subdirectories in the synchronization

process.



Argument Optional Accepts Default Description
Value

Time difference Yes Numeric 0 Time difference in hours of the
in hours value remote server in case it operates on

a different Time Zone.

Time difference Yes Numeric 0 Time difference in Minutes of the
in minutes value remote server in case it operates on

a different Time Zone.

Time difference N/A Boolean True Specify whether the server's time
ahead value zone is ahead or not.

Variables produced
Argument Type Description

FtpFilesAdded List of List of FTP files that initially existed in the source and after the
FTP synchronization process were added to the target.
files

FtpFilesModified List of List of FTP files that initially existed in both the source and the target
FTP and after the synchronization process were added to the target.
files

FtpFilesDeleted List of List of FTP files that initially existed in the target directory and after
FTP the synchronization process were deleted.
files

FilesAdded List of List of files that initially existed in the source and after the
Files synchronization process were added to the target.

FilesModified List of List of files that initially existed in both the source and the target and
Files after the synchronization process were added to the target.

FilesDeleted List of List of files that initially existed in the target directory and after the
Files synchronization process were deleted.

Exceptions
Exception Description

Listing error Indicates that the listing of the folder couldn't be performed

Not connected error Indicates that there's no open connection with the FTP server

File not found error Indicates that the file wasn't found



Exception Description

FTP connection aborted Indicates that the FTP connection was aborted
error

Upload file error Indicates that the file couldn't be uploaded

Remote file doesn't exist Indicates that the file doesn't exist on the FTP server
error

Can't download file error Indicates that it wasn't possible to download the file

Delete directory error Indicates that it wasn't possible to delete the directory

Synchronization failed Indicates that the synchronization process failed due to an
error unexpected error.



CyberArk actions
Article • 05/30/2024

CyberArk offers an identity security platform that secures human and machine identities
from end-to-end. Power Automate enables you to retrieve credentials from CyberArk
through the Get password from CyberArk action.

７ Note

To retrieve credentials from CyberArk, Power Automate issues web requests to
CyberArk’s Central Credential Provider web service (AIMWebService).

To find the required information to populate the action, see the following instructions:

Application ID: To find the application ID, open CyberArk Password Vault on a web
browser and navigate to the Applications tab. Select Components, open the
Private Ark application, and then select the desired Vault. You can add Owners
here.

Safe: Populate the name of the safe displayed in PrivateArk Client.

Folder and Object: Select a safe in PrivateArk Client, and populate the folder name
displayed on the left pane and the object name displayed in the main list.



Get password from CyberArk
Retrieves a password for a specific application from CyberArk.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Server No Text value The base URI for the web request to
address connect. For example,



Argument Optional Accepts Default Description
Value

https://yourservice.skytap.com:111

Application No Text value The application ID to use for the web
ID request.

To find the application ID, open CyberArk
Password Vault on a web browser and
navigate to the Applications tab. Select
Components, open the Private Ark
application, and then select the desired
Vault. You can add Owners here.

Safe No Text value The safe on CyberArk in which the
application belongs

Folder No Text value The folder necessary for the web request
query

Object No Text value The object necessary for the web request
query

Extra data Yes Text value The extra data (if any) for the web request's
query

Accept N/A Boolean False Specifies whether to accept untrusted
untrusted value certificates
certificates

Certificate N/A Don't use Don't use Specifies how to load (if needed) the
location certificate, certificate certificate for the request

Load
certificate
from
Windows
Store, Load
certificate
from file

Use only N/A Boolean False Specifies whether to load only valid
valid value certificates from the store
certificates

Store No Text value The path of the certificate in the certificate
certificate store. The certificate is represented by its
path serial number. The path should use the

following format:

(local path to certificate)/(certificate serial)



Argument Optional Accepts Default Description
Value

Certificates No File The path of the certificate.
path

Certificate No Direct The password for the certificate file
password encrypted

input or Text
value

Timeout Yes Numeric 30 The waiting time (in seconds) to get results
value from CyberArk

Variables produced

ﾉ Expand table

Argument Type Description

JSONResponse Custom object The API response result

CyberArkPassword Encrypted value The password retrieved from CyberArk

Exceptions

ﾉ Expand table

Exception Description

Failed to send web request Indicates a problem sending the web request

Timeout expired Indicates that the request timed out

Error response from web request Indicates that the web request returned an error response

Known issues
NTLM Authentication is currently not supported for web requests in Power
Automate for desktop.

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Active Directory actions
Article • 12/16/2022

Active Directory actions require a connection to an Active Directory server. Establish the
connection using the Connect to server action and an LDAP path. The LDAP path
specifies the domain controllers and should have the following format:

LDAP

LDAP://DC=contoso,DC=demo


If you work with groups, objects, or users, you need to specify also their location. The
Location field specifies the container and the domain controller, and should have the
following format:

LDAP

CN=Users,DC=contoso,DC=demo


After getting all the distinguished names using the dsquery user command, enter the
distinguished name in the following format. For this example, the username is nvarga.

LDAP

CN=nvarga,CN=Users,DC=contoso,DC=demo


If the container name contains a comma, you should enclose the name within double
quotes. For example CN=Varga, Norbert should be:

LDAP

CN="Varga, Norbert",DC=contoso,DC=com


Create group
Creates a group in the Active Directory.

Input parameters



Argument Optional Accepts Default Description
Value

Parent directory No Active Directory The parent entry of the Active
entry entry Directory server

Group name No Text value The name of the newly created
group

Location Yes Text value The location that the group will be
created in

Description Yes Text value The description for the group

Group scope N/A Local, Global, Global The scope of the group in the
Universal Active Directory

Group type N/A Security, Security The type of the group
Distribution

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Authentication error Indicates an error with the user's authentication

Invalid operation Indicates an invalid operation error

The server isn't Indicates that the Active Directory server isn't operational
operational

Unauthorized access Indicates that an authorization error occurred

Active Directory entry Indicates that the Active Directory entry given isn't found on the
not found Active Directory server

Object already exists Indicates that an object with the specified name already exists in the
Active Directory

Active Directory error General Active Directory error

Get group info



Gets information about a group from the Active Directory server.

Input parameters
Argument Optional Accepts Default Description

Value

Parent No Active The parent entry of the Active
directory entry Directory entry Directory server

Distinguished No Text value The distinguished name of the Active
name Directory entry

Variables produced
Argument Type Description

GroupInfo Group info The group's info

Exceptions
Exception Description

Authentication error Indicates an error with the user's authentication

Invalid operation Indicates an invalid operation error

The server isn't Indicates that the Active Directory server isn't operational
operational

Unauthorized access Indicates that an authorization error occurred

Active Directory entry Indicates that the Active Directory entry given isn't found on the
not found Active Directory server

Object doesn't exist on Indicates that the object doesn't exist in the Active Directory server
server

Active Directory error General Active Directory error

Get group members
Gets the members of a group in the Active Directory.



Input parameters
Argument Optional Accepts Default Description

Value

Parent No Active The parent entry of the Active
directory entry Directory entry Directory server

Distinguished No Text value The distinguished name of the Active
name Directory entry

Variables produced
Argument Type Description

GroupMembers List of Group members The variable that holds the members of the group

Exceptions
Exception Description

Authentication error Indicates an error with the user's authentication

Invalid operation Indicates an invalid operation error

The server isn't Indicates that the Active Directory server isn't operational
operational

Unauthorized access Indicates that an authorization error occurred

Active Directory entry Indicates that the Active Directory entry given isn't found on the
not found Active Directory server

Object doesn't exist on Indicates that the object doesn't exist in the Active Directory server
server

Active Directory error General Active Directory error

Modify group
Modifies a group in the Active Directory.

Input parameters



Argument Optional Accepts Default Description
Value

Parent No Active Directory entry The parent entry of the
directory Active Directory server
entry

Distinguished No Text value The distinguished name of
name the Active Directory entry

Operation N/A Rename group, Delete Rename Select the operation to
group, Add user, Remove group perform
user

New name No Text value The new name for the
group

User No Text value Specify the user's
distinguished distinguished name
name

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Authentication error Indicates an error with the user's authentication

Invalid operation Indicates an invalid operation error

The server isn't Indicates that the Active Directory server isn't operational
operational

Unauthorized access Indicates that an authorization error occurred

Active Directory entry Indicates that the Active Directory entry given isn't found on the
not found Active Directory server

Object doesn't exist on Indicates that the object doesn't exist in the Active Directory server
server

Object already exists Indicates that an object with the specified name already exists in the
Active Directory

Active Directory error General Active Directory error



Example
The following example uses the Modify group action to add the user nvarga to the
RPATest Active Directory group.

Create object
Creates an object in the Active Directory.

Input parameters
Argument Optional Accepts Default Description

Value

Parent No Active Directory The parent entry of the Active
directory entry entry Directory server

Location Yes Text value The location that the group will
be created in

Object type N/A Computer, Computer The type of the object
Organizational unit

Object name No Text value The name of the newly created
object



Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Authentication error Indicates an error with the user's authentication

Invalid operation Indicates an invalid operation error

The server isn't Indicates that the Active Directory server isn't operational
operational

Unauthorized access Indicates that an authorization error occurred

Active Directory entry Indicates that the Active Directory entry given isn't found on the
not found Active Directory server

Object already exists Indicates that an object with the specified name already exists in the
Active Directory

Invalid attribute syntax Indicates that a given attribute is invalid

Active Directory error General Active Directory error

Delete object
Deletes an object in the Active Directory.

Input parameters
Argument Optional Accepts Default Description

Value

Parent No Active The parent entry of the Active
directory entry Directory entry Directory server

Distinguished No Text value The distinguished name of the Active
name Directory entry

Variables produced
This action doesn't produce any variables.



Exceptions
Exception Description

Authentication error Indicates an error with the user's authentication

Invalid operation Indicates an invalid operation error

The server isn't Indicates that the Active Directory server isn't operational
operational

Unauthorized access Indicates that an authorization error occurred

Active Directory entry Indicates that the Active Directory entry given isn't found on the
not found Active Directory server

Object doesn't exist on Indicates that the object doesn't exist in the Active Directory server
server

Active Directory error General Active Directory error

Move object
Moves an object in the Active Directory.

Input parameters
Argument Optional Accepts Default Description

Value

Parent No Active The parent entry of the Active
directory entry Directory entry Directory server

Distinguished No Text value The distinguished name of the Active
name Directory entry

Move to No Text value The location for the object to be
location moved to

Variables produced
This action doesn't produce any variables.

Exceptions



Exception Description

Authentication error Indicates an error with the user's authentication

Invalid operation Indicates an invalid operation error

The server isn't Indicates that the Active Directory server isn't operational
operational

Unauthorized access Indicates that an authorization error occurred

Active Directory entry Indicates that the Active Directory entry given isn't found on the
not found Active Directory server

Object doesn't exist on Indicates that the object doesn't exist in the Active Directory server
server

Active Directory error General Active Directory error

Location can't be empty Indicates that an Active Directory object location is empty

Rename object
Renames an object in the Active Directory.

Input parameters
Argument Optional Accepts Default Description

Value

Parent No Active The parent entry of the Active
directory entry Directory entry Directory server

Distinguished No Text value The distinguished name of the Active
name Directory entry

New name No Text value Type the new name for the group

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description



Exception Description

Authentication error Indicates an error with the user's authentication

Invalid operation Indicates an invalid operation error

The server isn't Indicates that the Active Directory server isn't operational
operational

Unauthorized access Indicates that an authorization error occurred

Active Directory entry Indicates that the Active Directory entry given isn't found on the
not found Active Directory server

Object doesn't exist on Indicates that the object doesn't exist in the Active Directory server
server

Object already exists Indicates that an object with the specified name already exists in the
Active Directory

Active Directory error General Active Directory error

Create user
Creates a user in the Active Directory.

Input parameters
Argument Optional Accepts Default Description

Value

Parent No Active Directory entry The parent entry of the Active
directory entry Directory server

Location Yes Text value The location that the group will
be created in

First name No Text value The first name of the user

Initials Yes Text value The initials of the user

Last name Yes Text value The last name of the user

Username No Text value The username of the user

Password No Direct encrypted The password of the user
input or Text value



Argument Optional Accepts Default Description
Value

Password N/A Boolean value False Specify whether the password of
never expires the user will expire

Disabled N/A Boolean value False Specify whether the account will
account be disabled

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Authentication error Indicates an error with the user's authentication

Invalid operation Indicates an invalid operation error

The server isn't Indicates that the Active Directory server isn't operational
operational

Unauthorized access Indicates that an authorization error occurred

Active Directory entry Indicates that the Active Directory entry given isn't found on the
not found Active Directory server

Object already exists Indicates that an object with the specified name already exists in the
Active Directory

Couldn't set or update Indicates a problem setting or updating the user's password
password

Active Directory error General Active Directory error

Example
The following example creates a new user. The user's actual name is Norbert Varga, and
the username is nvarga. The presented configurations create the user in the Users
container and specify the extra controllers contoso and demo.



Get user info
Gets a user's information in the Active Directory.

Input parameters
Argument Optional Accepts Default Description

Value

Parent No Active The parent entry of the Active
directory entry Directory entry Directory server

Distinguished No Text value The distinguished name of the Active
name Directory entry



Variables produced
Argument Type Description

UserInfo User info The user's info

Exceptions
Exception Description

Authentication error Indicates an error with the user's authentication

Invalid operation Indicates an invalid operation error

The server isn't Indicates that the Active Directory server isn't operational
operational

Unauthorized access Indicates that an authorization error occurred

Active Directory entry Indicates that the Active Directory entry given isn't found on the
not found Active Directory server

Object doesn't exist on Indicates that the object doesn't exist in the Active Directory server
server

Active Directory error General Active Directory error

Modify user
Modify a user in the Active Directory.

Input parameters
Argument Optional Accepts Default Value Description

Parent No Active Directory entry The parent entry of
directory the Active
entry Directory server

Distinguished No Text value The distinguished
name name of the Active

Directory entry

Operation N/A Enable/disable user, Rename Enable/disable Select the
user, Delete user, Reset user operation to be
password performed



Argument Optional Accepts Default Value Description

Enable user N/A Boolean value False Enable or disable
the user

New name No Text value Type the new
name for the
group

New No Direct encrypted input or Text Type the new
password value password for the

group

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Authentication error Indicates an error with the user's authentication

Invalid operation Indicates an invalid operation error

The server isn't Indicates that the Active Directory server isn't operational
operational

Unauthorized access Indicates that an authorization error occurred

Active Directory entry Indicates that the Active Directory entry given isn't found on the
not found Active Directory server

Object doesn't exist on Indicates that the object doesn't exist in the Active Directory server
server

Object already exists Indicates that an object with the specified name already exists in the
Active Directory

Invalid attribute syntax Indicates that a given attribute is invalid

Active Directory error General Active Directory error

Couldn't set or update Indicates a problem setting or updating the user's password
password

Unlock user



Unlocks an Active Directory user.

Input parameters
Argument Optional Accepts Default Description

Value

Parent No Active The parent entry of the Active
directory entry Directory entry Directory server

Distinguished No Text value The distinguished name of the Active
name Directory entry

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Authentication error Indicates an error with the user's authentication

Invalid operation Indicates an invalid operation error

The server isn't Indicates that the Active Directory server isn't operational
operational

Unauthorized access Indicates that an authorization error occurred

Active Directory entry Indicates that the Active Directory entry given isn't found on the
not found Active Directory server

Object doesn't exist on Indicates that the object doesn't exist in the Active Directory server
server

Active Directory error General Active Directory error

Update user info
Updates a user's information in the Active Directory.

Input parameters



Argument Optional Accepts Default Description
Value

Parent No Active Directory entry The parent
directory entry of the
entry Active

Directory
server

Distinguished No Text value The
name distinguished

name of the
Active
Directory
entry

Display name Yes Text value The display
name of the
user

First name Yes Text value The first
name of the
user

Initials Yes Text value The initials of
the user

Last name Yes Text value The last
name of the
user

Title Yes Text value The title of
the user

The email of Yes Text value The email of
the user the user

The company Yes Text value The
of the user company of

the user

Telephone Yes Text value The
number telephone

number of
the user

Extension Yes Text value The
extension of
the user



Argument Optional Accepts Default Description
Value

City Yes Text value The city of
the user

Postal code Yes Text value The postal
code of the
user

State Yes Text value The state of
the user

Country N/A Afghanistan, Åland Islands, Albania, None The country
Algeria, American Samoa, Andorra, Angola, of the user
Anguilla, Antarctica, Antigua and Barbuda, as a two-
Argentina, Armenia, Aruba, Australia, letter code
Austria, Azerbaijan, Bahamas, Bahrain, (ISO 3166-1
Bangladesh, Barbados, Belarus, Belgium, alpha-2)
Belize, Benin, Bermuda, Bhutan, State of
Bolivia Plurinational, Bonaire, Bosnia and
Herzegovina, Botswana, Bouvet Island,
Brazil, British Indian Ocean Territory, Brunei
Darussalam, Bulgaria, Burkina Faso,
Burundi, Cabo Verde, Cambodia,
Cameroon, Canada, Cayman Islands,
Central African Republic, Chad, Chile,
China, Christmas Island, Cocos (Keeling)
Islands, Colombia, Comoros, Congo,
Democratic Republic of the Congo, Cook
Islands, Costa Rica, Côte d'Ivoire, Croatia,
Cuba, Curaçao, Cyprus, Czech Republic,
Denmark, Djibouti, Dominica, Dominican
Republic, Ecuador, Egypt, El Salvador,
Equatorial Guinea, Eritrea, Estonia, Ethiopia,
Falkland Islands (Malvinas), Faroe Islands,
Fiji, Finland, France, French Guiana, French
Polynesia, French Southern Territories,
Gabon, Gambia, Georgia, Germany, Ghana,
Gibraltar, Greece, Greenland, Grenada,
Guadeloupe, Guam, Guatemala, Guernsey,
Guinea, Guinea-Bissau, Guyana, Haiti,
Heard Island and McDonald Islands, Holy
See, Honduras, Hong Kong Special
Administrative Region, Hungary, Iceland,
India, Indonesia, Islamic Republic of Iran,
Iraq, Ireland, Isle of Man, Israel, Italy,
Jamaica, Japan, Jersey, Jordan, Kazakhstan,
Kenya, Kiribati, Democratic Peoples
Republic of Korea, Republic of Korea,



Argument Optional Accepts Default Description
Value

Kuwait, Kyrgyzstan, Lao People's
Democratic Republic, Latvia, Lebanon,
Lesotho, Liberia, Libya, Liechtenstein,
Lithuania, Luxembourg, Macao Special
Administrative Region, North Macedonia,
Madagascar, Malawi, Malaysia, Maldives,
Mali, Malta, Marshall Islands, Martinique,
Mauritania, Mauritius, Mayotte, Mexico,
Micronesia, Moldova, Monaco, Mongolia,
Montenegro, Montserrat, Morocco,
Mozambique, Myanmar, Namibia, Nauru,
Nepal, Netherlands, New Caledonia, New
Zealand, Nicaragua, Niger, Nigeria, Niue,
Norfolk Island, Northern Mariana Islands,
Norway, Oman, Pakistan, Palau, Palestine,
Panama, Papua New Guinea, Paraguay,
Peru, Philippines, Pitcairn, Poland, Portugal,
Puerto Rico, Qatar, Réunion, Romania,
Russia, Rwanda, Saint Barthélemy, Saint
Helena, Saint Kitts and Nevis, Saint Lucia,
Saint Martin (French part), Saint Pierre and
Miquelon, Saint Vincent and the
Grenadines, Samoa, San Marino, Sao Tome
and Principe, Saudi Arabia, Senegal, Serbia,
Seychelles, Sierra Leone, Singapore, Sint
Maarten (Dutch part), Slovakia, Slovenia,
Solomon Islands, Somalia, South Africa,
South Georgia and the South Sandwich
Islands, South Sudan, Spain, Sri Lanka,
Sudan, Suriname, Svalbard and Jan Mayen,
Swaziland, Sweden, Switzerland, Syrian
Arab Republic, Taiwan, Tajikistan, Tanzania,
Thailand, Timor-Leste, Togo, Tokelau,
Tonga, Trinidad and Tobago, Tunisia,
Türkiye, Turkmenistan, Turks and Caicos
Islands, Tuvalu, Uganda, Ukraine, United
Arab Emirates, United Kingdom of Great
Britain and Northern Ireland, United States
of America, United States Minor Outlying
Islands, Uruguay, Uzbekistan, Vanuatu,
Bolivarian Republic of Venezuela, Vietnam,
Virgin Islands (British), Virgin Islands (U.S.),
Wallis and Futuna, Yemen, Zambia,
Zimbabwe, None



Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Authentication error Indicates an error with the user's authentication

Invalid operation Indicates an invalid operation error

The server isn't Indicates that the Active Directory server isn't operational
operational

Unauthorized access Indicates that an authorization error occurred

Active Directory entry Indicates that the Active Directory entry given isn't found on the
not found Active Directory server

Object doesn't exist on Indicates that the object doesn't exist in the Active Directory server
server

Couldn't set or update Indicates a problem setting or updating the user's password
password

Active Directory error General Active Directory error

Connect to server
Connects to an Active Directory server.

Input parameters
Argument Optional Accepts Default Description

Value

LDAP path No Text value The LDAP path
of the Active
Directory
server



Argument Optional Accepts Default Description
Value

Use N/A Boolean value False Specify
authentication whether

authentication
is needed to
connect to the
server

Username No Text value The user's
username

Password No Direct encrypted input or Text value The user's
password

Authentication N/A None, Secure, Encryption, Secure Secure Specify the
type sockets layer, Read-only server, type of

Anonymous, Fast bind, Signing, Sealing, authentication
Delegation, Server bind to be used

Variables produced
Argument Type Description

ParentDirectoryEntry Active The parent of the Active Directory entry for use with later
Directory Active Directory actions
entry

Exceptions
Exception Description

Authentication error Indicates an error with the user's authentication

Unauthorized access Indicates that an authorization error occurred

The server isn't operational Indicates that the Active Directory server isn't operational

Invalid operation Indicates an invalid operation error

Active Directory error General Active Directory error

Close connection
Closes the connection with the Active Directory server.



Input parameters
Argument Optional Accepts Default Description

Value

Parent directory No Active Directory The parent entry of the Active
entry entry Directory server

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.



AWS actions
Article • 12/16/2022

） Important

You need an active AWS subscription to deploy AWS actions in your desktop flows.

Power Automate enables users to handle EC2 instances, volumes, and snapshots
through the AWS group of actions.

Before deploying any AWS action, create a new EC2 session using the Create EC2
session action.

To use a credentials file for authentication, disable Access keys and populate Profile
name and Profile location. If you don't want to reference a profile name explicitly,
choose default in Profile name to use the default profile.

Alternatively, enable Access keys and populate the access key ID, the secret access key,
and the region constraint specifying the endpoint.



After creating the session and deploying all the needed AWS actions, use the End EC2
session action to terminate the EC2 session.

Start EC2 instance
Start EC2 instance(s).



Input parameters
Argument Optional Accepts Default Value Description

EC2 client No EC2 client The EC2 client

Instance IDs No List of Text values The instance IDs to start

Variables produced
Argument Type Description

StartingEc2Instances List of Instance state The returned information for the started
changes instances

Exceptions
Exception Description

Authentication failed Indicates that the provided credentials couldn't be validated

Unauthorized Indicates that an unauthorized operation was requested
operation

Invalid instance ID Indicates that either the specified instance ID is malformed, or that the
specified instance doesn't exist

Insufficient capacity Indicates that there isn't enough capacity to fulfill the request

Amazon service Indicates that the request to AWS failed
request failed

Stop EC2 instance
Stop EC2 instance(s).

Input parameters
Argument Optional Accepts Default Description

Value

EC2 client No EC2 The EC2 client
client



Argument Optional Accepts Default Description
Value

Instance IDs No List of The instance IDs to stop
Text
values

Force stop N/A Boolean False Specifies whether to force the instances to stop.
value The instances don't have an opportunity to flush

file system caches or file system metadata

Hibernation: N/A Boolean False Specifies whether to hibernate the instance, if it
value was enabled for hibernation at launch. If the

instance can't hibernate successfully, a normal
shutdown occurs

Variables produced
Argument Type Description

StoppingEc2Instances List of Instance state The returned information for the stopped
changes instances

Exceptions
Exception Description

Authentication Indicates that the provided credentials couldn't be validated
failed

Unauthorized Indicates that an unauthorized operation was requested
operation

Unsupported Indicates that an unsupported operation was requested. For example, an
operation instance that is instance store-backed can't be stopped

Invalid instance Indicates that either the specified instance ID is malformed, or that the
ID specified instance doesn't exist

Amazon service Indicates that the request to AWS failed
request failed

Reboot EC2 instance
Reboot EC2 instance(s).



Input parameters
Argument Optional Accepts Default Value Description

EC2 client No EC2 client The EC2 client

Instance IDs No List of Text values The instance IDs to reboot

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Authentication Indicates that the provided credentials couldn't be validated
failed

Unauthorized Indicates that an unauthorized operation was requested
operation

Unsupported Indicates that an unsupported operation was requested. For example, an
operation instance that is instance store-backed can't be stopped

Invalid Indicates that either the specified instance ID is malformed, or that the specified
instance ID instance doesn't exist

Incorrect state Indicates that the resource is in an incorrect state for the request. This exception
for the can occur if there's an attempt to attach a volume that is still being created
request (ensure that the volume is 'available') or detach a volume that isn't attached

Amazon Indicates that the request to AWS failed
service
request failed

Get available EC2 instances
Get information for the relevant EC2 instances.

Input parameters
Argument Optional Accepts Default Description

Value



Argument Optional Accepts Default Description
Value

EC2 client No EC2 client The EC2 client

Availability Yes Text value Specifies the availability zone,
zone a region code followed by a

letter identifier

Instance N/A Pending, All, Unknown, All The state of the instance
state Running, Shutting down, (pending, running, shutting

Terminated, Stopping, down, terminated, stopping,
Stopped stopped)

Variables produced
Argument Type Description

Ec2InstancesInfo List of EC2 instances info The list of the EC2 instances

Exceptions
Exception Description

Authentication failed Indicates that the provided credentials couldn't be validated

Unauthorized operation Indicates that an unauthorized operation was requested

Amazon service request failed Indicates that the request to AWS failed

Describe instances
Returns all the information for the specified EC2 instance(s).

Input parameters
Argument Optional Accepts Default Description

Value

EC2 client No EC2 client The EC2 client

Instance Yes List of Text values The instance IDs to
IDs describe



Argument Optional Accepts Default Description
Value

Availability Yes Text value Specifies the availability
zone zone, a region code

followed by a letter
identifier

Instance N/A Pending, All, Unknown, Running, All The current state of the
state Shutting down, Terminated, instance

Stopping, Stopped

Variables produced
Argument Type Description

Ec2Instances List of EC2 instances The retrieved instance(s) with all the relevant information

Exceptions
Exception Description

Authentication failed Indicates that the provided credentials couldn't be validated

Unauthorized Indicates that an unauthorized operation was requested
operation

Invalid instance ID Indicates that either the specified instance ID is malformed, or that the
specified instance doesn't exist

Amazon service Indicates that the request to AWS failed
request failed

Create snapshot
Create a snapshot of an EBS volume and stores it in Amazon S3.

Input parameters
Argument Optional Accepts Default Value Description

EC2 client No EC2 client The EC2 client

Volume ID No Text value The ID of the EBS volume



Argument Optional Accepts Default Value Description

Name Yes Text value The name of the snapshot

Description Yes Text value A description for the snapshot

Purpose Yes Text value The purpose of the snapshot

Variables produced
Argument Type Description

Snapshot EBS snapshot The created snapshot

Exceptions
Exception Description

Authentication failed Indicates that the provided credentials couldn't be
validated

Unauthorized operation Indicates that an unauthorized operation was
requested

Invalid volume Indicates that either the volume ID isn't valid, or
the specified volume doesn't exist

or the volume isn't in the same qvailability
zone as the specified instance

Resource's limit is exceeded Indicates that the limit for the specified resource is
reached

Amazon service request failed Indicates that the request to AWS failed

Describe snapshots
Describes the specified EBS snapshots available.

Input parameters
Argument Optional Accepts Default Description

Value

EC2 client No EC2 client The EC2 client



Argument Optional Accepts Default Description
Value

Describe N/A All snapshots, Snapshots by All Specifies whether to get all
snapshots ID, Snapshots by owner ID, snapshots snapshots of the defined
mode Snapshots by restorable user region or filter snapshots

ID, Snapshots by custom filter by their ID, owner, or user
by which they're restorable

Snapshot Yes List of Text values The snapshot IDs to
IDs describe

Owner IDs Yes List of Text values The owner IDs who own
the snapshots

Restorable Yes List of Text values The IDs of the AWS
by user accounts that can create
IDs volumes from the

snapshot

Variables produced
Argument Type Description

EBSSnapshots List of EBS snapshots The retrieved snapshot(s) with all the relevant information

Exceptions
Exception Description

Authentication failed Indicates that the provided credentials couldn't be validated

Unauthorized Indicates that an unauthorized operation was requested
operation

Invalid snapshot ID Indicates that either the specified snapshot ID is invalid, or that the
specified snapshot doesn't exist

Invalid user ID Indicates that the specified user or owner isn't valid

Amazon service Indicates that the request to AWS failed
request failed

Delete snapshot
Delete the specified snapshot.



Input parameters
Argument Optional Accepts Default Value Description

EC2 client No EC2 client The EC2 client

Snapshot ID No Text value The ID of the EBS snapshot to delete

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Authentication failed Indicates that the provided credentials couldn't be validated

Unauthorized Indicates that an unauthorized operation was requested
operation

Invalid snapshot ID Indicates that either the specified snapshot ID is invalid, or that the
specified snapshot doesn't exist

The resource is in use Indicates that the operation can't be completed because the resource is
in use

Amazon service Indicates that the request to AWS failed
request failed

Create volume
Create an EBS volume.

Input parameters
Argument Optional Accepts Default Description

Value

EC2 client No EC2 client The EC2 client

Name Yes Text value The desired name for the volume

Purpose Yes Text value The purpose of the volume, if any



Argument Optional Accepts Default Description
Value

Availability No Text value Specifies the availability zone, a region
zone code followed by a letter identifier

From N/A Boolean value False Specifies whether to create the volume
snapshot from a specified snapshot

Snapshot No Text value The snapshot from to create the volume
ID from

Volume No Text value The size of the volume in GBs
size

Size Yes Text value The size must be equal to or larger than the
snapshot size

Encrypted N/A Boolean value False Specifies whether to encrypt the volume

Volume N/A Gp2, Standard, Gp2 The type of the volume
type Io1, Sc1, St1

Variables produced
Argument Type Description

Volume EBS volume The created volume

Exceptions
Exception Description

Authentication failed Indicates that the provided credentials couldn't be validated

Unauthorized operation Indicates that an unauthorized operation was requested

Invalid parameter Indicates that a parameter specified in the request isn't valid,
unsupported, or can't be used

Invalid zone Indicates that the specified availability zone doesn't exist, or
isn't available to use

Resource's limit is exceeded Indicates that the limit for the specified resource is reached

Volume type isn't supported in Indicates that the specified availability zone doesn't support
the specified zone provisioned IOPS SSD volumes



Exception Description

Amazon service request failed Indicates that the request to AWS failed

Attach volume
Attach an EBS volume to an EC2 instance.

Input parameters
Argument Optional Accepts Default Value Description

EC2 client No EC2 client The EC2 client

Volume ID No Text value The ID of the EBS volume

Instance ID No Text value The ID of the instance

Device name No Text value The name of the device

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Authentication failed Indicates that the provided credentials couldn't be validated

Unauthorized operation Indicates that an unauthorized operation was requested

Unsupported operation Indicates that an unsupported operation was requested. For
example, an instance that is instance store-backed can't be
stopped

Invalid parameter Indicates that a parameter specified in the request isn't valid,
unsupported, or can't be used

Invalid volume Indicates that either the volume ID isn't valid, or the specified
volume doesn't exist

or the volume isn't in the same
qvailability zone as the specified
instance



Exception Description

The resource is in use Indicates that the operation can't be completed because the
resource is in use

Amazon service request failed Indicates that the request to AWS failed

Detach volume
Detach an EBS volume from an EC2 instance.

Input parameters
Argument Optional Accepts Default Description

Value

EC2 client No EC2 The EC2 client
client

Volume ID No Text The ID of the EBS volume
value

Instance ID Yes Text The ID of the instance
value

Device Yes Text The name of the device
name value

Force N/A Boolean False Specifies whether to force detachment, if the
detachment value previous detachment attempt didn't occur cleanly

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Authentication Indicates that the provided credentials couldn't be validated
failed

Unauthorized Indicates that an unauthorized operation was requested
operation



Exception Description

Unsupported Indicates that an unsupported operation was requested. For example, an
operation instance that is instance store-backed can't be stopped

Invalid Indicates that a parameter specified in the request isn't valid, unsupported, or
parameter can't be used

Invalid Indicates an attempt to detach a volume from an instance to which it isn't
attempt to attached
detach

Incorrect state Indicates that the resource is in an incorrect state for the request. This exception
for the can occur if there's an attempt to attach a volume that is still being created
request (ensure that the volume is 'available') or detach a volume that isn't attached

Amazon Indicates that the request to AWS failed
service
request failed

Describe volumes
Describe the specified EBS volumes.

Input parameters
Argument Optional Accepts Default Description

Value

EC2 client No EC2 client The EC2 client

Describe N/A All volumes, Volumes of the All Specifies whether to describe
volumes specified instance, Volumes volumes all volumes, volumes specified
mode with the specified IDs by ID or volumes of an

instance

Volume No List of Text values The volume IDs to describe
IDs

Instance No Text value The ID of the instance that
ID the volume is attached to

Variables produced
Argument Type Description



Argument Type Description

EBSVolumes List of EBS volumes The retrieved EBS volumes with all the relevant information

Exceptions
Exception Description

Authentication failed Indicates that the provided credentials couldn't be validated

Unauthorized Indicates that an unauthorized operation was requested
operation

Invalid parameter Indicates that a parameter specified in the request isn't valid,
unsupported, or can't be used

Amazon service Indicates that the request to AWS failed
request failed

Delete volume
Delete the specified EBS volume.

Input parameters
Argument Optional Accepts Default Value Description

EC2 client No EC2 client The EC2 client

Volume ID No Text value The ID of the EBS volume to delete

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Authentication Indicates that the provided credentials couldn't be validated
failed



Exception Description

Unauthorized Indicates that an unauthorized operation was requested
operation

Invalid Indicates that a parameter specified in the request isn't valid, unsupported, or
parameter can't be used

Invalid volume Indicates that either the volume ID isn't valid, or the specified volume doesn't
exist or the volume isn't in the same qvailability zone as the specified instance

Incorrect state Indicates that the resource is in an incorrect state for the request. This exception
for the can occur if there's an attempt to attach a volume that is still being created
request (ensure that the volume is 'available') or detach a volume that isn't attached

The resource Indicates that the operation can't be completed because the resource is in use
is in use

Amazon Indicates that the request to AWS failed
service
request failed

Create EC2 session
Create an EC2 client to automate EC2 web services.

Input parameters
Argument Optional Accepts Default Description

Value

Access N/A Boolean value False Specifies whether to use access key ID and
keys secret access key in order to create the EC2

session

Access key No Text value The AWS access key ID
ID

Secret No Direct The AWS secret access key
encrypted input
or Text value

Region No Text value The region constant to use that determines
endpoint the endpoint to use

Profile No Text value default The name of the profile to use
name



Argument Optional Accepts Default Description
Value

Profile Yes Text value The location of the credentials file that
location contains the profile to use

Variables produced
Argument Type Description

Ec2Client EC2 client The EC2 client

Exceptions
Exception Description

Profile doesn't exist Indicates that the specified profile doesn't exist

Invalid profile Indicates that the specified profile isn't correctly configured

Create session failed Indicates that the creation of EC2 client failed

End EC2 session
Dispose an open EC2 client.

Input parameters
Argument Optional Accepts Default Value Description

EC2 client No EC2 client The EC2 client

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.



Azure actions
Article • 12/16/2022

） Important

You need an active Azure subscription to deploy Azure actions in your desktop
flows.

Power Automate allows you to manage Azure virtual machines through the Azure group
of actions. To implement Azure functionality in your desktop flows, create a new Azure
session using the Create session action.

This action requires you to enter the Client ID, an authentication key for the specific
application, and the respective password. Additionally, enter the Tenant ID that is the
Azure Active Directory in which you've created the application.

Lastly, populate the appropriate Subscription ID. The subscription ID is a GUID that
uniquely identifies your subscription to Azure services.

After creating the session and deploying all the needed Azure actions, use the End
session action to terminate the Azure session.



Get resource groups
Gets the resource groups based on the specified criteria.

Input parameters
Argument Optional Accepts Default Description

Value

Azure client No Azure The client used to connect to
client Azure

Resource group Yes Text value The name of the resource group
name

Variables produced
Argument Type Description

ResourceGroups List of Azure resource groups The retrieved resource groups

Exceptions
Exception Description

Failed to get the resource groups with the Indicates that getting the resource groups with the
specified criteria specified criteria failed



Create resource group
Creates a new resource group.

Input parameters
Argument Optional Accepts Default Description

Value

Azure client No Azure The client used to connect to Azure
client

Resource group No Text The name of the resource group
name value

Location No Text The location where the new disk will
value be created

Variables produced
Argument Type Description

ResourceGroup Azure resource group The created resource group

Exceptions
Exception Description

Resource group already exists Indicates that the resource group already exists and can't be
created

Failed to create resource Indicates that creating the resource group failed
group

Delete resource group
Deletes the specified resource group and all the contained resources.

Input parameters
Argument Optional Accepts Default Description

Value



Argument Optional Accepts Default Description
Value

Azure client No Azure The client used to connect to
client Azure

Resource group No Text value The name of the resource group
name

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

Failed to delete the resource group Indicates that deleting the resource group failed

Get disks
Gets the disks based on the specified criteria.

Input parameters
Argument Optional Accepts Default Description

Value

Azure No Azure client The client
client used to

connect to
Azure

Retrieve N/A All, With the specified resource group, With All Specify
disks the specified name in all resource groups, With which disks

specific name in the specified resource group to retrieve

Resource No Text value The
group resource

group
where the
disks reside



Argument Optional Accepts Default Description
Value

Disk name No Text value The name
of the disk

Variables produced
Argument Type Description

Disks List of Azure managed disks The retrieved disks with all the related information

Exceptions
Exception Description

Disk wasn't found Indicates that the disk with the specified criteria
doesn't exist

Resource group wasn't found Indicates that the specified resource group wasn't
found

Failed to get the disks with the specified Indicates that getting the disks with the specified
criteria criteria failed

Attach disk
Attaches an existing disk to the virtual machine with the specified name and resource
group.

Input parameters
Argument Optional Accepts Default Description

Value

Azure client No Azure The client used to connect to Azure
client

Virtual machine No Text value The VM where the disk will be
name attached

VM resource No Text value The resource group of the VM
group



Argument Optional Accepts Default Description
Value

Disk is managed N/A Boolean True Specify whether the disk to attach is
value managed

Disk name No Text value The name of the disk to attach

Disk's resource No Text value The resource group of the disk
group

Storage account No Text value The storage account where VHD file
is located

Container No Text value The container that holds the VHD file

VHD file No Text value The name of the VHD file

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

VM wasn't found Indicates that the specified VM wasn't found

Disk wasn't found Indicates that the disk with the specified criteria doesn't
exist

Both unmanaged and managed Indicates that the attachment failed because both
disk can't exist together in a VM unmanaged and managed disk can't exist together in a VM

Failed to attach the disk Indicates that the disk attachment failed

Detach disk
Detaches the disk from the virtual machine with the specified name and resource group.

Input parameters
Argument Optional Accepts Default Description

Value



Argument Optional Accepts Default Description
Value

Azure client No Azure The client used to connect to
client Azure

Virtual machine name No Text The VM from where the disk will
value be detached

Virtual machine's No Text The resource group of the VM
resource group value

Disk name No Text The name of the disk to detach
value

Disk is managed N/A Boolean True Specify whether the disk to
value detach is managed

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

VM wasn't found Indicates that the specified VM wasn't found

Failed to detach because the disk isn't Indicates that the detachment failed because the disk
attached to the specified VM isn't attached to the specified VM

Failed to detach disk Indicates that detaching the disk failed

Create managed disk
Creates a managed disk with the specified settings.

Input parameters
Argument Optional Accepts Default Description

Value

Azure No Azure client The client used to connect to Azure
client



Argument Optional Accepts Default Description
Value

Disk name No Text value The name of the managed disk to
create

Resource N/A Use existing, Create Use Specify whether a new resource
group new existing group will be created or an existing
option one will be used

Resource No Text value The resource group of the disk
group
name

Location No Text value The location where the new disk is
created

Source N/A None, Snapshot, None Specifies whether to create an empty
type Storage blob disk or use the snapshot of another

disk or use a blob in a storage
account

Snapshot No Text value The managed snapshot to use as a
name source

Snapshot's No Text value The resource group of the snapshot
resource
group

Blob URL No Text value The URL of the blob

Disk size No Numeric value Size of the disk in GB
in GB

Storage N/A Standard HDD, Standard The disk type
account Premium SSD, HDD
type Standard SSD, Ultra

disk SSD

Storage No Text value The name of the storage account
account where VHD file is stored
name

Availability Yes Text value The availability zone for the
zone managed disk

Variables produced
Argument Type Description



Argument Type Description

ManagedDisk Azure managed disk The created managed disk

Exceptions
Exception Description

Resource group already exists Indicates that the resource group already exists and
can't be created

Resource group wasn't found Indicates that the specified resource group wasn't
found

The resource with the specified name Indicates that the resource with the specified name
already exists already exists

Snapshot wasn't found Indicates that the specified snapshot wasn't found

Failed to create disk Indicates that creating the disk failed

Delete disk
Deletes the managed disk with the specified name and resource group.

Input parameters
Argument Optional Accepts Default Description

Value

Azure client No Azure The client used to connect to Azure
client

Disk name No Text value The name of the managed disk to
delete

Resource No Text value The resource group of the disk
group

Variables produced
This action doesn't produce any variables.

Exceptions



Exception Description

Disk wasn't found Indicates that the disk with the specified criteria
doesn't exist

Failed to delete the disk because it's Indicates a problem deleting the disk because it's
attached to a VM attached to a VM

Failed to delete disk Indicates that deleting the disk failed

Get snapshots
Gets the snapshots based on the specified criteria.

Input parameters
Argument Optional Accepts Default Description

Value

Azure No Azure client The client
client used to

connect to
Azure

Retrieve N/A All, With the specified resource group, With All Specify
snapshots the specified name in all resource groups, With which

specific name in the specified resource group snapshots
to retrieve

Resource No Text value The
group resource

group
where the
snapshots
reside

Snapshot No Text value The name
name of the

snapshot

Variables produced
Argument Type Description

Snapshots List of Azure snapshots The retrieved snapshots with all the related information



Exceptions
Exception Description

Snapshot wasn't found Indicates that the specified snapshot wasn't found

Resource group wasn't found Indicates that the specified resource group wasn't
found

Failed to get the snapshots with the Indicates that getting the snapshots with the
specified criteria specified criteria failed

Create snapshot
Creates a snapshot from the specified disk.

Input parameters
Argument Optional Accepts Default Description

Value

Azure client No Azure client The client used to connect to Azure

Snapshot No Text value The name of the snapshot to create
name

Resource N/A Use Use Specifies whether a new resource group
group option existing, existing will be created or an existing one will be

Create new used

Resource No Text value The resource group where the snapshot
group will be created

Location No Text value The location where the new disk will be
created

Source disk No Text value The name of the managed disk that will be
used as source data

Source disk's No Text value The resource group of the managed disk
resource that will be used as source data
group

Variables produced
Argument Type Description



Argument Type Description

Snapshot Azure snapshot The created snapshot

Exceptions
Exception Description

Resource group already exists Indicates that the resource group already exists and
can't be created

Resource group wasn't found Indicates that the specified resource group wasn't
found

The resource with the specified name Indicates that the resource with the specified name
already exists already exists

Disk wasn't found Indicates that the disk with the specified criteria
doesn't exist

Failed to create snapshot Indicates that creating the snapshot failed

Delete snapshot
Deletes the snapshot with the specified name and resource group.

Input parameters
Argument Optional Accepts Default Value Description

Azure client No Azure client The client used to connect to Azure

Snapshot name No Text value The name of the snapshot to delete

Resource group No Text value The resource group of the snapshot

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description



Exception Description

Snapshot wasn't found Indicates that the specified snapshot wasn't found

Failed to delete snapshot Indicates that deleting the snapshot failed

Get virtual machines
Gets the basic information for the virtual machines.

Input parameters
Argument Optional Accepts Default Description

Value

Azure No Azure client The client used to
client connect to Azure

Resource Yes Text value The resource
group group of the

virtual machine

Status N/A Running, Deallocating, Deallocated, Any The status of the
Starting, Stopped, Stopping, Unknown, virtual machine
Any

Variables produced
Argument Type Description

VirtualMachinesInfo List of Azure virtual The retrieved virtual machines with basic
machine info information

Exceptions
Exception Description

Resource group wasn't found Indicates that the specified resource group wasn't
found

Failed to get the VMs with basic Indicates that getting the VMs with basic information
information failed



Describe virtual machine
Gets all the information for the virtual machine(s) based on the specified criteria.

Input parameters
Argument Optional Accepts Default Description

Value

Azure No Azure client The client
client used to

connect to
Azure

Describe N/A All, With the specified resource group, With All Specify
virtual the specified name in all resource groups, With which
machines specific name in the specified resource group virtual

machines to
describe

Resource No Text value The
group resource

group of
the virtual
machine

Virtual No Text value The name
machine of the
name virtual

machine

Status N/A Running, Deallocating, Deallocated, Starting, Any The status
Stopped, Stopping, Unknown, Any of the

virtual
machine

Variables produced
Argument Type Description

VirtualMachines List of Azure virtual The retrieved virtual machines with all the related
machines information

Exceptions



Exception Description

VM wasn't found Indicates that the specified VM wasn't found

Resource group wasn't found Indicates that the specified resource group wasn't
found

Failed to get basic information of the Indicates that getting basic information of the VM(s)
VM(s) failed

Start virtual machine
Starts the virtual machine.

Input parameters
Argument Optional Accepts Default Description

Value

Azure client No Azure The client used to connect to Azure
client

Virtual machine No Text value The name of the virtual machine
name

Resource group No Text value The resource group of the virtual
machine

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

VM wasn't found Indicates that the specified VM wasn't found

Failed to start the VM Indicates that an error occurred while trying to start the VM

Stop virtual machine



Stops the virtual machine and delocates the related hardware (CPU and memory) and
network resources.

Input parameters
Argument Optional Accepts Default Description

Value

Azure client No Azure The client used to connect to Azure
client

Virtual machine No Text value The name of the virtual machine
name

Resource group No Text value The resource group of the virtual
machine

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

VM wasn't found Indicates that the specified VM wasn't found

Failed to stop the VM Indicates that an error occurred while trying to stop the VM

Shut down virtual machine
Shuts down the operating system of a virtual machine.

Input parameters
Argument Optional Accepts Default Description

Value

Azure client No Azure The client used to connect to Azure
client

Virtual machine No Text value The name of the virtual machine
name



Argument Optional Accepts Default Description
Value

Resource group No Text value The resource group of the virtual
machine

Variables produced
This action doesn't produce any variables.

Exceptions
Exception Description

VM wasn't found Indicates that the specified VM wasn't found

Failed to shut down the VM Indicates an error occurred while trying to shut down the VM

Restart virtual machine
Restarts a virtual machine.

Input parameters
Argument Optional Accepts Default Description

Value

Azure client No Azure The client used to connect to Azure
client

Virtual machine No Text value The name of the virtual machine
name

Resource group No Text value The resource group of the virtual
machine

Variables produced
This action doesn't produce any variables.

Exceptions



Exception Description

VM wasn't found Indicates that the specified VM wasn't found

Failed to restart the VM Indicates that an error occurred while trying to restart the VM

Create session
Creates an Azure session.

Input parameters
Argument Optional Accepts Default Description

Value

Client ID No Text value The client ID of the application, also known
as application ID, which identifies the
application that is using the token

Client secret No Direct The secret for the client ID
encrypted
input or Text
value

Tenant ID No Text value The directory ID of the Azure Active
Directory

Subscription Yes Text value The Azure subscription ID. If not provided,
ID the default subscription will be used

Variables produced
Argument Type Description

AzureClient Azure client The created Azure client

Exceptions
Exception Description

Failed to create Azure client Indicates that creating the Azure client failed

Get subscriptions



Gets subscriptions that the current account can access.

Input parameters
Argument Optional Accepts Default Value Description

Azure client No Azure client The client used to connect to Azure

Variables produced
Argument Type Description

Subscriptions List of Azure The retrieved subscriptions with all the related
subscriptions information

Exceptions
Exception Description

Failed to get the subscriptions with the Indicates that getting the subscriptions with the
specified criteria specified criteria failed

End session
Ends an Azure session.

Input parameters
Argument Optional Accepts Default Value Description

Azure client No Azure client The client used to connect to Azure

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.



Cognitive actions
Article • 12/16/2022

The cognitive actions have been segregated into three new categories.

Google cognitive
IBM cognitive
Microsoft cognitive



Google cognitive actions
Article • 12/16/2022

Google cognitive services allow you to process unstructured data through machine
learning and simplify complicated tasks like text analysis and computer vision.

You can implement this functionality in your desktop flows using the Google cognitive
group of actions.

All Google cognitive actions require an API key that authorizes you to use the respective
services. You can manage your API keys in the APIs & services section of the Cloud
Console.

Analyze sentiment
Invokes the Google Cloud Natural Language service named 'Analyze Sentiment'.



Input parameters
Argument Optional Accepts Default Description

Value

API key No Text The Google Cloud API key to be used for this API
value call

Document N/A Plain Plain The type of document to transmit
type text, text

HTML

Provide N/A From From Specify whether the document will be provided by
document file, file a full path or a Google Cloud Storage URI

From
GCS

File path No File The full path (folder plus filename) of the
document to transmit

GCS No Text The URI of the image residing on Google Cloud
Content value Storage
URI

Language Yes Text The language of the text
value

Timeout Yes Numeric 30 The time (in seconds) that the agent should wait
value for a connection to be established with the server,

before it fails

Variables produced
Argument Type Description

JSONResponse Custom object The API response results

StatusCode Numeric value The status code returned

Exceptions
Exception Description

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services



Exception Description

Request timeout expired Indicates that the timeout expired while performing the
request

Analyze entities
Invokes the Google Cloud Natural Language service named 'Analyze Entities'.

Input parameters
Argument Optional Accepts Default Description

Value

API key No Text The Google Cloud API key to be used for this API
value call

Document N/A Plain Plain The type of the document to transmit
type text, text

HTML

Provide N/A From From Specify whether the document will be provided by
file file, file a full path or a Google Cloud Storage URI

From
GCS

File path No File The full path (folder plus filename) of the
document to transmit

GCS URL No Text The URI of the document residing on Google
value Cloud Storage

Language Yes Text The language of the text
value

Timeout Yes Numeric 30 The time (in seconds) that the agent should wait
value for a connection to be established with the server,

before it fails

Variables produced
Argument Type Description

JSONResponse Custom object The API response results

StatusCode Numeric value The status code returned



Exceptions
Exception Description

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Request timeout expired Indicates that the timeout expired while performing the
request

Analyze syntax
Invokes the Google Cloud Natural Language service named 'Analyze Syntax'.

Input parameters
Argument Optional Accepts Default Description

Value

API key No Text The Google Cloud API key to be used for this API
value call

Document N/A Plain Plain The type of document to transmit
type text, text

HTML

Provide N/A From From Specify whether the document will be provided by
document file, file a full path or a Google Cloud Storage URI

From
GCS

File path No File The full path (folder plus filename) of the
document to transmit

GCS No Text The URI of the image residing on Google Cloud
Content value Storage
URI

Language Yes Text The language of the text
value

Timeout Yes Numeric 30 The time (in seconds) that the agent should wait
value for a connection to be established with the server,

before it fails

Variables produced



Argument Type Description

JSONResponse Custom object The API response results

StatusCode Numeric value The status code returned

Exceptions
Exception Description

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Request timeout expired Indicates that the timeout expired while performing the
request

Label detection
Invokes the Google Cloud Vision service named 'Label Detection'.

Input parameters
Argument Optional Accepts Default Description

Value

API key No Text The Google Cloud API key to be used for this API
value call

Provide N/A From From Specify whether the image will be provided by a
image file, file full path or a Google Cloud Storage URI

From
GCS

Image file No File The full path (folder plus filename) of the image
file to transmit

GCS No Text The URI of the image residing on Google Cloud
Image URI value Storage

Timeout Yes Numeric 30 The time (in seconds) that the agent should wait
value for a connection to be established with the server,

before it fails

Variables produced



Argument Type Description

JSONResponse Custom object The API response results

StatusCode Numeric value The status code returned

Exceptions
Exception Description

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Request timeout expired Indicates that the timeout expired while performing the
request

Landmark detection
Invokes the Google Cloud Vision service named 'Landmark Detection'.

Input parameters
Argument Optional Accepts Default Description

Value

API key No Text The Google Cloud API key to be used for this API
value call

Provide N/A From From Specify whether the image will be provided by a
image file, file full path or a Google Cloud Storage URI

From
GCS

Image file No File The full path (folder plus filename) of the image
path file to transmit

GCS No Text The URI of the image residing on Google Cloud
Image URI value Storage

Timeout Yes Numeric 30 The time (in seconds) that the agent should wait
value for a connection to be established with the server,

before it fails

Variables produced



Argument Type Description

JSONResponse Custom object The API response results

StatusCode Numeric value The status code returned

Exceptions
Exception Description

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Request timeout expired Indicates that the timeout expired while performing the
request

Text Detection
Invokes the Google Cloud Vision service named 'Text Detection'.

Input parameters
Argument Optional Accepts Default Description

Value

API key No Text The Google Cloud API key to be used for this API
value call

Provide N/A From From Specify whether the image will be provided by a
image file, file full path or a Google Cloud Storage URI

From
GCS

Image file No File The full path (folder plus filename) of the image
file to transmit

GCS No Text The URI of the image residing on Google Cloud
Image URI value Storage

Timeout Yes Numeric 30 The time (in seconds) that the agent should wait
value for a connection to be established with the server,

before it fails

Variables produced



Argument Type Description

JSONResponse Custom object The API response results

StatusCode Numeric value The status code returned

Exceptions
Exception Description

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Request timeout expired Indicates that the timeout expired while performing the
request

Logo detection
Invokes the Google Cloud Vision service named 'Logo Detection'.

Input parameters
Argument Optional Accepts Default Description

Value

API key No Text The Google Cloud API key to be used for this API
value call

Provide N/A From From Specify whether the image will be provided by a
image file, file full path or a Google Cloud Storage URI

From
GCS

Image file No File The full path (folder plus filename) of the image
file to transmit

GCS No Text The URI of the image residing on Google Cloud
Image URI value Storage

Timeout Yes Numeric 30 The time (in seconds) that the agent should wait
value for a connection to be established with the server,

before it fails

Variables produced



Argument Type Description

JSONResponse Custom object The API response results

StatusCode Numeric value The status code returned

Exceptions
Exception Description

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Request timeout expired Indicates that the timeout expired while performing the
request

Image properties detection
Invokes the Google Cloud Vision service named 'Image Properties Detection'.

Input parameters
Argument Optional Accepts Default Description

Value

API key No Text The Google Cloud API key to be used for this API
value call

Provide N/A From From Specify whether the image will be provided by a
image file, file full path or a Google Cloud Storage URI

From
GCS

Image file No File The full path (folder plus filename) of the image
file to transmit

GCS No Text The URI of the image residing on Google Cloud
Image URI value Storage

Timeout Yes Numeric 30 The time (in seconds) that the agent should wait
value for a connection to be established with the server,

before it fails

Variables produced



Argument Type Description

JSONResponse Custom object The API response results

StatusCode Numeric value The status code returned

Exceptions
Exception Description

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Request timeout expired Indicates that the timeout expired while performing the
request

Safe search detection
Invokes the Google Cloud Vision service named 'Safe Search Detection'.

Input parameters
Argument Optional Accepts Default Description

Value

API key No Text The Google Cloud API key to be used for this API
value call

Provide N/A From From Specify whether the image will be provided by a
image file, file full path or a Google Cloud Storage URI

From
GCS

Image file No File The full path (folder plus filename) of the image
file to transmit

GCS No Text The URI of the image residing on Google Cloud
Image URI value Storage

Timeout Yes Numeric 30 The time (in seconds) that the agent should wait
value for a connection to be established with the server,

before it fails

Variables produced



Argument Type Description

JSONResponse Custom object The API response results

StatusCode Numeric value The status code returned

Exceptions
Exception Description

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Request timeout expired Indicates that the timeout expired while performing the
request



IBM cognitive actions
Article • 12/16/2022

IBM cognitive services are machine learning algorithms that use artificial intelligence to
perform complex operations, such as language tone analysis and visual recognition.

Desktop flows enable you to use these services through the IBM cognitive actions.

All IBM cognitive actions require an API key that you can create and manage through
the IBM Cloud console. Additionally, they require the release date of the used API and
the service endpoint location.

Convert document



Invokes the IBM service named 'Convert Document'.

Input parameters
Argument Optional Accepts Default Description

Value

Username No Text value The
username
to be used
for this call

Password No Direct encrypted input or Text value The
password to
use for this
call

Version No Text value The release
date date of the

API to use

File path No File The path to
the file to
analyze

Mime type N/A text/html, text/xhtml+xml, application/pdf, text/html The MIME
application/msword, type of the
application/vnd.openxmlformats- file
officedocument.wordprocessingml.document

Conversion N/A Answer units, Normalized HTML, Normalized Answer The output
target text units format of

the
conversion

Answer Yes Text value The heading
units levels as a

comma-
separated
string



Argument Optional Accepts Default Description
Value

Timeout Yes Numeric value 30 The time (in
seconds)
that the
agent
should wait
for a
connection
to be
established
with the
server,
before it
fails

Variables produced
Argument Type Description

JSONResponse Custom object The results of the API call

StatusCode Numeric value The status code of the API call

Exceptions
Exception Description

Request timeout expired Indicates that the timeout expired while performing the
request

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Translate
Invokes the IBM service named 'Translate'.

Input parameters
Argument Optional Accepts Default Description

Value



Argument Optional Accepts Default Description
Value

API key No Text value The API key to use for this call

Version No Text value The release date of the API to use
date

Service N/A US South, US East, US East The account's service location. Can be
endpoint Europe, Australia, seen through IBM "Manage" in the
location Japan, UK, Korea resources section

Instance No Text value The Instance ID of the service.
ID

Translate N/A Model ID, Source Model Specify the mode to be used for this
mode and target ID call

Model ID No Text value The unique model_id of the translation
model that will be used to translate the
text

Source No Text value The source language of the text

Target No Text value The translation target language in 2 or
5 letter language code

Text No List of Text values The text to send or list of words to be
separately translated

Timeout Yes Numeric value 30 The time (in seconds) that the agent
should wait for a connection to be
established with the server, before it
fails

Variables produced
Argument Type Description

JSONResponse Custom object The results of the API call

StatusCode Numeric value The status code returned

Exceptions
Exception Description



Exception Description

Request timeout expired Indicates that the timeout expired while performing the
request

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Identify language
Invokes the IBM service named 'Identify Language'.

Input parameters
Argument Optional Accepts Default Description

Value

API key No Text value The API key to use for this call

Version No Text value The release date of the API to use
date

Service N/A US South, US East, US East The account's service location. Can be
endpoint Europe, Australia, seen through IBM "Manage" in the
location Japan, UK, Korea resources section

Instance No Text value The Instance ID of the service.
ID

Text No Text value The text to analyze

Content Yes Text value text/plain The format of the requested values
type

Timeout Yes Numeric value 30 The time (in seconds) that the agent
should wait for a connection to be
established with the server, before it
fails

Variables produced
Argument Type Description

JSONResponse Custom object The results of the API call

StatusCode Numeric value The status code of the API call



Exceptions
Exception Description

Request timeout expired Indicates that the timeout expired while performing the
request

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Analyze tone
Invokes the IBM service named 'Analyze Tone'.

Input parameters
Argument Optional Accepts Default Description

Value

API key No Text value The API key to use for this call

Version No Text value The release date of the API to use
date

Service N/A US South, US East, US East The account's service location. Can be
endpoint Europe, Australia, seen through IBM "Manage" in the
location Japan, UK, Korea resources section

Instance No Text value The Instance ID of the service.
ID

Provide N/A From text, From file From Specify how the text to be analyzed
text text will be provided

Text No Text value The text to analyze

File path No File The path to the file to analyze

Content N/A text/plain, text/plain The content type of the text that will
type text/html, be sent

application/json

Tones Yes Text value The tone with which the results will be
filtered (optional)

Sentences Yes Text value Specify whether to remove the
sentence analysis



Argument Optional Accepts Default Description
Value

Timeout Yes Numeric value 30 The time (in seconds) that the agent
should wait for a connection to be
established with the server, before it
fails

Variables produced
Argument Type Description

JSONResponse Custom object The results of the API call

StatusCode Numeric value The status code of the API call

Exceptions
Exception Description

Request timeout expired Indicates that the timeout expired while performing the
request

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Classify Image
Invokes the IBM service named 'Classify Image'.

Input parameters
Argument Optional Accepts Default Description

Value

API key No Text value The API key to use for this call

Version No Text value The release date of the API to use
date

Service N/A US South, US The account's service location. Can be seen
endpoint Europe, South through IBM "Manage" in the resources section
location Korea



Argument Optional Accepts Default Description
Value

Instance ID No Text value The Instance ID of the service.

Provide N/A From file, From Specify how the image will be provided
image From GCS file

Image file No File The path to the image to be analyzed
path

Image URL No Text value The URL of the image to be analyzed

Owners Yes Text value me The classifiers to be used as a comma separated
list

Classifier Yes Text value default The classifier Ids to be used as a comma
IDs separated list

Threshold Yes Text value The minimum score a class must have to be
displayed in the response as a floating value

Language Yes Text value The language of the output

Timeout Yes Numeric 30 The time (in seconds) that the agent should wait
value for a connection to be established with the

server, before it fails

Variables produced
Argument Type Description

JSONResponse Custom object The results of the API call

StatusCode Numeric value The status code of the API call

Exceptions
Exception Description

Request timeout expired Indicates that the timeout expired while performing the
request

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services



Microsoft cognitive actions
Article • 11/08/2023

Azure Cognitive Services enables you to accelerate decision-making using artificial
intelligence without requiring machine learning expertise.

） Important

Azure is retiring Azure Cognitive Services Text Analytics v2.x on 29 February
2024 . This library is used by the Microsoft Cognitive Text Analytics actions. After
February 29, 2024 those actions will no longer be supported in desktop flows and
will not be operational.

Desktop flows provide a wide variety of Microsoft cognitive actions that allow you to
integrate this functionality into your desktop flows. Text analysis, computer vision, and
spell-checking are all tasks that Microsoft cognitive actions can perform.

All Microsoft cognitive actions require a subscription key that validates your subscription
for a service or group of services. The keys are available in the Azure portal for each
resource you've created.



Spell check
Invokes the Microsoft Cognitive service named 'Bing Spell Check.'

Input parameters
Argument Optional Accepts Default Description

Value

Subscription No Text value The subscription key to use for this API call
key

Text No List of Text The text or the list of texts to send
values

Mode Yes Text value Specify the spell-check mode

Mkt Yes Text value For proof mode, the only supported
language codes are: en-us, es-es, pt-br. For
spell mode, all language codes are
supported



Argument Optional Accepts Default Description
Value

Timeout Yes Numeric 30 The time (in seconds) that the agent should
value wait for a connection to be established with

the server, before it fails

Variables produced
Argument Type Description

JSONResponse Custom object The API response results

StatusCode Numeric value The status code returned

Exceptions
Exception Description

Request timeout expired Indicates that the timeout expired while performing the
request

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Analyze image
Invokes the Microsoft Cognitive service named 'Analyze Image.'

Input parameters
Argument Optional Accepts Default Description

Value

Server N/A West US, West US 2, East US, West US The server location to be
location East US 2, West Central US, used for this API call

South Central US, West
Europe, North Europe,
Southeast Asia, East Asia,
Australia East, Brazil South,
Canada Central, Central India,
UK South, Japan East



Argument Optional Accepts Default Description
Value

Subscription No Text value The subscription key to
key use for this API call

Provide N/A From file, From GCS From Specify whether the
image file image will be provided by

a full path or a URL
address

Image file No File The full path (folder plus
filename) of the image file
to transmit

Image URL No Text value The URL address of an
image

Visual Yes Text value A text value indicating
features what visual feature types

to return. Multiple values
should be comma-
separated. For example:
categories, tags,
description

Details Yes Text value A text value indicating
which domain-specific
details to return. Multiple
values should be comma-
separated

Language Yes Text value A text value indicating
which language to return.
The service will return
recognition results in the
specified language

Timeout Yes Numeric value 30 The time (in seconds) that
the agent should wait for
a connection to be
established with the
server, before it fails

Variables produced
Argument Type Description

JSONResponse Custom object The API response results



Argument Type Description

StatusCode Numeric value The status code returned

Exceptions
Exception Description

Request timeout expired Indicates that the timeout expired while performing the
request

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Describe image
Invokes the Microsoft Cognitive service named 'Describe Image.'

Input parameters
Argument Optional Accepts Default Description

Value

Server N/A West US, West US 2, East US, West US The server location to
location East US 2, West Central US, be used for this API call

South Central US, West Europe,
North Europe, Southeast Asia,
East Asia, Australia East, Brazil
South, Canada Central, Central
India, UK South, Japan East

Subscription No Text value The subscription key to
key use for this API call

Provide N/A From file, From GCS From Specify whether the
image file image will be provided

by a full path or a URL
address

Image file No File The full path (folder
plus filename) of the
image file to transmit

Image URL No Text value The URL address of an
image



Argument Optional Accepts Default Description
Value

Max Yes Text value The maximum number
candidates of candidate

descriptions to be
returned. The default is
1

Timeout Yes Numeric value 30 The time (in seconds)
that the agent should
wait for a connection to
be established with the
server, before it fails

Variables produced
Argument Type Description

JSONResponse Custom object The API response results

StatusCode Numeric value The status code returned

Exceptions
Exception Description

Request timeout expired Indicates that the timeout expired while performing the
request

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

OCR
Invokes the Microsoft Cognitive service named 'OCR.'

Input parameters
Argument Optional Accepts Default Description

Value

Server N/A West US, West US 2, East US, West US The server location to
location East US 2, West Central US, be used for this API call



Argument Optional Accepts Default Description
Value

South Central US, West Europe,
North Europe, Southeast Asia,
East Asia, Australia East, Brazil
South, Canada Central, Central
India, UK South, Japan East

Subscription No Text value The subscription key to
key use for this API call

Provide N/A From file, From GCS From Specify whether the
image file image will be provided

by a full path or a URL
address

Image file No File The full path (folder
plus filename) of the
image file to transmit

Image URL No Text value The URL address of an
image

Language Yes Text value The BCP-47 language
code of the text to
detect in the image

Detect Yes Text value Specify whether to
orientation detect the text

orientation in the
image

Timeout Yes Numeric value 30 The time (in seconds)
that the agent should
wait for a connection to
be established with the
server, before it fails

Variables produced
Argument Type Description

JSONResponse Custom object The API response results

StatusCode Numeric value The status code returned

Exceptions



Exception Description

Request timeout expired Indicates that the timeout expired while performing the
request

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Tag image
Invokes the Microsoft Cognitive service named 'Tag Image.'

Input parameters
Argument Optional Accepts Default Description

Value

Server N/A West US, West US 2, East US, West US The server location to
location East US 2, West Central US, be used for this API call

South Central US, West Europe,
North Europe, Southeast Asia,
East Asia, Australia East, Brazil
South, Canada Central, Central
India, UK South, Japan East

Subscription No Text value The subscription key to
key use for this API call

Provide N/A From file, From GCS From Specify whether the
image file image will be provided

by a full path or a URL
address

Image file No File The full path (folder
plus filename) of the
image file to transmit

Image URL No Text value The URL address of an
image

Timeout Yes Numeric value 30 The time (in seconds)
that the agent should
wait for a connection to
be established with the
server, before it fails



Variables produced
Argument Type Description

JSONResponse Custom object The API response results

StatusCode Numeric value The status code returned

Exceptions
Exception Description

Request timeout expired Indicates that the timeout expired while performing the
request

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Detect language
Invokes the Microsoft Cognitive service named 'Text Analytics - Detect Language.'

Input parameters
Argument Optional Accepts Default Description

Value

Server N/A West US, West US 2, East US, West US The server location to
location East US 2, West Central US, be used for this API call

South Central US, West Europe,
North Europe, Southeast Asia,
East Asia, Australia East, Brazil
South, Canada Central, Central
India, UK South, Japan East

Subscription No Text value The subscription key to
key use for this API call

Text No Text value The text to analyze

Timeout Yes Numeric value 30 The time (in seconds)
that the agent should
wait for a connection to
be established with the
server, before it fails



Variables produced
Argument Type Description

JSONResponse Custom object The API response results

StatusCode Numeric value The status code returned

Exceptions
Exception Description

Request timeout expired Indicates that the timeout expired while performing the
request

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Key phrases
Invokes the Microsoft Cognitive service named 'Text Analytics - Key Phrases.'

Input parameters
Argument Optional Accepts Default Description

Value

Server N/A West US, West US 2, East US, West US The server location to
location East US 2, West Central US, be used for this API call

South Central US, West Europe,
North Europe, Southeast Asia,
East Asia, Australia East, Brazil
South, Canada Central, Central
India, UK South, Japan East

Subscription No Text value The subscription key to
key use for this API call

Text No List of Text values The text or the list of
texts to analyze

Language Yes Text value The language of the
text(s)

Timeout Yes Numeric value 30 The time (in seconds)
that the agent should



Argument Optional Accepts Default Description
Value

wait for a connection to
be established with the
server, before it fails

Variables produced
Argument Type Description

JSONResponse Custom object The API response results

StatusCode Numeric value The status code returned

Exceptions
Exception Description

Request timeout expired Indicates that the timeout expired while performing the
request

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services

Sentiment
Invokes the Microsoft Cognitive service named 'Text Analytics - Sentiment.'

Input parameters
Argument Optional Accepts Default Description

Value

Server N/A West US, West US 2, East US, West US The server location to be
location East US 2, West Central US, used for this API call

South Central US, West Europe,
North Europe, Southeast Asia,
East Asia, Australia East, Brazil
South, Canada Central, Central
India, UK South, Japan East

Subscription No Text value The subscription key to
key use for this API call



Argument Optional Accepts Default Description
Value

Text No List of Text values Text

Language Yes Text value The two letter ISO 639-1
representation of the
language of the text(s)

Timeout Yes Numeric value 30 The time (in seconds)
that the agent should
wait for a connection to
be established with the
server, before it fails

Variables produced
Argument Type Description

JSONResponse Custom object The API response results

StatusCode Numeric value The status code returned

Exceptions
Exception Description

Request timeout expired Indicates that the timeout expired while performing the
request

Failed to Invoke cognitive Indicates a problem while trying to invoke Cognitive Services
services



Log message action
Article • 08/02/2023

The Log message action enables you to log a custom text message with a severity level
of Info, Warning or Error in the flow run action details.

） Important

The Log message action in Power Automate for desktop is a premium feature,
which requires a Power Automate subscription .

At runtime, all action logs are uploaded to the Power Automate service, and are visible
in the flow run action details view of the Power Automate portal.

７ Note

The text message should contain a maximum of 128 characters.
Action logs are not uploaded to the Power Automate service when the flow is
executed through the Power Automate for desktop designer.

Log message



Adds a custom text message to the flow run action details.

Input parameters
Argument Optional Accepts Default Value Description

Message No Text value The message to log

Log level N/A Info, Warning, Error Info The severity level of the message

Variables produced
This action doesn't produce any variables.

Exceptions
This action doesn't include any exceptions.



SharePoint
Article • 05/24/2024

The SharePoint group of actions allows the utilization of the SharePoint connector from
within desktop flows, alleviating the need to create a cloud flow in order to use its
actions. This connector is the same as the one used across Power Automate cloud flows,
Power Apps, and Logic Apps. It uses the same parameters and returns the same type of
data.

Prerequisites and limitations
You need an Attended RPA license.
In addition to implementing data loss prevention policies (DLP) for SharePoint
cloud actions, administrators can disable the SharePoint actions by modifying the
appropriate registry setting.

Getting started with SharePoint actions in
desktop flows
This section presents examples on how to use SharePoint actions in your desktop flows.

How to download the content of a SharePoint folder

） Important

Before replicating the following steps, ensure that you are familiar with lists,
custom objects, loops, conditionals, and the percentage notation.

1. Ensure that you installed the latest version of Power Automate for desktop.

2. Create a new desktop flow.

3. If the identifier of the target folder is unknown, use the Get folder metadata using
path SharePoint action to retrieve it. This action requires the folder's path and
produces a custom object containing the folder's metadata. You can access the
identifier using the Id property.



4. Deploy the List folder SharePoint action and populate the appropriate SharePoint
URL and the previously retrieved identifier. The produced list contains custom
objects representing items in the target folder.

5. After retrieving the list, use a For each loop to iterate through the objects inside it.



6. If the items in the target folder are only files, use the Get file content using path
action, and the Path property inside the block to retrieve the current file's contents.

7. Then, deploy the Convert binary data to file action to store the retrieved data in a
local file. You can use the Name property to name the new file with the same name
as the original SharePoint file.



The previous steps cover the case where the target folder contains only files. However, if
the folder contains subfolders with files inside them, modify your desktop flow
accordingly:

1. Add an If condition inside the previously deployed loop to check whether the
currently selected item is a folder. To perform this check, use the IsFolder property
of the current item.



2. Inside the if-block, use the Get folder metadata using path action to get the
identifier of the currently selected folder. The folder path is the same as the one
you used at the beginning of the flow, plus the folder's name. You can access the
folder using the Name property of the current item.

3. As you did before, deploy the List folder SharePoint action and populate the
appropriate SharePoint URL and the previously retrieved identifier.



4. Deploy a For each loop to iterate through the files inside the selected subfolder,
and move and modify the previously deployed Get file content using path and
Convert binary data to file actions to retrieve and save locally the contents of each
file.

If you want to download files of specific subfolders, modify the previously deployed
conditional to check the desired condition. For example, the following condition checks
whether the current item's name is any other than 2022.

７ Note

Although you could use a new nested If action, combining the checks in only one
conditional makes the desktop flow less complicated and easier to read.



If you want to download only files of a specific type, add a conditional before retrieving
the file contents to check whether the file name ends with a particular extension.

How to upload a local file to SharePoint
1. Ensure that you installed the latest version of Power Automate for desktop.

2. Create a new desktop flow.

3. Deploy the Convert file to binary data action and select the desired file on your
local drive. The action stores the converted file in the BinaryData variable.



4. Find the SharePoint group of actions in the flow designer and deploy the Create
file action in the workspace.

5. Select an existing connection reference and fill in the required parameters. Here's
an example about how to fill the fields:

） Important

Don't forget to add the appropriate file extension after the file name.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Office 365 Outlook
Article • 05/24/2024

The Office 365 Outlook group of actions allows the utilization of the Office 365 Outlook
connector from within desktop flows, alleviating the need to create a cloud flow in order
to use its actions. This connector is the same as the one used across Power Automate
cloud flows, Power Apps, and Logic Apps. It uses the same parameters and returns the
same type of data.

Prerequisites and limitations
You need an Attended RPA license.
On top of Data loss prevention policies (DLP) for Office 365 Outlook, machine
administrators can disable the Office 365 Outlook actions by modifying the
appropriate registry setting.

Send an email with attachments
This section presents an example of how to send an email with attachments in your
desktop flows, using Office 365 Outlook actions.

７ Note

In order to include file attachments in your emails, you need to convert those files
using the Convert file to binary data action. Then use the variable containing the
binary data in the Send and Email(v2) action, when adding a file attachment.

Convert the file to attach as binary data using the Convert file to binary data action.



Open the Send an Email(v2) action from Office 365 Outlook group of actions. Within
the Advanced section, next to the Attachments parameter, select Edit.



Add a fixed number of attachments
In the Attachments window, there's already an item existing in the list. Select More to
configure it to contain the desired attachment.



Modify the Name property with the name of the file to be attached. Update
ContentBytes to reference the binary data representing the file.

７ Note

Notice how the %BinaryData%  variable is utilized in the attachment entry in the
ContentBytes property.

You can add more attachments by selecting the plus button.



When all the files to be attached are finalized, select Save to close the Attachments
window and return to the Send an Email(v2) action configuration.



Add a dynamic number of attachments
When you aren't aware of the total number of file attachments you want to include in an
email, use the following approach:



Create a new list. This list contains the attachments to be sent.
A custom object must be used to represent each file attachment. Each custom
object must have the two properties comprising an attachment, 'Name' and
'ContentBytes'.
Once the list is complete, you must pass it as an input to the Attachments
property of the Office 365 Outlook action.

Example
Your desktop flow receives a list containing a dynamic number of filepaths as an input.
You want to attach those files to an email. You begin by creating a new list to store the
files to be sent.

７ Note

You need to loop through the inputted list containing the filepaths, convert them to
binary data, and add the custom object representing each file to the attachments
list.

Add a For each action to loop through the desktop flow input list. During each loop, the
current item is a filepath, pointing to the actual file.

To use it with cloud connector actions, convert the current file to binary data.



The name of the file is needed for the respective property representing it. Use the Get
file path part action to retrieve the name of the current file.

Then add the custom object representing the file in the list of file attachments. To do
that, use the Add item to list action. In the Item property, reference the custom object
using the following syntax:



robin

{'Name': %variable holding the file name%, 'ContentBytes': %variable 
containing the binary data%}

Finally pass the list of file attachments as an input to the Attachments property of the
Send an email (V2) action.



Your action layout should be similar to the following example:



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Work queues actions
Article • 10/15/2024

Work Queues in Power Automate can be used to store process-relevant data and
provide a way to decouple complex processes and automations, allowing them to
communicate asynchronously.

Work queues can play a crucial role in improving the efficiency, scalability, and resiliency
of automations and help prioritize work. Work queues allow you to complete highest-
priority items first, regardless of whether they're processed by digital workers, human
workers, or through integrations.

７ Note

Production-level support for the first set of work queue-related actions
requires Power Automate desktop version 2.37 or later.
Work queue actions in Power Automate for desktop is a premium feature,
which requires a Power Automate subscription .
Currently only Process work queue items and Update work queue item actions
can be classified and allowed or restricted through data loss prevention (DLP)
policies, with other actions following soon. Note that cloud flow-based usage
of work queues can't be restricted by DLP policies.

Process work queue items
The Process work queue items action indicates to the queue orchestrator that the
machine is ready to process one or more work queue items. The user context requesting
a new item needs to have sufficient privileges on the work queue and work queue items
table in order to process work queues.





The work queue referenced in the previous action is used by the queue orchestrator to
determine the next available items in that work queue that are in Queued state. As the
desktop flow steps through the actions within the Process work queue items loop that
this action renders, you can call on the value by utilizing the variable you have
designated for the action along with the property .Value . In this case, you could call the
value of the work queue item using the variable %WorkQueueItem.Value%

） Important

By supplying a FetchXML expression in the "Filter rows" field, you bypass the
default work queue orchestrator's FIFO logic for queued items. This allows you to
set a custom dequeue order and ignore item expiration dates and other settings
that are automatically applied when no filter expression is provided.

Processworkqueueitemaction

The Process work queue item action action requires the following arguments.

Input parameters



ﾉ Expand table

Argument Optional Accepts Default Value Description

Work queue No Text The work queue ID of the
work queue that contains
items to process.

Filter rows Yes Text The FetchXML query
expression used to retrieve
items from the work queue.

Overwrite work Yes Boolean False When enabled, a field appears
queue auto- allowing you to set or
retry overwrite the maximum
configuration number of retries for IT

Exceptions .

Max retry count No Text When not The maximum allowed
value, overwritten, it uses number of retries for IT
Numeric the default max- Exceptions . This parameter
value retry count defined lets you adjust the retry count

on the work queue to a higher or lower value, or
record. even disable the retry

mechanism by setting the
count to 0.

Variables produced

ﾉ Expand table

Argument Type Description

WorkQueueItem No Information stored in the work queue item being processed

Exceptions

ﾉ Expand table

Exception Description

Work queue not found The value entered into the work queue parameter is invalid.

Work queue paused or The work queue is either paused or stopped, which isn't a valid state
stopped when processing items.



Exception Description

Invalid FetchXML An invalid FetchXML expression was provided.

Failed to process work Bad request - error in query syntax.
queue

What are FetchXML queries?
Microsoft Dataverse FetchXML is a language used for retrieving data from a Dataverse
database. It's designed to be easy to create, use, and understand. For example, you
might want to ask the orchestrator to process items in a different order than first-in-
first-out (FIFO) and within a specific expiration timeframe.

To limit FetchXML query support to processing work queue items, a limited set of
FetchXML terms and expressions are supported. These terms include filters, conditions,
and ordering expressions, all restricted to the work queue item table (workqueueitem).
Only items that are in a Queued  state are returned.

Example FetchXML query
The following is an example query expression for how to filter on the name  and order
the results by the records expiring first (FEFO).

XML

<filter type="and">
  <condition attribute="expirydate" operator="on-or-before" value="2024-10-
18" />
  <condition attribute="name" operator="eq" value="MyNonUniqueNameString" />
</filter>
<order attribute="expirydate" descending="false" />

Query support details and reference data
List of query operators available for use, including operators such as on-or-before,
between, and last-month.
List of attributes available in the work queue item table.

Update work queue item



The Update work queue item action allows users to change the status and processing
results of the selected work queue item.



Updateworkqueueitemaction

The Update work queue item action action requires the following arguments.

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Work queue No Text Work queue item variable that has been
item previously returned by the queue

orchestrator

Status No Processed, Processed Update the work queue item being
Generic processed using a status from the list of
Exception options.

Processing Yes Text Custom processing notes or value to
notes append to the queue item being

processed.

Clear Yes Boolean False When enabled, hides and clears the
processing processing notes field on this screen
notes and removes any processing notes from



Argument Optional Accepts Default Description
Value

the database that have been previously
captured for this item.

Exceptions

ﾉ Expand table

Argument Description

Work queue item not The work queue item being processed has either been deleted or no
found longer belongs to the queue that it was called from.

Work queue item on The work queue item being processed contains a status of on hold  in
hold the queue orchestrator and can no longer be updated.

Failed to update work The work queue item being updated has encountered an unexpected
queue item error. Check the error message for more details.

Add work queue item
The Add work queue item action allows users to populate work queue items into a work
queue, which has been set up in the flow portal.





Enqueueworkqueueitemaction

The Add work queue item action requires the following arguments.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Work queue No Text value The work queue item to add the item into



Argument Optional Accepts Default Description
Value

Priority No High, Normal The priority to set the work queue item to
Normal,
Low

Name No Text value, Custom name or ID for the new work
Numeric queue item
value

Input No Text value, The data, which belongs to the value
Numeric column to be processed
value

Expires Yes Datetime The datetime value set to expire the queue
item, otherwise adopts the default value if
one is set for the queue

Processing Yes Text value, Custom processing notes to be added to
notes Numeric the new queue item

value

Has unique Yes Text value, When enabled, a value should be provided
id or Numeric that is unique within this queue. If left
reference value empty, a unique value in the format of

system-<GUID>  is automatically provided by
the system

Variables produced

ﾉ Expand table

Argument Type Description

WorkQueueItem No Information stored for the work queue item being added

Exceptions

ﾉ Expand table

Argument Description

Work queue not found The value entered into the work queue parameter is invalid

Failed to add item into The work queue item couldn't be added into the work queue. Bad
work queue request - error in query syntax



Add multiple work queue items
The Add multiple work queue items action allows users to add one or more work
queue items to a work queue based on the data provided as work queue item data
table.



This action requires a custom data table that holds one or more work queue items. The
data table must have eight columns and conform to the following schema:

ﾉ Expand table

Column Description Required Allowed Values
Name

Name The name of the item. No Any alphanumeric string

Input Input details or data of the item. Yes Any alphanumeric string

Expires in Specifies the duration until the item No Date and time value
expires.



Column Description Required Allowed Values
Name

Processing Processing notes related to the item. No Any alphanumeric string
notes

Priority The priority level of the item. Yes Numeric value of either 100
(High), 200 (Normal), 300
(Low)

Unique A unique identifier or reference value No Any unique alphanumeric
reference for the item. string or reference

Status Status of the item on ingestion. Yes Numeric value of either zero
(Queued), one (On Hold).

Delay until Specifies a date and time until the No Date and time value
work queue items should be ignored
for processing.

Robin code snippet for creating the data table
The following example is a robin code (used in traditional flows) snippet that you can
copy and paste directly into the Power Automate desktop designer window. This snippet
adds a Create new data table action with the expected set of fields to your flow.

JSON

Variables.CreateNewDatatable InputTable: { ^['Name', 'Input', 'Expires in', 
'Processing notes', 'Priority', 'Unique reference', 'Status', 'Delay 
until'], [$'''''', $'''''', $'''''', $'''''', $'''''', $'''''', $'''''', 
$''''''] } DataTable=> DataTable

PowerFx code snippet for creating the data table
The following example is a PowerFx code snippet you can copy and paste directly into
the Power Automate desktop designer window. This snippet adds a Create new data
table action with the expected set of fields to your flow.

JSON

Variables.CreateNewDatatable InputTable: { ^['Name', 'Input', 'Expires in', 
'Processing notes', 'Priority', 'Unique reference', 'Status', 'Delay 
until'], [$fx'', $fx'', $fx'', $fx'', $fx'', $fx'', $fx'', $fx''] } 
DataTable=> DataTable



Batchenqueueworkqueueitemsaction

The Add multiple work queue items action requires the following arguments.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Work queue No Text The work queue item to add the item into
value

Work queue Yes Datatable The custom data table holding work
item data queue items to be added to the work

queue

Variables produced

ﾉ Expand table

Argument Type Default Description
Value

FailedWorkQueueItems No Enabled If there are failures, this object holds the
index of the item that failed to be inserted
together with an error code. The index
returned is the position (index) of the item
in the provided work queue data table of
the Add multiple work queue items action.

HasFailedItems No Enabled An indicator for whether the actions
encountered ingestion errors because of
work queue item data issues.

SuccessfulWorkQueueItems Disabled No A custom object holding the index and work
queue items that were successfully added to
the work queue.

Exceptions

ﾉ Expand table



Argument Description

Work queue not found The value entered into the work queue parameter is invalid

Work queue paused or The work queue item couldn't be added into the work queue
stopped because the work queue is either paused or stopped.

Failed to batch enqueue a list The work queue items couldn't be added into the work queue
of work queue items because of a request or communication error.

Requeue item with delay
The Requeue item with delay action allows users to readd a queue item being
processed in the desktop flow, back into its originating queue. In addition, the queued
item can be held and released until a defined time.



Requeueworkqueueitemaction

The Requeue item with delay action requires the following arguments.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Work queue No Work queue The work queue item to add the item into
item item

Delay until No Datetime Normal The datetime value applied to delay the
value queue item until

Expires Yes Datetime Custom expiration time for the item being
value requeued

Processing Yes Text value, Custom processing notes to be added to
notes Numeric the new queue item

value

Clear Yes Boolean False When enabled, hides and clears the
processing processing notes field on this screen and
notes removes any processing notes from the

database that have been previously
captured for this item

Exceptions

ﾉ Expand table

Argument Description

Work queue not found The value entered into the work queue parameter is invalid

Work queue item not The queue item value is invalid
found

Failed to requeue work The work queue item couldn't be added into the work queue. Bad
queue item request - error in query syntax

Update work queue item processing notes
The Update work queue item processing notes action allows users to update or clear
processing notes of the selected work queue item without changing its state or any
other property.





updateprocessingnotesaction

The Update work queue item processing notes action action requires the following
arguments.

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Work queue No Text Work queue item variable that's been
item previously returned by the queue orchestrator

Processing Yes Text Custom processing result or value to append
notes to the queue item processed

Clear Yes Boolean False When enabled, hides and clears the processing
processing notes field on this screen and removes any
notes processing notes from the database that were

previously captured for this item

Exceptions

ﾉ Expand table



Argument Description

Work queue not found The work queue associated with the item has either been deleted or
is no longer accessible

Work queue item not The work queue item is invalid
found

Failed to append the The work queue item being updated has encountered an
processing results unexpected error. Check the error message for more details.

Get work queue items by filter
The Get work queue items by filter action allows users to retrieve one or more work
queue items based on a FetchXML filter expression.





Getworkqueueitemsaction

The Get work queue items by filter action requires the following arguments.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

Work queue No Text Work queue to retrieve items from

Filter rows No Text FetchXML query expression used to retrieve
items from the work queue

Rows to No Number 5000 The maximum number of work queue items
return returned by the orchestrator

Variables produced

ﾉ Expand table

Argument Type Default Description
Value

WorkQueueItems No Enabled List of work queue items matching the filter
expression.

Exceptions

ﾉ Expand table

Argument Description

Work queue The work queue to retrieve items from.

Filter rows The FetchXML query expression used to retrieve items from the work queue.

Rows to The maximum number of work queue items returned by the orchestrator
return (default is 5000).

What are FetchXML queries?



Microsoft Dataverse FetchXML is a language used for retrieving data from a Dataverse
database. It's designed to be easy to create, use, and understand. For example, you
might want to ask Dataverse to give you a list of all work queue items that are in IT
Exception  state.

To limit the FetchXml query support to retrieving work queue items, we only support a
limited set of FetchXml terms and expressions. These terms and expressions include
attributes, filters, conditions, and ordering expressions, all limited to the work queue
item table (workqueueitem). You must explicitly specify which properties to return from
the work queue item table and the desired sort order.

Example FetchXML query
The following example is a query expression for how to fetch several properties, filter
out erroneous items marked as IT Exceptions , and order the results by those records
expiring first (FEFO).

XML

<attribute name="statecode" />
<attribute name="uniqueidbyqueue" />
<attribute name="createdon" />
<attribute name="completedon" />
<attribute name="workqueueitemid" />
<attribute name="executioncontext" />
<attribute name="name" />
<attribute name="expirydate" />
<attribute name="processingresult" />
<attribute name="priority" />
<attribute name="statuscode" />
<attribute name="modifiedon" />
<attribute name="processingstarttime" />
<attribute name="retrycount" />
<attribute name="requeuecount" />
<attribute name="input" />
<attribute name="delayuntil" />
<filter type="and">
    <condition attribute="statecode" operator="eq" value="4" />
    <condition attribute="statuscode" operator="eq" value="5" />
    <condition attribute="expirydate" operator="on-or-before" value="2024-
10-18" />
</filter>
<order attribute="expirydate" descending="false" />

Query support details and reference data



List of query operators available for use, including operators such as on-or-before,
between, and last-month.
List of attributes available in the work queue item table.

Status (statecode)

ﾉ Expand table

Status Code Description

Queued 0 Item is queued

Processing 1 Item is being processed

Processed 2 Item was processed

OnHold 3 Item is on hold

Error 4 Item encountered an error

Status Reason (statuscode)

ﾉ Expand table

Status Reason Code Description

Queued 0 Item is queued

Processing 1 Item is being processed

Processed 2 Item was processed

OnHold (Paused) 3 Item is on hold (paused)

GenericException 4 Item encountered a generic exception

ITException 5 Item encountered an IT exception

BusinessException 6 Item encountered a business exception

DeadLetter 7 Item is in on-hold

ProcessingTimeout 8 Item processing timed out

Related information
Work queue overview



Manage work queues
Bulk-import work queue data
Trigger work queues
Process work queues

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Custom actions
Article • 07/26/2024

Custom actions developed by your organization and uploaded to the respective
environments can be included in desktop flows and utilized like actions that belong in
the standard library of automation actions.

） Important

Custom actions in Power Automate for desktop is a premium feature which
requires a Power Automate subscription .
This feature requires Power Automate for desktop v2.32 or later.

Custom actions exist at the environment level. As a best practice, use a "dev—test—
prod" model when developing custom actions.

Related information
Assets library
Upload custom actions
Use custom actions

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Cloud Connectors as Power Automate
for desktop actions
Article • 03/21/2025

Cloud Connectors available for Power Automate are now available for desktop flows as
well.

Prerequisites and limitations
You need an Attended RPA license.
Specific endpoints must be included in the allowlist for desktop flows containing
cloud connector actions to work properly. More information: Desktop flow services
required for runtime
For Office 365 Outlook actions, if you're using an EWS application access policy,
ensure that the following user-agents are allowed (on top of the user agents listed
here) for successful desktop flow execution: PowerAutomateLocal/,
PowerAutomateCloud/
Sharing desktop flows with cloud connector actions is currently supported with
certain requirements. Learn more in Share desktop flows that contain connector
actions. Learn about connector actions and their association with connections and
connection references in Use connector actions.
To enable attended or unattended runs (cloud-initiated runs), make sure your
desktop flow uses the Power Automate v2 schema and all connection references
are marked as embedded.
Connection reference embedding is only available for co-owners. Users (run-only)
can run flows shared with them only via Power Automate for desktop's console
using their own connections.
The Microsoft Dataverse connector supports the option Current in the Environment
parameter of its operations in desktop flows. This option allows dynamic resolution
based on the environment. This connector also has the following limitations:

The following actions are currently supported in desktop flows:
Add a new row to selected environment
Delete a row from selected environment
Download a file or an image from selected environment
Get a row by ID from selected environment
List rows from selected environment
Perform a bound action in selected environment
Perform an unbound action in selected environment



Relate rows in selected environment
Unrelate rows in selected environment
Update a row in selected environment
Upload a file or an image to selected environment

Use files in cloud connector actions
To pass a file as an input to a cloud connector action, you must first convert it to binary
data, using the Convert file to binary data action.

Cloud connector actions that create or retrieve files actually produce binary data
representing the respective files. To access the actual file, make sure to use the Convert
binary data to file action first.

Embed connection references on a desktop
flow
With connection reference embedding, you can provide other co-owners access to your
connection references and their underlying resources. You do this process only in the
scope of the respective shared desktop flow.

To embed a connection reference to a flow, you have access to as a co-owner:

Select the desktop flow in Power Automate (make.powerautomate.com), and then
select Details.

In the Connection references section, select Manage.



In the Connection references screen all of the connection references used in a flow
are displayed.

Set the Embed in desktop flow option to Yes to enable it.



After you confirm your selection, the connection reference is embedded in the desktop
flow.

７ Note

You can only embed or remove connection references that you own. Connection
references added by other co-owners can only be managed by them.

） Important

To enable attended or unattended runs (cloud-initiated runs), make sure that your
desktop flow uses the Power Automate v2 schema and all connection references
are marked as embedded.

Bring your own connection
All co-owners and run-only users are required to bring your own connection (BYOC)
during console executions for connection references that aren't embedded.



７ Note

BYOC is available for both co-owners and run-only makers. BYOC is only available
for console initiated flow executions.

List of cloud connectors
These cloud connectors are added by default to desktop flows in Power Automate for
desktop and are always visible in the actions pane:

Microsoft Dataverse
SharePoint
Excel Online (Business)
Microsoft Forms
Microsoft Teams
Office 365 Outlook
OneDrive
OneDrive for work or school
OneNote (Business)
RSS
Word Online (Business)

You can add the rest of the (non-custom) Power Automate cloud connectors to a
desktop flow through the Assets library.



７ Note

Future updates and additions to non-custom Power Automate connectors and their
operations automatically appear in Power Automate for desktop.

Known limitations
Create a connection for a connector in desktop flows through the sign-in dialog. If
an error occurs, create the connection through the corresponding portal page.

Not all connection types are supported to be created through Power Automate for
desktop. For these connectors, create a connection through the corresponding
portal page.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



SAP automation actions
Article • 03/11/2025

Our group of actions for SAP automation provides a set of tools to help streamline and
automate your SAP workflows. With these actions, you can easily launch the SAP GUI
app, create new sessions, select menu items, start and end transactions, and more.

With the actions of the SAP automation group, you can easily interact with SAP UI
elements by clicking on them, filling in text fields, and extracting their data. Just enter
the SAP UI element ID attribute value. If you don't know the ID value, you can use the
Power Automate for desktop UI element picker to capture the required SAP element
and retrieve its ID value. When you capture an SAP UI element in this way, only the
element's ID value is recovered, and no UI element is added to the desktop flow's UI
element repository.

Our SAP automation actions can also be integrated seamlessly with other actions
available in Power Automate for desktop, including the UI automation group of actions.
This group of actions allows you to capture all SAP GUI UI elements and add them to
the desktop flow's UI element repository. By combining our SAP GUI automation actions
with the UI automation group of actions, you can create powerful RPA workflows that
automate even the most complex SAP processes.

７ Note

Power Automate for desktop supports automation with SAP GUI version 750 or
later.

Launch SAP
Open the SAP GUI application and connect to an SAP system.

For connection mode:

The server description option allows you to connect with an SAP system through
the SAP name or IP address. To do this, you need the necessary login credentials
and access permissions. The server description is a human-readable name or
description of the SAP system.
The server connection string option allows you to connect with an SAP system
through a connection string. The server connection string typically includes the
server ‘s name or IP address, the instance number, and the system ID. The server



connection string is a specific format for identifying and connecting to an SAP
system.

For multiple logon options:

Terminate this logon option terminates the specific action’s login.
Continue this logon and end any other logons option replaces the existing SAP
instance with the specific logon.
Continue this logon without ending any other logons in the system option creates
a new SAP session.

７ Note

SAP GUI doesn't allow more than six active connections (sessions) to an SAP
system.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Connection N/A Server description and Server Specify how to connect to
mode server connection string description the SAP GUI server.

Login mode N/A Manual login and single Manual Specify how to log in to the
sign-on (SSO) login SAP GUI server, either log in

to the server by manually
entering your username and
password or using single
sign-on (SSO).

Server Yes Text value Specifies SAP system name
description or IP address for connection.

Connection Yes Text value Specifies the connection
string string for the SAP GUI server.

The connection string is a
unique identifier that
specifies the server's name,
system number, and other
connection details.

Client No Text value Specifies the SAP client
number for connection.



Argument Optional Accepts Default Description
Value

Username No Text value Specifies the SAP user ID for
login.

Password Yes Text value Specifies the SAP user
password for login.

Language No Text value Specifies the SAP login
language for the user
interface.

Multiple No Terminate this logon, Terminate Multiple logon options
logon continue this logon and this logon specify how the SAP system
options end any other logons, behaves when the user tries

Continue this logon to log in when they're
without ending any already logged in.
other logons in the
system

Variables produced

ﾉ Expand table

Argument Type Description

SAPInstance SAP The SAP instance to use with SAP automation actions.
instance The SAP instance refers to the specific SAP window.

CurrentSAPLoginTerminated Boolean Whether the SAP login being performed with the
value specific action is terminated or not.

OtherSAPLoginTerminated Boolean Whether the other SAP logins are terminated or not.
value

Exceptions

ﾉ Expand table

Exception Description

SAP GUI login action fails Indicates a problem logging in to an SAP GUI system.

Attach



Attach the running SAP GUI application to an SAP instance.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

Attach No Foreground or Window Specifies the mode for attaching the SAP
mode last activated, title instance to a window. If Foreground or last

Window title activated option is selected, the SAP
instance is attached to the SAP session in
the foreground. If there's no SAP session in
the foreground, it attaches to the last SAP
session that was launched and isn't closed
yet.

Window Yes Text Specifies the title of the SAP window to
title which the instance is attached. The window

title can be selected from the drop-down
list of existing SAP sessions or entered
manually.

Variables produced

ﾉ Expand table

Argument Type Description

SAPInstance SAP The SAP instance to use with SAP automation actions. The SAP
instance instance refers to the specific SAP window.

Exceptions

ﾉ Expand table

Exception Description

Attach to SAP error Indicates a problem attaching to an SAP instance.

Create new SAP session



Creates a new SAP session based on the same SAP instance.

７ Note

SAP GUI doesn't allow more than six active connections (sessions) to an SAP
system.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

SAPInstance No SAP Select the variable that holds the SAP instance
instance you want to work with. This variable should be

defined in a previous SAP login action.

Variables produced
ﾉ Expand table

Argument Type Description

SAPInstance SAP The SAP instance to use with SAP automation actions. The SAP
instance instance refers to the specific SAP window.

Exceptions

ﾉ Expand table

Exception Description

Create new SAP session action fails Indicates a problem creating a new SAP session.

Select SAP navigation item
Select an SAP menu item in the application toolbar of the SAP window.

Input parameters



ﾉ Expand table

Argument Optional Accepts Default Description
Value

SAPInstance No SAP Select the variable that holds the SAP instance
instance you want to work with. Define this variable in a

previous SAP login action.

Navigation No Text The name of the item in the navigation toolbar
item name value to select, such as 'System'. You can also specify

an option from a submenu by using the '>'
symbol to indicate the parent-child
relationship. For example, 'Program > Execute'
means that the 'Execute' option, which is part
of the submenu under 'Program', is selected.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

SAP GUI select navigation toolbar item Indicates a problem selecting a navigation toolbar
error item.

Select SAP menu item
Select an SAP menu item in the window tool bar. Enter the name of the item in the
respective input parameter manually, in the same language as the SAP GUI screen is
being displayed.

Input parameters
ﾉ Expand table



Argument Optional Accepts Default Description
Value

SAPInstance No SAP Select the variable that holds the SAP instance
instance you want to work with. This variable should

be defined in a previous SAP login action.

Menu item No Text The name of the menu item in the toolbar to
name value be selected, such as ‘Save’. Insert the name of

the menu item as it's displayed in the
machine’s SAP installation.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Select SAP menu item action fails Indicates a problem selecting a menu item.

Close SAP connection
Close the SAP connection of the selected SAP instance. Note that all instances related to
the specific connection will be terminated.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

SAPInstance No SAP Select the variable that holds the SAP instance
instance you want to work with. This variable should be

defined in a previous SAP login action.

Variables produced



This action doesn't produce any variables.

Exceptions
ﾉ Expand table

Exception Description

Close SAP session action fails Indicates a problem closing an SAP session.

Start SAP transaction
Opens a specific transaction code in existing session.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

SAPInstance No SAP Select the variable that holds the SAP
instance instance you want to work with. This variable

should be defined in a previous SAP login
action.

Transaction No Text The transaction code that you desire to
code value execute.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Start SAP transaction action fails Indicates a problem starting an SAP transaction.



End SAP transaction
Closes the SAP transaction in a specific SAP instance and returns to the SAP easy access
menu. An SAP transaction must be started before for the specific SAP session.

Input parameters
ﾉ Expand table

Argument Optional Accepts Default Description
Value

SAPInstance No SAP Select the variable that holds the SAP instance
instance you want to work with. This variable should be

defined in a previous SAP login action.

Variables produced
This action doesn't produce any variables.

Exceptions
ﾉ Expand table

Exception Description

End SAP transaction action fails Indicates a problem ending an SAP transaction.

Click SAP UI element
Interacts through click action on any UI element of an SAP window.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

SAPInstance No SAP instance Select the variable that holds the SAP
instance you want to work with. This



Argument Optional Accepts Default Description
Value

variable should be defined in a
previous SAP login action.

Element type No Basic SAP Basic SAP Select the SAP element type that you
element, element need to interact with. The ‘Click SAP
Checkbox, element’ option performs a click
Label, Drop- action on any SAP element as
down list buttons, radio buttons, tabs, text

fields, trees.

SAP element No Numeric The SAP element’s ID. This parameter
ID determines the UI element in SAP

that action interacts with. You can use
the below button for indication the
SAP UI element in the SAP screen or
insert the value manually.

Set SAP Yes Checked, Checked Specify whether the checkbox
checkbox Unchecked becomes checked or unchecked.
state to

SAP element No Numeric The SAP element’s ID. This parameter
ID determines the UI element in SAP

that action interacts with. You can use
the below button for indication the
SAP UI element in the SAP screen or
insert the value manually.

SAP label Yes Expand, Expand Specify whether to expand or collapse
operation Collapse, the SAP label.

Choose

Drop-down Yes Text value Specify the drop-down option is
option value selected.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table



Exception Description

Click Sap GUI Element error Indicates that the click failed.

Get details of SAP UI element
Gets the value of an SAP UI element's attribute in an SAP window.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

SAPInstance No SAP Select the variable that holds the SAP instance
instance you want to work with. This variable should be

defined in a previous SAP login action.

SAP element No Numeric The SAP element’s ID. This parameter
ID determines the UI element in SAP that action

interacts with. You can use the below button
for indication the SAP UI element in the SAP
screen or insert the value manually.

Attribute No Text Own text The attribute whose value is retrieved.
name value

Variables produced
ﾉ Expand table

Argument Type Description

AttributeValue Text value The value of the SAP UI element's attribute.

Exceptions

ﾉ Expand table

Exception Description

Get SAP element detail error Indicates a problem retrieving the UI element's attribute.



Populate SAP text field in element
Fills a text box in an SAP window with the specified text.

Input parameters

ﾉ Expand table

Argument Optional Accepts Default Description
Value

SAPInstance No SAP instance Select the variable that holds the SAP
instance you want to work with. This
variable should be defined in a previous
SAP login action.

SAP element No Numeric The SAP element’s ID. This parameter
ID determines the UI element in SAP that

action interacts with. You can use the
below button for indication the SAP UI
element in the SAP screen or insert the
value manually.

Text to fill in No Direct The text to fill in the SAP text field
encrypted
input or Text
value

If field isn't Yes Replace text, Replace Specify whether to replace existing
empty Append text text content, or to append.

Variables produced
This action doesn't produce any variables.

Exceptions

ﾉ Expand table

Exception Description

Populate Sap Text Field Value error Indicates a problem populating the specified SAP text field.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Power Automate secret variables actions
(preview)
Article • 03/21/2025

[This article is prerelease documentation and is subject to change.]

In this module, you find actions that allow you to safely retrieve sensitive data that are
available in your environment, offering direct integration with the corresponding
components.

You can securely retrieve CyberArk-based credentials and use them in desktop flows
(preview), or retrieve Azure Key Vault-based credentials and use them in desktop flows
(preview). The credential values are only retrieved at runtime and aren't logged.
Credential type variables are enforced to be sensitive.

） Important

This is a preview feature.
Preview features aren’t meant for production use and might have restricted
functionality. These features are subject to supplemental terms of use , and
are available before an official release so that customers can get early access
and provide feedback.

Get credential
Retrieves the values of a credential created through Power Automate's portal page for
this environment.

７ Note

This action isn't available in sovereign clouds yet.

Input parameters

ﾉ Expand table



Argument Optional Accepts Default Description
Value

Credential No Text value The credential whose values are retrieved

Timeout No Numeric 0 The maximum waiting time (in seconds) to
value get the credential

Variables produced

ﾉ Expand table

Argument Type Description

Credential Credential The content of the retrieved credential

Exceptions

ﾉ Expand table

Exception Description

Failed to get credential Indicates a problem while retrieving the credential

Invalid credentials configuration Indicates that the credentials configuration is invalid

Credential timed out Indicates that the request timed out

Failed to contact credentials Indicates that there was a failure in contacting the credentials
vault vault

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Troubleshoot desktop flows runtime
Article • 01/14/2025

To open the Power Automate troubleshoot tab:

1. Launch Power Automate machine runtime
2. Select Troubleshoot
3. Select Launch Troubleshoot tool

７ Note

You need to have admin privileges to open the troubleshoot tool from Power
Automate machine runtime.

Diagnose runtime connectivity issues
７ Note

You can access the diagnostic tool from Power Automate console as well. Select
help. From the dropdown, select troubleshooter > diagnose connectivity issues
for cloud runtime.

The diagnostic tool helps you identify connectivity issues between your computer and
services required to run Power Automate. It can help debug both cloud runtime and
machine registration issues you might experience. To run the tool, select Launch
diagnostic tool in the troubleshoot tab in the machine runtime.

When you run the tool, Power Automate tries to connect to each required service. If a
connection fails, the logs can help you understand the list of endpoints you must allow.
For the cloud runtime to work, the Power Automate service (UIFlowService) running on
your machine must have access to *.dynamics.com, *.servicebus.windows.net,
*.gateway.prod.island.powerapps.com, and *.api.powerplatform.com.

The tool can check different items based on whether your machine is registered. If you
experience problems registering your machine, read registration troubleshooting
documentation before running the tool. The following table lists the endpoints the tool
checks and the actions to take depending on your machine state.

ﾉ Expand table



Required services What it checks What to do if it fails

Azure Relay (*.servicebus.windows.net) If the machine If your machine isn't registered,
is registered, it ensure *.servicebus.windows.net has
checks the connectivity. If your machine is
specific registered, you can either allow
endpoints used *.servicebus.windows.net or
for machine- specifically the endpoints in the logs.
cloud
communication
that are
established
upon
registration. If
your computer
isn't registered,
it checks a
static relay
endpoint.

Dataverse (*.dynamics.com) If the machine Allow connectivity to *.dynamics.com
is registered, it or your team’s Dataverse URL.
contacts your
specific
Dataverse
environment. If
the machine
isn't registered,
it doesn't do a
check.

Desktop flow service If the machine The logs should tell you what failed.
(*.gateway.prod.island.powerapps.com is registered, it Up to version 2.51,
and *.api.powerplatform.com) checks that the *.gateway.prod.island.powerapps.com

endpoint is must be reachable. Starting with
reachable for version 2.52, *.api.powerplatform.com
desktop flow must also be reachable.
runtime.

Remember that the Power Automate service (UIFlowService) running on your machine is
making the call to required services. On-premises proxy servers might have rules that
require calls to come from a specific user. Consider changing the on-premises service
account to fix these errors if a specific endpoint works in a user session but not via the
Power Automate service.

You can review the list of all services required for desktop flow runtime.



Resolve failed connection between Power
Automate components
See "Communication error" and the connection between Power Automate components
fails

Change the on-premises Service account
The Power Automate service (UIFlowService) communicates with Power Automate cloud
services for machine registration and running desktop flows.

By default, it runs as a virtual account created by the Power Automate installer called NT
SERVICE\UIFlowService.

Most on-premises environments don't require changing the default configuration.
However, you may run into errors registering machines or running flows for the
following reasons:

Your network doesn't allow requests made by the NT SERVICE\UIFlowService
virtual account to reach Power Automate cloud services.
Your machine or group policy disallows the Log on as a service privilege for the
NT SERVICE\UIFlowService account.

In either of these cases, you can ask your domain or network administrator to grant NT
SERVICE\UIFlowService the appropriate privileges. Alternatively, you can replicate the
following steps to change the account with which the Power Automate service runs:

1. Launch the Machine runtime application and select the Troubleshoot tab.
2. Select Change account.
3. Select This account.
4. Provide the new account, for example: DOMAIN\AlexJohnson.
5. Provide the password of this account and select Configure.



Changing the service account can also be accomplished by using a command line tool
that ships with Power Automate called "TroubleshootingTool.Console.exe". This tool is
useful when scripting the upgrade of Power Automate to a more recent version, as
upgrading will reset the UIFlowService to run against the default virtual account.

You can find TroubleshootingTool.Console.exe in the directory where you installed Power
Automate, typically "%programfiles(x86)%\Power Automate Desktop". To change the
service account, do the following:

1. Open a command prompt as an administrator and navigate to the tool.
2. Create a temporary file with the account password as the only content inside (e.g.

temp.txt)
3. Type the following: TroubleshootingTool.Console.exe ChangeUIFlowServiceAccount

<accountname> < <pathToTemporaryFile>
4. Delete the temporary file

Example:

TroubleshootingTool.Console.exe ChangeUIFlowServiceAccount mydomain\myuser <

tempfilethatcontainspassword.txt

The tool also provides other functionality such as getting the name of the account that
the service is currently running as, resetting it to run as the default virtual account, or
simply restarting the service. For more information on all supported commands, simply
run the TroubleshootingTool.Console.exe with no arguments.



Troubleshoot desktop flow runs
If your desktop flow run fails, go to Errors when running attended or unattended
desktop flows and find mitigation steps for different error codes.

If you encounter errors related to the desktop flow run queue, go to Troubleshoot
desktop flow run queue errors.

Collect machine logs
There are several logs you can collect for the machine’s configuration and service logs.
To do so, select Exports logs link in the Troubleshoot tool.

This file is saved to the desktop as a zip file.

Resolve Power Automate agent for virtual
desktops issues
If you encounter errors while launching the Power Automate agent for virtual desktops,
perform the following steps:

1. Close the RDP or Citrix session.
2. Ensure you've installed the correct version of Power Automate for desktop.
3. Connect again to the RDP or Citrix virtual desktop.



4. Restart the Power Automate agent for virtual desktops.

If the agent for virtual desktops can't communicate with Power Automate for desktop,
the agent will be closed. If you're sure that a correct Power Automate for desktop
version is installed, one that supports UI automation in virtual desktops, try the
following remediation steps:

1. Open PowerShell

2. Navigate to the appropriate directory using the following command:

PowerShell

cd "C:\Program Files (x86)\Power Automate Desktop\RDP\DVCPlugin\x64"

3. Run the following two commands:

PowerShell

regsvr32 /u 
.\Microsoft.Flow.RPA.Desktop.UIAutomation.RDP.DVC.Plugin.dll

PowerShell

regsvr32  .\Microsoft.Flow.RPA.Desktop.UIAutomation.RDP.DVC.Plugin.dll

Troubleshoot hosted machines
See Troubleshoot hosted machines in Power Automate for desktop

Get self-help or ask help from support
If you need help, use our self-help options, or ask for help from support.

Self help
1. Go to the Power Automate support site .
2. Go to the Self Help category, and select one of the available self-help options.

Ask for help from support



1. Go to the Power Automate support site .
2. Select Contact support under the Ask for help category.
3. Enter Desktop flows in Problem type, and populate the other fields with

information about your issue.
4. Select See solutions.

） Important

The following statement is subject to change.

We offer customer support for all Power Automate for Desktop versions released
within a year of the latest public release. Security issues are addressed for product
releases up to 6 months old. Bug fixes and product enhancements are always
included in the latest version.

Related information
Power Automate Troubleshooting

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Process migrator for Softomotive
products (preview)
Article • 02/07/2024

[This topic is prerelease documentation and is subject to change.]

） Important

Effective November 3 2023, the Process migrator for Softomotive products
(preview) will be deprecated. “Deprecated” means we intend to remove the
feature or capability from a future release. The feature or capability will
continue to work until it is officially removed. This deprecation notification can
span a few months or years. After removal, the feature or capability will no
longer work. This notice is to allow you sufficient time to plan, migrate and
update your code before the feature or capability is removed.
You may migrate your flows to Power Automate until the deprecation date of
the Process migrator for Softomotive products.

Process migrator for Softomotive products (preview) enables users to convert
automations into desktop flows for use in Power Automate.

This migration utility redefines automations to their equivalent Power Automate desktop
flow action definitions where such parity exists.

Some actions have been deprecated because they don't fit into the Power Platform
ecosystem. However, workarounds should be applicable to overcome what appears to
be missing functionality.

Prerequisites
For Process migrator for Softomotive products (preview) to be able to install and
function as expected, the following Prerequisites are needed:

The latest publicly available version of Power Automate for desktop installed
Access to a Power Automate environment. Follow the get started documentation if
you haven't already provisioned an environment



Installing Process migrator for Softomotive
products (preview)
After successfully downloading the setup file  of the Process migrator for Softomotive
products (preview), run it to install it on your machine.

７ Note

Make sure you are performing a clean installation of Process migrator for
Softomotive products (preview). Also, the migrator will only function as
intended when migrating into an evironment with V1 schema enabled. If the
enviroment you are attempting to migrate into has V2 schema enabled, the
migration utlity will not function as intended. If you require an environment
with V1 schema enabled, please contact your Power Platform administrator.

Uninstall any previous installations of the application.
Remove any previous installation residue (empty installation folders etc.)
Install the latest version of the application.

In the displayed dialog, select an installation path and accept Microsoft's terms of use.



Now, you can run the Process migrator for Softomotive products (preview).

Running Process migrator for Softomotive
products (preview)

1. After launching Process migrator for Softomotive products (preview), you'll be
prompted to populate your Power Automate account.



The application might prompt you to connect to the account you use to access
your environments in order to save the migrated processes as desktop flows.

2. Select the Softomotive product from which you want to migrate processes.



Completing migration and accessing the migrated
processes

1. During the migration, a dialog will display information about the current state of
the migration and a progress bar.

2. When the migration is completed, an autogenerated log file will be displayed
showing the migrated processes.



3. You can access the exported logs at
C:\Users{username}\AppData\Local\Microsoft\Process migrator for Softomotive
products\Logs

７ Note

For the migrated desktop flows to be visible, some time is required. To
instantly view the migrated desktop flows in Power Automate:

Sign out and sign in again in Power Automate, or
Restart the Power Automate service by exiting the service and re-running
Power Automate.



4. Now, you can modify the migrated processes (now desktop flows) through Power
Automate.

 Tip

Running the Process migrator for Softomotive products (preview) will be
paused once an encrypted process has been encountered, waiting for the
password to be inserted by the user. It's advised to group processes based on
whether they are encrypted or not. This way, unencrypted processes will be
migrated without supervision and the encrypted ones will have the required
user attendance.



Overview of RPA templates and
Dynamics 365
Article • 12/16/2022

For many businesses, success increasingly depends on having the agility to innovate and
adapt to rapid change, responding to customer needs, competitive pressure, and
industry trends. However, achieving all these tasks can be difficult when employees
spend time on time-consuming work, such as repetitive tasks and complex processes.

Considering the above, we're dedicated to helping organizations automate manual
business processes across legacy and modern applications, so you can focus on what's
most important for your business and customers.

We're introducing enhanced workplace automation capabilities for Microsoft Dynamics
365—a set of prebuilt RPA solution templates that seamlessly integrate with selected
Dynamics 365 applications.

Initially available for Dynamics 365 Customer Service, Dynamics 365 Supply Chain
Management, and Dynamics 365 Finance, the prebuilt automation templates enable
teams to rapidly automate common business scenarios, freeing time from day-to-day
manual, repetitive, and error-prone tasks.

Developers can further extend any of those solutions using custom actions, custom
connectors, Microsoft Azure services, and APIs to take full advantage of Microsoft's
cloud and data ecosystem.



Save time across customer service, finance, and
supply chain roles
Explore some of the ways that RPA can help streamline processes and save valuable time
across the workforce.

Dynamics 365 Customer Service: Helping call
center agents rapidly validate customer
credentials
Most contact centers require agents to validate or authenticate customer identities
before proceeding with the service engagement. By enhancing Dynamics 365 Customer
Service with RPA, agents can automate steps of the validation process, streamlining call
times and helping agents to troubleshoot and solve customer issues faster.

Dynamics 365 Supply Chain Management:
Streamline ordering of replacement parts for
manufacturing line equipment
We've heard from manufacturing customers about the need to improve the process of
ordering replacement parts for equipment on the factory floor. Often, technicians who
identify defective parts on the manufacturing line need to write down part numbers and
place orders into the tracking system one by one. This approach is an inefficient and
error-prone process. Integrating RPA processes into Dynamics 365 Supply Chain
Management allows technicians to scan and enter part details and submit orders on the
spot, saving time and effort. Since Power Automate natively integrates with Azure IoT
connectors, this solution can be easily extended to use the Azure IoT management
system.

Watch a video  to learn more about the new capabilities included in the latest update
to Dynamics 365 Supply Chain Management.

Dynamics 365 Finance: Streamline the creation
of end-of-billing cycle reports
At the end of billing cycles, finance workers often generate many different end-of-cycle
reports for every account. Traditionally, this task is a manual, time-consuming, and error-



prone process. Dynamics 365 Finance helps streamline many of these processes. By
integrating RPA capabilities in Power Automate, finance teams can now automate many
processes more efficiently, allowing finance professionals to focus on more critical
strategic tasks. These capabilities also improve the accuracy demanded by increasingly
restrictive financial audit regulations.

Next steps
Take the first step to enable your customer service, supply chain, and finance teams to
automate processes in Dynamics 365. Get a free Power Automate RPA trial license, install
Power Automate for desktop, and then import the three solutions mentioned above into
your environment to set it up.



Create orders on Dynamics 365 Supply
Chain Management
Article • 02/24/2023

Dynamics 365  empowers your organization to deliver operational excellence and
delight every customer. To make your use of Dynamics 365 even more productive and
save users time and errors, we're releasing free automation solutions that let Dynamics
365 customers automate common tasks.

This article outlines the steps administrators need to allow users to automate quality
order creation for Dynamics 365 Supply Chain Management  and focus on higher-
priority activities that require their unique creativity.

Prerequisites
Before starting, you must prepare your environment with adequate licenses and
software setup. This section provides step-by-step instructions about how to get the
grounds ready.

Software
You'll need to:

Install Power Automate. Power Automate will carry out the steps in Dynamics 365
as if a human were doing it in front of their computer.
Sign out of the Dynamics 365 app you wish to automate.
Get the appropriate security role for the automation to run.

Sign out of the Dynamics 365 app you wish to automate
To accomplish the full automation, sign out of the application before running the
automation for the first time. You need to do this step if you switch between automation
and your account.

Get the appropriate security role set up for the account
running the automation
You need to decide which work account will run the automation. It can be a dedicated
account created by your admin in Azure Active Directory or the account of an existing



employee. Check that the chosen account has the appropriate security roles to access
the surfaces you're automating.

We recommend the following security roles:

Application Security role Link to
documentation

Power Platform Environment admin or environment maker (if the
environment already has Dataverse and unattended
license needed)

Dynamic 365
Supply Chain
Management

Licenses
If you already use Power Automate, PowerApps and Dynamics 365 applications on a
day-to-day basis, you can skip this section and go to Install the Dynamics 365 RPA
solutions.

Otherwise, you need at least a trial license for these three products. This section shows
you how to acquire these trial licenses.

Get a trial license for Power Automate
Power Automate can automate processes by doing what a human would do on a
keyboard and screen.

There are two ways to automate processes:

1. Attended mode: someone is sitting in front of their computer and watching the
process run as if they were doing it manually.

2. Unattended mode: the process runs in the background on remote machines that
users don’t see.

To run attended, users need to acquire the Power Automate per-user license with RPA.
To run unattended, users need to have acquired two licenses: Power Automate per-user
license with RPA and the Power Automate unattended add-on.

To get a trial license for Power Automate per-user license with RPA:

1. Go to the Power Automate portal, navigate to My Flows > Desktop flows.
2. Select Start free trial now



Alternatively, launch Power Automate for desktop and select Start trial on the console
on the Premium features dialog.

To add a trial license for Power Automate unattended add-on:

1. As an admin, you can get an RPA unattended add-on and assign it to your
environment. To find more information about the RPA unattended add-on, go to
Power Automate sign-up Q&A in your organization

Get a trial license for Power Apps
Follow the instructions in Explore Power Apps for free for 30 days to get a trial license
for Power Apps.

Get a trial license for the Dynamics 365 applications you wish to
automate
To get started with Dynamics 365 Supply Chain Management and automate the quality
order creation process, see Discover how Dynamics 365 Supply Chain Management can
transform the way you do business .

Setup steps
Now that prerequisites are set, you are on your way to get the free solutions that
automate your processes.

Install Power Automate for desktop
1. Download and install Power Automate on the machine that will run the

automation. You can find more information about Power Automate installation in
Install Power Automate.

2. Switch the Power Automate machine settings to the environment in which you'll
install the solution.



3. Sign in to the Power Automate portal  to create a cloud flow with manual trigger.

4. Add the appropriate action to run desktop flows.



5. Select Directly to machine in the Connect field. Then, select the machine name on
which you've installed Power Automate, and enter the machine credential (the
username and password you use to sign in to the machine. To find more
information about direct connectivity, see Manage machines.



Install the Dynamics 365 RPA solution
1. Download  the Dynamics 365 automation solution and save it on your machine.

2. Import the Dynamics 365 automation solution in the environment of your choice:
a. Go to https://powerautomate.microsoft.com  and sign in using your work

account.
b. Select the environment in which you wish to work.
c. In the vertical menu on the left of your screen, select Solutions.
d. In the main bar, select Import then Browse.
e. Navigate to the solution file you previously downloaded and double-click on it.
f. Select Next.

3. Configure the connections needed to be used by the solution in the environment:

a. For each connector the solution uses, either select an existing connection or
create a new one using your Microsoft account and credentials of your choice.



b. Go back to the tab in which you initiate the above step and select Refresh.

c. Select Import. The solution explorer shows you a message informing you that
the solution is being imported. This step may take a few minutes.

4. Enter the parameters that the solution should use to run the process:

a. From the solutions explorer, select the appropriate solution to open it.

b. In this step, you'll see some rows with the value Environment Variable in the
Type column. Add values for each of these.

c. Select each environment variable, and under Current Value, select Add New
Value to put in your parameter.

Environment Description
variable
name

QOrder URL for the SCM environment including parameters for company and form
Parameter - for the InventQualityOrderTable. For example:
SCM Portal https://hxoshmyfoodus9o1mf.sandbox.operations.int.dynamics.com/?
URL cmp=USMF&mi=InventQualityOrderTable

SCM SignIn The user account to sign in to Dynamics 365 SCM. For example:
User helloworld@contoso.com

QOrder The name of the site to use for filling in the quality order creation form.
Parameter –
Site



Environment Description
variable
name

QOrder Configure the Test group for the quality order creation
Parameter –
Test Group

QOrder Configure the Warehouse for the quality order creation
Parameter -
Warehouse

5. Turn on the cloud flow in the solution:
a. In the solution, select the … menu for the QOrder - CloudFlow cloud flow.
b. Select Turn On

6. Put in the encrypted credentials to be used by the solution to sign in to Dynamics
365:

a. From the solution explorer, select the line item called QOrder – Desktop Flow

b. Select Edit, then Launch App. This step will launch Power Automate for desktop.

c. Under the Subflows dropdown, select LoginSCM.

d. In the LoginSCM subflow, open the properties of the action 8.

e. Fill in the Text field with the password of the account to use during automation.



7. Share each component of the solution (app, connection, flow, desktop flow) to
other users in your company as run only user.

8. Have the user launch the QOrder-Application Power App from their phone and
start using it.

Known issues
Known issue Workaround

If you acquire the adequate licenses for Power After you acquire the licenses, go back to the
Automate and Power Apps after you install the solution explorer, select the … menu for the
solution, the flow or app will be turned off. app or flow, and then select Turn On.



Use RPA with Dynamics 365 Finance
Article • 02/24/2023

Dynamics 365  empowers your organization to deliver operational excellence and
delight every customer. To make your use of Dynamics 365 even more productive and
save users time and errors, we're releasing free automation solutions that let Dynamics
365 customers automate common tasks.

This article outlines the steps you need to automate end of cycle reporting in Dynamics
365 Finance  and focus on higher-priority activities that require your unique creativity.

Prerequisites
Before starting, you must prepare your environment with adequate licenses and
software setup. This section provides step-by-step instructions about how to get the
grounds ready.

Software
You'll need to:

Install Power Automate. Power Automate will carry out the steps in Dynamics 365
as if a human were doing it in front of their computer.
Set the appropriate file download configuration in Microsoft Edge to have
complete automation.
Sign out of the Dynamics 365 app you wish to automate.
Get the appropriate security role for the automation to run.

Set the appropriate file download configuration on Microsoft Edge
Microsoft Edge has two ways of downloading files from the internet onto your desktop:

1. It downloads directly on your machine, and saves the file in the destination folder
specified in the Microsoft Edge settings.

2. It asks for the user’s permissions before downloading a file, waits for the user to
accept the download, and then downloads and saves the file in the destination
folder specified in the Microsoft Edge settings.

To make this process fully automated and not require a human in front of the computer
for it to work, you need Microsoft Edge to download files using the first mechanism.



1. Launch Microsoft Edge on your machine.
2. Open the browser settings.
3. In the vertical menu in the left of your screen, select Downloads.
4. Disable the toggle Ask me what to do with each download.
5. Close your browser.

Sign out of the Dynamics 365 app
To accomplish the full automation, sign out of the application before running the
automation for the first time. You need to do this step if you switch between automation
and your account.

Get the appropriate security role set up for the account running the
automation
You need to decide which work account will run the automation. It can be a dedicated
account created by your admin in Azure Active Directory or the account of an existing
employee. Check that the chosen account has the appropriate security roles to access
the surfaces you're automating. To find more information about security roles, go to
Managing security roles in Dynamics 365 .

We recommend the following security roles:

Application Security role Link to
documentation

Power Platform Environment admin or environment maker (if the
environment already has Dataverse and unattended
license needed)

Dynamic 365
Supply Chain
Management

Licenses
If you already use Power Automate, PowerApps and Dynamics 365 applications on a
day-to-day basis, you can skip this section and go to Install the Dynamics 365 RPA
solutions.

Otherwise, you need at least a trial license for these three products. This section shows
you how to acquire these trial licenses.



Get a trial license for Power Automate
Power Automate can automate processes by doing what a human would do on a
keyboard and screen.

There are two ways to automate processes:

1. Attended mode: someone is sitting in front of their computer and watching the
process run as if they were doing it manually.

2. Unattended mode: the process runs in the background on remote machines that
users don’t see.

To run attended, users need to acquire the Power Automate per-user license with RPA.
To run unattended, users need to have acquired two licenses: Power Automate per-user
license with RPA and the Power Automate unattended add-on.

To get a trial license for Power Automate per-user license with RPA:

1. Go to the Power Automate portal, navigate to My Flows > Desktop flows.
2. Select Start free trial now

Alternatively, launch Power Automate for desktop and select Start trial on the console
on the Premium features dialog.

To add a trial license for Power Automate unattended add-on:

1. As an admin, you can get an RPA unattended add-on and assign it to your
environment. To find more information about the RPA unattended add-on, go to
Power Automate sign-up Q&A in your organization

Get a trial license for the Dynamics 365 applications you wish to
automate
To get started with Dynamics 365 Finance and automate the end-of-cycle reporting
process, go to Discover how Dynamics 365 Finance can transform the way you do
business .

Setup steps
Now that prerequisites are set, you are on your way to get the free solutions that
automate your processes.

Install Power Automate



1. Download and install Power Automate on the machine that will run the
automation. You can find more information about Power Automate installation in
Install Power Automate.

2. Switch the Power Automate machine settings to the environment in which you'll
install the solution.

3. Sign in to the Power Automate portal  to create a cloud flow with manual trigger.

4. Add the appropriate action to run desktop flows.



5. Select Directly to machine in the Connect field. Then, select the machine name on
which you've installed Power Automate, and enter the machine credential (the
username and password you use to sign in to the machine. To find more
information about direct connectivity, see Manage machines.



Install the Dynamics 365 RPA solution
1. [Download]https://aka.ms/D365FinanceEndCycleReportingRPASolution) the

Dynamics 365 Finance automation solution and save it on your machine.

2. Import the Dynamics 365 automation solution in the environment of your choice:
a. Go to https://powerautomate.microsoft.com  and sign in using your work

account.
b. Select the environment in which you wish to work.
c. In the vertical menu on the left of your screen, select Solutions.
d. In the main bar, select Import then Browse.
e. Navigate to the solution file you previously downloaded and double-click on it.
f. Select Next.

3. Configure the connections needed to be used by the solution in the environment:
a. For each connector the solution uses, either select an existing connection or

create a new one using your Microsoft account and credentials of your choice.



a. Go back to the tab in which you initiate the above step and select Refresh.

b. Select Import. The solution explorer shows you a message informing you that
the solution is being imported. This step may take a few minutes.

4. Enter the parameters that the solution should use to run the process:

a. From the solutions explorer, select the appropriate solution to open it.

b. In this step, you'll see some rows with the value Environment Variable in the
Type column. Add values for each of these.

c. Select each environment variable, and under Current Value, select Add New
Value to put in your parameter.

Environment Description
variable name

D365CompanyName The name of the company to use in your Dynamics 365
organization. It's located at the top right corner of your screen.

D365FinanceSite The URL to your Dynamics 365 Finance website. It goes until
dynamics.com

D365SiteUserName The email address of the user account the automation should run
under.

5. Turn on the cloud flow in the solution:
a. In the solution, select the … menu for the Report Reconciliation cloud flow.
b. Select Turn On



6. Put in the encrypted credentials to be used by the solution to sign in to Dynamics
365:

a. From the solution explorer, select the line item called Report Validation

b. Select Edit, then Launch App. This step will launch Power Automate for desktop.

c. Under the Subflows dropdown, select login_to_FnO.

d. In the login_to_FnO subflow, open the properties of the action 11.

e. Fill in the Text field with the password of the account to use during automation.

7. Now, test your flows. The demo below shows how the end-to-end scenario works.
You should get a Teams message when the running is complete.



You can customize the desktop flow or cloud flow to create custom reports for your own
scenarios. If you choose to run the automation unattended, you can switch the run
mode from cloud flow.

Known issues
Known issue Workaround

The cloud flow doesn’t run after Go back to the solution explorer, select the … menu for
selecting Play in the flow designer the app or flow, and then select Turn On.



Use RPA with Dynamics 365 Customer
Service
Article • 02/24/2023

Dynamics 365  empowers your organization to deliver operational excellence and
delight every customer. To make your use of Dynamics 365 even more productive and
save users time and errors, we're releasing free automation solutions that let Dynamics
365 customers automate common tasks.

This article outlines the steps you need to automate end of cycle reporting in Dynamics
365 Customer Service  and focus on higher-priority activities that require your unique
creativity.

Prerequisites
Before starting, you must prepare your environment with adequate licenses and
software setup. This section provides step-by-step instructions about how to get the
grounds ready.

Software
Install Dynamics 365 for Customer Service.

Install Power Automate. Power Automate will carry out the steps in Dynamics 365
as if a human were doing it in front of their computer.

The Contoso CRM app from Microsoft. This app showcases how RPA works. You
can use it as an example to build your own RPA action.

） Important

Ensure you get the appropriate security roles  for the account that runs your
automation. This account can be a dedicated one created by your admin in Azure
Active Directory or an employee's account.

Use the following recommended security roles:

Application Security role Link to documentation



Application Security role Link to documentation

Power Platform Option 1: Environment admin 

Option 2: Environment maker (if the environment
already has Dataverse and unattended license
needed)

Dynamics 365 D365 Customer Service administrator Enable users for
for Customer Customer Service and
Service assign roles

Licenses
1. Get a trial license for Power Automate, if you don't have a paid license. The license

you need depends on the mode in which your automations run.

Power Automate support two modes to automate processes.

Attended mode: someone is sitting in front of their computer and watching
the process run as if they were doing it manually. To run attended, users need
to acquire the Power Automate per-user license with RPA.

Unattended mode: the process runs in the background on remote machines
that users don’t see. To run unattended, users need to have acquired two
licenses: Power Automate per-user license with RPA and the Power
Automate unattended add-on.

To get a trial license for Power Automate per-user license with RPA:
a. Go to the Power Automate portal, navigate to My Flows > Desktop flows.
b. Select Start free trial now

Alternatively, launch Power Automate for desktop and select Start trial on the
console on the Premium features dialog.

To add a trial license for Power Automate unattended add-on:
a. As an admin, you can get an RPA unattended add-on and assign it to your

environment. To find more information about the RPA unattended add-on, go
to Power Automate sign-up Q&A in your organization

2. Get a trial license for the Dynamics 365 for Customer Service app .

Set up your device



Now that prerequisites are set, you are on your way to get the free solutions that
automate your processes.

Get the latest updates for your environment
1. Go to Power Platform admin center , select the environment in which you're

interested, and then select Dynamics 365 apps.

2. Confirm that the Agent Productivity Tools and App profile manager are updated.

3. If you see Update available for Agent Productivity Tools and App profile
manager, select Update available.

Install and configure Power Automate
1. Download and install Power Automate on the machine that will run the

automation. You can find more information about Power Automate installation in
Install Power Automate.

2. Switch the Power Automate machine settings to the environment in which you'll
install the solution.



3. Sign in to the Power Automate portal  to create a cloud flow with manual trigger.

4. Add the appropriate action to run desktop flows.



5. Select Directly to machine  from the list.

6. Select Directly to machine in the Connect field. Then, select the machine name on
which you've installed Power Automate, and enter the machine credential (the
username and password you use to sign in to the machine. To find more
information about direct connectivity, see Manage machines.



Install and configure Contoso CRM app
1. Download the Contoso CRM app package  on the machine where the

automation runs.

2. Run setup.exe from the extracted package.

The Contoso app shows you how the end-to-end automation scenario works so
that you can follow the example to create your own automation.

Select More info > Run anyway on the Windows protected you PC screen that
appears during the installation.



3. When the installation is complete, run the Contoso CRM app from the Windows
Start menu.

Install the Dynamics 365 RPA solution



1. Download  the automation solution and save it on your machine.

2. Import the Dynamics 365 automation solution in the environment of your choice:
a. Go to https://powerautomate.microsoft.com  and sign in using your work

account.
b. Select the environment in which you wish to work.
c. In the vertical menu on the left of your screen, select Solutions.
d. In the main bar, select Import then Browse.
e. Navigate to the solution file you previously downloaded and double-click on it.
f. Select Next.

3. Configure the connections needed to be used by the solution in the environment:

a. For each connector the solution uses, either select an existing connection or
create a new one using your Microsoft account and credentials of your choice.

b. For the Desktop connection domain/username and password, ensure you use
the machine's Windows credentials.

4. Go back to the tab in which you initiate the above step and select Refresh.

5. Select Import. The solution explorer shows you a message informing you that the
solution is being imported. This step may take a few minutes.

6. Open Case entity session – default template (or your current case entity session
template), open Agent scripts tab, and then add Case agent script with
automation. To find more information about session templates, go to Manage
session templates.

7. From the Dynamics 365 Customer Service app, sign in to Power Automate.
a. From the case you're working on, select the … menu > Flow.



8. Select Login to Flow.

9. Authenticate using your Dynamics 365 account.

10. Now open one of your cases using Shift + Left Click to launch the productivity
tools panel.

11. From the Agent Script session in the productivity panel, you can see several agent
script steps. The first step is Run Automation to validate Customer. Select the Run
button and confirm it runs.

12. The automation starts on the machine where you have installed Power Automate.
You can watch how the automation uses the case data, opens the Contoso CRM
app, and then finishes the lookup automatically. After the automation runs, refresh
the timeline to view the logs regarding the run result. Here's a demo on how it
runs.



Customize the automation solution
1. Now, you can start customizing the automation to meet your unique requirements.

To do this, open Power Automate and select Edit on the Legacy Contoso App
Contact Lookup desktop flow. You can save a copy to work on your
customizations or work on the template directly.

2. Notice that there are multiple child flows. Each child flow uses the keyboard or the
mouse to interact with the Contoso CRM app. You need to update the steps to
interact with your legacy app.

3. After testing the desktop flow, you can save it. Now, open the cloud flow in
https://powerautomate.microsoft.com/manage/solutions  from within the solution
tab -> Customer Service RPA solution.



4. Open the cloud flow named Automation to validate customer info and expand
each action to review. In the Desktop flow action, you can switch to use any
desktop flow and input/output parameters. To find more information about
triggering desktop flows from cloud flows, go to Trigger desktop flows from cloud
flows.

5. Save the cloud flow. Go back to Dynamics 365 portal and trigger the agent script
action to test. You'll see your customization automation running.

6. Once you finished testing, you can share the cloud flow with everyone in the
organization with run-only mode and switch it to run in unattended mode. This
way every agent will be able to reuse the same automation. License wise, the cloud
flow should be put under a per flow plan.

Troubleshooting and known issues
Known issue Workaround

Can't see the productivity Productivity tools aren't available on the home session. You need
tools panel in the Dynamics to create a new session (Shift-click on case link) to see it.
365 customer service. Productivity tools runtime initialization is async, so wait 1 – 2

seconds on home session before creating new sessions.

Agent can’t see the flow At the first time, every agent needs to sign in to the flow from the
Dynamics 365 widget.

During installation, users get Confirm with yes I am sure to install every time prompted
prompted multiple times to
confirm the installation.



Known issue Workaround

The agent script isn’t added Add manually the agent script to the case session template.
to the current session
template automatically after
importing the demo
solution.



Business process flows overview
Article • 09/25/2024

You can help ensure that people enter data consistently and follow the same steps every
time they work with a customer by creating a business process flow. For example, you
might want to create a business process flow to have everyone handle customer service
requests the same way, or to require that people get approval for an invoice before
submitting an order. Business process flows use the same underlying technology as
other processes, but the capabilities that they provide are different from other features
that use processes. To learn how to create or edit a business process flow, go to Create a
business process flow.

Watch a short video about business process flows.

Why business process flows are used
Business process flows provide a guide for people to get work done. They provide a
streamlined user experience that leads people through the processes their organization
defines for interactions that need to be advanced to a conclusion of some kind. This
user experience can be tailored so that people with different security roles can have an
experience that best suits the work they do.

Use business process flows to define a set of steps for people to follow to take them to
a desired outcome. These steps provide a visual indicator that tells people where they
are in the business process. Business process flows reduce the need for training because
new users don’t have to focus on which table they should be using. They can let the
process guide them. You can configure business process flows to support common sales
methodologies that can help your sales groups achieve better results. For service
groups, business process flows can help new staff get up-to-speed more quickly and
avoid mistakes that could result in unsatisfied customers.

What business process flows can do
With business process flows, you define a set of stages and steps that are then displayed
in a control at the top of the form.





Each stage contains a group of steps. Each step represents a column where data can be
entered. You can advance to the next stage by using the Next Stage button. In model-
driven apps, you can work with a business process flow stage inside the stage flyout or
you can pin it to the side pane. Business process flows don't support expanding the
stage flyout to the side pane on mobile devices.

You can make a step required so that people must enter data for a corresponding
column before they can proceed to the next stage. This is commonly called "stage-
gating." If you're adding a business-required or system-required column to a business
process flow stage, we recommend that you add this column to your form as well.

Business process flows appear relatively simple compared to other types of processes
because they don't provide any conditional business logic or automation beyond
providing the streamlined experience for data entry and controlling entry into stages.
However, when you combine them with other processes and customizations, they can
play an important role in saving people time, reducing training costs, and increasing
user adoption.

７ Note

If any stage, including the current stage, has required columns (except hidden
columns), you must fill in the columns on those stages before you save the form or
move to a new stage. Disabled columns will still block stage navigation if they are
empty and required. Required steps bound to a Two Option (Yes/No) column must
have Yes (true) as their value, otherwise they are considered empty and block stage
navigation. Note that this behavior is different than how business required fields
are handled on a form, where No is not considered an empty value.



Business process flows integrated with other
customizations
When you or your user enters data using business process flows, the data changes are
also applied to form columns so that any automation provided by business rules or form
scripts can be applied immediately. Steps can be added that set values for columns that
aren't present in the form and these columns are added to the Xrm.Page  object model
used for form scripts. Any workflows that are initiated by changes to columns included
in a business process flow are applied when the data in the form is saved. If the
automation is applied by a real-time workflow, the changes are immediately visible to
the user when the data in the form is refreshed after the row is saved.

Although the business process flow control in the form doesn't provide any direct client-
side programmability, changes applied by business rules or form scripts are
automatically applied to business process flow controls. If you hide a column on a form,
that column is also hidden in the business process flow control. If you set a value by
using business rules or form scripts, that value is set within the business process flow.

Concurrent process flows
Concurrent business process flows let customizers configure multiple business processes
and associate them with the same starting row. Users can switch between multiple
business processes running concurrently, and resume their work at the stage in the
process that they were on.

System business process flows
When your Power Platform environment has the Enable Dynamics 365 apps setting on,
the following business process flows are included. To understand how business process
flows work, review these system business process flows:

Lead to Opportunity Sales Process
Phone to Case Process
Sales Process

Multiple tables in business process flows
You can use a business process flow for a single table or span multiple tables. For
example, you can have a process that begins with an opportunity, then continues to a
quote, an order, and then an invoice, before finally returning to close the opportunity.



You can design business process flows that tie together the rows for up to five different
tables into a single process so that people using the app can focus on the flow of their
process rather than on which table they're working in. They can more easily navigate
between related table rows.

Multiple business process flows are available
per table
Not every user in an organization follows the same process and different conditions
might require that a different process be applied. You can have up to 10 active business
process flows per table to provide appropriate processes for different situations.

Control which business process flow is applied
You can associate business process flows with security roles so that only people with
those security roles can view or use them. You can also set the order of the business
process flows so that you can control which business process flow is set by default. This
works in the same way that multiple forms for a table are defined.

When someone creates a new table row, the list of available active business process
definition is filtered by the user’s security role. The first activated business process
definition available for the user’s security role according to the process order list is the
one applied by default. If more than one active business process definitions are
available, users can load another from the Switch Process dialog. Whenever processes
are switched, the one currently rendered goes to the background and is replaced by the
selected one, but it maintains its state and can be switched back. Each row can have
multiple process instances associated (each for a different business process flow
definition, up to a total of 10). On form load, only one business process flow is rendered.
When any user applies a different process, that process can only load by default for that
particular user.

To make sure a business process is loaded by default for all users (behavior equivalent
to "pinning" the process), a custom client API script (web resource) can be added on
form load that specifically loads an existing business process instance based on the
business process definition ID.

Business process flow considerations
You can define business process flows only for those tables that support them. You also
need to be aware of the limits for the number of processes, stages, and steps that can



be added.

Business process flows that call a workflow
You can call on-demand workflows from inside a business process flow. You configure
this from the business process flow designer by dragging a workflow component to a
process stage or to the Global Workflows section.

When you include a workflow that you want to trigger on Stage Exit of a stage in your
business process flow, and that stage is the last stage in the flow, the designer gives the
impression that the workflow is triggered when that stage is completed. However, the
workflow isn't triggered because a stage transition doesn't take place. You don't receive
a warning or error preventing you from including the workflow on the stage. When a
user interacts with the business process flow, finishing or abandoning the process
doesn't result in a stage transition, and therefore the workflow isn't triggered. Consider
the following examples:

You create a business process flow with two stages. S1 connects to S2, with a
workflow on stage S2 and sets the trigger to Stage Exit.

You create a business process flow with three stages, S1 connect to S2, then S2
branches to S3. You include a workflow on S2 and set the trigger to Stage Exit.

The workflow doesn't trigger in either case. To work around this issue, add a global
workflow and add the workflow you want to trigger to it so that the workflow is
triggered for the business process rather than a stage of the process. You can set the
trigger for a global workflow to Process Abandoned or Process Completed to cause the
workflow to trigger when a user abandons or completes the business process.

Tables that can use business process flows
All custom tables can use business process flows. The following standard tables can also
use business process flows. Some tables require a Dynamics 365 app, such as Dynamics
365 for Sales or Dynamics 365 for Customer Service.

Account
Appointment
Campaign
Campaign Activity
Campaign Response
Competitor
Contact



Email
Entitlement
Fax
Case
Invoice
Lead
Letter
Marketing List
Opportunity
Phone Call
Product
Price List Item
Quote
Recurring Appointment
Sales Literature
Social Activity
Order
User
Task
Team

To enable a custom table for business process flows, select the Business process flows
(columns will be created) check box in the table definition. You can’t undo this action.

７ Note

If you navigate to the business process flow stage that contains the Social
Activity  table and choose the Next Stage button, you’ll see the Create option.
When you choose Create, the Social Activity form loads. However, because Social
Activity  isn’t valid for Create  from the app user interface, you won’t be able to
save the form and you’ll see the error message: “Unexpected error.”

Maximum number of processes, stages, and steps
To ensure acceptable performance and the usability of the user interface, there are some
limitations you should be aware of when you use business process flows:

There can be no more than 10 activated business process flow processes per table.
Each process can contain no more than 30 stages.
Multi-table processes can contain no more than five tables.



Business process flow table customization
support
Business process flow tables can appear in the system so that table row data can be
made available in grids, views, charts, and dashboards.

Use business process flow table rows with grids, views,
charts, and dashboards
With business process flows available as a table, you can use advanced finds, views,
charts, and dashboards sourced from business process flow data for a given table, such
as a lead or opportunity. System administrators and customizers can create custom
business process flow grids, views, charts, and dashboards similar to those created with
any other table.

To access a default business process flow view, go to Power Apps , select Solutions,
open the solution you want, select Objects > Tables, and open the process table that
you want, such as Lead To Opportunity Sales Process table. Select Views, and then
select the view that you want.

Several default views are available that you can view as a chart, such as the Active
Opportunity Sales Process view.

Interact with the business process flow table from a
workflow
You can also interact with business process flow tables from a workflow. For example,
you can create a workflow for the Business Process Flow table row to change the Active
Stage when a column on the Opportunity table row is updated. For more information
about how to do this, go to Automate business process flow stages using workflows .



Run business process flows offline
You can use business process flows offline if the following conditions are met:

The business process flow is used from a Power Apps app.
The Power Apps app is enabled for offline use.
The business process flow has a single table.

Specifically, the three commands that are available for a business process flow when the
Power Apps app is offline are:

Next stage
Previous stage
Set Active stage

Lookup column in a business process flow stage
Recent rows are visible in a lookup column for a model-driven app. To prevent the most
recently used items from showing up in the lookup, follow these steps:

1. While in the form designer with a table form for a table used in a business process
flow, select your lookup column data step from the Tree view on the left
navigation pane.

2. Check Disable most recently used items.



3. Save and then publish.

Limitations of using business process flow tables
Currently, you can’t create custom forms for tables based on a business process
flow.

If a solution includes a business process flow table, the business process flow table
must be manually added to the solution before you export it. Otherwise, the
business process flow table won't be included in the solution package. To learn
more, go to create and edit tables.

Adding the process table to a model-driven app might result in limited
functionality. To learn more, go to creating and editing business process flows.

The name of a business process flow doesn't change after the flow is created for a
form. If you change the name in the business process flow definition, new business
process flows display the updated name, but older ones display the original name.
The name doesn't translate after it's set. If the flow creator's language settings was
set to Spanish when the business process flow instance was created, the name will
be in Spanish for all users, even if the flow creator changed their language later.



Related information
Get started with Power Apps
Get started with Power Apps
Whitepaper: Process Enablement with Dynamics 365

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Tutorial: Create a business process flow
Article • 01/16/2025

） Important

As of August 2022, you can no longer create or manage business process flows
from Power Automate outside of the solution explorer. Business process flows and
instances continue to be supported through the solution explorer, Power Apps, and
Dataverse table views.

This article shows you how to create a business process flow with Power Apps. To learn
more about the benefits of using business process flows, go to Business process flows
overview. For information on how to create mobile task flows, go to Create a mobile
task flow.

When a user starts a business process flow, the stages and steps of the process display
in the process bar at the top of a form.

 Tip

After you create a business process flow definition, you can control who can create,
read, update, or delete the business process flow instance. For example, for service-
related processes, provide full access for customer service reps to change the
business process flow instance, but provide read-only access for sales reps to
monitor post-sales activities for their customers. To set security for a business



process flow definition that you create, select Enable Security Roles on the action
bar.

Prerequisites
To create business process flows, you need a Power Apps or Power Automate per
user license, or a Dynamics 365 license plan  that includes business process flow
use rights.
A table with which the business process flow is associated. If the business process
flow isn't related to an existing table, create a new table before you create the flow.

Create a business process flow
1. In Power Apps  or Power Automate , select Solutions from the navigation bar

on the left.

2. Select or create a solution to use for the business process flow.

3. Within the solution, select New > Automation > Process > Business process flow.
a. Give your flow a Display name and Name (LogicalName).
b. Select the table to use for the flow.
c. Select Create.

The new business process flow is created. You can now edit it with a first single
stage created for you.

4. Add stages. If your users progress from one business stage to another in the
process:



a. Drag a Stage component from the Components tab and drop it on a + sign in
the designer.

b. To set the properties for a stage, select the stage, and then set the properties in
the Properties tab on the right side of the screen:

Enter a display name.

If desired, select a category for the stage. The category (such as Qualify or
Develop), appears as a chevron in the process bar.

When you're done changing properties, select the Apply button.

5. Add steps to a stage. To see the steps in a stage, select Details in the lower-right
corner of the stage. To add more steps:

a. Drag the Step component to the stage from the Components tab.

b. Select the step, and then set properties in the Properties tab:
i. Enter a display name for the step.
ii. If you want users to enter data to complete a step, select the appropriate

column from the drop-down list.
iii. Select Required if people must fill in the column to complete the step before

moving to the next stage of the process.
iv. Select Apply when you're done.

７ Note



If you set a two-option boolean column as Required, users can't
continue unless the column value is Yes. The user is required to mark the
column as completed before moving to the next stage.
If either Yes or No are acceptable column values, then you should make
the column a choice instead of a two-option boolean column.

6. Add a branch (condition) to the process. To add a branching condition:

a. Drag the Condition component from the Components tab to a + sign between
two stages.

b. Select the condition, and then set properties in the Properties tab. For more
information on branching properties, go to Enhance business process flows with
branching. When you're finished setting properties for the condition, select
Apply.

7. Add a workflow. To invoke a workflow:

a. Drag a Workflow component from the Components tab to a stage or the
Global Workflow item in the designer. Where you add it depends on these
conditions:

Drag it to a stage to trigger the workflow on entry or exit of the stage. The
workflow component must be based on the same primary table as the
stage.
Drag it to the Global Workflow item to trigger the workflow when the
process is activated or archived (when the status changes to Completed or
Abandoned). The workflow component must be based on the same
primary table as the process.

b. Select the workflow, and then set properties in the Properties tab:
i. Enter a display name.
ii. Select when the workflow should be triggered.
iii. Search for an existing on-demand active workflow that matches the stage

table or create a new workflow by selecting New.
iv. Select Apply when you're done.

For more information on workflows, go to Workflow processes.



8. To validate the business process flow, select Validate on the action bar.

9. To save the process as a draft while you continue to work on it, select Save in the
action bar.

） Important

As long as a process is a draft, people aren't able to use it.

10. To activate the process and make it available to your team, select Activate on the
action bar.

11. To provide control over who can create, read, update, or delete the business
process flow instance, select Edit Security Roles on the command bar of the
designer. For example, for service-related processes, provide full access for
customer service reps to change the business process flow instance, and read-only
access for sales reps to monitor post-sales activities for their customers.

In the Security Roles screen, select the name of a role to open the security role
information page. Select the Business Process Flows tab, and then assign appropriate
privileges on the business process flow for a security role.

７ Note

The System Administrator and System Customizer security roles have access to new
business process flows by default.

Specify privileges by selecting the appropriate radio buttons, and select Save. For more
information about privileges, go to Business process flow privileges.

Next, don't forget to assign the security role to appropriate users in your organization.



 Tip

Here are a few tips to keep in mind as you work on your task flow in the designer
window:

To take a snapshot of everything in the business process flow window, select
Snapshot on the action bar. This option is useful if you want to share and get
comments on the process from a team member.
Use the mini-map to navigate quickly to different parts of the process. This
feature is useful when you have a complicated process that scrolls off the
screen.
To add a description for the business process, select Details under the process
name in the left corner of the business process flow window. You can use up
to 2,000 characters.

Design business process flows with branches
Consider these points when designing business process flows with branches:

A process can span a maximum of five unique tables.

Use a maximum of 30 stages per process and 30 steps per stage.

Each branch can be no more than 10 levels deep.

Branching rules must be based on the steps in the preceding stage.

You can combine multiple conditions in a rule by using the AND  operator or the OR
operator, but not both operators.

When defining a process flow, optionally select a table relationship. This
relationship must be a 1:N (One-to-Many) relationship.

Multiple active processes can run concurrently on the same record.

Rearrange tiles (stages, steps, conditions) on the process flow by dragging and
dropping.

When merging branches using the connector command, all peer branches must
merge to a single stage. Peer branches must merge to a single stage or end the
process. A peer branch can't merge with other branches and end the process at
the same time.



You can revisit a table used in the process multiple times (multiple closed entity
loops).

A process can return to the previous stage regardless of the table type.

For example, if the active stage is Deliver Quote on a quote record, users can
move the active stage back to the Propose stage on an opportunity record.

In another example, suppose a process is in the Present Proposal stage in your
process flow: Qualify Lead > Identify Needs > Create Proposal > Present
Proposal > Close. If the proposal requires more research to identify customer
needs, users can select the Identify Needs stage of your process and choose Set
Active.

Edit a business process flow
To edit a business process flow, open the solution explorer, select Processes, and then
select the Business Process Flow from the list of processes that you want to edit.

Select the business process flow you want to edit from the list of processes. It opens in
the designer, where you can make updates. Expand Details under the name of the
process to rename it or add a description, and view additional information.

Other things to know about business process
flows
Edit Stages
Business process flows can have up to 30 stages.

You can add or change the following properties of a stage:

Stage Name

Table. You can change the table for any stage except the first one.



Stage Category. A category lets you group stages by a type of action. It's useful for
reports that group rows by the stage they are in. The options for the stage
category come from the Stage Category global choice. You can add more options
to this global choice and change the labels of existing options if you want. You can
also delete these options if you wish, but we recommend that you keep the
existing options. You can't add the exact same option back if you delete it. If you
don’t want them to be used, change the label to ”Do not use”.

Relationship. Enter a relationship when the preceding stage in the process is based
on a different table. For the stage currently being defined, choose Select
relationships to identify a relationship to use when moving between the two
stages. Select a relationship for the following benefits:

Relationships often have column maps defined that automatically carry over
data between rows, minimizing data entry.

When you select Next stage on the process bar for a row, any rows that use the
relationship are listed in the process flow, promoting reuse of rows in the
process. In addition, you can use workflows to automate creation of rows so
that the user simply selects it instead of creating one to further streamline the
process.

Edit Steps
Each stage can have up to 30 steps.

Add branch
To learn about adding a branch to a stage, go to Enhance business process flows with
branching.

To make a business process flow available for people to use, you must order the process
flow, enable security roles, and activate it.

Set Process Flow Order
When you have more than one business process flow for a table (row type), you need to
set which process is automatically assigned to new rows. In the command bar, select
Order Process Flow. For new rows or rows that don't already have a process flow
associated with them, the first business process flow that a user has access to is used.

Enable Security Roles
Users have access to a business process flow depending on the privilege defined on the
business process flow in the security role assigned to the user.

By default, only the System Administrator and System Customizer security roles can
view a new business process flow.



To specify privileges on a business process flow, open the business process flow for edit,
and then select Edit Security Roles on the command bar of the business process flow
designer. See step 13 under Create a business process flow listed earlier in this article.

Activate
Before anyone can use the business process flow, you must activate it. In the command
bar, select Activate. After you confirm the activation, the business process flow is ready
to use. If a business process flow has errors, you can't activate it until the errors are
corrected.

Add an on-demand action to a business
process flow
The Dynamics 365 (online), version 9.0 update introduces a business process flow
feature: business process flow automation with Action Steps. You can add a button to a
business process flow that triggers an action or workflow.

Add on-demand workflows or actions using an Action
Step
As part of the opportunity qualification process, Contoso requires a designated reviewer
to review all opportunities. Later Contoso created an action that:

Creates a task row that is assigned to the opportunity reviewer.
Appends “Ready for review” to the opportunity topic.

Additionally, Contoso needs to be able to run these actions on demand. To integrate
these tasks into the opportunity qualification process, the actions must appear on the
opportunity business process flow. To enable this functionality, select As a Business



Process Flow action step.

Next, the Action Step is added to Contoso’s opportunity business process flow. Then the
process flow is validated and updated.

Now, members of Contoso’s salesforce can kick off the action from the Opportunity
Qualify business process step, on demand, by selecting Execute.



） Important

To be able to execute an action or workflow on demand, the business process
flow must include an Action Step. If the Action Step runs a workflow, the
workflow must be configured to run on demand.
The table associated with the action or workflow must be the same as the
table associated with the business process flow.

Limitation of using Action Steps in a business process
flow

Actions aren't available as Action Steps if the input or output parameters are Table,
EntityCollection, or OptionSet (Choice) types. Actions with more than one
EntityReference output parameter or any number of EntityReference input
parameters aren't available as Action Steps. Actions not associated with a primary
table (global action) aren't available as Action Steps.

The action center
When you need to see the list of business process flows in which you're involved, check
out the unified action center.



In the unified action center, you see all business processes in which you're assigned at
least one Microsoft Dataverse table row that the process uses. For example, if a business
process uses the Lead and Opportunity tables in Dataverse, you see all instances of this
process where either the Lead or the Opportunity row is assigned to you.

View all instances that are currently being worked under the Active tab. From this tab,
you can view the following details:

The name of the process.
The current stage for each process.
The owner of the Dataverse row associated with the active stage.
The time since the instance was created.

Select an instance to open it in a new tab, or select it to copy a link, share a link via
email, abandon, or delete the instance.

Next steps
Business process flows overview



Enhance business process flows with branching
Overview of approvals
Detailed steps for adding an instant flow to a business process flow

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create instant flows in business process
flows
Article • 12/16/2022

You can run an instant flow to automate repetitive tasks, generate documents, track
approvals, and more, from inside a stage in a business process.

Add an instant flow as a step in a business
process
Let's assume you sell printers and you use the Lead to Opportunity Sales Process to
close deals. As part of this process, you’d like to have the team lead review and approve
proposals that the sales team puts together in an earlier stage of the business process
flow before sharing it with the customer.

To do this, you'll need to do two things:

1. Build an instant flow that requests review and approval of the proposal from the
team.

2. Add the instant flow as a step in the Lead to Opportunity Sales Process.

 Tip

Only solution-aware flows can be added as a step in a business process.

Build an instant flow
1. In Power Automate, select Solutions in the navigation menu.

2. Select Default Solution from the list of solutions that appears.

3. Select the + New menu, and then select Flow from the list that appears.

4. Search for, and then select the Microsoft Dataverse connector.

5. Search for, and then select the When a row is selected trigger from the list of
Microsoft Dataverse triggers.

6. Set Environment to Default, and then set Table Name to Lead to Opportunity
Sales Process.



7. Add a text input column for the user to enter the link to the proposal.

We'll need information from the business process flow instance to help provide
context for the approval request so follow these steps to do this.

8. Add the Parse JSON action.

9. Set Content to table by selecting it from the list of dynamic values for the When a
row is selected trigger.

10. Paste the following content into the Schema column.

JSON

{

    "type": "object",

    "properties": {

    "entity": {

        "type": "object",

        "properties": {

            "FlowsWorkflowLogId": {

                "type": "string"

            },

            "BPFInstanceId": {

                "type": "string"

            },

            "BPFInstanceEntityName": {

                "type": "string"

            },

            "BPFDefinitionId": {

                "type": "string"

            },

            "BPFDefinitionEntityName": {

                "type": "string"

            },

            "StepId": {

                "type": "string"

            },

            "BPFDefinitionName": {




                "type": "string"

            },

            "BPFInstanceName": {

                "type": "string"

            },

            "BPFFlowStageLocalizedName": {

                "type": "string"

            },

            "BPFFlowStageEntityName": {

                "type": "string"

            },

            "BPFFlowStageEntityCollectionName": {

                "type": "string"

            },

            "BPFFlowStageTableRowID": {

                "type": "string"

            },

            "BPFActiveStageId": {

                "type": "string"

            },

            "BPFActiveStageEntityName": {

                "type": "string"

            },

            "BPFActiveStageLocalizedName": {

                "type": "string"

            }

        }

      }

    }

}


Things should look like this now:

11. Add the Get row by ID action from the Microsoft Dataverse connector.



12. Set Table Name to Lead to Opportunity Sales Process, and Row ID to
BPFFlowStageTableRowID.

Now that we have the data, define the approval process by adding the Start and
wait for an approval (V2) action, and then filling in the relevant information. Learn
more about approvals if you are not familiar.

 Tip

Use the dynamic content picker to add columns from the Get row by ID
action to add relevant information to the approval request so that
approvers can easily know what the request is about.
To provide further context regarding the active stage that the business
process is in, add the BPFActiveStageLocalizedName column from the
list of dynamic values.

Your Start and wait for an approval (V2) card might look similar to this one:



13. Finally, save the flow and then turn it on.

Add this flow as a step in the Lead to
Opportunity Sales Process.
Now that you've created the instant flow, all that's needed is for you to add it to your
business process flow.

1. Open the Lead to Opportunity Sales Process in the business process flow
designer.

2. Drag and drop the Flow Step (Preview) from the list of Components onto the
Propose stage.

3. Next, select the search icon in the Select a Flow column to list all flows that you
can added to a business process flow.

4. Select a cloud flow from the list, and then save your changes by selecting the
Apply button at the bottom of the properties pane.

5. Finally, select the Update button to make this business process flow with its new
instant flow step available to your users.

Flow step considerations
The status of your flow step might be Processing even after your flow successfully ran to
completion, if you are not writing to the process log. In order to mark a cloud flow step
as completed, add the Update a row action of the Microsoft Dataverse connector under
the If yes path. Set the Table to Process Logs. Then set Row ID to FlowsWorkflowLogId
by picking it from the list of dynamic values. Finally, set Status Value to Succeeded by
selecting it from the dropdown.

７ Note

The user requires read access to the System Jobs table in Dataverse for the status
to change from Processing to Completed.



Tutorial: Enhance business process flows
with branching
Article • 05/05/2023

Business process flows guide you through various stages of sales, marketing, or service
processes toward completion. In simple cases, a linear business process flow is a good
option. However, in more complex scenarios, you can enhance a business process flow
with branching. If you have the create permissions on business process flows, you’ll be
able create business process flow with multiple branches by using the If-Else  logic.
The branching condition can be formed of multiple logical expressions that use a
combination of AND  or OR  operators. The branch selection is done automatically, in real
time, based on rules defined during the process definition. For example, in selling cars,
you can configure a single business process flow, which after a common qualification
stage splits into two separate branches on the basis of a rule (Does the customer prefer
a new car or pre-owned car, is their budget above or below $20,000, and so on. ), one
branch, for selling new cars and another branch, for selling pre-owned cars. For more
information about Business process flows, see Business process flows overview.

The following diagram shows a business process flow with branches.

What you need to know when designing
business process flows with branches



Take notice of the following information when you design the business process flow
with the branches:

A process can span across a maximum of five unique tables.

You can use a maximum of 30 stages per process and a maximum of 30 steps per
stage.

Each branch can be no more that five levels deep.

Branching rule must be based on the steps in the stage that immediately precedes
it.

You can combine multiple conditions in a rule by using the AND  operator or the OR
operator, but not both operators.

When you define a process flow, you can optionally select a table relationship. This
relationship must be a 1:N (One-to-Many) table relationship.

More than one active process can run concurrently on the same data row.

You can rearrange tiles (Stages, Steps, Conditions etc.) on the process flow using
drag and drop.

When merging branches, all peer branches must merge to a single stage. The peer
branches must all either merge to a single stage, or each peer branch must end the
process. A peer branch can’t merge with other branches and at the same time end
the process.

Client API changes can't trigger evaluation of branching condition, as branching
relies on Business rules.

For forms in model-driven apps, interacting with future stages triggers their
conditions and business rules. However, if the active stage remains the same, those
rules won't be run again when the form reloads. Only rules in the active stage are
run on form load.

７ Note

A table used in the process can be revisited multiple times (multiple closed
table loops).

A process can go back to the previous stage regardless of a table type. For
example, if the active stage is Deliver Quote on a quote row, process users



can move the active stage back to the Propose stage on an opportunity row.

In another example, suppose a process is currently in the Present Proposal
stage in your process flow: Qualify Lead > Identify Needs > Create Proposal
> Present Proposal > Close. If the proposal presented to the customer
requires more research to identify customer needs, users can simply select the
Identify Needs stage of your process and choose Set Active.

Example: Car selling process flow with two
branches
Let’s look at the example of the business process flow with two branches, for selling new
and pre-owned cars.

First, we’ll create a new process named Car Sales Process.

1. Open solution explorer and then in the left navigation pane select Processes.

2. Select New to create a new process.

3. Specify the Category as Business Process Flow and for the primary Entity choose
Lead.

4. Add the first stage to the process called Qualify and add steps Purchase Time
frame and Car Preference.

5. After the common Qualify stage, we split the process into to two separate
branches, by using the Condition tile.

a. Configure the condition tile with rules that meet your business requirements

b. To add the first branch for a stage, add a Stage tile on the “Yes” path of the
condition tile

c. To add the second branch that is executed when condition isn't satisfied, add
another Stage tile on the “No” path of the condition tile

 Tip

You can add another condition on the “no” path of an existing condition tile to
create more complex branching.



If the Car preference = New, the process branches out to the New Car Sales stage,
otherwise, it jumps to the Pre-Owned Car Sales stage, in the second branch, as shown
below.



After completing all the steps in the New Car Sales stage or Pre-Owned Car Sales stage,
the process returns back to the main flow, with the Deliver Quote stage.

Prevent information disclosure
Consider a business process flow with branches for processing a loan request at a bank,
as shown below. The custom tables used in the stages are shown in parenthesis.



In this scenario, the bank loan officer needs access to the Request row, but the loan
officer shouldn’t have any visibility into the investigation of the request. At first glance, it
looks that we can easily do this by assigning the loan officer a security role that specifies
no access to the Investigation table. But, let’s look at the example in more detail and see
if this is really true.

Let’s say that a customer puts in the loan request for over $60,000 to the bank. The loan
officer reviews the request in the first stage. If the branching rule that checks if the
amount owed to the bank will exceed $50,000 is satisfied, the next stage in the process
is to investigate if the request is fraudulent. If it’s determined that this is indeed a case
of fraud, the process moves on to taking a legal action against the requestor. The loan
officer shouldn’t have visibility into the two investigative stages as the officer doesn’t
have access to the Investigation table.

However, if the loan officer opens the Request row, all would be able to see the entire
end-to-end process. Not only will the loan officer be able to see the fraud investigation
stage, but they’ll also be able to identify the outcome of the investigation by having
been able to see the Legal Action stage in the process. Also, the officer will be able to
preview the steps in the investigative stages by choosing the stage. While the loan
officer won’t be able to see the data or the step completion status, they’ll be able to
identify the potential actions that were taken against the submitter of the request
during the investigation and legal action stages.

In this process flow, the loan officer will be able to see the Fraud Investigation and Legal
Action stages, which constitutes an improper information disclosure. We recommend
paying special attention to the information that may become disclosed due to
branching. In our example, split the process into two separate processes, one for the
request processing and another one for the fraud investigation, to prevent the
information disclosure. The process for the loan officer will look like this:



The process for the investigation will be self-contained and include the following stages:

You'll need to provide a workflow to synchronize the Approve/Deny decision from the
Investigation row to the Request row.

Next steps
Create a business process flow

Create custom business logic with processes



Add an on-demand workflow to a
business process flow
Article • 03/10/2023

You can trigger on-demand workflows from inside a business process flow. For example,
you can add an on-demand workflow to a business process flow so that an activity, such
as a task or email, is created whenever a stage is completed.

A workflow becomes activated based on where you drop the workflow onto the
business process flow designer.

On-demand stage processes. When the workflow is dropped onto a business
process flow stage, the workflow is triggered on entry or exit of the stage.
On-demand global processes. When the workflow is dropped onto the Global
Workflows area, the workflow is triggered on process activation or process archival
(when the status transitions to an applied, completed, reactivated, or abandoned
state).

Notice the following requirements when you add a workflow to a business process flow.

For workflows added to a stage: You can only use active, on-demand workflows
created for the same table of the stage where you add the workflow.
For global workflows: You can only use active, on-demand workflows created for
the primary table of the business process flow.

Add an on-demand workflow to a business
process flow stage
You add an on-demand workflow from the business process flow designer by dragging
the workflow component to a process stage or to the global workflows section.

On the PowerApps  site, select Model-driven (lower left of the navigation pane).

Open the business process flow designer. You can do this in one of two ways.

If the business process flow is already added to an app, go to Apps, next to the
app you want select …, and then select Edit. In the app designer, select the
business process flow, and then select .
Otherwise, open solution explorer, in the left navigation pane select Processes, and
then select the business process flow that you want.



Decide whether you want the on-demand workflow to be triggered by one of the
following business process flow events.

On-demand stage processes. Triggers the workflow on entry or on exit of the
stage.
On-demand global processes. Triggers the workflow either on process activation or
process archival (when the status transitions to an applied, completed, reactivated,
or abandoned state).

In the example below, an on-demand workflow named My on demand workflow is
added to Stage 1 of the business process flow.

1. Expand stage 1 to reveal the Triggered Process section.

2. Select the Components tab and drag Workflow to the Triggered Process section.


Alternatively, you can drag Workflow to the Global Workflows section, which
triggers the workflow either on process activation or process archival.


3. In the search box of the Properties tab, enter and search the name of the on-
demand workflow you want to add to the business process flow stage, and then



select Apply.


4. On the Properties tab under Trigger select either Stage Entry or Stage Exit.


Alternatively, when you drop the workflow onto the Global Workflows section, the
trigger options are Process applied, Process reactivated, Process abandoned, and
Process completed.

5. Select Update on the business process flow designer toolbar.

See also
Use Workflow processes to automate processes that don't require user interaction 

Tutorial: Create a business process flow to standardize processes 

Business process flow automation in Dynamics 365






Best practices in using business process
flow columns
Article • 02/22/2023

Legacy process-related columns in tables is deprecated. Here are some best practices
for using the Active Stage (activestageid) column on the business process flow table.

Reporting on the active stage of a business
process flow
Let’s say that you’d like to get a view of your sales pipeline by reporting on the active
stage that the Lead to Opportunity Sales Process is on.

Previously, to report on business processes by stage, one might define a view on each
related table of the business process flow and then report on the Active Stage
(activestageid) column.

With the deprecation of the Active Stage (activestageid) column on related tables, there
are two ways to report on business process flows.

Option 1: Views and charts on business process flow
table**(Recommended)**
In versions 9.0 and higher, each business process flow creates its own Dataverse table,
usually with the same name as the business process flow. To report on the business
process flow, select the table for the business process flow you want to report on, and
then create views and charts, just as you did before.

In our example, follow these steps to go to the Lead to Opportunity Sales Process
table:

1. Sign in to Power Apps .

To learn more about using the Power Apps interface, go to Get started with Power
Apps.

2. On the left navigation pane, select More > Tables.

3. Set the filter to All.

4. Search for, and then select the Lead to Opportunity Sales Process table.



Here, you can define views and charts just as you do on any other table.

5. On the Data experences tile, select Views or Charts.

An advantage of this approach is that you can use a single view or chart to report
on business process flows that span multiple tables.

As the business process flow table is no different from any other custom table in
Dataverse, you can add custom columns to the table to track any additional information
you need.

Option 2: copy active stage to a related table
Alternatively, to continue reporting off the related table, create a cloud flow to copy the
Active Stage (activestageid) column from the business process flow table into a custom
column on the related Dataverse tables.

Here are a few things to keep in mind when you use this approach:

1. It's possible to have more than one business process flow running on a single
table. With this approach, it's best to have one custom column that stores the
active stage for each business process flow that runs on the table. This approach
ensures the integrity of the reporting.

2. As reporting is driven from the related table, it's not possible to create a single
view that reports on business process flows that span multiple tables.

Using the active stage to run logic
Here are some cases in which you might want to run logic that's based on the active
stage:

Using the active stage to run client-side logic
As you use the business process, there are many things that you might want to do
automatically. For instance:

Change the active business process flow based on newly available information on
the form or business process flow.

Move the active stage to the next or previous stage, based on values the users
entered for steps or form columns.



Hide or show form tabs and columns based on the selected stage.

Show informative messages and run calculations based on the active business
process flows, the active or selected stage, or events such as moving the active
stage.

 Tip

For scenarios like these, use the supported set of client APIs for business process
flows.

Using the active stage to run server-side logic
There might be cases where automation based on the business process flow needs to
be done server side. For instance:

Send an email to a user if the Qualify the stage of the Opportunity Sales Process
is active for longer than 15 days.

Automatically create a set of activities relevant to the active stage of the
Opportunity Sales Process each time it changes.

Automatically finish the Opportunity Sales Process when the phone call activity for
closing completes.

 Tip

Use classic Dataverse workflows or flows you define on the table for the business
process flow.

To build a classic Dataverse workflow that creates activities for internal solution reviews
and to follow up with the customer in the Propose stage of the Opportunity Sales
Process:

1. Create it on the Opportunity Sales Process table and set it to run each time the
Active Stage column of the table changes.

2. Define a condition to check if the Active Stage column equals Propose.

3. Create an appointment and phone call row for the internal review of the solution
and the customer call to review the solution respectively.



See also
Get started with Power Apps



Overview of process mining and task
mining in Power Automate
Article • 03/14/2025

Process mining and task mining in Power Automate allow you to gain a better
understanding of your business processes so you can optimize them.

Process mining
The process mining capability in Power Automate is better suited for discovery of
inefficiencies in organization-wide processes. It enables you to gain a deep
understanding of your processes using event log files that you can get from your system
of recording (apps you use in your processes). The process mining capability displays
maps of your processes with data and metrics to recognize performance issues. Example
processes suitable for the process mining capability include accounts receivable and
order-to-cash.

The process mining capability can be a key driver in making intelligent, day-today
improvements on every level. You can discover and model processes for which you have
data readily available, giving you an X-ray visualization of what goes on in your
organization. In addition, you can standardize, optimize, and improve operations, while
staying informed about progress towards defined key process indicators.

Task mining
The task mining capability in Power Automate is better suited to discover tasks
happening on the desktop. It enables you to zoom-in to specific desktop tasks you
might have discovered during your process mining analysis. You can understand how
your company performs its process tasks through monitoring recorded user actions and
collecting data from these actions. You gain insights from this data that lets you know
how processes are performed, find common mistakes while performing tasks, and
identify tasks that can be automated.

When to use the process mining capability
Here are some reasons to help you decide to use the process mining capability.

See the actual steps needed to perform your organization’s operation process and
remove any guesswork.



Save time and money by optimizing processes.
Detect noncompliant processes and/or tasks.
Discover automation opportunities.
Compare processes.
Find mistakes.
Understand where and why problems occur.

Explore the topics in the documentation for the process mining and task mining
capabilities in Power Automate for the following:

Business scenarios
Understand where and why problems occur.

When to use the task mining capability
Here are some reasons to help you decide to use the task mining capability.

Understand what employees actually do while performing each task on their
desktops.
Identify and eliminate unnecessary actions in process tasks.
Identify the most common actions through user interactions.
Ensure compliance and perform audit.
Automate tasks that would accelerate processes and reduce human errors.

What you'll find in this documentation
Explore topics in process mining and task mining in this documentation for the following:

Business scenarios
Tutorials
Guided procedures
Videos

Licensing
Process mining is licensed as part of Microsoft Power Automate. There are three Power
Automate licenses that are related to process mining and a Power BI license is required
for Power BI report customization.

Power Automate trial license



For a limited time of 90 days, the Power Automate trial license offers:

Task mining capabilities: Enable you to analyze a recorded process and view the
analytics report. You can invite others to contribute recordings to the process for
richer insights.

Process mining capabilities: Enable you to create a process, connect to an event
log using data flows, analyze a process from data, view the analytics report on the
web, and perform advanced analytics on the desktop application. The trial offers
limited process mining capacity of 100 MB per process. Therefore, to process more
data, we highly recommend that you purchase the Power Automate Premium
license and the Power Automate Process Mining add-on.

To learn more, go Power Automate Process Mining add-on in this article.

Power Automate Premium license
The Power Automate Premium license is a per-user license with the following offerings:

Task mining capabilities: Enable you to analyze a recorded process and view the
analytics report. You can invite others to contribute recordings to the process for
richer insights.

Process mining capabilities: Enable you to create a process, connect to an event
log using data flows, analyze a process from data, view the analytics report in the
web, and perform advanced analytics in the desktop application. Each Power
Automate Premium license adds 50 MB of process mining capacity to a tenant wide
capacity pool up to a total of 100 GB. When you reach 100 GB, you need to
purchase the Power Automate Process Mining add-on to process additional data.

To learn more, go Power Automate Process Mining add-on in this article.

Additional 250 MB of Dataverse database capacity.

Additional 2 GB of Dataverse file capacity.

Power Automate Process Mining add-on
The Process Mining add-on is a tenant wide license that is available for the Power
Automate Premium license. It offers:

Additional 100 GB of process mining capacity to the capacity pool, from which
users with the Power Automate Premium license can consume.



Additional 2 GB of Dataverse database capacity.

Additional 1 TB of Dataverse file capacity.

Get Power Automate pricing details at Power Automate pricing . For inquiries about
add-on capability licensing, contact Microsoft Process and Task Mining Questions.

Power BI license
To customize your report, you need to link the process to your own Power BI workspace,
and a Power BI Premium license. To learn more about Power BI licensing, go to Power BI
pricing .

Preview
Some features are in preview, denoted by the preview tag. For process templates that
are still in preview, licenses and trials aren't needed.

Dataverse capacity
Depending on the size of the process data you import, you might run out of Dataverse
storage capacity. If this happens, ask your admin about purchasing more storage
capacity, or delete existing processes to free up storage. The process data we store uses
mostly file capacity.

To learn more about Dataverse storage capacity, go to New Microsoft Dataverse storage
capacity.

Prerequisites
Before you start using the process mining capability, make sure you have the following
prerequisites:

The required licenses or trials depending on the capabilities you want access to.

A Microsoft Power Platform environment with a Microsoft Dataverse database. 

To learn how to create an environment, go to Create and manage environments
in the Power Platform admin center. 

To learn how to add a database to an environment, go to Add a Microsoft
Dataverse database. 



Adequate roles are assigned for users who want to use the process mining
capability. The Environment Maker is required to create, share, and contribute to
processes. Go to Security and privacy to learn more.

Additional considerations for specific capabilities:

For the Power Automate Process Mining desktop app, download and install Power
Automate Process Mining desktop app.

To customize your report, you need to set up your Power BI workspace and register
the process mining service principal in Microsoft Entra ID.

For task mining, download and install Power Automate for desktop.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Overview of process mining
Article • 11/04/2024

Process mining is a research area and technology that helps businesses understand their
real processes, how they're operated, and identify opportunities for improvement,
automation, and digitalization.

The process mining capability in Power Automate works with the existing Microsoft
platform and ecosystem to provide end-to-end solutions and enable faster business
decisions. By extracting event data from your system of records, it visualizes the
processes happening in your organization, allowing you to customize your process
mining reports, compare processes, determine the root cause of inefficiencies, and
monitor KPIs.

Overall, the process mining capability is a valuable tool for businesses seeking to
improve their operational efficiency and make informed decisions.

Benefits of the process mining capability
The business value of the process mining capability lies in its ability to help
organizations gain insights into their operational processes and identify areas for
improvement. By analyzing event data from various sources, the process mining
capability provides a clear view of how processes are actually being executed in practice.
This helps businesses to:

Improve operational efficiency: Process mining can help identify bottlenecks and
inefficiencies in processes, allowing organizations to streamline their operations
and improve productivity.
Enhance customer experience: By identifying process pain points and eliminating
them, organizations can improve the customer experience and increase
satisfaction.
Optimize resources: Process mining enables businesses to identify opportunities
for automation, reducing the need for manual intervention and allowing resources
to be allocated more effectively.
Ensure compliance: Process mining can help organizations to identify
noncompliant processes and take corrective action to avoid legal and financial
risks.
Improve supply chain management processes: Create processes that help
warehouse and operations managers gain insights into the material flow in the
warehouse. This can help improve the performance of the warehouse. To learn



more, go to Analyze warehouse material movement through process mining
(preview).

Business examples
Overall, process mining provides valuable insights that can help organizations improve
their operations, enhance customer satisfaction, and stay competitive in a rapidly
changing business landscape.

Telecommunications
Streamline the activation process to reduce wait times.
Simplify business operations to reduce costs and complexity.
Manage high-volume content analytics.

Financial services
Accelerate the time to value for small and medium-sized businesses.
Ensure compliance by keeping up with regulatory changes and mitigating risks.
Address competition from fintech challengers.

Manufacturing
Address supply chain disruptions to ensure timely delivery of products.
Adopt new automations to improve efficiency and productivity.

Automotive
Accelerate transformation to mobility providers to stay competitive in the
market.
Identify inefficiencies in production processes, such as long cycle times and
frequent downtime.
Identify and address quality issues early, reducing the likelihood of costly recalls
or warranty claims.

Customer service desk
Identify opportunities for standardization to reduce rework and eliminate
pending cases.
Analyze reasons for returns and improve customer satisfaction by monitoring
performance.

These areas represent key challenges and opportunities for businesses to improve their
operations, stay competitive, and meet the needs of their customers.

Components



Following are the main components for the process mining capability:

Data requirements
Transform and map data
Troubleshoot issues (if necessary)
Use KPIs and visualizations for analytics
Edit and refresh processes
Share processes

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Tutorial: Get started with the process
mining capability
Article • 02/10/2025

This tutorial allows you to experience the process mining capability with sample data. In
this tutorial, you create a process, import data, and then analyze it.

７ Note

If you don't see all of the features described in this article and are using your
default environment, create a new environment and retry.

Download the sample data
For the process mining tutorial, download the sample event log CSV file: 

English version
French version

The sample data in this tutorial is for illustration only and is fictitious. No real association
is intended or inferred.

Create a process
７ Note

If you encounter an error message while attempting to create and analyze a
process, it may be due to a missing security role. To resolve this, please contact the
administrator of your environment and request that they assign you the
Environment Maker security role.

1. Sign in to Power Automate .
2. Select your environment.
3. On the navigation pane to the left, select Process mining.
4. In the Create new process section, select Start here.
5. In the Create a new process screen, enter a process name, and then select Import

data.
6. (Optional) Enter a description for your process.



7. Select Continue.
8. (Optional) Select a Power BI workspace to attach your process to and give your

report a name.
9. Select Continue.

Import data
1. In the Choose a data source screen, select Text/CSV.

2. Under the Connection settings heading, select Upload file (Preview).

3. Select Browse.

4. Find and select SampleData_AP_Refunds_Financial_EventLog.csv, which you
downloaded previously.

5. Select Open.

6. If you're asked to authenticate, select Sign in and follow the prompts.

7. Select Next.

8. When you see the power query, which allows you to transform your data, select
Next.

9. Match the Attribute Name from sample data to the Attribute Type as appropriate.
In this sample, the data attributes you change are InvoiceValue, Resource,
StartTimestamp, EndTimestamp, CaseId, and ActivityName.

When you finish, the attribute mapping should look like the following screenshot.



10. Select Save and analyze. The analysis might take a few minutes to run.

When the analysis process is complete, you see a process map and a dashboard
with other insights about your process. On the dashboard, you can view many
metrics that can help you analyze your process. To learn how to analyze the
process map and metrics, go to Visualize and gain insights from processes in the
process mining capability.

Analyze a process



Let's take the analysis of our process beyond KPIs. We use the Power Automate Process
Mining desktop app, where you can edit and analyze your processes created in the
process mining capability.

1. From the command bar of the analytics report page, select Download Process
Mining app to download it.

2. On the toolbar, select the environment from the top right.

3. Search for the process you created with the process mining capability in Power
Automate (AP Refunds Process).

4. To display the default view, select Default.

Based on your settings, the process model is:

Downloaded to your local computer and analyzed locally
Kept and analyzed in the cloud (preview). You're notified about the
availability of this option with message on top of your application.

Learn more about setting the new option in Application settings.

You’re ready to use the advanced capabilities of the Process Mining desktop app.

5. On the Customize panel toolbar, select Frequency (the first icon), and then select
Case count in the Metric dropdown menu.

The process map displays the number of cases of the process that include the
activity specified at each node.

6. On the Customize panel, select the clock icon, and then select Mean duration
from the dropdown menu.



Notice that the Refund with special voucher step has a long mean duration
compared to other steps.

7. On the Customize panel, select Finance (the piece of paper icon), and then select
Mean from the Metric dropdown menu.

Notice that the same Refund With Special Voucher step involves only $631.11 in
invoice value, which is less than half of most of the other steps.

8. This step might be a good candidate for extra investigation, so select this step's
node.

9. On the Customization panel, select Create filter > Attributes.

Compare paths with different views
We want to compare the paths that have this Refund With Special Voucher step with
the paths that don't have this step, but instead have another step called Refund With
Standard Voucher. Let's filter for paths that have Refund With Special Voucher and not
Refund With Standard Voucher. Let's also filter for paths with Refund With Standard
Voucher and without Refund With Special Voucher.



Create the 'Refund With Special Voucher' view
1. On the Filtering page, ensure Refund With Special Voucher is selected in the

holds any of the values field.

2. On the command bar, select Add filter > Attributes.

3. This time, select Does not include from the Filter result dropdown menu.

4. On the List tab, select Refund With Standard Voucher to place it in the holds any
of the values field.

Your Filtering screen should look like this:

5. On the bottom right corner, select Apply.

6. On the command bar at the top, select Save > Save as, and then enter Refund w/
Special Voucher > Save.

Create the 'Refund With Standard Voucher' view



1. Go back to the filter screen by selecting the Filter button in the bottom left of the
screen.

2. Clear the Filter criteria set and repeat steps 1 through 4 of the previous section,
but choose Refund With Standard Voucher in step 1 and Refund With Special
Voucher in step 4.

3. In the command bar at the top, select Save > Save as, and then enter Refund w/
Standard Voucher > Save.

Compare views
You created two different views. One view shows the paths that have the Refund With
Special Voucher step but not the Refund With Standard Voucher step (Refund w/
Special Voucher). The other view is its inverse (Refund w/ Standard Voucher). Let's
compare these two views.

1. On the left panel, select Process compare.

2. Below the Compare tile, select Add layer.

3. From the Views dropdown menu, select Refund w/ Special Voucher > Add layer.

The process map that is created is a comparison of the two views.

4. In the Customize panel, ensure that Mean duration is selected as the metric.

5. Save this view as Standard vs. Special.

Understand the process map with different
views
The green nodes represent steps common to both views. A red node represents the step
that takes place only in the process with a special voucher (as indicated by the Compare
legend). Blue nodes represent steps that take place only in the paths with standard
voucher.



1. Expand the Customize panel by selecting Customize on the right navigation bar.

2. Select the Performance (the clock icon).

3. From the Metric dropdown menu, select Mean duration.

From the procedure in Analyze a process (previously in this article), there were only nine
cases with Refund With Special Voucher. On average, the process is lengthened by
almost 17 hours according to the process compare map in this section.

Notice that cases that have the Refund With Standard Voucher step also have the
possibility of invoices being rejected as the blue node, which represents the Reject
Invoice step suggests. This Reject Invoice step contributes only 2.8 hours on average to
the process.



Based on insights we derived from this analysis, let's summarize our findings, derive a
conclusion, and offer some recommendations for this process.

Insights summary
Refund With Special Voucher:

Takes place only a few times in the process compared to other steps.

Has a relatively low amount of money flowing through it.

Significantly increases the mean duration of the entire process.

Refund With Standard Voucher:
The cases with this step also have the invoices being subsequently rejected. This
causes rework and adds some time to the mean duration of the process.

Considerations for choosing a special or standard
voucher
This organization has two ways to make refunds using vouchers: Refund With Special
Voucher or Refund With Standard Voucher. The latter might sometimes cause some
rework because some of those invoices are subsequently rejected. Alternatively, using
the special voucher never causes invoice rejection. This might make it seem like using a
special voucher should be the consistent course of action.

However, having the possibility of the invoice being rejected through a standard
voucher saves the organization more time than using a special voucher. This never



causes the invoice to be rejected—the difference in mean duration is approximately
13.79 hours.

Recommendation
An organization should focus on using standard vouchers versus special vouchers
because just a few special vouchers can add much time to the process.

An organization should do further analysis to determine why using the standard invoice
often causes invoice rejection. If they're able to uncover a remedy for this, the
organization can implement this to further improve the process.

To learn more about how to take advantage of the advanced capabilities of Power
Automate Process Mining, go to Overview of Power Automate Process Mining.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Azure templates for process mining
Article • 07/18/2023

Easily onboard your process mining data with process mining templates. Templates help
you start mining your processes for insights with just a few selections. You'll avoid the
data identification and manipulation that's required with traditional process mining
tools. Azure DevOps (work tracking), Azure DevOps (pipelines), Logic Apps (standard
plan), Logic Apps (consumption plan), and Durable Functions templates provide insights
that help you identify opportunities and optimize your development processes.

Creating and running a template is similar for all the Azure templates.

Azure DevOps (work tracking) template
The Azure DevOps (work tracking) template analyzes the execution and handling of
tracked Azure DevOps (ADO) work items to help you maximize your development
processes and manage dependencies. To learn more, go to What is Azure DevOps?

The Azure DevOps (work tracking) template uses data from your Azure Boards to
analyze your work items. You'll need to gather some information from ADO before you
can run the template.

Gather information from ADO Boards
1. In your Azure DevOps environment in the left panel, select Project settings.

2. Select Boards > Team configuration, and then select the Area tab.



3. Find the organization name and project name at the top of the Project Settings
page. Take note of the area name.

Create and run the Azure DevOps (work Tracking)
template

1. In Power Automate in the left panel, select Process mining.

2. In the Start with a popular template section, select the Azure tab, and then select
the Azure DevOps (work tracking tile.

3. In the Process name field, enter a name for your process.



4. In the Organization name, Project name, and Area name fields, enter the
information from ADO.

5. (Optional) In the Description field, enter a description of the process.

6. Select Create.

7. In the Connect to data source screen in the Authentication kind field, replace
"Anonymous" with Organizational account.

If you're signed in, you'll see your credentials. You can switch to a different account
if needed. If you're not signed in, select Sign in and sign in to your account.

8. Select Save.

The process mining capability will analyze your process. It might take a few minutes for
the analytics to appear.

Learn how to visualize and gain insights from processes. You can also use the custom
attributes filter to dive deeper into your insights.

Azure DevOps (pipelines) template
The Azure DevOps (pipelines) template analyzes the execution and handling of tracked
pipelines and boards to help you maximize your development processes and manage
dependencies. To learn more, go to What is Azure Pipelines?

The Azure DevOps (pipelines) template uses data from Azure DevOps to analyze your
pipelines. You'll need to gather some information from ADO before you can run the
template.

Gather information from ADO Pipelines
1. In your Azure DevOps environment in the left panel, select Pipelines, and then

select Pipelines again.



2. Find the organization name and project name at the top of the Pipelines page.
Take note of the pipeline name.

Create and run the Azure DevOps (pipelines) template
1. In Power Automate in the left panel, select Process mining.

2. In the Start with a popular template section, select the Azure tab, and then select
the Azure DevOps (pipelines) tile.

3. In the Process name field, enter a name for your process.

4. In the Organization Name, Project name, and Pipeline Name fields, enter the
information from ADO.

5. (Optional) In the Description field, enter a description of the process.

6. Select Create.

7. In the Connect to data source screen in the Authentication kind field, replace
"Anonymous" with Organizational account.

If you're signed in, you'll see your credentials. You can switch to a different account
if needed. If you're not signed in, select Sign in and sign in to your account.

8. Select Save.

The process mining capability will analyze your process. It might take a few minutes for
the analytics to appear.

Learn how to visualize and gain insights from processes. You can also use the custom
attributes filter to dive deeper into your insights.



Logic Apps (standard plan) template
The Logic Apps (standard plan) template analyzes the execution of your Logic Apps to
help you maximize your automated processes and manage dependencies. To learn
more, go to What is Azure Logic Apps?.

The Logic Apps with App (standard plan) template uses telemetry data from Azure
Monitor Application Insights to analyze your apps. You'll need to get an Application ID
for your app in an Application Insights resource before you can run the template.

Get your app's Application Insights Application ID
If you're not an Azure admin: Ask your Azure admin to create an Application Insights
resource for your app and give you the app's Application ID and the dimensions to
enter for Case ID and Activity.

If you're an Azure admin:

Create and run the Logic Apps with App Insights
template

1. To deploy a template, you need to create an Application Insights resource. For
instructions, go to Create an Application Insights resource.

2. On the Azure tab in the Start with a popular template section, select the Logic
Apps (standard plan) tile.

3. Create an Application Insights resource for your app.

4. In the left panel, select Configure > API Access.

5. Copy the Application ID.

Create and run the Logic Apps (standard plan) template
1. In Power Automate in the left panel, select Process mining.

2. In the Start with a popular template section, select the Azure tab, and then select
the Logic Apps (standard plan) tile.

3. In the Process name field, enter a name for your process.



4. In the Logic App Application Insights Application Id field, paste the Application ID
from Application Insights.

5. (Optional) In the Description field, enter a description of the process.

6. Select Create.

7. In the Authentication kind field, replace "Anonymous" with Organizational
account.

If you're signed in, you'll see your credentials. You can switch to a different account
if needed. If you're not signed in, select Sign in and sign in to your account.

8. Select Save.

The process mining capability will analyze your process. It might take up to two minutes
for the analytics to appear.

Learn how to visualize and gain insights from processes. You can also use the custom
attributes filter to dive deeper into your insights.

Logic Apps (consumption plan) template
The Logic Apps (consumption plan) template analyzes the execution of your Logic Apps
to help you identify opportunities and optimize your Logic Apps (consumption plan)
usage. To learn more, go to Usage metering, billing, and pricing models for Azure Logic
Apps.

The Logic Apps (consumption plan) template enables you to visualize the execution
and orchestration of your Logic Apps. Insights allow you to maximize your automated
processes and manage dependencies.

To learn more about Logic Apps, go to the Azure Logic Apps documentation.

Prerequisite
Before you can visualize your Logic Apps, you must have an Azure Logic Apps
Consumption Plan (Multi-tenant) license. To learn more, go to Logic Apps pricing .

Create and run the Logic Apps (consumption plan)
template



1. To deploy a template, you need to create an Application Insights resource. For
instructions, go to Create an Application Insights resource.

The Logic App Consumption Plan template uses data from Azure DevOps to analyze
your consumption. You need to gather some information from ADO before you can run
the template.

Gather information from ADO Logic Apps
1. In your Azure Logic Apps environment, select your app, and then in the left panel,

select Overview.

2. Take note of the app name, Resource group, and Subscription ID.

Create and run the Logic Apps (consumption plan)
template

1. In Power Automate in the left panel, select Process mining.

2. In the Start with a popular template section, select the Azure tab, and then select
the Logic Apps (consumption plan) tile.

3. In the Process name field, enter a name for your process.

4. In the Azure subscription Id, Resource group name, and Logic app name fields,
enter the information from ADO.

5. (Optional) In the Description field, enter a description of the process.

6. Select Create.

7. In the Authentication kind field, replace "Anonymous" with Organizational
account.



If you're signed in, you'll see your credentials. You can switch to a different account
if needed. If you're not signed in, select Sign in and sign in to your account.

8. Select Save.

The process mining capability will analyze your process. It might take a few minutes for
the analytics to appear.

Learn how to visualize and gain insights from processes. You can also use the custom
attributes filter to dive deeper into your insights.

Durable Functions template
The Durable Functions template analyzes the execution of your Durable Functions to
help you identify opportunities and optimize states, checkpoints, and restarts. To learn
more, go to What are Durable Functions?

The Durable Functions template uses data from your Azure Durable Functions storage
account for its analysis. You'll need to gather some information from Azure before you
can run the template.

Create and run the Durable Functions template
1. Have both the process mining capability in Power Automate and the Azure portal

open in separate browser tabs.

2. In the process mining capability, in the Start with a popular template section,
select the Azure tab, and then select the Durable Functions tile.

3. In the Process name field, enter a name for your process.

4. In Azure portal, go to your Azure Durable Functions storage account. In the left
panel under Data storage, select Tables. Copy the table names that end with
Instances and History.



5. In the process mining capability, paste the Instances table name in the Instance
Table Storage Name field and the History table name in the History Table Storage
Name field.

6. In Azure portal, copy the value in the Url column.

7. In the process mining capability, paste the URL in the Table Storage Account URL
field.

8. (Optional) In the Description field, enter a description of the process.

9. Select Create.

10. On the Connect to data source screen, paste the URL from Step 6 in the Account
name or URL field.



11. In Azure portal in the left pane, select Security + Networking > Access keys.

12. Select Show keys. Copy the value of Key1 or Key2.

13. In the process mining capability, paste the key value in the Account key field.

14. Once the connection credentials are established, select Save.

The process mining capability will analyze your process. It might take a few minutes for
the analytics to appear.

Learn how to visualize and gain insights from processes. You can also use the custom
attributes filter to dive deeper into your insights.

See also
What is Azure DevOps?
What is Azure Pipelines?
What is Azure Logic Apps?
Azure Monitor Application Insights
Usage metering, billing, and pricing models for Azure Logic Apps
What are Durable Functions?



Finance and operations templates for
process mining
Article • 07/18/2023

If you're interested in analyzing your finance and operation process easily, onboard your
data with templates in the process mining capability. Templates help you start mining
your processes for insights by enabling you to connect to your system of record and
surfacing contextual insights. You'll avoid the data identification and manipulation that's
required with traditional process mining tools and reach process rich insights on
analysis.

Accounts payable template
The accounts payable (AP) process tracks the process from receiving an invoice to
paying it out. Between these two steps, there are countless variants that can occur based
on compliance, automation, and industry. The Accounts payable template enables SAP
users to extract data from their SAP system and visualize their AP process with minimal
to no data manipulation required.

Prerequisites
Connecting and defining the Accounts payable template will require IT and admin
support.

The Accounts payable template requires connection to SAP through:

SQL Server database
Oracle database
OData

For the template ingestion to work, the required tables must be found in the database
(copy or original) with the original table name:

Table Description

BKPF Accounting document header

BSEG Accounting document

CDHDR Change document header



Table Description

CDPOS Change document items

Create and run the Accounts payable template
To see the available templates, select Process mining on the left.

1. Under the Start with a popular template heading, select the Finance & Operations
tab, and then select Accounts payable.

2. Select a connection type from the three connection types available (SQL database,
Oracle database, and OData service).

3. If you're selecting SQL database, enter the Process name, Server Name, Database
Name, and Schema Name.

To learn more, go to SQL Server.

4. (Optional) To improve the analyze time of the report, refine data by defining Start
Date, End Date, Client, and Company Code.

5. Once you're on the connection page, fill out credential information and select Next

To learn more about the fields, go to Connect to SQL Server database from Power
Query Online.



6. Once the connection is complete, your process will be analyzed. You can change
screens at any time during the analysis.

7. Once the analysis is done, you can view your process report.

Procure to pay (P2P) template
The procure to pay (P2P) process begins at purchase requisition. Then, it flows to the
creation of a purchase order before closing out an invoice payment. It's a complex
process that organizations use to ensure compliant spend and fiscal responsibility. The
Procure to pay template enables SAP users to extract data from their SAP system and
visualize their P2P process with minimal to no data manipulation required. This template
allows you to find areas for potential efficiencies and automation.

Prerequisites
Connecting and defining the P2P template will require IT and admin support.

The P2P Template requires connection to SAP through:

SQL Server database
Oracle database
OData

For the template ingestion to work, the required tables must be found in the database
(copy or original) with the original table name:

Table Description

BKPF Accounting Document Header

BSEG Accounting Document

CDHDR Change Document Header

CDPOS Change Document Items

EKKO Purchasing Document Header

EKPO Purchasing Document Items

EKBE History per Purchasing Document

EBAN Purchase Requisition

USR02 Logon Data



Table Description

RSEG Document item; Incoming Invoice

T008T Blocking Reason Names

NAST Message Status

DD07T DD: Texts for Domain Fixed Values

T001 Company Codes

T024E Purchasing Organizations

T024 Purchasing Groups

TCURR Exchange Rates data

TCURX Decimal places in currency

LFA1 Vendor Master

MAKT Material Master

T023T Material Group Descriptions

EKET Scheduling Agreement Schedule Lines

Create and run the Procure to pay (P2P) template
To see the available templates, select Process mining on the left.

1. Under the Start with a popular template heading, select the Finance & Operations
tab, and then select Procure to pay (P2P).

2. To complete creating and running the P2P template, perform the steps in Create
and run the Accounts payable template in this article starting with step 2.

Read your custom report
Once the analysis is done, there will be a custom report to visualize your P2P process.
The first page will have an end-to-end view of the PP2P process. By selecting the caret,
you can navigate to the Invoice analysis report for a deeper understanding of your
invoice process.



Visualizations and KPIs
P2P templates have additional KPIs and visualizations built on top of the standard
report. To learn more about the process map and filters, go to Visualize and gain
insights from processes.

PO items: The PO line item is the Case ID for this report. Every unique PO line item
is represented as a case.

PO value: Aggregate value of PO line items.

Net order value normalized: PO value normalized to USD currency based on the
latest conversion rate obtained from the currency table from the SAP system.

Spend by company code: PO line item spend aggregated by company code.

Top vendors: PO line item spend aggregated by the vendor.

Purchase order items and value by month: X axis represents months. Y1 axis
represents whole number of PO items (bar graph). Y2 axis represents value of PO
items (line graph).

Invoice value: Aggregate value of unique invoices.

Invoices: Count of unique invoices in your process.

Average payment term: Based on invoice payment term, the average days given
by vendors to complete payment.

Average cycle time: Based on process, the average time it takes organization to
pay out or complete invoices.

Discount realization rate: Total discount taken based on invoice payment date
divided by total discount available to organization.

Discount availability: Total available discount to the organization.



Paid on time rate: Invoices paid on or before due date divided by total number of
invoices.

Paid on time: X axis represents months. Y1 axis represents whole number of
invoices (bar graph). Y2 axis represents paid on time rate (line graph).

Invoice Value: X axis represents months. Y1 axis represents whole number of
invoices (bar graph). Y2 axis represents paid on time rate (line graph).

Customization and issue handling
Templates are composed of a data flow and a report. Like a process created from Start
from Blank, both the data flow and the report can be customized and changed. To learn
more, go to the following topics:

Troubleshoot issues with process mining
Edit and transform process (data flows and report)



Power Platform templates for process
mining
Article • 07/18/2023

Templates designed to work with the process mining capability make it easy for
organizations to onboard their data for process mining and gain insights with just a few
selections. Unlike traditional process mining tools, Power Platform templates eliminate
the need for data identification and manipulation.

Templates are available for Desktop flows, Power Virtual Agents, and Power Apps
insights. Each template provides insights that help identify automation opportunities
and address performance and compliance issues in workflows.

By using templates in the process mining capability, organizations can quickly and easily
start mining their processes for insights and streamline their workflows. Templates
simplify the process and allow organizations to focus on the insights and opportunities
that matter most, rather than getting bogged down in data manipulation and
processing.

Desktop flows template
The Desktop Flows template analyzes the run history of flows created using robotic
process automation (RPA)  in Power Automate. This template provides insights into the
performance and compliance of RPA workflows. To learn more about desktop flows,
please refer to theIntroduction to desktop flows documentation.

By analyzing the run history of RPA flows, the Desktop Flows template can identify
potential issues, such as errors or inefficiencies, and provide recommendations for
improvement. This information can help organizations optimize their RPA workflows and
improve overall performance. Additionally, the Desktop Flows template can help
organizations ensure compliance with regulatory requirements by identifying potential
violations and recommending corrective actions.

Overall, the Desktop Flows template is a powerful tool that can help organizations
maximize the value of their RPA workflows while minimizing risks and improving
compliance.

Create and run the Desktop flows template
1. In Power Automate in the left panel, select Process mining.



2. In the Start with a popular template section, select the Power Platform tab, and
then select the Desktop flows tile.

3. In the Process name field, enter a name for your process.

4. If you know the Flow ID of the flow you want to analyze, enter it in the Flow ID
(optional) field. If you don't know the Flow ID, you can skip this step.

 Tip

To find the Flow ID, edit the flow and look at the URL in your browser's
address bar. Everything between "flows/" and "/details" is the Flow ID:

5. (Optional) In the Description field, enter a description for the process.

6. Select Create.

7. In the Authentication kind field, replace "Anonymous" with Organizational
account.

If you're signed in, you'll see your credentials. You can switch to a different account
if needed. If you're not signed in, select Sign in and sign in to your account.

The process mining capability will analyze your process. It might take up to two minutes
for the analytics to appear.

Learn how to visualize and gain insights from processes. You can also use the custom
attributes filter to dive deeper into your insights.

Power Virtual Agents template
The Power Virtual Agents template is designed to analyze the performance and usage of
your chatbots, providing insights into your users' journeys and helping you maximize
the bots' effectiveness. To learn more about Power Virtual Agents, you can refer to the
Power Virtual Agents overview.



Create and run the Power Virtual Agents template
1. In Power Automate on the left panel, select Process mining.

2. In the Start with a popular template section, select the Power Platform tab, and
then select the Power Virtual Agents tile.

3. In the Process name field, enter a name for your process.

4. (Optional) In the Description field, enter a description for the process.

5. Select Create.

6. In the Authentication kind field, replace "Anonymous" with Organizational
account.

If you're signed in, you'll see your credentials. You can switch to a different account
if needed. If you're not signed in, select Sign in and sign in to your account.

7. Select Save.

The process mining capability will analyze your process. It might take several minutes for
the analytics to appear.

Learn how to visualize and gain insights from processes. You can also use the custom
attributes filter to dive deeper into your insights.

Power Apps insights template
The Power Apps insights template helps you visualize the performance and usage of
your Power Apps. It enables you to optimize your apps' functionality and manage its
success rate. To learn more about Power Apps, check out What is Power Apps?

The Power Apps insights template uses telemetry data from Azure Monitor Application
Insights to analyze your apps. To use this template, you'll need to obtain an Application
ID for your app in an Application Insights resource.

Get your app's Application Insights Application ID
If you're not an Azure admin: Ask your Azure admin to create an Application Insights
resource for your app and give you the app's Application ID and the dimensions to
enter for Case ID and Activity.

If you're an Azure admin:



1. Create an Application Insights resource for your app.

2. In the left panel, select Configure > API Access.

3. Copy the Application ID.

4. Take note of the dimensions you'll want to map to Case ID and Activity in the
Power Apps insights template.

To test the dimensions, go to Log Analytics and enter the following query:

Azure CLI

    traces
    | where timestamp > ago(30d)
    | project
        timestamp,
        message,
        severityLevel,
        operation_Name,
        operation_Id,
        session_Id,
        user_Id,
        client_Type,
        client_City,
        client_StateOrProvince,
        client_CountryOrRegion,
        client_Browser,
        appId,
        customDimensions

Create and run the Power Apps insights template
1. In Power Automate on the left panel, select Process mining.

2. In the Start with a popular template section, select the Power Platform tab, and
then select the Power Apps insights tile.

3. In the Process name field, enter a name for your process.

4. In the Power Apps application insights app ID field, paste the Application ID from
Application Insights.

5. In the Case ID field name and Activity field name fields, select the dimensions that
represent the Case ID and Activity you want to analyze.

6. (Optional) In the Description field, enter a description for the process.



7. Select Create.

8. In the Authentication kind field, replace "Anonymous" with Organizational
account.

If you're signed in, you'll see your credentials. You can switch to a different account
if needed. If you're not signed in, select Sign in and sign in to your account.

9. Go back to the Create a new process screen in process mining and paste it in the
Power apps application insights app Id field.

10. Identify the parameter that you want to analyze from your app and enter it in the
Case Id field name and Activity field name fields in the Create a new process
screen.

11. Select Save.

The process mining capability will analyze your process. It might take up to two minutes
for the analytics to appear. You can leave the page and return later.

Learn how to visualize and gain insights from processes. You can also use the custom
attributes filter to dive deeper into your insights.

See also
Introduction to desktop flows
Power Virtual Agents overview
Azure Monitor Application Insights
What is Power Apps?



Prepare processes and data
Article • 11/22/2024

Before you can use the process mining capability in Power Automate effectively, you
need to understand:

Data requirements.
Where to get log data from your application.
How to connect to a data source.

Here's a short video on how to upload data for use with the process mining capability:

https://www.microsoft.com/en-us/videoplayer/embed/RE5b4UA?postJsllMsg=true

Data requirements
Event logs and activity logs are tables stored in your system of record that document
when an event or activity occurs. For example, activities you perform in your customer
relationship management (CRM) app are saved as an event log in your CRM app. For
process mining to analyze the event log, the following fields are necessary:

Case ID

Case ID should represent an instance of your process and is often the object that
the process acts on. It can be a "patient ID" for an inpatient check-in process, an
"order ID" for an order submission process, or a "request ID" for an approval
process. This ID must be present for all activities in the log.

Activity Name

Activities are the steps of your process, and activity names describe each step. In a
typical approval process, the activity names might be "submit request," "request
approved," "request rejected," and "revise request."

Start Timestamp and End Timestamp

Timestamps indicate the exact time that an event or activity took place. Event logs
have only one timestamp. This indicates the time that an event or activity occurred
in the system. Activity logs have two timestamps: a start timestamp and an end
timestamp. These indicate the start and end of each event or activity.

You can also extend your analysis by ingesting optional attribute types:



Resource

A human or technical resource executing a specific event.

Event Level Attribute

Additional analytical attribute, which has different value per event, for example,
Department performing the activity.

Case Level Attribute (first event)

Case Level Attribute is an additional attribute, that from the analytical point of
view is considered to have a single value per case (for example, Amount of
Invoice in USD). However, the event log to be ingested doesn't necessarily have
to comply with consistency by having the same value for the specific attribute
for all events in the event log. It might not be possible to ensure that, for
example, when incremental data refresh is used. Power Automate Process
Mining ingests the data as is, storing all values provided in the event log, but
uses a so called case level attribute interpretation mechanism to work with the
attributes on case level.

In other words, whenever the attribute is used for specific function, which
requires event level values (for example, event level filtering), the product uses
the event level values. Whenever a case level value is needed (for example, case
level filter, root cause analysis), it uses the interpreted value, which is taken from
the chronologically first event in the case.

Case Level Attribute (last event)

The same as Case Level Attribute (first event) but when interpreted on case level,
the value is taken from the chronologically last event in the case.

Financial per Event

Fixed cost/revenue/numeric value that changes per activity performed, for
example, courier service costs. Financial value is calculated as a sum (mean,
minimum, maximum) of the financial values per each event.

Financial Per Case (first event)

Financial per Case attribute is an additional numeric attribute, that from the
analytical point of view is considered to have a single value per case (for example,
Amount of Invoice in USD). However, the event log to be ingested doesn't
necessarily have to comply with consistency by having the same value for the
specific attribute for all events in the event log. It might not be possible to ensure



that, for example, when incremental data refresh is used. Power Automate Process
Mining ingests the data as is, storing all values provided in the event log. However,
it uses a so called case level attribute interpretation mechanism to work with the
attributes on case level.

In other words, whenever the attribute is used for specific function, which requires
event level values (for example, event level filtering), the product uses the event
level values. Whenever a case level value is needed (for example, case level filter,
root cause analysis), it uses the interpreted value, which is taken from the
chronologically first event in the case.

Financial Per Case (last event)

The same as Financial Per Case (first event) but when interpreted on case level, the
value is taken from the chronologically last event in the case.

Where to get log data from your application
The process mining capability needs event log data to perform process mining. While
many tables that exist in your application’s database contain the current state of the
data, they might not contain a historical record of the events that happened, which is
the required event log format. Fortunately, in many larger applications, this historical
record, or log is often stored in a specific table. For example, many Dynamics
applications keep this record in the Activities table. Other applications, like SAP or
Salesforce, have similar concepts, but the name might be different.

In these tables that log historical records, the data structure can be complex. You might
need to join the log table with other tables in the application database to get specific
IDs or names. Also, not all events that you're interested in are logged. You might need
to determine what events should be kept or filtered out. If you need help, you should
contact the IT team that manages this application to understand more.

Connect to a data source
The benefit of connecting to a database directly is keeping the process report up to
date with the latest data from the data source.

Power Query supports a large variety of connectors that provide a way for the process
mining capability to connect and import data from the corresponding data source.
Common connectors include Text/CSV, Microsoft Dataverse, and SQL Server database. If
you're using an application like SAP or Salesforce, you might be able to connect to



those data sources directly via their connectors. For information on supported
connectors and how to use them, go to Connectors in Power Query.

Try out the process mining capability with the Text/CSV
connector
One easy way to try out the process mining capability regardless of where your data
source is located is with the Text/CSV connector. You might need to work with your
database admin to export a small sample of the event log as a CSV file. Once you have
the CSV file, you can import it into the process mining capability using the following
steps in the data source selection screen.

７ Note

You must have OneDrive for Business to use the Text/CSV connector. If you don't
have OneDrive for Business, consider using Blank table instead of Text/CSV, as in
the followng step 3. You won't be able to import as many records in Blank table.

1. On the process mining home page, create a process by selecting Start here.

2. Enter a process name and select Create.

3. On the Choose data source screen, select All categories > Text/CSV.

4. Select Browse OneDrive. You might need to authenticate.

5. Upload your event log by selecting the Upload icon in the upper right and then
selecting Files.

6. Upload your event log, select your file from the list, and then select Open to use
that file.



Use the Dataflow connector
The Dataflow connector isn't supported in Microsoft Power Platform. The existing
Dataflow can't be used as a data source for Power Automate Process Mining.

Use the Dataverse connector
The Dataverse connector isn't supported in Microsoft Power Platform. You need to
connect to it using the OData connector, which requires a few more steps.

1. Make sure you have access to the Dataverse environment.

2. You need the environment URL of the Dataverse environment you're trying to
connect to. Normally it looks like this:

To learn how to find your URL, go to Finding your Dataverse environment URL.

3. On the Power Query - Choose data sources screen, select OData.

4. In the URL textbox, type api/data/v9.2 at the end of the URL so it looks like this:

5. Under Connection credentials, select Organizational account in the
Authentication kind field.

6. Select Sign in and enter your credentials.

7. Select Next.

8. Expand the OData folder. You should see all the Dataverse tables in that
environment. As an example, the Activities table is called activitypointers.

9. Select the checkbox next to the table you want to import, and then select Next.

Feedback
Was this page helpful?  Yes  No



Provide product feedback



Copilot in Process Mining ingestion
(preview)
Article • 04/01/2025

[This article is prerelease documentation and is subject to change.]

Copilot in Process Mining ingestion navigates you through the ingestion experience in
Process Mining. With Copilot in Process Mining ingestion, you can identify your process
during data ingestion and automap your data to the required data schema.

Copilot can perform the following actions:

Discover your process in your Azure Data Lake.
Give automapping recommendations to required data schema.
Answer your questions about your process data.
Answer your general questions about processes.

） Important

This feature is generally available only in the United States region, and is in
preview for all other regions.
Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.
For more information, go to our preview terms .
This capability is powered by Azure OpenAI Service.
More information: FAQ for Copilot data security and privacy in Power
Platform

Prerequisite
You need a Power Platform environment for Copilot in Process Mining.

７ Note

If you still don’t see the Copilot experience, contact your admin. An admin can
turn the Copilot feature off or on in the Power Platform admin center.



In some geographic regions outside United States, Australia, and United
Kingdom, an admin needs to turn on the cross geo calls to enable Copilot.
More information: Copilot availability by region.

Ingest Data with Copilot
Follow these steps to ingest data with Copilot.

1. Sign in to Power Automate .

2. Select Process mining > Start here (under Create new process).

3. In the Process name field, enter a name for your process.

4. Under the Data source heading, select Azure Data Lake (preview).

5. Select Continue.

6. Complete the steps in the Connection setup screens for the Azure Data Lake
container.

7. Select Next.

8. Select the folder or file you're interested in analyzing and Copilot identifies the
process.



9. Confirm that it's the process you're interested in analyzing by selecting Confirm
process > Next.

10. In the mapping screen, Copilot offers an automapping suggestion that you can
review and choose to map your data to.

11. Once you've reviewed the automapping, you can save and analyze your process.

Frequently asked questions
For the list of questions for Copilot in Process Mining ingestion, go to Frequently asked
questions.

Limitations of Copilot in Power Automate
For a list of limitations of Copilot in Power Automate, go to Limitations of Copilot in
Power Automate.

Related information
Responsible AI FAQs for Power Automate
FAQ for Copilot in Power Automate Process Mining
FAQ for Copilot data security and privacy in Microsoft Power Platform

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Copilot in Process Mining process
analytics (preview)
Article • 04/01/2025

[This article is prerelease documentation and is subject to change.]

Copilot in Process Mining process analytics provides process insights through quick and
easy natural language expression. Copilot can surface insights on your process and
recommend solutions in power automate process mining.

Copilot can perform the following actions:

Surface top insights in your process.
Offer recommendations on automation.
Answer your questions about your process data.
Answer your general questions about process mining.

） Important

This is a preview feature.
Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.
For more information, go to our preview terms .
This capability is powered by Azure OpenAI Service.
More information: FAQ for Copilot data security and privacy in Power
Platform

Prerequisite
You need a Power Platform environment for Copilot in Process Mining.

７ Note

If you still don’t see the Copilot experience, contact your admin. An admin can
turn the Copilot feature off or on in the Power Platform admin center.
In some geographic regions outside United States, Australia, and United
Kingdom, an admin needs to turn on the cross geo calls to enable Copilot.



More information: Copilot availability by region.

Copilot in Process Mining analysis
Copilot in Process Mining process analytics helps you generate process insights through
natural language. Copilot can easily summarize findings from your data quantitatively
and qualitatively. Prompts help you get a quick start on your process mining journey.

Make sure you've done the following:

Finished the process import and see the imported process on the Process Mining
web page.

If you plan to use Copilot on the Process Mining desktop application, download
and install the Process Mining desktop application on your local machine.

For instructions, go to Download Power Automate Process Mining desktop app.

Analyze your process
Follow these steps to analyze the process with Copilot. You can analyze your process in
the Power Automate Process Mining web page or in the Process Mining desktop app.

Analyze your process in the Power Automate Process
Mining web page

1. In Power Automate in the left navigation pane, select Process mining.

2. In the Environments field in th titlebar, select your process mining environment
with an imported process.

3. Open the imported process.



There are two ways to open the process:

If you wait until the import operation finishes, the process opens
automatically after the import, OR
After steps 1 and 2, you see the Process Mining environment home page.
Processes display as tiles. Select a process tile, or select the All processes link
to list all processes. To open a process, select its name.

Analyze your process in the Process Mining desktop app

） Important

This feature is generally available only in the United States region, and is in preview
for all other regions.

1. Open the Process Mining desktop app:
a. On the taskbar, select the Windows Start icon.
b. In the search bar, enter process mining.
c. On the right panel, select Power Automate Process Mining app.

2. In the My processes tab, select your process mining environment with an imported
process.

3. Select the process to analyze.



4. In process map view, select Copilot on the command bar to the right. The Copilot
pane opens.

Copilot offers several prepared suggestions to easily get you started on engaging
with your data.

5. Select a suggestion to have Copilot provide the response.

If available, it also provides subsequent prepared suggestions.



6. (Optional) You can continue in conversation with Copilot by selecting subsequent
suggestions. Alternatively, you can ask your own questions at any time using the
text field in bottom part of the Copilot pane.



Copilot in the Process Mining desktop app leverages knowledge of the open process
statistics. It communicates the various statistical information.

How to write a good prompt
For more general information about writing prompts with generative AI, go to The art of
the prompt: How to get the best out of generative AI .

For general information about writing prompts in Power Automate, go to How to write a
good prompt.

Copilot in the Process Mining desktop app has access to process statistics for top items
for activities, edges, and variants. You can ask questions related to your statistics and
Copilot can answer with correct data. When asking about statistical properties, Copilot



has access to information about frequency (activity, edge counts, and case counts),
durations (total and average), and rework statistics.

The following list provides examples of good prompts within the scope of available
process statistics.

What is the most common variant?
Which activity has the highest frequency?
What activities have the highest rework and rework percentage?
Compare activities with the highest rework (%) attribute.
Make a summary description of the process, use the data provided to support your
conclusions.

The following list provides examples of prompts focused on general knowledge about
process mining.

Give me introduction to process mining.
Let's talk about data quality of event log dataset for process mining.
What are the most common process mining event log related data quality issues?

Frequently asked questions
Use this section to find answers to frequently asked questions.

How do I create an environment with Copilot?
1. Go to Create a Power Platform environment.

2. Create a Power Platform environment.

If you need help with creating a preview environment, ask your Power Platform
admin.

Why don't I see Copilot?
Ask your admin if they turned off the Copilot feature in the Power Platform admin
center for your environment.

How do I disable Copilot?
Have your tenant admin ask the MS Support team to disable Copilot in your tenant.



Limitations of Copilot in process analysis
Copilot has limited information about processes. Only access to the most common
activities and variants are available. If the process contains many activities or
variants, Copilot can answer prompts only for the most frequent ones.
Copilot doesn't have access to statistical information about custom attributes in
the process like financial, resource, or vendor attributes.

Limitations of Copilot in Power Automate
You can't use Copilot in Process Mining ingestion on processes created with
dataflows.
You can't use Copilot in task mining processes.
Copilot has a limited view of your ingested data in the ingestion experience. This
limits the questions it might be able to answer for your data and process, such as
the longest running activity or amount of rework in process.
(Applies only to Copilot in process analytics) Copilot can't be used in a web report
of Process Mining.
You can't use Copilot if you're using a personal Microsoft account. For example,
you can't use someone@live.com . Use a work or school account like
someone@contoso.com  instead.
Copilot supports English language only for models.

Related information
Responsible AI FAQs for Power Automate
FAQ for Copilot in Power Automate Process Mining
FAQ for Copilot data security and privacy in Microsoft Power Platform

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Connect to SAP ERP from process
mining (preview)
Article • 07/27/2023

[This topic is pre-release documentation and is subject to change.]

The SAP ERP (enterprise resource planning) connector in beta enables you to extract
data from your SAP system. It allows you to invoke remote function calls (RFC) and
business application programming interface (BAPI) functions using an on-premises data
gateway. This SAP RFC connector is supported by Power Platform dataflows within
Microsoft Power Automate Process Mining.

） Important

Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.

Prerequisites
Enabling SAP ERP connector requires several prerequisites to be completed. All
prerequisites must be completed on the same machine where extraction will be made.
You must have admin permissions with access to the target SAP instance.

Ensure the windows machine (64 bit OS) is updated and has access to the target
SAP machine.
Ensure SAP credentials have requisite permission to run the desired RFCs or BAPIs.
Ensure there are SAP S-user credentials to be able to download the SAP .NET
Connector installer.

Set up the connector
The following installers must exist in the desktop or virtual machine before using the
connector.

1. Go to SAP Connector for Microsoft .NET  to download and install the NCo 3.0 for
64 bit.

Don't install NCo 3.1, as this version is not yet supported.



Access to the download requires a valid S-user. You might need to contact
your SAP team.
Choose the 64 bit version. The 32 bit version won't work.
During installation, in the optional setup steps screen, select Install
assemblies to GAC.

2. Download and install Microsoft SAP RFC Reader  (V0.1.02232.26).

.NET Framework 4.7.2 or greater is required.
This is supported by Windows 10, Windows 11, Windows Server 2012 R2,
Windows Server 2016, Windows Server 2019, and Windows Server 2022.

3. Download and install the Power Query On-premises data gateway installation . To
learn more about the gateway requirements or for support, go to Install an on-
premises data gateway.

Connection settings for SAP ERP
To instantiate your dataflow connection to the SAP ERP connector, you need to create a
connection string with the following parameters.

Name Key Required Type Description

AS host AppServerHost Application String The hostname of the SAP
server application server.

Client Client Application Integer The SAP client ID to connect to
and message the SAP system.
server

AS system SystemNumber Application Integer The SAP system’s system
number server number. It's a number from 00

to 99.

Message MessageServerHost Message String Hostname of the SAP system’s
server server message server.

Message MessageServerService Message String Service name or the port
server server number under which the
service message server is listening for
name/port load balancing requests.

System ID SystemID Message String SAP system's three letter system
server ID.

Logon LogonGroup Message String The logon group for the SAP
group server system from which the message



Name Key Required Type Description

server selects an application
server.

Logon type LogonType Application String The type of logon to the SAP
and message system. It's either application
server server logon (type A), or group

logon (Type B, also known as
message server). Values can be
ApplicationServer  or Group .

Set up the SAP system connection string
This connector supports SAP authentication only currently. Constructing the script is
dependent on connection type and is outlined in the following sections.

Application server
1. Connection string template: {"AppServerHost":"<application server>","Client":"

<client id>","SystemNumber":"<system

number","LogonType":"ApplicationServer"} .`

2. Replace everything in <>  with your application server system settings. For example,
for a server sap.contoso.com with system number 00 and client id 100:
{"AppServerHost":"sap.contoso.com","Client":"100","SystemNumber":"00","LogonTy

pe":"ApplicationServer"} .

Message server
Although Data gateway isn't marked as a requirement in connection settings,
identifying the data gateway is required for connecting to the SAP ERP connector.

1. Connection string template: {"MessageServerHost": "<message server>",
"MessageServerService":"<message server service name/port>", "LogonType":

"Group", "SystemID": "<system id>", "Client": "<client id>", "LogonGroup":"

<logon group>"} .

2. Replace everything in <>  with your message server system settings noting that you
might or might not require both MessageServerService and SystemID. For
example, for server 10.0.0.1 with message server port 3333 and client id 800 and
logon group COTO: {"MessageServerHost": "10.0.0.1",



"MessageServerService":"3333", "LogonType": "Group", "Client": "800",

"LogonGroup":"COTO"} .`

Enable function parsing
After connections, the RFC shows up as a function with the parameter metadata and an
optional Enable Function Parsing option. Fill in the parameters and select Invoke to get
the data. You should rely on your SAP produced documentation or custom
documentation for RFC parameters.

The function parsing mode for the connector understands contracts of two widely used
RFCs: RFC_READ_TABLE  and /SAPDS/RFC_READ_TABLE2 . They'll take this interpretation and
parse out the output in an easy to read format instead of requiring you to do so in M
script. Function parsing can be enabled not only for the previously mentioned RFCs, but
also for RFCs with the same contract such as BBP_RFC_READ_TABLE  or
/BODS/RFC_READ_TABLE2 . This includes custom RFCS deployed by the customer to the
SAP system.

Authentication
The SAP ERP connector only supports basic SAP authentication. Because the connector
is designed to be used by multiple users of an app, the connections aren't shared. Each
user authenticates with the SAP system.

Known issues and limitations
The following are some of the known issues and limitations of the SAP ERP connector.

The connector supports only RFCs and BAPIs.
The connector doesn't support receiving messages from SAP Server.
Transactional RFCs (tRFCs) aren't supported.
The gateway has a 2 MB payload limit for write operations and an 8 MB
compressed data response limit for read operations.

FAQ

The SAP ERP beta connector is labeled as third party. Is
this connector not created or managed by Microsoft?



The connector was created by Microsoft and is managed by Microsoft. As a beta
connector, it holds a third party label until it becomes generally available.

I'm getting the following error when attempting to
connect: “The given data source kind is not supported
Data source kind SAPERP”. How do I address this?
As a custom connector, by default we save the connection in your [System
Drive]\Windows\ServiceProfiles\PBIEqwService\Documents\Power BI Desktop\Custom
Connectors folder. If this folder doesn't exist, or if the gateway is configured to use a
different custom connector folder, you get this error. To fix this, copy the SAPERP.mez
connector file from [System
Drive]\Windows\ServiceProfiles\PBIEqwService\Documents\Power BI Desktop\Custom
Connectors and into the folder that you configured in your gateway.

Do I always need to identify a data gateway in connection
settings?
As part of connection setting you must identify a data gateway to successfully connect
through the SAP ERP connector.

My connection continues to fail, what can I do to
remediate?
Make sure to check that installers described in this article are current. Reinstalling drivers
might solve your connection issues.



Transform and map data
Article • 04/20/2024

After you select the data source you want to use, you're taken to the Power Query
Editor. The Query Editor is a powerful tool to transform your data. To learn more, go to
The Power Query user interface.

Here are some reasons why you might want to transform the data:

You might not be interested in all the activity names that are logged, and so you
want to filter for specific activity names that are important to the process you're
trying to mine.

You might want to rename some of the activity names to be more descriptive and
understandable. This is often not the case with names in a database.

You might be interested in only a specific date range, and not the entire history of
data.

You might want to combine multiple ID columns to form the case ID. This is often
done when the ID you want to use for process mining doesn't exist or is a
combination of multiple IDs in the application. For example, when a customer files
support tickets, the support ticket might be assigned to multiple customer service
agents. If you want to analyze how each agent handles each ticket, you would
combine the agent ID and the ticket ID into the case ID.

Filter activity names
1. Select the caret next to the activity name column to bring up the sort and filter

menu.

2. If there's a message that says List may be incomplete, select Load more.

3. Select only the activity names that you want to analyze. Uncheck any name you
want to exclude.



4. Alternatively, you can use the Text filter menu for more advanced filtering. For
more information on filtering by value, go to Filter by values in a column.

Rename activities
1. Ensure that the Activity Name column is selected.
2. Above the toolbar, select the Transform tab.
3. On the toolbar, select Replace values.
4. Under Values to find, type the activity name as it appears in the data source that

you want to replace.
5. Under Replace with, type the activity name you want to show in the process map.
6. Repeat this process for all the values you want to replace.

Reduce the number of total records
One strategy for reducing the total number of records is to use only the latest records.
To do this, you need to first sort the data by time.

1. Open the sort and filter menu by selecting the caret next to the startTimestamp
column.



2. To have the most recent records show up first, select Sort descending.

3. Select OK, and then select Keep rows on the toolbar.

4. Enter 150000 under Number of rows.

5. Select OK to filter for the top 150,000 rows.

Combine multiple IDs
You can use Ctrl + click to select multiple columns that you want to combine.

1. On the Transform tab toolbar, select Merge columns.
2. (Optional) Select a separator from the dropdown list. Alternatively, you can select

none.
3. Change the name (or make a note of the default name that's generated), so you

can select it when mapping to a case ID.

Map data
Mapping tells the process mining capability what column is mapped to which attribute
type (for example, case ID, activity name, or timestamp).

1. To navigate to the Mapping screen, select Next.



2. Use the dropdown menus next to the respective columns to select their attribute
type. For more information, follow the description of the attribute types.

3. When the data is ingested from Azure Data Lake Gen2 using a CSV file format, you
can use the dropdown menus in the Data type column to change the data types
for the import. For columns having numeric values, consider their analytical usage
of whether the attribute is a continuous value (for example, invoice amount set to
Number) or a categorical value (for example, material code set to Text).

4. Case ID, Activity, and Start timestamp are mandatory attributes to continue with
the analysis.

5. To start the analysis of your process, select Save and analyze.



Visualize and gain insights from
processes
Article • 05/24/2024

This article explains metrics and visuals, and what they could tell you about your
process.

Some of the metrics and visuals are only available in setup with your own Power BI
workspace. These metrics and visuals are clearly marked in the text as Premium. To be
able to access them and gain full insights, make sure you complete the steps in the
following articles:

Connect your Power BI workspace to the process mining capability
Create your own custom Power BI workspace
Load your process analytics in Power BI

After completing these steps, return to the analytics page of your process in the process
mining capability.

７ Note

The standard report applies the Power BI report filter set to ViewID = 1, which
usually is the view named Default. All report pages and visualisations reflect this
filter by default, unless changed.

Process map
The process map empowers you to visualize and gain insights from processes. By
looking at a graphical representation of how your business processes are performed,
you can glean insights about where opportunities exist.

Activities describe tasks or actions, the sequence of which makes up a business process.
Activities can be performed by humans or machines, in an automation scenario. In the
process map, different activities appear as nodes, and transitions between activities
appear as edges. Each process sequence has a start and an end.

Different activity combinations and variants are shown separately on the process map. A
process variant is a unique sequence from start to finish of the process. Each variant
differs from the others by at least one activity.



You can easily switch between different layers and associated metrics on the process
map using the controls on the top left of the process map visual.

The metrics for following layers visualize the same metric on both nodes and transitions.
You can switch between the absolute value and relative ratio to the process level metric
by clicking the % icon next to the selected metric.

Frequency layer

Total count: The total frequency of an activity/transition captured in the process
data.

Case count: The number of process instances in which an activity/transition
occurred.

Maximum occurrence in case: The maximum number of times an
activity/transition is repeated in one process instance.

Performance layer

Total duration: The total duration of an activity/transition captured in the data.
Value can also be displayed as a ratio (percentage) between the total duration
of an activity/transition captured in the data and the total duration of all cases.

Mean duration: Mean duration of an activity/transition captured in the data.
Value can also be displayed as a ratio (percentage) between the mean duration
of an activity/transition captured in the data and the mean case duration.

Maximum duration: Maximum duration of an activity/transition captured in the
data.

Minimum duration: Minimum duration of an activity/transition captured in the
data.

Rework layer

Select different metrics to be visualized on nodes and on transitions to get better
insights. If you select the link icon between them, the selection to the same metrics
both for nodes and transitions is locked. You can switch between the absolute
value and relative ratio to the process level metric by selecting the % icon next to
the metric.

Rework count: Rework count represents the sum of all self-loops and loops.

Self-loop count: Self-loop represents a specific repetition where an activity is
directly followed by the same activity. In terms of edges/transitions, the starting



and ending activity of edge is the same.

Loop inflow: Loop inflow represents the repetitions of an activity's
predecessors.

Loop outflow: Loop outflow represents the repetitions of an activity's
successors.

Loop count: Loop represents specific repetition where activity is followed by the
same activity, but not directly. For example, at least one more activity is always
involved.

Net loop gain: Available for activities only. This activity metric represents the
difference between Loop outflow and Loop inflow. If the value is positive, the
activity is directly followed by more repeated activities than it was preceded.
Such activities start new loops in processes. If the value is negative, the activity
is directly followed by less repeated activities than it was preceded. Such
activities end, close, or exit loops in processes. The halo effect color also helps
us see positive and negative trends in the process - red color represents a
problem (start of new loops); the blue color represents a favorable change (end
of loops).

To learn more about the process map visual, go to Process map overview.

Use KPIs and visualizations for analytics
You get several prebuilt KPIs and visualizations to help you to understand your process.
You can filter by selectors, such as Activity and Case Id (Premium), and custom filters
(Premium) if you added the custom attributes (data columns) when you uploaded your
data for analysis.

The following screenshot is an example of visualizations and analytics you see in the
premium version.



If you didn't purchase the premium version, you have access to the default version. The
top of the default version shows only the four KPIs listed in the KPIs section in this
article and not the two KPIs with (Premium) in the title. Also, you won't see the Average
duration of cases over time chart.

KPIs
These KPIs are the same metrics that you see at the top of your report.

Median case duration (Premium): The median case duration shows the center of
all the case durations that are more resistant to outliers in the data.

Average Case Duration: Shows the average case duration, which can be greatly
affected by outliers in the data.

Self-Loop Cases %: Percentage of cases that have an activity that repeats itself.

Loop Cases %: Percentage of cases that have a sequence of activities that has at
least one activity that is repeated.

Rework Cases %: Percentage of cases that have either a Self-Loop or Loop.

Resource Count (Premium): Count of how many resources are in the process.

To enlarge the view so you can dig deeper into your process, select the Map tab.

Filters pane



To drill down into the process, use the filters in the filters dialog. To see the filters, select
Filters in the upper-right side of the Summary tab.

The filters dialog contains the following filters:

Activity selector: Allows you to select cases that contain the selected activity.

Case filter (Premium): Allows you to see the process visualization and analytics
filtered to the case.

Start date filter (Premium): Allows you to see the process visualization in a
particular period.

Custom attribute filters (Premium): Allows you to filter on both your event and
case level custom attributes for your process.

To select multiple activities or cases, you can use Ctrl + click .

If you didn't purchase the premium version, you have access to the default version. The
Filters pane shows only the activity selector. You don't have access to the other filters
listed in this section with (Premium) in the title.

Visualizations
Variants by frequency: Shows which variants are the most common, sorted by the
most common to the least common. You can select one or multiple variants in the
bar chart to analyze details of the variants by filtering for them. This would update
the process map, KPIs, and other visualizations. To select multiple variants, press
Ctrl and select the desired variants.

Variants by time: Shows a bar chart of the longest duration variant to the shortest
one. Filtering on specific variant updates the process map and KPIs so you could
get insights into the behavior of the selected variants.

Average duration of cases over time (Premium): Shows how duration of the
process changes over time.

Cases, Activities, and Variants: Shows number of cases, activities, and variants
based on the current filter settings.



Time Analysis (Premium)
The Time Analysis (Premium) doesn't have an alternative default view. It allows you to
drill down into time bottlenecks by cases, variants, and activity. The Time Analysis
(Premium) also shows you average time spent per case and per variants ordered by the
time spent.

The analysis view appears on the right and the corresponding map appears on the left.



Variant DNA
The Variant DNA view is available in both the default and premium views. To show the
order of all the activities in each variant sorted based on the variants that happen the
most often, select the Variant DNA tab. The activities are color coded and abbreviated
to quickly show a high-level view of the order of the activities that occur. This also helps
identify noncompliant processes, self-loops, and loops quickly.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Customize a report with your own
Power BI workspace
Article • 04/04/2025

You can use your own custom Power BI workspace and leverage a higher capacity to
analyze processes with a lot more data. You're also able to customize the look and feel
of the report.

Set up your workspace
You need to set up your Power BI workspace to connect it to the process mining
capability and then customize it. The following sections in this article walk you through
how to set up your workspace.

Connect your Power BI workspace to the process mining
capability

1. Sign in to the Azure portal .

2. Search for azure active directory in the search bar and select Microsoft Entra ID.

3. Under Manage, select Users.

4. Select User settings and review the App registrations selection.

If App registrations is Yes, any user can register the process mining capability
as an app.
If App registrations is No, only admins can register apps. If you're an admin,
you can choose to turn this on to allow others to register the process mining
capability as an app.

5. On the Windows taskbar, select Search.

6. Type powershell, and then select Run as Administrator.

Install Azure tools
If you didn't do this yet, install the Azure tools.

1. On the Administrator: Windows PowerShell screen, type Install-Module AzureAD,
and then select Enter.



2. When prompted to confirm installation, enter Y, and then select Enter.

3. Connect your Azure account by typing Connect-AzureAD, and then sign in.

4. Validate that you're signed in.

5. Register the process mining service principal by typing this command:

New-AzureADServicePrincipal -AppId dad3c6de-ed58-42ef-989f-9c0303aaeedc
-DisplayName ‘Process Insights Prod’

6. Sign in to Microsoft Power BI .

7. Select the ellipsis (...) > Settings > Admin portal.

8. Scroll down to Developer settings and do the following steps:

a. Expand the dropdown menu for Embed content in apps and enable it by
toggling the slider.

b. Expand the dropdown menu for Service principals can use Fabric APIs and
enable it by toggling the slider.



Both settings can be applied to the whole organization. Alternatively, you can
set up a dedicated security group and include the Process Insights Prod service
principal (registered in step 5) in it.

9. Return to the Power BI home page.

Create your own custom Power BI workspace
Now that you connected your Power BI workspace to the process mining capability and
installed the Microsoft Azure tools, you can create your own custom Power BI
workspace.

1. On the left panel, select Workspaces > Create a Workspace.

2. In Advanced Options, select a premium Power BI license. (We recommend a
premium per capacity license.)



3. Select Apply.

4. In the created workspace, select Manage access.

5. Select Add people or groups.

6. Select Search for, and then add Process Insights Prod.

7. Assign it admin access.

） Important

It is required that the service principal gets added as an admin. If you skip this
step, the feature doesn't work.

Load your process analytics in Power BI
Load your process analytics in Power BI to start customizing your report.

1. After analyzing a process, go to the process Details page by selecting the name of
the process in the breadcrumbs.

2. On the Details card, select Edit.

3. In the Power BI Workspace (optional) dropdown menu, select a workspace of your
choice.

4. If you select a workspace, give the report a unique name in the required Report
name field.

We recommend that you use a unique name. If you use a name of a report that
already exists, the process mining capability overwrites the existing report of
another process. This could lead to loss of custom reports and composite datasets
of that process. After refreshing the process, if you decide to change the report
name, you'll need to publish a new report.

5. You might then toggle the Update report when refreshing data option between
on and off.

If the toggle is on, a new report is published in Power BI and is embedded in the
analytics page of the process mining capability. If the toggle is off after refreshing
the data, the existing report isn't updated in the process mining capability.



Customize reports in Power BI workspace
With the powerful integration of the process mining capability with Power BI, you can
customize your process reports in an attached Power BI workspace. In this example, you
perform a simple customization of the Power BI report to include a card that holds or
tracks one of the analytic measures.

To be able to do this, make sure you completed these steps in this article:

Connect your Power BI workspace to the process mining capability
Create your own custom Power BI workspace
Load your process analytics in Power BI

After completing these steps, return to the analytics page of your process in the process
mining capability.

1. Refresh and reanalyze the process by selecting Refresh.

2. Select Open in Power BI. If you don't see this button, make sure you completed
the steps in the Load your process analytics in Power BI section in this article.

You're redirected to a Power BI web screen that shows you a report of your
process.

3. Begin customizing your report by downloading it to your local machine. To do this,
select File > Download this file.

4. Select the A copy of your report with a live connection to data online (.pbix)
radio button. The report is downloaded with live connection.

5. Open the downloaded report in Power BI Desktop. Ensure you have the latest
Power BI Desktop version.

6. Go to the Modeling tab and select Make changes to this model. You might need
to have the Contributor role to be able to see that option in the Modeling tab.

7. Select Add a local model.



8. Select the tables that you'd like to include in the local model. We recommend that
you keep the default selection.

9. Select Submit.

The local model is created. Now you can make changes to existing visuals, or add a
new data source to the report.

10. Move the cards that hold the donuts (blue circles) for the Variants, Cases, and
Activities metrics to the right by selecting and dragging each card.

11. On the Visualizations pane, select the card element.

12. A new card appears. Resize it, and then drag it to the left of the Variants donut
(blue circle).

13. On the Data pane, expand ReportMeasures and select Self Loop %.

14. On the command bar, select Save.

In your process, you don’t have any self loops, so you should see 0.00% in that
card.



15. Save the report.

16. From the Home tab, select Publish.

17. Select your workspace, and choose Select to publish the report to the Power BI
service.

After the report is successfully published, you can open it from the pop-out
window.

You successfully customized your Power BI workspace. Every time you refresh your
process and reopen your Power BI report, your metrics and customizations are updated.
Try out Power BI and customize your reports to learn how they can help you analyze
your process effectively.

Once this step is done, you see the report in your Power BI workspace with the report
name that you entered. You can edit and save it. Your report is updated with the
changes that you made with Power BI.

If you encounter issues or error messages, go to Issues with your own Power BI
workspace.

Related information
Workspaces in Power BI

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Use the optimized data structure in a
Power BI report (preview)
Article • 04/20/2024

[This article is prerelease documentation and is subject to change.]

The new optimized data structure leads to faster and more memory efficient analysis of
processes. By saving on memory, customers can analyze larger processes and save on
costs by using smaller Power BI capacities to perform analysis.

In addition, a more intuitive Power BI model data structure is used, which allows
customers to dig deeper into their insights with less time and effort. To learn more
about this data model, go to the Power BI data model structure section this article.

） Important

This is a preview feature.
Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.

Previous optimized structure to deprecate soon
The new optimized data structure replaces the previous structure completely and the
previous data structure will be deprecated. To find out the date and necessary steps, go
to the banner in the process Details page.

The new optimized data structure takes place in the background, so you'll see it only in
the resulting model as described in the following section.

Enable XMLA read/write setting
To use the optimized data structure, the XMLA endpoint property must be enabled for
read-write. By default, Premium capacity or Premium Per User semantic model
workloads have the XMLA endpoint property setting enabled for read-only.

） Important



Enabling XMLA can only be done by the capacity admin.

Enable read-write for a Premium capacity semantic model
workload

1. Sign in to Power BI .

2. Select Settings > Admin portal.

3. In the Power BI Admin portal, select Capacity settings > Power BI Premium >
capacity name.

4. Expand Power BI Workloads.

5. In the XMLA Endpoint setting, select Read Write.

The XMLA Endpoint setting applies to all workspaces and semantic models
assigned to the capacity.

Enable read-write for a Premium Per User semantic model
workload

1. Sign in to Power BI .
2. Select Settings > Admin portal.
3. In the Power BI Admin portal, select Premium Per User.
4. Expand Semantic model workload settings.
5. In the XMLA Endpoint setting, select Read Write.

Enable using the optimized data structure



For new processes that use a custom workspace, the optimized data structure is set to
true by default. To enable it or confirm it is enabled, perform the following steps.

1. Go to the process details page and select Edit.

2. Select a custom workspace by selecting the dropdown menu under the Power Bi
Workspace (optional) field.

3. Confirm that the Use optimized data structure toggle is On. If it's off, select the
toggle to enable it.

4. To save the changes, select Save if the button is enabled.

If it's not enabled, that means the value of the Use optimized data structure field
was already set to On, thus you can skip this step.

Power BI data model structure



When a process is published to Power BI, a default data source and a corresponding
report are created. The following screenshot is an example of the structure of the
dataset in the published data source in Power BI.

For an enlarged view of the screenshot, select the magnifying glass in the lower-right
corner.



Relationships
Relationships necessary for filtering and interconnectivity of visuals are predefined in the
published data model. There isn't a need to manually create more relationships unless
other data sources are connected. For this scenario, use the Power BI composite data
model and build relationships on top of that model.

Data model summary
From a logical perspective, the data model consists of many entity subsets as depicted
in the first paragraph of this section.

Process Data: All process related data without filtering and calculated measures.
View Data: Entities giving the process data into the context of the created process
analytical view—applied filters, calculated measures, and custom metrics.
Visuals data: Entities providing precalculated data necessary for process mining
custom visuals to display.
Helping entities: Other entities needed by Power BI.

Following is the brief description of the subsets and included entities.



Process Data
The content of process data entities changes in specific scenarios.

When process model data is refreshed.
When a new view is created.

Working with these entities allows you to access the raw process data not influenced by
the applied filters.

ﾉ Expand table

Entity Description

Cases List of all cases in the process. Each case contains a unique case
identifier index, Case ID display, and values for each of the case
attributes, as defined in the mapping setup step.

Events List of all events in the process. Each event references a case into
which it belongs using Case_ID , has a unique event identifier index,
and values for each of the event attributes, as defined in the mapping
setup step.

AttributesMetadata Entity holds the definition of all case/event-level attributes as defined
in the import of event log data into process model. It includes its
datatype, attribute type, and attribute level being either case or event.

MiningAttributeLabels Holds values of available mining attributes. A process view can be set
up to look at the process from different perspective based on the
selected mining attribute. If no other mining attribute is available, the
entity holds the values of Activity  attribute.

CustomMetricsMetadata Includes the definition of custom metrics created in the Process
Mining desktop app. Based on the context in which the metric is
available, many entries might exist for the same custom metric, having
a different Type . It also includes the custom metric result data type
that can be used for conversion or formatting of the values.

Views List of available (published) views created in the Power Automate
desktop app. Only public process views are published to the data set.
Entries can be used to filter report, report page, and visual to visualize
only data from the specific process view.

View Data
The content of view data entities changes in the following scenarios.

When a user changes the filtering definition in any process view.



When a new custom metric is created.

View data entities allows you to access process data influenced by the applied filters and
accesses the measures calculated based on the applied filters. As both case and event
level filters can be used in the definition of a process view, it is recommended to work
with view data entities, as the influence on the resulting dataset might be significant.

ﾉ Expand table

Entity Description

ViewCases Entity holds information on which cases are included in which view. In
addition, it includes the information for which variant the case is
following and precalculated measures for the case. If a case is included in
several views, the entity holds a record for each case-view combination.
This is important, as some of the values of calculated case measures
depend on the filtering criteria set in the view. It also holds any
precalculated custom metric values (if defined in process context and
valid on case level). The case record is uniquely identified by the Index
column.

ViewEvents Entity holds information on which events are included in which view and
which case they are connected to (event level process view filters might
modify the events included in the case). In addition, it includes
precalculated measures for the event. If an event is included in several
views, the entity holds a record for each event-view combination. This is
important, as some of the values of calculated event measures depend
on the filtering criteria set in the view. It also holds any precalculated
custom metric values (if defined in process context and valid on event
level). The event record is uniquely identified by the Index column.

ViewTransitions Entity holds information on which transitions are included in which view.
In addition, it includes precalculated measures for the transition. If a
transition is included in several views, the entity holds a record for each
transition-view combination. This is important, as some of the values of
calculated transition measures depend on the filtering criteria set in the
view. It also holds any precalculated custom metric values (if defined in
process context and valid on transition / edge level). The transition
record is uniquely identified by the Index column.

ViewParallelTransitions Entity holds a record for a combination of transition and case, when that
transition is considered parallel in that case in a particular view.

Variants Entity holds the relations between variants and process views. A record is
included if a particular variant is included in a view after the filtering
criteria are taken into account.

Visuals data



Visuals data entities are recalculated only when there's a data refresh for the process
model.

ﾉ Expand table

Entity Description

ProcessMapMetrics Aggregated measures for all nodes and transitions in the process model
that are needed for visualization in process map custom visual.

VariantDNA Aggregated measures and relations to events and attributes that are
needed for visualization in variant DNA custom visual.

Other entities

ﾉ Expand table

Entity Description

LocalizationTable Internal table used for localization purpose.

LocalizationMeasures Internal measures used for localization purpose.

ReportMeasures Precreated and preformatted most frequent measures that can be used
for summary KPIs in the process report. Their evaluation might be subject
to filtering and interactive selection in Power BI report.

Power BI composite data model
We recommend that you use the Power BI composite data model on top of the data
model published by Power Automate Process Mining and create necessary
modifications there for the following scenarios.

When more data sources are needed
When more entities should be created
When more relationships are needed
When custom DAX queries are needed

To learn more about creating Power BI composite data models, go to Use composite
models in Power BI Desktop.



Customize a report with your own Fabric
workspace (preview)
Article • 04/10/2025

[This topic is prerelease documentation and is subject to change.]

You can use your own custom Fabric workspace and leverage a higher capacity to analyze
processes with a lot more data. You're also able to customize the look and feel of the report.
When using you own custom Fabric workspace, data from Power Automate Process Mining is
first stored in Fabric Lakehouse where they are transformed into delta tables. A semantic model
is automatically created on top of the tables to power the default report. The Power BI report
connects to the data using Direct Lake mode.

） Important

This is a preview feature.
Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.
For more information, go to our preview terms .

Set up your workspace
To connect the workspace to the process mining capability and then customize the default
report (or create a new one) you need to:

Create and set up your Fabric workspace
Assign admin access rights on the workspace to Process Insights service principal
Create a Fabric Lakehouse in the connected workspace

The following sections in this article walk you through how to set up your workspace.

Check the App registration settings in AAD
1. Sign in to the Azure portal .

2. Search for azure active directory in the search bar and select Microsoft Entra ID.

3. Under Manage, select Users.



4. Select User settings and review the App registrations selection.

If App registrations is Yes, any user can register the process mining capability as an
app.
If App registrations is No, only admins can register apps. If you're an admin, you
can choose to turn this on to allow others to register the process mining capability
as an app.

5. On the Windows taskbar, select Search.

6. Type powershell, and then select Run as Administrator.

Install Azure tools and register a Process Insights service
principal in AAD
If you didn't do this yet, install the Azure tools.

1. On the Administrator: Windows PowerShell screen, type Install-Module AzureAD, and
then select Enter.

2. When prompted to confirm installation, enter Y, and then select Enter.

3. Connect your Azure account by typing Connect-AzureAD, and then sign in.

4. Validate that you're signed in.

5. Register the process mining service principal by typing this command:

New-AzureADServicePrincipal -AppId dad3c6de-ed58-42ef-989f-9c0303aaeedc -
DisplayName 'Process Insights Prod'

6. Sign in to Microsoft Power BI .

7. Select the ellipsis (...) > Settings > Admin portal.

8. Scroll down to Developer settings and do the following steps:
a. Expand the dropdown menu for Embed content in apps and enable it by toggling the

slider.
b. Expand the dropdown menu for Allow service principals to use Power BI APIs and

enable it by toggling the slider.



9. Return to the Power BI home page.

Create your own custom Fabric workspace
Now that you connected to the process mining capability and installed the Microsoft Azure
tools, you can create your own custom Fabric workspace.

1. Select Workspaces > Create a Workspace.

2. In Advanced Options, select a Fabric capacity.

3. Select Apply.

4. In the created workspace, select Manage access.

5. Select Add people or groups.

6. Select Search for, and then add Process Insights Prod.

7. Assign it admin access.

） Important



It's required that the service principal gets added as an admin. If you skip this step,
the feature doesn't work.

Use existing Fabric workspace
You can also use an already existing Fabric workspace. In this case, please ensure that your
account has at least Contributor access rights in that workspace and ensure you meet the
other pre-requisites.

Create a Fabric Lakehouse
Now it's necessary to create a Fabric Lakehouse to store the delta tables for the semantic
model:

1. Go to your workspace.
2. Select New item in the top left corner.
3. In the right panel search or select Lakehouse.
4. Fill in the name of your Lakehouse and ensure that the Lakehouse schemas option is

unchecked (Lakehouse schemas are currently not supported). You can use a single
Lakehouse for all your processes in this workspace, or you can create a new Lakehouse for
each process. A separate semantic model is always created for a single process.

5. Wait until the Lakehouse is successfully created.
6. Lakehouse is automatically created with a default semantic model and a SQL analytics

endpoint. After the process is ingested and analyzed, a new semantic model is created.
The default semantic model is not used by Power Automate Process Mining.

Load your process analytics in Fabric
Load your process analytics in Fabric to start customizing your report. Take these steps:

1. Navigate to your Power Platform environment .

2. Select Process mining from the left navigation and click Start here in the Create new
process section.

3. Fill in the process name and select the ingestion type (location of your data).

4. Select Continue.

5. Select Your Fabric workspace and then select Continue.



6. Select your Fabric workspace and Fabric Lakehouse from the lists and give the report a
unique name in the required Report name field.

We recommend that you use a unique name. If you use a report name that already exists,
the process mining capability overwrites the existing report of another process. This could
lead to loss of custom reports and composite datasets of that process. After refreshing
the process, if you decide to change the report name, you'll need to publish a new report.

7. Select Continue.

8. Follow the rest of the wizard steps based on the selected ingestion method.

9. Once the process analysis completes successfully, you can access the default report
created in the workspace, newly created semantic model, and delta tables created in your
Fabric Lakehouse.

Customize reports in Fabric workspace
With the powerful integration of the process mining capability with Power BI, you can
customize your process reports in an attached Fabric workspace. In this example, you perform
a simple customization of the Power BI report to include a card that holds or tracks one of the
analytic measures.

To be able to do this, make sure you completed these steps in this article:

Connect your Fabric workspace to the process mining capability
Create your own custom Fabric workspace
Load your process analytics in Fabric

After completing these steps, return to the analytics page of your process in the process
mining capability.

1. Select Open in Power BI. If you don't see this button, make sure you completed the steps
in the Load your process analytics in Fabric section in this article. This redirects you to a
Power BI web screen that shows you a report of your process.

2. Begin customizing your report by downloading it to your local machine. To do this, select
File > Download this file.



3. Select A copy of your report with a live connection to data online (.pbix) to download a
report with a live connection.

4. Open the downloaded report in Power BI Desktop. Ensure you have the latest Power BI
Desktop version and the preview feature Enable PBIR format is switched on.

5. Move the cards that hold the donuts (blue circles) for the Variants, Cases, and Activities
metrics to the right by selecting and dragging each card.

6. On the Visualizations pane, select the card element.

7. A new card appears. Resize it, and then drag it to the left of the Variants donut (blue
circle).

8. On the Data pane, expand ReportMeasures and select Self Loop %.

9. On the command bar, select Save.

In your process, you don't have any self loops, so you should see 0.00% in that card.

10. Save the report.

11. Go to the Home tab and then select Publish.

12. Select your workspace, and choose Select to publish the report to the Power BI service.

After the report successfully publishes, you can open it from the pop-out window.

You successfully customized your Power BI report. Every time you refresh your process and
reopen your Power BI report, it updates your metrics and customizations. Try out Power BI and
customize your reports to see and learn how they can help you analyze your process
effectively.



Once this step is done, you see the report in your Fabric workspace with the report name that
you entered. You can edit and save it. Your report is updated with the changes that you made
with Power BI.

If you encounter issues or error messages, go to Troubleshooting.

Related information
Workspaces in Fabric and Power BI



Structure of semantic model in Fabric
workspace (preview)
Article • 04/10/2025

[This article is prerelease documentation and is subject to change.]

The new optimized DirectLake semantic model leads to faster and more memory-efficient
analysis of processes. By saving on memory, you can analyze larger processes and save on
costs by using smaller Fabric capacities to perform analysis. In addition, a more intuitive Power
BI semantic model data structure is used, which allows you to dig deeper into insights with less
time and effort.

） Important

This is a preview feature.
Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.
For more information, go to our preview terms .

Semantic model description
When a process is published to Fabric workspace, it creates a new semantic model and a
corresponding report. This screenshot is an example of a semantic model structure published
to Fabric.

Select the magnifying glass in the lower-right corner of the image to enlarge it.





Relationships
Relationships necessary for filtering and interconnectivity of visuals are predefined in the
published data model. There isn't a need to manually create more relationships unless other
data sources are connected. For this scenario, use the Power BI composite semantic model and
build relationships on top of that model.

Data model summary
From a logical perspective, the data model consists of many entity subsets as depicted in the
first paragraph of this section.

Process Data: All process-related data without filtering and calculated measures.
Visuals data: Entities providing precalculated data necessary for process mining custom
visuals to display.
Helping entities: Other entities needed by Power BI.

Following is the brief description of the subsets and included entities.

Process Data
The content of process data entities changes in specific scenarios.

When process model data is refreshed.
When a new view is created.
When a new custom metric is created.
When a user changes the filtering definition in any process view.



Working with these entities allows you to:

Access the raw process data.
Process data influenced by applied filters.
Access the measures calculated based on the applied filters.

ﾉ Expand table

Entity Description

Cases List of all cases and their attributes in the process. Each case contains a unique Case
ID display, and values for each of the case attributes, as defined in the mapping
setup step. Combine with CaseMetrics entity to get complete case information.

Events List of all event attributes in the process. Each event has a unique event identifier
index, and values for each of the event attributes, as defined in the mapping setup
step. Combine with ProcessMapMetrics entity filtered by Is_Node  column to get a
complete event information.

CaseMetrics Entity holds all case-level metrics related to a specific combination of case and view.
Case level custom metrics defined in Power Automate Process Mining desktop app
will be added to this entity.

AttributesMetadata Entity holds the definition of all case/event-level attributes as defined in the import
of event log data into process model. It includes its datatype, attribute type, and
attribute level being either case or event.

MiningAttributes Holds values of available mining attributes. A process view can be set up to look at
the process from different perspective based on the selected mining attribute. If no
other mining attribute is available, the entity holds the values of Activity  attribute.

Views List of available (published) views created in the Power Automate Process Mining
desktop app. Only public process views are published to the data set. Entries can be
used to filter report, report page, and visual to visualize only data from the specific
process view.

Variants Entity holds the relations between variants and process views. A record is included if
a particular variant is included in a view after the filtering criteria are taken into
account.

Visuals data
Visuals data entities are recalculated only when there's a data refresh for the process model.

ﾉ Expand table



Entity Description

ProcessMapMetrics Aggregated measures for all nodes and transitions in the process model that are
needed for visualization in process map custom visual. This entity combines event
(node) information and edge (transition) information - to use the events or edges in
your other visuals, filter by the value in Is_Node  column. Event level custom metrics
defined in Power Automate Process Mining desktop app will be added to this entity.

Other entities

ﾉ Expand table

Entity Description

LocalizationTable Internal table used for localization purpose.

Power BI composite model
We recommend that you use the Power BI composite model on top of the semantic model
published by Power Automate Process Mining and create the necessary modifications there for
these scenarios:

You need to create more data sources
You need to create more entities
You need to create more relationships
You need to create more custom DAX queries

） Important

The semantic model is created in DirectLake access mode, but its option is set to
Automatic. This setting means that using a nonoptimal DAX queries or incorrectly setting a
composite model might result in fallback to DirectQuery mode—this means that your
report will not break, but you might experience lower performance.

To learn more about creating Power BI composite data models on top of DirectLake semantic
models, go to: Building a composite models on a semantic model or model.



Application lifecycle management in
Process Mining overview
Article • 08/12/2024

ALM (application lifecycle management) encompasses the entire lifecycle of
applications, including governance, development, and maintenance. It incorporates
various disciplines such as requirements management, software architecture,
development, testing, maintenance, change management, support, continuous
integration, project management, deployment, release management, and governance.

For an overview of ALM in Power Platform, go to Overview of application lifecycle
management with Microsoft Power Platform.

With ALM, you can migrate all your process mining entities, including dataflow
connections, custom metrics, Power BI reports, and more, from one environment to
another—or in the case of Power BI reports, from one workspace to another. You can
also rebind your Power BI reports with or without using a composite model. Another
feature involves using Power BI pipelines for moving entities across two different
workspaces.

To learn more about these ALM features, select from the following list:

Migrate Process Mining entities with Power Platform solutions
Migrate customized Process Mining Power BI reports
Migrate using Power BI pipelines and rebinding

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Migrate ALM process mining entities
with Power Platform solutions
Article • 04/04/2025

Application lifecycle management (ALM) in Process Mining allows you to migrate your
process mining entities with Power Platform solutions. To complete the migration, you
need to create and export your solution in your Dev environment. Then, you need to
change to your Test environment to import it.

The source and target of your process mining artifacts determine which environment
you need to use:

Dev environment: The environment from which you want to port artifacts.
Test environment: The environment to which you want to port artifacts.

Create and export your solution
７ Note

The created solution includes the process context state at the time of the last
analysis (data refresh). To include custom metrics, business rules, and other changes
done to the process context after the last analysis, you should re-analyze the
process using Refresh data on the process details page before creating the
solution.

Create and export your process solution in the Dev environment.

1. Sign in to Power Automate .

2. Select your Dev environment.

3. On the left navigation menu, select Process mining and create your process.

Get instructions in Create a process.

4. On the navigation menu, select Solutions.

If Solutions doesn't appear on the menu, select More > Solutions.

5. Create a new solution with the following steps:

a. On the menu bar at the top, select +New solution.



b. In the Display name field, enter the name to display.

c. In the Publisher dropdown menu, select a publisher.

If you want to edit the selected publisher, select the pencil icon next to the
dropdown menu.

d. In the Version field, enter a version (for example, 1.0.0.0).

6. At the bottom of the screen, select Create.

7. On the menu bar at the top, select Add existing > More > Other > PM Inferred
Task.

8. From the Add existing PM Inferred Task list, select the process you created and
want to migrate to the Test environment, and then select Add.

9. On the navigation menu, select the back arrow to go to the Solutions screen. You
should now see the solution you created.

10. Select your solution, and then select Export solution on the menu at the top.

11. On the Before you export screen, select Publish.

12. When all customizations are published, select Next.

13. Select Export.

Download and import your exported solution



Below the menu at the top, a green message bar appears to indicate your export was
successful. It also contains a button for you to download the exported folder.

1. From the green message bar, select Download.

2. Go to your Test environment.

3. On the left navigation menu, select Solutions.

4. Import the solution with the following steps.
a. On the menu bar at the top, select Import solution.
b. On the Import a solution screen, select Browse.
c. From your file explorer, select the solution you downloaded.
d. Select Next.
e. Select Import.

After the solution successfully imports, your process appears on the Process
Mining homepage with an orange exclamation mark inside a speech bubble.

5. To complete the import, select your solution and follow the Setup process.

Update entities in your Test environment
You can update entities in your Test environment by upgrading or updating your
solution. Learn more in Apply the upgrade or update in the target environment.

Learn more about solutions in Solution concepts.

Feedback
Was this page helpful?  Yes  No



Provide product feedback



Power BI reports in Process Mining
overview
Article • 08/12/2024

The rebind method you choose depends on whether the two processes you have are
using two different workspaces or the same workspace.

The articles in this section use fictitious names. These names are for demonstration
purposes and you should use names that suit your preferences. As you go through the
procedures, select your own environments and workspaces that correspond to these
references.

Dev environment: Environment from which you want to migrate process mining
artifacts.
Test environment: Environment to which you want to migrate process mining
artifacts.
WkSpace A: Custom Power BI workspace associated with the Dev environment
from which you want to migrate the Power BI report.
WkSpace B: Custom Power BI workspace associated with the Test environment to
which you want to migrate the Power BI report.
Report A: Name of the Power BI report for the process in Dev environment.
Report B: Name of the Power BI report for the process in Test environment.

７ Note

Typically, you perform ALM for the Power BI report after you have performed ALM
for the other resources of the process using solutions.

The procedures in the Migrate customized Process Mining Power BI reports section
assume you completed the following tasks:

1. You attached a Power BI workspace to your process in your Dev environment.

2. You performed ALM on other process mining artifacts using solutions.

3. You made the Power BI report customizations that you want to migrate. If you
didn't do this task, do the following steps:
a. Navigate to the report page of your process in Power Automate.
b. From the command bar, select Open in Power BI.
c. Make the changes you want to migrate and save and publish the report.



You can transfer the Power BI reports in three ways:

Rebind without a using a composite model
With two different workspaces
With the same workspace

Rebind using a composite model
With two different workspaces
With the same workspace

Use Power BI pipelines and rebind

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Rebind reports without using a
composite model (different workspaces)
Article • 08/12/2024

If you linked your process in Test environment to a workspace (for example, WkSpace B)
that's different from the one used by the process in Dev environment (for example,
WkSpace A), follow the steps in this article.

Attach a workspace to your process
1. In the Environments dropdown menu at the top of the screen, select your Test

environment.

2. On the navigation pane to the left, select Process mining.

If your process was newly copied over to the Test environment, there's an
exclamation mark inside a speech bubble on the process. This mark indicates that
the process was imported.

3. Select the process, and then select Confirm.

4. If you newly imported the process, continue to step 5. If you didn't newly import
the process, go to step 6.

5. Select a new workspace for this process by following these steps:

a. In the Power BI workspace dropdown menu, select a different workspace, which
you'll use in the Test environment.

b. In the Report Name field, enter the same report name as your previous report.

） Important



The report name must be identical to your previous report.

c. To continue setting up the process, select Continue.

6. (If you didn't newly import the process) Attach a custom Power BI workspace to
the process:

a. Go to the process details page for the process.

b. On the Details card, select Edit.

c. From the Power BI workspace (optional) dropdown menu, select your WkSpace
B Power BI workspace that you want to migrate customizations to.

d. Provide the same report name as the name you used for the process in Dev
environment.

） Important

The report name must be identical to the report name of the process in
Dev environment.

e. Select Save > Continue.

f. From the command bar or in the report view, select Refresh data.



Rebind the Power BI report
1. Sign in to Power BI .

2. From the left navigation pane, select Workspaces > your WkSpace A.

3. In your WkSpace A, select your Report A.

4. To download the report, from the command bar, select File > Download this file >
"A copy of your report with a live connection…" > Download.

5. Open the downloaded report in Power BI for desktop.

6. After you edit the report, select Transform data > Data source settings from the
command bar in the Home tab.

7. From the list of semantic models, select the semantic model of the process that's in
your WkSpace B workspace, and then select Connect.

This is called rebinding. The report refreshes. Learn more about semantic models in
Semantic models in the Power BI service.

8. From the command bar, save the report by selecting Save.

9. From the command bar, publish the report by selecting Publish.

10. From the Publish to Power BI menu, select your WkSpace B > Select.

A message that says Replacing report appears because you retained the report
name.



11. Select Replace to overwrite the old report in WkSpace B. This action overwrites the
existing report with an updated version that incorporates the new customizations.
It also preserves the original report name for consistency.

12. When this process completes, return to Power BI and open WkSpace B.

The report is now successfully migrated from WkSpace A and is connected to the
semantic model of the process you had in your WkSpace B.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Rebind reports without using a
composite model (same workspace)
Article • 08/12/2024

If you linked your process in your Test environment to a workspace (for example,
WkSpace A) that's the same as the one used for the process in your Dev environment
(for example, WkSpace A), follow the steps in this article.

Attach a workspace to your process
1. In the Environments dropdown menu at the top of the screen, select your Test

environment.

2. On the navigation pane to the left, select Process mining.

If your process was newly copied over to the Test environment, there's an
exclamation mark inside a speech bubble on the process. This mark indicates that
the process was imported.

3. Select the process, and then select Confirm.

4. If you newly imported the process, continue to step 5. If you didn't newly import
the process, go to step 6.

5. Select the same workspace for this process by following these steps:

a. In the Power BI workspace dropdown menu, select the same workspace as the
previous workspace.

b. In the Report Name field, enter a different report name from your previous
report name.

） Important



The report name must be different from your previous report name.

c. To continue setting up the process, select Continue.

6. (If you didn't newly import the process) Attach a custom Power BI workspace to
the process:

a. Go to the process details page for the process.

b. On the Details card, select Edit.

c. From the Power BI workspace (optional) dropdown menu, select your WkSpace
A Power BI workspace that you want to migrate customizations to.

d. Provide a different report name from the name you used for the process in Dev
environment.

） Important

The report name must be different from the report name of the process in
Dev environment.

e. Select Save > Continue.

f. From the command bar or in the report view, select Refresh data.



Rebind the Power BI report
1. Sign in to Power BI .

2. From the left navigation pane, select Workspaces > your WkSpace A.

3. In your WkSpace A, open your Report A.

4. From the command bar, download the report by selecting File >Download this file
> "A copy of your report with a live connection" > Download.

5. Open the downloaded report in Power BI for desktop.

6. From the File menu, select Save as.

7. Enter the same name for the report as your Report B, and then select Save.

） Important

Make sure you to do this step to ensure that this report overwrites Report B
when you publish.

8. From the command bar in the Home tab, select Transform data > Data source
settings.

9. From the list of semantic models, select the semantic model of the process that's in
the Test environment and whose report is in your WkSpace A, and then select
Connect.



Since you're using the same workspace for both your processes in Dev and Test,
the location of the semantic model you select is your WkSpace A. This is called
rebinding.

The report refreshes. Learn more about semantic models in Semantic models in the
Power BI service.

10. From the command bar, save the report by selecting Save.

11. From the command bar, publish the report by selecting Publish.

12. From the list of destinations, select your WkSpace A > Select.

A message that says Replacing report opens, indicating you gave the report the
same name as your old Report B.

13. To overwrite the old report in WkSpace A, select Replace.

14. When this process completes, return to Power BI and open WkSpace A.

The customizations from Report A are now successfully transferred to Report B in
the same WkSpace A.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Rebind reports using a composite
model (different workspaces)
Article • 08/12/2024

To migrate customizations of your Process Mining report from one workspace to
another, follow the steps in this article. Learn more about composite models in Use
composite models in Power BI Desktop and Customize reports in Power BI workspace.

If you linked your process in the Test environment to a workspace (for example,
WkSpace B) that's different from the one used by the process in the Dev environment
(for example, WkSpace A), follow the steps in this section.

Attach a workspace to your process
1. In the Environments dropdown menu at the top of the screen, select your Test

environment.

2. On the navigation pane to the left, select Process mining.

If your process was newly copied over to the Test environment, there's an
exclamation mark inside a speech bubble on the process. This mark indicates that
the process was imported.

3. Select the process, and then select Confirm.

4. If you newly imported the process, continue to step 5. If you didn't newly import
the process, go to step 6.

5. Select a new workspace for this process by following these steps:

a. In the Power BI workspace dropdown menu, select a different workspace, which
you'll use in the Test environment.

b. In the Report Name field, enter the same report name as your previous report.



） Important

The report name must be identical to your previous report.

c. To continue setting up the process, select Continue.

6. (If you didn't newly import the process) Attach a custom Power BI workspace to
the process:

a. Go to the process details page for the process.

b. On the Details card, select Edit.

c. From the Power BI workspace (optional) dropdown menu, select your WkSpace
B Power BI workspace that you want to migrate customizations to.

d. Provide the same report name as the name you used for the process in Dev
environment.

） Important

The report name must be identical to the report name of the process in
Dev environment.

e. Select Save > Continue.



f. From the command bar or in the report view, select Refresh data.

7. Sign in to Power BI .

Before you get started, ensure that the states of your reports, workspaces, and their
lineages correspond to what's in the following sections.

State of your Report A
The following report and its composite model are in WkSpace A. Your report can look
like this, or have customizations of your choice.

State of your WkSpace A
Your WkSpace A should have the following entities:

ﾉ Expand table

Number Description Entity

1 The original report of your process. Report A

2 The original semantic model of your process. Report_A_Dataset_206…

3 The updated report with the composite model. Report A

4 The composite model. Report A



The numbering corresponds with the numbering of entities in the following screenshot.

There are three (3) entities titled Report A. You can differentiate them using their icons
and their Refreshed timestamps:

The icon with the yellow bars represents the reports. The other icon is that of the
composite model or semantic model.

The report with the same Refreshed timestamp as the composite model is the
report of the composite model.

Your lineage view should look like the following screenshot. The semantic model points
to the composite model, which then points to a report.

State of your WkSpace B
Your WkSpace B should have the following entities:

ﾉ Expand table



Number Description Entity

1 The original report of the process you transferred from the Report A
Dev environment.

2 The original semantic model of the process you transferred Report_A_Dataset_206…
from the Dev environment.

The numbering corresponds with the numbering of entities in the following screenshot.

Your lineage views should like the following screenshot. A semantic model points to a
report:

To understand the distinctions between each entity, familiarize yourself with the entities
before you proceed.

Rebind the report in Power BI
1. Sign in to Power BI .

2. Navigate to your WkSpace A.

3. From the list of entities, select the three dots beside the composite model, and
then select Download this file.



4. In Power BI desktop , open the downloaded file.

5. From the home tab, select Transform data > Data source settings. Notice the
Direct Query connection in the Data source settings.

6. Select Change Source.

7. Search for and select for the semantic model of the process that was created in
Test. Its semantic model is in your WkSpace B.

8. Select Create.

9. When the Connect to your data message appears, select relevant tables, and then
select Submit.

10. When the query changes are applied, select Close.

11. Save the report.

12. From the Home tab, select Publish.



13. Select your WkSpace B as the destination, and then choose Select.

14. When the publishing completes, go to your WkSpace B in Power BI to confirm the
changes were applied.

The lineage view now shows the composite model. In the following screenshot, it's
the first red box.

15. Select the Report A that the composite model points to. In the previous
screenshot, it's the second red box.

16. Select Open report.

The report looks like that of the composite model from WkSpace A with the Self
Loop percentage in the report.

Feedback
Was this page helpful?  Yes  No



Provide product feedback



Rebind reports using a composite
model (same workspace)
Article • 08/12/2024

If you linked your process in your Test environment to a workspace (for example,
WkSpace B) that's the same as the one used for the process in your Dev environment
(for example, WkSpace A), follow the steps in this article.

Attach a workspace to your process
1. In the Environments dropdown menu at the top of the screen, select your Test

environment.

2. On the navigation pane to the left, select Process mining.

If your process was newly copied over to the Test environment, there's an
exclamation mark inside a speech bubble on the process. This mark indicates that
the process was imported.

3. Select the process, and then select Confirm.

4. If you newly imported the process, continue to step 5. If you didn't newly import
the process, go to step 6.

5. Select the same workspace for this process by following these steps:

a. In the Power BI workspace dropdown menu, select the same workspace as the
previous workspace.

b. In the Report Name field, enter a different report name from your previous
report name.

） Important



The report name must be different from your previous report name.

c. To continue setting up the process, select Continue.

6. (If you didn't newly import the process) Attach a custom Power BI workspace to
the process:

a. Go to the process details page for the process.

b. On the Details card, select Edit.

c. From the Power BI workspace (optional) dropdown menu, select your WkSpace
A Power BI workspace.

d. Provide a different report name from the name you used for the process in Dev
environment.

） Important

The report name must be different from the report name of the process in
Dev environment.

e. Select Save > Continue.

f. From the command bar or in the report view, select Refresh data.



7. Sign in to Power BI .

Before you get started, ensure that the states of your reports, workspaces, and their
lineages correspond to what's in the following sections.

State of your WkSpace A
Your WkSpace A should have the following entities:

ﾉ Expand table

Number Description Entity

1 The original report of your process. Report A

2 The original semantic model of your process. Report_A_Dataset_206…

3 The updated report with the composite model. Report A

4 The composite model. Report A

5 The original report of the copied process. Report B

6 The original semantic model of the copied process Report_B_Dataset_206…

The numbering corresponds with the numbering of entities in the following screenshot.

There are three (3) entities titled 'Report A'. You can differentiate them using their icons
and their Refreshed timestamps:

The icon with the yellow bars represents the reports and the other icon is that of
the composite model or semantic model.

The report with the same Refreshed timestamp as the composite model is the
report of the composite model.



Your lineage view should look like the following screenshot:

Rebind the report in Power BI
1. Sign in to Power BI .

2. Navigate to your WkSpace A.

3. From the list of entities, select the three dots beside the composite model, and
then select Download this file.



4. In Power BI desktop , open the downloaded file.

5. From the File menu, select Save as and give the report a new name such as Report
B.

6. From the home tab, select Transform data > Data source settings. Notice the
Direct Query connection in the Data source settings.

7. Select Change Source.

8. Search for and select the semantic model of the process that's in your Test
environment. The semantic model is Report B_Dataset_206… and it should be in
your WkSpace A.

9. Select Create.

10. When the Connect to your data message appears, select relevant tables, and then
select Submit.

11. When the query changes are applied, select Close.



12. Save the report.

13. From the Home tab, select Publish.

14. Select your WkSpace A as the destination, and then choose Select.

15. When the publishing completes, go to your WkSpace A in Power BI to confirm the
changes are applied.

The lineage view now shows the composite model.

16. Select the Report B that the composite model points to. It's the second red box in
the previous image.

17. Select Open report.

The report looks like that of the composite model from WkSpace A with the Self
Loop percentage in the report.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Migrate using Power BI pipelines and
rebinding
Article • 08/12/2024

This solution involves using Power BI pipelines for moving entities across two different
workspaces.

Attach a workspace to your process
1. In the Environments dropdown menu at the top of the screen, select your Test

environment.

2. On the navigation pane to the left, select Process mining.

If your process was newly copied over to the Test environment, there's an
exclamation mark inside a speech bubble on the process. This mark indicates that
the process was imported.

3. Select the process, and then select Confirm.

4. If your process was newly copied to the Test environment, select the process and
go to step 5. If the process wasn't newly imported, go to step 6.

5. Select a new workspace for this process:

a. Select a different workspace that you will be using for the Test environment.

b. For Report Name, enter a different report name than that of your previous
report.

） Important



The report name must be different from the report name of the process in
Dev environment.

c. Select Continue and continue setting up your process.

6. (If your process wasn't newly imported) Attach a custom Power BI workspace to
the process:
a. Go to the process details page for the process.
b. On the Details card, select Edit.
c. From the Power BI workspace (optional) dropdown menu, select your WkSpace

B Power BI workspace that you want to port changes to.
d. Provide the different report name than that which you used before.
e. Select Save > Continue.
f. From the command bar or in the report view, select Refresh data.

Deploy Power BI reports using pipelines
1. Sign in to Power BI .

2. From the left navigation pane, select Deployment pipelines.



3. Create a new Power BI pipeline by following these steps:

a. Select New pipeline.

b. In the Pipeline name and Description (optional) fields, enter a name and
description.

c. Select Next.

d. Customize your stages.

For this example, we use Dev and Test. If you see others, select the trash can
icon next to it.

a. Select Create.

4. Assign workspaces for the pipeline.

a. For the Dev stage: From the dropdown menu, select your WkSpace A > Assign
a workspace.

b. For the Test stage: From the dropdown menu, select your WkSpace B > Assign
a workspace.

In the following screenshot, your environments might use a different name.



The visual that compares the contents of each workspace now shows.

5. From your ALM A workspace, select Deploy > Deploy.

When deployment is complete, go to your WkSpace B, which contains items
copied over from your WkSpace A.



Rebind your semantic model
The final step is to rebind the semantic model in the ALM B workspace to the report
from the ALM A workspace.

1. Go to your WkSpace B, and then select Report A.

It's normal to see issues with loading the report.

2. To download the report, from the command bar, select File > Download this file >
A copy of your report with a live connection… > Download.

3. After downloading, open the file in Power BI desktop.

4. From the command bar, select Transform data > Data source settings.

5. From the list of semantic models, select the Report B_Dataset_206… semantic
model.

6. Select Connect.



The procedure is a success if the report has report customizations from the Report
A but uses the semantic model from the original Report B.

7. When you finish, select Save > Publish from the command bar and publish to your
WkSpace B.

8. When complete, go to Power BI web and go to your WkSpace B workspace. The
new report is now in the workspace. You can also rename it.

9. You can clean up the workspace by deleting the semantic models and reports that
you don't need.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Improve cloud flows with process
insights (preview)
Article • 01/13/2024

[This topic is prerelease documentation and is subject to change.]

The process mining capability can help you gain valuable insights and optimize your
cloud flows. You can visualize your flow's performance, identify bottlenecks and
opportunities for improvement, and monitor for performance drifts. By utilizing the
process mining capability to analyze your flow's run history with process mining
techniques, you can generate these insights directly from the flow details page.

） Important

This is a preview feature.

） Important
This is a preview feature.
Preview features aren’t meant for production use and may have
restricted functionality. These features are available before an official
release so that customers can get early access and provide feedback.

Prerequisites
To generate process insights, you must meet the following prerequisites:

Flow runs must have been generated within the last 28 days.
Only the owner of a flow has the ability to generate process insights.
You must have access to Microsoft Dataverse (i.e., a low-code data platform that
allows you to store and manage data for your applications)
You must have the environment maker role.

Known limitations
Please note the following known limitations of this feature:



After a flow runs, it may take approximately 15 to 30 minutes for data to be added
for analysis. However, historical runs up to 28 days are immediately available for
analysis.
This feature is not currently supported for Dataverse for Microsoft Teams
environments.
Cloud flow analytics for your older flows might not appear immediately in the
Process Mining desktop application. To have the analytics appear, select Improve
your flow on the details page of your flow.

Terminology
To better understand the process insights feature, it's helpful to be familiar with the
following terminology:

Flow runs are referred to as 'cases' in the report, while actions are represented as
'activities'.
A path is a specific sequence of activities, representing a 'trace' through the
process from start to end. Each path differs from the others by at least one activity.
Custom metrics and filters enable you to generate personalized insights based on
criteria such as flow version or successful versus failed flow runs.

Improve your flow with process insights
On your flow details page, you can see the Process insights card. To see your flow
process visualization and analytics, select Improve your flow.

1. Go to your flow details page.

2. Generate flow runs if the flow hasn't run in the last 28 days.

3. On the Process mining (preview) tile, select Improve your flows.

4. Wait for analysis to complete.



When analysis completes, the flow process analytics screen displays.

5. To get the most common run path in your automation, select the most frequent
variant.

6. Customize your insights based on custom filters for your flow like flow version,
action status, action status code, or action error.

7. Select time analysis report to drill down into bottlenecks based on cases, variants,
and time.

７ Note

To re-analyze the process based on your latest flow runs, go to the analytics page
and select Refresh. This updates your data and re-analyzes the process. You can
continue viewing the analytics while the analysis is processing.



Share process mining processes
Article • 03/11/2024

When you create a process in the process mining capability, only you can see it. But you
might want to share the analytics and insights with others. Share your process mining
processes with others in your organization so they can also glean insights to make
decisions.

There are a few ways you can share your process.

Share from process lists page
1. On the process mining homepage, beneath the cards for the processes, select All

processes.

2. Highlight a process, select the vertical ellipsis (⋮), and then select Share.

Share from process details page
On the process details page, you can share the process by selecting Manage from the
Shared with card.

Share from analytics report page
On the analytics report page, you can share the process by selecting Share in the
command bar.

Share panel
When you select the share action, a share panel displays. The share panel is where you
select users in your Microsoft Entra (which may include external users) and share your



process with them. You can search for any user to invite to your process in the
Dataverse tenant.

When you share a process with others, the option to send an email invitation is
automatically selected for convenience. Viewers are invited to view the process's
analytics. There's a link in the email invitation that leads them to the shared process's
analytics.

Share action
The share action is available on the Processes screen for the following:

Each process where you're an owner.

The system administrator in the environment.

Any security role that has share permissions on the process mining system entities.

The share action is also available on the process details page with the same conditions.
For process mining, only the co-owner and viewer roles are available for sharing with
others.

Share a process with a co-owner
Adding a co-owner to the process allows the owner to include other people who can
help manage the process. A co-owner can perform the following actions:



View and edit process details.

View the process analytics.

Share the process with other co-owners and viewers.

Share a process with a viewer
Adding a viewer to a process shares analytics and insights with other people. A viewer
can perform the following actions:

View the process details.

View the process analytics.

） Important

If a user is an admin in an environment, they already have access to all the
processes. Therefore, if that user is added as a Co-owner or a Viewer, they
won't show up in the list of co-owners or viewers even if they are successfully
assigned either of those roles.

Removing all process roles from a user (such as viewer) doesn't remove that
process from the user's process list view. They can't perform any actions on
the process.

Process mining currently does not support sharing for AAD groups.

Co-owners don't have access to the power query editor and can't modify a
dataflow.



Bring your own Azure Data Lake Storage
Gen2
Article • 01/18/2025

Power Automate Process Mining gives you the option to store and read event log data
directly from Azure Data Lake Storage Gen2. This feature simplifies extract, transform,
load (ETL) management by connecting directly to your storage account.

This feature currently supports the ingestion of the following:

CSV
Single CSV file.
Folder with multiple CSV files that have the same structure. All files are ingested.

Parquet
Single parquet file.
Folder with multiple parquet files that have the same structure. All files are
ingested.

Delta-parquet
Folder that contains a delta-parquet structure.

Prerequisites
The Data Lake Storage account must be Gen2. You can check this out from the
Azure portal. Azure Data Lake Gen1 storage accounts aren't supported.

The Data Lake Storage account must have hierarchical namespace enabled.

The Owner role must be attributed to the user performing the initial container
setup for the environment for the following users in the same environment. These
users are connecting to the same container and must have these assignments:

Storage Blob Data Reader or Storage Blob Data Contributor role assigned
Azure Resource Manager Reader role assigned, at minimum.

Resource Sharing (CORS) rule to your storage account should be established to
share with Power Automate Process Mining.

Allowed origins must be set to https://make.powerautomate.com  and
https://make.powerapps.com .

Allowed methods must include: get , options , put , post .



Allowed headers should be as flexible as possible. We recommend defining
them as * .

Exposed headers should be as flexible as possible. We recommend defining
them as * .

The maximum age should be as flexible as possible. We recommend using
86400 .

CSV data in your Data Lake Storage should meet the following CSV file format
requirements:

Compression type: None
Column delimiter: Comma (,)
Row delimiter: Default and encoding. For example, Default (\r,\n, or \r\n)

All data must be in final event log format and meet the requirements listed in Data
requirements. Data should be ready to be mapped to the process mining schema.



No data transformation is available post ingestion.

The size (width) of the header row is currently limited to 1 MB.

） Important

Ensure that time stamp represented in your CSV file follows the ISO 8601 standard
format (for example, YYYY-MM-DD HH:MM:SS.sss  or YYYY-MM-DDTHH:MM:SS.sss ).

Connect to Azure Data Lake Storage
1. On the navigation pane to the left, select Process mining > Start here.

2. In the Process name field, enter a name for your process.

3. Under the Data source heading, select Import data > Azure Data Lake >
Continue.

4. On the Connection setup screen, select your Subscription ID, Resource Group,
Storage account, and Container from the dropdown menus.

5. Select the file or folder containing the event log data.

You can either select a single file or a folder with multiple files. All files must have
the same headers and format.



6. Select Next.

7. On the Map your data screen, map your data to the required schema.

8. Complete the connection by selecting Save and Analyze.

Define incremental data refresh settings
You can refresh a process ingested from Azure Data Lake on a schedule, either through
a full or incremental refresh. Though there are no retention policies, you can ingest data
incrementally using one of the following methods:

If you selected a single file in the previous section, append more data to the selected
file.

If you selected a folder in the previous section, add incremental files to the selected
folder.

） Important

When you add incremental files to a selected folder or subfolder, make sure you
indicate the increment order by naming files with dates such as YYYMMDD.csv or
YYYYMMDDHHMMSS.csv.

To refresh a process:

1. Go to the Details page of the process.

2. Select Refresh Settings.

3. On the Schedule refresh screen, complete the following steps:
a. Turn on the Keep data up to date toggle switch.
b. In the Refresh data every dropdown lists, select the frequency of the refresh.



c. In the Start at fields, select the date and time of the refresh.
d. Turn on the Incremental refresh toggle switch.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Bring your own network isolated Azure
Data Lake Storage Gen2
Article • 04/22/2024

Onboarding your Azure Data Lake can be found in Use your own Azure Data Lake
Storage Gen2, but relates to storage accounts that are open to the public internet. To
use Process Mining against network isolated Azure Data Lakes, follow the steps in this
article.

Prerequisites
Perform and verify your Azure Storage account is network isolated.

In the Azure portal , go to the Networking tab for the storage account and proceed to
set the following values.

These fields are expected to be permanently set:

Enabled from selected virtual networks and IP addresses
Allow Azure services on the trusted services list to access this storage account

This field can be temporarily set:

Add your client IP address

The following screenshot shows the permanent and temporary fields.



Create a managed identity
You need to run a PowerShell script to create a managed identity. This script needs to be
run per environment.

The minimum required role to complete all steps is Azure Subscription Owner for the
subscription that contains the storage account. The user must be an administrator on
the environment that the policy will be connected.

The following steps are needed from a completely new state:

1. Install Azure CLI on your machine: https://aka.ms/InstallAzureCliWindows
2. Get the compressed folder in https://github.com/microsoft/PowerApps-

Samples/blob/master/powershell/managed-identities/Common.zip  and
download.



3. Extract the compressed folder and make sure you can run PowerShell scripts from
that location.

4. From the root of the folder, go through the ollowing set of steps. Some
modification is necessary to the scripts.

5. Take the following PowerShell script and use it to create a new .ps1  file in the root
of the Common  directory. Choose any name for it.

PowerShell

# PowerShell script
# To have ready beforehand $subscriptionId, $resourceGroupName, 
$enterprisePolicyLocation, $environmentId
# Note: The $enterprisePolicyLocation must be set to the same location as 
the environment. And the environments with spaces should have the spaces 
removed i.e. “South Africa” -> “southafrica”
# Note: You can choose the value for $NewEnterprisePolicyName i.e. 
CreateMSITokenForExternalLake  
Install-Module -Name Microsoft.PowerApps.Administration.PowerShell
Install-Module -Name Microsoft.PowerApps.PowerShell -AllowClobber
Az login
Update-AzConfig -DefaultSubscriptionForLogin $subscriptionId
./SetupSubscriptionForPowerPlatform.ps1
$subscriptionId
cd Identity
./CreateIdentityEnterprisePolicy.ps1
$subscriptionId
$resourceGroupName
$NewEnterprisePolicyName
$enterprisePolicyLocation
./NewIdentity.ps1 -environmentId $environmentId -policyArmId 
/subscriptions/$subscriptionId/resourceGroups/$resourceGroupName/providers/M
icrosoft.PowerPlatform/enterprisePolicies/$NewEnterprisePolicyName -endpoint 
prod

6. To find the respective $enterprisePolicyLocation for the previous script, go to:
a. The $enterprisePolicyLocation must be set to the same location as the

environment. And the environments with spaces should have the spaces
removed.

b. For example, set South Africa as southafrica.

7. Run the newly created .ps1  file using Windows PowerShell.

8. Walk through the series of steps until the script outputs a successful 202 response.

７ Note



Only one managed identity can be associated to a Dataverse environment at a
time. If another is connected to the same environment, then the previous
association is lost.

Add the managed identity
Once the managed identity is successfully created, add it through Access Control (IAM).

1. In the Azure portal, go to the Storage account.
2. On the navigation pane to the left, select Access Control (IAM).
3. In the Add dropdown list, select Add role assignment.
4. Under Role, search for and select Storage Blob Data Contributor.
5. Under members, select Managed identity and then select Select members.
6. In the Subscription dropdown list, locate your subscription name.
7. In the Managed identity dropdown list, find and select

Microsoft.powerplatform/enterprisepolicies.
8. In the Select dropdown list, locate the identity you created. It uses the name you

used in the NewEnterprisePolicyName in the PowerShell script.
9. Select Select and then Review + assign.

Troubleshooting
If you get the error message, Couldn't connect to container in the Connection Setup
screen, you need to have the owner of the storage account and the person who initially
established the connection share the datalakefolder record with you in the respective
org in Dataverse.

To fix this error, go to [your_org_url]/main.aspx?
app=d365default&forceUCI=1&pagetype=entitylist&etn=datalakefolder and replace
[your_org_url] with the real value.



1. Find [your_org_url] by doing the following steps:

a. In the Power Automate environments, go to the Process Mining homepage.

b. Select Ctrl + Alt + A.

c. In Instance url, find [your_org_url].

d. Go to [your_org_url]/main.aspx?
app=d365default&forceUCI=1&pagetype=entitylist&etn=datalakefolder and
replace [your_org_url] with the real value.

Example:
https://org0a00aab.crm10.dynamics.com/main.aspx?

app=d365default&forceUCI=1&pagetype=entitylist&etn=datalakefolder

2. On the loaded page, do the following steps:
a. From the table, select the appropriate data lake folder record.
b. At the top of the screen, select Share.
c. To search for the user to add, select Add User/Team.
d. Select Share.



Ingest files from Fabric OneLake
(preview)
Article • 01/18/2025

[This article is prerelease documentation and is subject to change.]

Power Automate Process Mining gives you the option to store and read event log data
files directly from Fabric OneLake via Fabric Lakehouse. This feature simplifies extract,
transform, load (ETL) management by connecting directly to your OneLake.

This feature currently supports the ingestion of the following:

CSV
Single CSV file.
Folder with multiple CSV files that have the same structure. All files are ingested.

Parquet
Single parquet file.
Folder with multiple parquet files that have the same structure. All files are
ingested.

Delta-parquet
Folder that contains a delta-parquet structure.

） Important

This is a preview feature.
Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.

Prerequisites
A Fabric workspace that's different from the default My workspace.

The Admin role must be attributed to the user performing the initial workspace
setup for the environment for the other users in the same environment.

The Fabric workspace needs to be shared to the Process Insight Prod service
principal with an Admin role. To register the Process Insights Prod service
principal, follow the steps in Install Azure tools.



A Fabric Lakehouse must be created in this workspace with the data in supported
formats located in the Files folder of the Lakehouse.

） Important

The following items aren't currently supported:

Fabric Lakehouses with Schema support enabled.
Delta tables in Lakehouse.

Connect to Fabric OneLake
1. On the navigation pane to the left, select Process mining > Start here.

2. In the Process name field, enter a name for your process.

3. Under the Data source heading, select Import data > OneLake (preview) >
Continue.



4. Select an optional Power BI workspace or select Skip.

5. On the Connection setup screen, select your Fabric Workspace from the
dropdown menu. This populates the Lakehouse dropdown menu. From the menu,
select the lakehouse that contains your data files and select Next.

6. Browse the Lakehouse folder structure and select the file or folder containing the
event log data.

You can either select a single file or a folder with multiple files. All files must have
the same headers and format.

7. Select Next.

8. On the Map your data screen, map your data to the required schema.

9. Complete the connection by selecting Save and Analyze.



Define incremental data refresh settings
You can refresh a process ingested from Fabric OneLake on a schedule, either through a
full or incremental refresh. Though there are no retention policies, you can ingest data
incrementally using one of the following methods:

If you selected a single file in the previous section, append more data to the selected
file.

If you selected a folder in the previous section, add incremental files to the selected
folder.

） Important

When you add incremental files to a selected folder or subfolder, make sure you
indicate the increment order by naming files with dates such as YYYMMDD.csv or
YYYYMMDDHHMMSS.csv.

To refresh a process:

1. Go to the Details page of the process.

2. Select Refresh Settings.

3. On the Schedule refresh screen, complete the following steps:
a. Turn on the Keep data up to date toggle switch.
b. In the Refresh data every dropdown lists, select the frequency of the refresh.
c. In the Start at fields, select the date and time of the refresh.
d. Turn on the Incremental refresh toggle switch.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Edit and refresh processes
Article • 07/18/2023

Process mining is a technique used to extract insights from event logs of a process.
During the process, it is common to make edits to the mapping or query of an existing
process. The following are some of the reasons why you might want to edit your
process:

Your data might have multiple ID columns that can be used as case ID, and
changing what you use as a case ID might help you discover more insights.

Some attributes may be mapped to something more specific, which can provide
additional options during analysis, like financial or resource attribute types.

If you have transformed your data in Power Query, you may want to adjust the
transformation if the resulting process is not what you need.

Edit mapping and query
To edit your mapping or query, follow these steps:

1. In the process details page, select Setup to return to the mapping page.

2. To change the case ID or other mappings, select the values in the dropdown menu
that correspond to the column name from the original data.

3. For more advanced edits, select Transform data in Power Query on the top right.

4. In the Power Query editor, you can edit the applied steps, like choose columns, by
selecting (or double-clicking) the corresponding step in the Applied steps area
under Query settings. If you want to add a new step, select it in the toolbar. 

Otherwise, select the step you want to add in the toolbar.

２ Warning

Avoid selecting options like Choose columns again in the toolbar if they are
already listed in the applied steps, as it will be added as a new step to the end
of applied steps. This means that if you already applied the Choose columns
step, the new Choose columns step will give you fewer options to choose
from, since the original Choose columns step already filtered down the list of
available columns.



Refresh data
If you have a transactional data source, like Dataverse or SQL, select Refresh data to
update your process with the latest data from your data source. The refresh process may
take some time, and you will be prompted to confirm the refresh by selecting Refresh
again.

Schedule refresh
To keep your data updated, you can use the schedule refresh feature. Select Schedule
refresh on the right side of the Data Source card to display the schedule refresh panel.
By default, the Keep data up to date toggle is on, and you can save the default
configuration, which is to schedule a refresh every day starting tomorrow at the time
you configure by clicking Save directly. You can change the default settings by
interacting with the controls on the schedule refresh panel to change the interval, the
period (day, week, month), the start date and time. Note that the highest refresh
frequency is currently every 1 day.

Once schedule refresh is configured, you will see the details in the Data Source card,
including the next scheduled refresh date and time.

Disconnect data
If you want to change the data source for your process, you can easily do this. For
example, you might have been using a CSV file before, but now you want to connect to
a transactional data source instead. To disconnect your current data source, select
Disconnect data on the right side of the Data Source card. Once you have disconnected,
select Setup again to connect to your new data source.



Set up millisecond support when
ingesting data with dataflows
Article • 02/25/2025

To get started with setting up millisecond support when ingesting data with dataflows,
go to the Power Automate Process mining home page to create a new process. Learn
more in Get started with the process mining capability.

Step 1: Transform your data
To transform your data for the Power Query component, follow these steps.

1. In the Create new process section of the Power Automate Process mining home
page, select Start here.

2. In the Create a new process screen, enter a process name.

3. Enter a description for the process.

4. In Data Source, select Import data.

5. Select Dataflow.

6. Select Continue.

7. Upload the source file that contains the process event log.

8. Continue until you reach the Transform your data (optional) step to display the
Power Query component.

Step 2: Define the event's start timestamp
To define the custom column for the event's start timestamp, follow these steps.



1. Select the Add column tab in the top bar.

2. Select the Custom column button to open the custom column window.

3. In the New column name field, enter StartTimestamp.millisecondsEpoch.

4. For Data type, select Whole number.

5. In Custom column formula field, enter
Duration.TotalSeconds(DateTimeZone.From([StartDate]) - #datetimezone(1970,
1, 1, 0, 0, 0, 0, 0)) * 1000.

6. In Available column(s), select the source column from your event log, such as
StartDate .

The custom column values must match the values in the following screenshot
exactly.

Step 3: Define the event's end timestamp
To customize the event's end timestamp, follow these steps.

1. Repeat the steps in Step 2: Define the event's start timestamp using the EndDate
column.

In the New column name field, use EndTimestamp.millisecondsEpoch  instead.



As a result of these mappings, there are two custom columns as part of event log.
Each of these columns displays huge numeric values, which represent the total
number of seconds since January 1, 1970 to the StartDate  or EndDate  value. For
dates after the year 2024, the value has approximately 13 digits.

The following screenshot displays the end result of mapping two new custom
columns as part of the event log.

2. To continue mapping your attributes, select Next.



Step 4: Map your data
To map your data, choose the correct mapping. Assign the custom columns' attribute
type as Event Start  and Event End , respectively.

７ Note

The attribute mapping screen intentionally hides these two custom columns in case
you map to the wrong data type. It must be a whole number.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Overview of Power Automate Process
Mining
Article • 04/01/2025

Take advantage of additional enterprise process mining capabilities with the Power
Automate Process Mining desktop app. For example, there are many ways to break
down your process cycles into smaller pieces for analysis. With the Power Automate
Process Mining desktop app, you can easily delve into the details of your processes.

To fully use the Process Mining desktop app, you need a Power Automate Premium
license to unlock the enterprise process mining capabilities. To learn how to install the
Process Mining desktop app, go to Download Power Automate Process Mining desktop
app.

Benefits of the Process Mining desktop app
The Process Mining desktop app helps businesses to:

Keep informed of the progress toward key process indicators (KPIs).
Understand where and why problems occur.
Identify inefficiencies.
Standardize and optimize operations.

Business example
Power Automate Process Mining analyzes data from processes that you create using the
process mining capability in Power Automate. For example, you can get deep insights
into how your processes run, uncover the root cause of problems, and build useful
outputs for the rest of your organization.

Use Copilot in Process Mining process analytics
(preview)
Copilot in Process Mining process analytics provides process insights through quick and
easy natural language expression. Copilot can surface insights on your process and
recommend solutions in power automate process mining. To learn more, go to Copilot
in Process Mining process analytics (preview).



Components
Following are the main components for the Process Mining desktop app:

Process map
Process animation
Statistics
Root cause analysis
Variants
Process compare
Export
Filtering
Settings
Advanced features

Custom metrics
Business rules

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Standard installation of Power
Automate Process Mining desktop app
Article • 12/04/2024

Before you can start using Power Automate Process Mining desktop app, you need to
download and install it to your desktop. You can do this using the standard installation
from the Power Automate Process Mining web page, or with a custom installation.

The standard installation process requires access to Microsoft Windows App Installer. To
find out if you access, contact your admin.

If you encounter difficulties due to company restrictions, contact your admin. Your
admin might ask you to install the app from the MSIX file instead. Learn more in Custom
installation of Power Automate Process Mining desktop app.

７ Note

Power Automate Process Mining desktop app is supported on Windows 10 and
above. Windows Server systems aren't supported.

Run the standard installation
To perform a custom installation, follow these steps:

1. Sign in to Power Automate .

2. On the panel to the left, select Process mining.

3. At the top of the process mining screen, select Download app.

4. After the installer file downloads, select Install when prompted to run the installer.

Allow a few minutes for the installer to download and install the application files.



5. When the welcome screen opens, select the preferred application language and
select Next step to start the guided configuration wizard.

6. In the next step, accept the terms of use and confirm the choice of telemetry data
collection, and then select Next step.

7. By default, the installation process stores process mining data in a new Process
Mining folder in the Documents folder in your OneDrive. Change the location if
necessary, and then select Next step.

If the selected folder was used before, Power Automate Process Mining lets you
choose whether you want to use the content of the folder (for example, data and
settings from a previous installation), or clean up the folder. Select Use or Cleanup
to specify your choice. To go back and change the storage location, select Cancel.

8. Select Apply and Mine! to finish the wizard.

9. Sign in to Power Automate Process Mining with your work account.

10. Start process mining from the Processes screen.

Related information
Explore the home page

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Custom installation of Power Automate
Process Mining desktop app
Article • 12/04/2024

Your admin might have disabled the option to install Power Automate Process Mining
desktop app on your workstation with Microsoft App Installer, which is used in the
standard installation. In this case, you can use the MSIX file to install the app. With this
installation, updates are managed customarily during the application startup process.

Installation scenarios
The following table lists the different scenarios to install the Power Automate Process
Mining desktop app for all scenarios.

ﾉ Expand table

App Internet Steps
Installer access
allowed

Yes Yes Download and install Power Automate Process Mining desktop app
using the portal link in the standard installation article. The
installation checks for automatic updates and makes sure auto-
updating works.

No Yes Use the custom installation in Run the custom installation in this
article.

Yes or No No You can’t download the package from the portal. You and your
admin have specific tasks:

You: Ask your admin to download the MSIX package and share it
with you. Then, install the package and set up the custom location
for updates.

Admin: Download the updates and put them into the custom
location that the user set up.

Run the custom installation
If App Installer isn't allowed and you have internet access, follow these steps:



1. Download the MSIX bundle  file. The app checks for updates automatically at
startup.

2. Select Open file.
3. Select Install.

If you have access to extranet locations, the app checks automatically for updates for
the standard installation with App Installer. If you have limited access to extranet, which
might prevent auto-updates, continue with the following instructions.

Upload the latest version of the app
If you don’t have access to extranet locations and can’t access install files for updates,
you can store update files on their own cloud. From this location, you can update the
app.

For this scenario, the admin needs to upload the latest version of the application MSIX
bundle  file to the internal location and rename the MSIX file as follows:

PowerAutomateProcessMining_{latestVersion}.msixbundle

Get the latest version number for the downloaded update
Download the text file that contains the product version number.

1. Download the msixVersion  text file.

2. Select Open file.

3. Copy the last version number from the file into
PowerAutomateProcessMining_{latestVersion}.msixbundle .

For example, if the last version number is 6.1.2401.1234, the MSIX file name is
PowerAutomateProcessMining_6.1.2401.1234.msixbundle .

Set up the custom location for updates
After you install the Process Mining desktop app with the MSIX package, the system
looks for a setting where the update is located. You need to identify this setting as the
internal location where the MSIX files for the update are stored.

1. In the Settings menu, select Options.
2. In the Options screen, select Update.



3. In the Local Url to installers field, enter the internal location where the MSIX files
for the update are stored.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Explore the home page
Article • 07/18/2023

The Processes screen is the Power Automate Process Mining desktop app home page.
It's where you'll find an overview of your processes and views. It's also where you can
dig deeper into your processes by creating different views, or ways of analyzing your
processes.

Launch the application
Although Power Automate Process Mining is a desktop app, it's connected to Power
Automate through your work account. The first screen you'll see is Processes. It lists the
processes you created in process mining, and displays the views associated with them as
tiles.

Open the Process Mining desktop app and sign in with your work account.

Select an environment
If the Process screen doesn't show the processes you expect, you might need to select a
different environment.

1. Select Environments in the title bar to open the list of environments you have
access to.

2. Select an environment, or search for and select an environment.

Organize your processes
You can organize your processes and views in a way that works best for you.



My processes > Process name: List processes by name, with their associated views
displayed as tiles below them. Select the caret to the left of the process name to
show or hide the views. This view is the default when you open the Process Mining
desktop app.

Shared with me > Process name:

Sort by: Select an option in this dropdown menu to sort views in ascending or
descending order by name, or by most recent or oldest.

Refresh: Refresh the list of processes from process mining in Power Automate. For
example, if you create a process in the process mining portal of Power Automate,
select Refresh to update the list in the Processes screen.

Search in processes and views: Search for a process or view by name.

Explore view tiles
A view represents an analysis of a single process model. It stores all your settings for
analyzing the process. To analyze a process from several viewpoints, create multiple
views. You can work with a view by yourself or with your colleagues.

The first time you open the Process Mining desktop app, if you haven't created any
views of your processes, you'll see a default view for each process. The Default tile is
blank until after the first time you select it. After you've opened a view, the tile displays a
miniature version of the process map, as in the following example:

A view tile contains the following information:

The name of the view.

The view's save state.

The date and time the view was last modified.



A lock icon if the view is private to you only, No lock indicates the view is public.

Manage views
To open a view, select its tile. If the view isn't updated to the process version, the app
displays a warning.

To delete, rename, or change the privacy of a view, in the Processes or Views view,
select (...) in a view tile to open a menu of actions.

Make private or Make public: Make a public view private or make a private view
public.

Rename: Change the name of a view.

Delete: Delete a view you no longer need.

Manage processes
In the My processes view, you'll see icons and a tile that allow you to manage your
processes.

Icons

Publish to Power BI: Publish changes to the view settings and filters back into
Power BI report. This will trigger re-analysis of the process.

Process context: Display, create, and change custom metrics, map hierarchies,
and other process settings.

Process info: Display information about the attributes of the process model
data and its refresh history.

Tile
Create new view: Open the process in its default state so that you can change
the view settings, apply filters and save them as a new view.



Manage settings with process context
Article • 07/26/2024

The Process context page is where you can create and manage process level settings
that you want to apply to the views you create for a process.

Open the Process context screen
There are two ways to open the Process context screen depending on where you are in
the Power Automate Process Mining desktop app.

From the Processes screen: Select Process context.

From any other screen in Power Automate Process Mining: On the menu bar in
the upper right corner, select Process context.

Launch process mining capabilities
On the Process context screen, you can launch the following capabilities. To learn about
each capability, select the link.

Custom metrics: Create and manage custom metrics.

Business rules: Create and manage business rules.

Map Hierarchies: Create and manage hierarchies.

Case categorization: Categorize cases as Running, Finished, or Stuck.

General settings: Select the default Activity label.

Related information
Explore the home page

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Categorize cases
Article • 07/26/2024

Case categorization allows you to identify which cases are finished, running, stuck, and
incompletely imported. You can then use these categories in custom metrics.

Case categories are split into two groups:

Exclusive (Finished, Running, and Stuck)

Case flags (Incompletely imported)

A case can be placed in only one of the three categories: either it's Finished, Running, or
Stuck. The Incompletely imported flag can be applied to any case, regardless of its
category. For example, a case can be both Running and Incompletely imported.

Create categorization rules
Set rules in simple or advanced mode. Any rule that you set in simple mode carries over
to advanced mode. Change modes by turning Advanced mode on or off.

Following is an example of the simple mode, which appears when Advanced mode is
turned off.

７ Note

Switching from advanced mode to simple mode resets the rules to the default.

1. Enter the Case categorization screen from any location with the Process context
selection.

From the Processes screen: Select Process context.

From any other screen in the Power Automate Process Mining desktop app:
On the menu bar in the upper right corner, select Process context.

2. Set rules for categorizing cases as directed in the following sections.



3. Select Save.

Categorize cases as Finished
Initially, all cases are categorized as Finished. Turn Advanced mode off to continue in
simple mode.

Select which activities are finishing activities. Cases that end in one of these activities are
considered Finished.

Use the simple mode
In simple mode, select an activity (or multiple activities) in the List tab. Alternatively,
search for an activity in the Search in attribute values field and then select it. You can
also select the Expression tab and use the comparison dropdown menu and value field
to define an activity in terms of an expression.

Use the advanced mode
When Advanced mode is turned on, you have more options:

Select a filter in the Add filter dropdown menu to specify attributes that define a
finishing activity or use any combination of filters.

Remove all filters.

Use the import and export filters by selecting (...).

Switch individual filters on or off.



Categorize cases as Stuck
Cases that aren't Finished are either Stuck or Running. To distinguish between them,
you can define when the case is considered Stuck. If a case isn't Finished and the time
between the last activity in the case and the date you select exceeds the time value, the
case is considered Stuck.

1. In simple mode, select Stuck.

2. Enter or select a date, or select the last event in the dataset.

3. Enter a time value.

When Advanced mode is turned on, you have more options:

1. Select a filter in the Add filter dropdown menu to specify attributes that define a
Stuck case.

2. Use the import filter by selecting (...).

Categorize cases as Running
Cases that aren't Finished or Stuck are considered Running.

The case is evaluated in sequence. If it satisfies the conditions for Finished,
categorization stops there. If it doesn't, the app checks the conditions for Stuck. If those
conditions are also false, it categorizes the case as Running.

Categorize cases flagged as Incompletely imported



Cases that don't start where they should are flagged as Incompletely imported. This can
happen when the export from the original data source split the case in half and only
included the latter part of the case activities.

To clear the Incompletely imported flag, select which activities are starting activities.

1. In simple mode, select an activity (or multiple activities) in the List tab.
Alternatively, search for an activity in the Search in attribute values field and then
select it. You can also select the Expression tab and use the comparison dropdown
menu and value field to define an activity in terms of an expression.

2. When Advanced mode is turned on, you have more options:

Select a filter in the Add filter dropdown menu. You can use any combination
of filters.

Remove all filters.

Use the import and export filters by selecting (...).

Switch individual filters on or off.

Use case categories
After you categorize the case, each category has its own function in custom metrics,
returning True or False for each case:

ISFINISHED()
ISSTUCK()
ISRUNNING()
ISINCOMPLETEIMPORT()

Related information
Explore the home page

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Process map overview
Article • 02/03/2025

A process map provides a view of the activities performed in a process and their
sessions. It represents the behavior of the process captured in data by means of
activities and directed edges.

The process map corresponds with the mining result of the process. It reflects filter
settings above the data, and the chosen frequency, or time metrics. When you apply
filters, mining is performed again, metrics are recalculated, and a new process map is
generated.

Process map nodes
Process map activities (also known as nodes) represent a unique activity, or unique
values of different selected mining attributes, performed, executed, or passed through in
the process.

Frequency metric, time metric, or finance metric can be displayed for nodes. The system
can display only one metric at a time.

The size and color of the highlight (also known as the halo effect) expresses the total
proportion of the frequency, time metric in question in relation to the other nodes in the
process map.

Process map edges
Chart edges represent transitions between individual events and describe the sequence
of activities in the process. A transition between events means that they directly follow
one after the other. The thickness of the edge and the number displayed next to it
depend on the selected display metric (frequency, time, finance) and its value.



Start and end node
All nodes/activities starting process instances are connected to the start node. All
nodes/activities ending process instances are connected to the end node. These nodes
don't represent process nodes/activities, but the input and output points of the process
under analysis. Their purpose is to facilitate the identification of the start and end
nodes/activities of the process. The display of these nodes and edges related to them
can be turned off in the Process Map Display Settings panel.

Start and end identifier
Chart nodes starting and ending process instances contain colored indicators in the
right part of the node. The green indicator represents the initial activity (upper right),
the red indicator represents the final activity (bottom right) of the process. A node
occurs as each start and end in process instances contains both indicators.

Manage process map views
When you open a project view for the first time, a process map with the default view
parameters displays. The structure of the process map and the information vary
depending on your view settings. The default process map typically contains the
backbone of the process. It displays the most frequent activities and the most dominant
edges. The basic view also includes the start and end nodes.

The following table describes ways that you can manage views.



ﾉ Expand table

Action Description

Switch views from On the command bar at the top left, select Processes, and then select
the Processes another process.
screen

Switch views from On the command bar at the center, select the dropdown menu, and then
the current screen choose an option.

Rename, save, On the command bar at the top, select the Save dropdown menu and
save as, and choose an option.
discard a process

View ongoing On the title bar, select Tasks (the bell icon). You'll see the status of tasks that
tasks are running in the background and the history of completed tasks. If a task

couldn't be completed, select Retry to restart it. If you want to edit its
parameters before restarting the task, select Edit.

Node details
If you select a node, detailed information about the activity displays.

ﾉ Expand table

Detail Description

Frequency The frequency information about a process activity.

Performance Information about the duration of an event/activity compared to the entire
process under analysis. For example, you can find out the total time or average
duration of the activity.

Rework Various metrics about activity repetitions within the cases. For example, you can
find out how many times the activity has been repeated or how many times the
activity was followed by a repeated activity.

Financial Finance information about a process activity. For example, you can find out the
analysis total costs/incomes about process activity, average values, costs/incomes about

the case, and more.

Custom Information about the custom metrics. To learn more, go to Custom metrics.
metrics

Business Information about the business rules. To learn more, go to Business rules.
rules



Detail Description

Top An overview of the most frequent attributes in the event. If there are more
attributes attributes available in the process, you can also add displayed information to the

other attributes.

Advanced To display the advanced panel for a node, select Advanced Panel button. This
panel panel displays a list of previous or subsequent activities with a selected attribute

and an optional number of attribute values. On this panel, you can display only
the attributes that were marked as case-level attributes during the process import.
To switch to the list of previous or next activities,
select Predecessor/Successor button on the top of the panel.

Edge details
If you select an edge, detailed information about the transition displays.

ﾉ Expand table

Detail Description

Frequency Frequency information about an edge/transition in the process.

Performance information about the duration of the transition compared to the entire process
under analysis. The duration of the transition represents the waiting time between
the end of the previous event and the beginning of the next event.

Rework Various metrics about the edge repetitions within cases. For example, you can find
out how often the edge/transition is repeated in comparison to the total edge
occurrences. You can also compare how many times the starting and ending
activities of the edge were repeated.

Financial Information about the costs/incomes of the whole case given the case-level
analysis finance attribute.

Custom Information about the custom metrics. To learn more, go to Custom metrics.
metrics

Top Overview of the most frequently occurring attributes within the event. If there are
attributes multiple attributes within a process, you can add displaying of the information to

other attributes. Only attributes that were marked as case-level attributes during
the process import can be added among the top attributes of this panel. The
number of displayed values of the selected attributes is optional.

Top Overview of the most frequently occurring attributes within the event. If there are
attributes multiple attributes within a process, you can add displaying of the information to

other attributes. Only attributes that were marked as case-level attributes during



Detail Description

the process import can be added among the top attributes of this panel. The
number of displayed values of the selected attributes is optional.

Advanced To display the advanced panel for an edge, select Advanced Panel. This panel
panel displays the starting and ending activities of the edge with the selected attribute

and an optional number of attribute values. On this panel, you can view any
attribute imported with the process.

Process map settings
To open the process map settings, select Customize on the right side of the screen.

The Customize panel allows you to choose between the process map or the social chart.
Switching between these views will cause mining in the process to start over.

Mining attribute selection
By default, the process map displays based on the Activity attribute, which is a standard
mining attribute. You can observe the process flow between the executed activities. If
you want to see how the process flows between values of a different event level
attribute (for example, Resource, but not in social chart layout, regions, departments, or
plants, a Mining Attribute Selection is available.

Mining attribute selections shows only relevant event log attributes and by selecting a
different attribute, the process map is recalculated including the available metrics used
in frequency, performance, finance, or rework analysis.

The selection of the mining attribute has an impact on the process map view and
included metrics, but it doesn't influence the other process view screens, which are still
calculated using the Activity attribute.

Variant analysis screen is available also for other mining attributes. A separate selection
must be used. To learn more, go to Variant mining attribute.

Activities
Use this slider to determine the number of activities to be shown on the process map. It
changes the complexity of the process map based on the importance of the activities



performed in the process.

Paths
Use this slider to determine the number of transitions shown on the process map. It
changes the amount of detail in the process view with regards to links between activities
found in the process.

You can filter displayed edges/transitions using the edge slider. It defines the range of
edge metric values which are shown to the user, hiding unimportant edges/transitions.
This control doesn't affect the data set but helps to focus on the most relevant aspects
of the process map transitions.

Map clustering
Map clustering allows you to visually encapsulate activities in the process map view into
clusters. You can also do this in the social chart view with a resource attribute selected.
Nodes are grouped and laid out close to each other and visually bordered by blue
dashed rectangles based on the value of the selected clustering attribute.

1. On the panel to the right, select Customize (the top icon).

2. Select either the Process map or Social chart tab.

3. In the Mining attribute dropdown menu, select an attribute.

4. In the Clustering attribute dropdown menu, select an attribute.

The map clustering attribute selection control is populated automatically by Power
Automate Process Mining. The attributes must fulfill the following premises:

Process map: Each value of the attribute Activity must have exactly one
corresponding value of the clustering attribute. It can also be an empty value. In
this case, the activity is placed on canvas outside of any cluster. For example,
approval must have always value Management in clustering attribute and PO
archival must always have value Accounting.

Social chart: Each value of the attribute Resource must have exactly one
corresponding value of the clustering attribute. It can also be an empty value. In
this case, the resource is placed on canvas outside of any cluster. For example,
John Doe must always have the value CostCenter1 in the clustering attribute and
Mary Jane must always have the value CostCenter34.



A specific activity or resource can be included only in one cluster, or outside of any
cluster.

The clusters are collapsible/expandable so that you can simplify the process map by
hiding the activities/resources in the cluster. To do this, select the blue icon with two
arrows in the top right corner of the cluster border. To expand the cluster, select the two
arrows icon on the cluster (which is highlighted in blue color).

It's also possible to collapse or expand all clusters at the same time using the Collapse
All/Expand All options in the clustering context menu.

Hierarchical process maps
Hierarchical process maps use clustering technique to enable you to visually encapsulate
activities in clusters. They group them into further clusters in the process map view or
resource in the social chart view. Nodes are grouped and laid out close to each other
and are visually bordered by blue dashed rectangles based on the value of the selected
clustering attributes.

Hierarchical process maps allow you to drill down into a hierarchy of clusters, analyze
aggregated data for individual hierarchy levels, and focus only on relevant process parts,
even in very complex unstructured processes. Functionality can be used with added
value in RPA initiatives to drill down into either UI recording combined with high level IS
event logs, and in bot monitoring scenarios to drill down into bot execution.
Organizational structure mining, hardware infrastructure, and software system structure
are other use cases.

To learn more, go to Hierarchical process mining.

Process map advanced settings
The following properties can be set in the advanced settings of the process map:

Display start and end nodes, and edges related to them.

Store the backbone activities on the same line on the process map.

Map orientation: Top to bottom or left to right.

Highlight the activities that go before and after the activity being presently
monitored.



Export a process map or social map
You can convert and export a process map or social map to:

A BPMN 2.0–compliant format that allows you to work with the map in any
standard BPMN modeling tool. You can choose a BPMN format with or without
gateways.

A PNG image.

An XML file containing a list of activities, resources, and edges for processing in
any third-party tools.

To export a process map or social map, select Export process map from the menu at the
top, and then make your selection.

Social chart
The social chart shows the important parts and parameters of your process through links
and dependencies between resources involved in the process.

Social chart advanced settings
You can set the following properties in the advanced settings of the social graph:

Display start and end nodes and edges related to them.

Highlight resources connected to the resource currently monitored.

Switch chart layout
Use the switch to switch chart layout according to different algorithms. The option to
switch chart layout is especially important for large and complex charts and to make
process analysis easier. The layouts are designed to display social graphs with a large
number of nodes and edges.

Resources
Use this slider to determine the number of resources to be shown in the social chart. It
changes the complexity of the chart based on the importance of the resources entering
the process.



Connections
Use this slider to determine the number of connections to be shown in the social graph.

Variant panel
The Variant panel contains a list of variants created during the process reconstruction.
Variants can be arranged according to the number of process instances they group or
by the number of events in case of variants. By selecting each variant in the list, the
sequence of one or more variants in the process or social map will be highlighted. The
selected variants can be filtered immediately on the filter screen by selecting the filter
icon.

When selecting one or more variants to the right of the indicator of the current volume
of process instances and events, a coverage indicator of the process instances by the
selected variants is displayed at the bottom of the screen. If the complexity of the
process map was reduced with the scrolling elements, not all process activities or edges
are shown, the number of not shown activities and edges of the selected variants
displays in the lower right corner.

View settings
To define various settings valid only for the current view, select View Settings on the
command bar at the top.

To learn more, go to View settings.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



View settings
Article • 07/26/2024

You can define various settings for the current process view on the View settings screen.

The screen consists of four tabs:

General settings

Duration settings

Activity label

Calendar settings

General settings
The General settings tab allows you to define the duration format to be used for the
current view. The global settings of the duration format used for all new processes and
views can be defined in Settings > Options > General.

To learn more, go to Settings.

Duration settings
The Duration settings tab allows you to select the maximum unit of time to be
displayed. For example, if you select Day, all the larger units of time (for example, weeks,
months, and years) will be converted into days while all the smaller units (hours,
minutes, seconds, and milliseconds) will display normally based on the time format
precision setting.

Since the length of months and years vary, they are converted to days using their
average length:

1 month = 30.436875 days
1 year = 365.2425 days

Use the Time format precision dropdown menu to define how many time units will
displayedFor example, when you select Year in the Max time unit dropdown menu, and



then select 2 in the Time format precision, only years and months will display. If you
select 3, years, months, and weeks will display.

７ Note

The values of the units that aren't displayed aren't converted into larger ones but
are completely omitted. For example, 15 days will display as 2 weeks and not 2.07
weeks.

The Show duration in working hourscheckbox automatically sets the max time unit to
"hour" and time format precision to "unlimited".

Activity label
The Activity label tab allows you to do the following:

Set the default activity label.

Select the display format (Activity, Label, or Custom)

(If the default label is Custom) Edit the display format.

Calendar settings
Select an existing calendar in the Calendar dropdown menu. If the menu options don't
include the calendar template that you want to use, select the ellipses (...) to define a
new template. If an existing calendar is close to what you want, select it in the Calendar
dropdown menu, and then select (...) > Edit.

Calendar templates can be shared across Power Automate Process Mining projects. To
manage all calendar templates, select Settings > Working hours. To learn more, go to
Settings.

Related information
Process map overview

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Hierarchical process mining
Article • 07/18/2023

The defined hierarchy, as it's bound to process attributes, is valid and usable for all
process views in the context of the process for which it has been defined.

To define the hierarchy in the process map view and social chart:

1. On the panel to the right, selevt Customize (the top icon).

2. On the toolbar in the Customize panel, select the Hierarchy tab.

3. Next to the Hierarchy field, select the ellipses (...), and then select Add hierarchy.

Use the Edit hierarchy and Delete hierarchy items to modify the defined hierarchies.

You can do the same in the Process context menu screen. It allows you to define the
name of the hierarchy, and automatically identifies all clustering attributes in the
process, specifying the number of unique attribute values - levels. To define the
hierarchy, select and move the desired attributes to the right part of the screen. Use
drag and drop to reorder the items in the final list. The list of hierarchies is validated for
correctness. The same rules that apply for the individual clustering attributes must be
applied for the levels in the hierarchy. The lower level of the hierarchy must act as a
clustering attribute for the higher hierarchy level.



You're informed if the validation rules aren't met and saving of the hierarchy isn't
allowed.

The available clustering attributes must fulfill the following premises:

Process map: Each value of the attribute Activity must have exactly one
corresponding value of the clustering attribute. It can also be an empty value (in
this case. the activity is placed on canvas outside of any cluster). For example,
Approval must have always value Management in the clustering attribute, and PO
archival must always have value Accounting.

Social chart: Each value of the attribute Resource must have exactly one
corresponding value of the clustering attribute. It can also be an empty value. In
this case, the resource is placed on canvas outside of any cluster. For example,
John Doe must always have the value CostCenter1 in the clustering attribute and
Mary Jane must always have the value CostCenter34.

A specific activity or resource can be included only in one cluster, or outside of any
cluster. The same applies between clusters in lower and clusters in higher hierarchy level.

The clusters are collapsible and expandable so that you can simplify the process map by
hiding the activities or resources in the cluster. To do this, select the blue << in the top
right corner of the cluster border. To expand the cluster, select >> on the cluster, which
is highlighted in blue.



It's also possible to collapse and expand all clusters at the same time using the Collapse
All/Expand All options in the clustering context menu.

The process may contain multiple levels of hierarchy. To quickly navigate through
individual levels, use the hierarchy display options available in the bottom right corner
of the Process map and Process animation. Using the selection list, you can select an
exact level or expand all clusters. Using the buttons next to this list, you can successively
increase and decrease the displayed level.

See also
Process map overview



Rework metrics
Article • 07/08/2023

Rework metrics represent a layer of data analysis with a focus on identifying various
kinds of repetitions found in a process. Rework information is covered in the Statistics
screen and can be visualized on the process map for better understanding the root
cause of each repetition and its overall impact. Reducing repetitions is crucial for
improving the efficiency of the process as well as reducing costs.

The following sections list the types of rework metrics.

Self-loop
Self-loop represents a specific repetition where an activity is directly followed by the
same activity. In terms of edges and transitions, the starting and ending activity of edge
is the same.

Example of self-loop
The activity called BP Transfer repeats itself nine (9) times. There are zero values over all
the other activities and edges because no other activities are involved in this type of
repetition.

Loop
Loop represents specific repetition where an activity is followed by the same activity, but
not directly. For example, at least one additional activity is always involved.

Example of loop
Activities SetDeliveryDate and Approve are repeated seven (7) times. The edge between
these two activities is also repeated seven (7) times. Keep in mind that in a process map,
an activity might be repeated, but each time a different edge or transition can be used.
The loop count value for a non-repeated edge is zero, regardless of the loop count for
the starting or ending activity of the edge.

Rework
Rework count represents the sum of all self-loops and loops.



Example of rework
The number of self-loops of the activity BP Transfer displays with the number of loops of
the activities SetDeliveryDate and Approve. If any of the activities contained both self-
loops and loops, their numbers would add up.

Loop inflow
Loop inflow represents the repetitions of an activity's predecessors.

Example of loop inflow
In this example, the activity SetDeliveryDate has been repeated seven (7) times, so the
loop inflow for the activity Approve is also seven (7), as SetDeliveryDate is the only
predecessor of Approve.

As the activity SetDeliveryDate has been preceded by non-repeated activities, its loop
inflow value is zero, regardless of the number of repetitions of itself. However, the edge
between SetDeliveryDate and Approve has a non-zero value as the starting activity was
repeated.

Loop outflow
Loop outflow represents the repetitions of an activity's successors.

Example of loop outflow
The activity Approve has the value of zero, none of the successor activities was
repeated. SetDeliveryDate shows value 7, as activity's Approve loop count equals 7. The
edge between SetDeliveryDate and Approve shows value 7, as the ending edge
activity Approve has been repeated 7 times.

Net loop gain
This activity metric represents the difference between Loop outflow and Loop inflow. If
the value is positive, the activity is directly followed by more repeated activities than it
was preceded. Such activities start new loops in processes. If the value is negative, the
activity is directly followed by less repeated activities than it was preceded. Such
activities end, close, or exit loops in processes. The halo effect color also helps us see



positive and negative trends in the process - red color represents a problem (start of
new loops); the blue color represents a favorable change (end of loops).

Example of net loop gain
SetDeliveryDate is followed by repeated activity Approve while it has no repeated
predecessors (value 0). The activity is thus involved in the creation of seven (7) new
loops (value 7). Activity Approve is not followed by a repeated activity (value 0), but its
predecessors are repeated seven (7) times. The activity Approve is thus involved in
closing seven (7) loops (value -7).

Rework metrics - process map
In rework metrics, the map displays information representing the volume of repetitions
for activities and edges the process involves.

To display the rework information:

1. On the panel on the right, select Customize (the top icon).

2. On the Customize toolbar, select Rework.

You can select if one metric is used both for activities and edges, or each metric is
set separately. To switch between count and percentage for each metric, select %.

The list of metrics is the same for both activities and edges, with one exception.
Metric Net Loop Gain is available only for activities.

By selecting an activity or edge, you can display rework details about the particular
object. The percentage represents the proportion of the individual types of reworks to
the overall number of instances.



Rework metrics - statistics
In the Statistics screen, the rework information is available for Case overview, Activities,
Edge statistics, Resources, and all event-level attribute statistics.

The rework columns are located at the far-right end of the table and the information can
be also displayed in the chart. The percentage is calculated from the Event frequency
value. In Case overview, it's calculated from the Event count.

Information about reworks is also present in the overview panel. The percentage shows
the proportion of the displayed rows that contain self-loops, loops, and reworks. In the
following example, one out of two cases contains a self-loop so the overview panel
shows 50% average self-loop. Similarly, one out of the two contains a loop. This is why
the average loop shows 50%. This means that both cases contain a rework, so the
average rework shows 100%.



In this example, one case contains one self-loop and one loop. The other one doesn't
contain any reworks. That means the average self-loop, average loop, and average
rework fields in the overview panel are 50% because only one of the two cases contain
them.

Rework metrics - filters
The Metrics filter supports filtering per case according to the amount of self-loops,
loops, and reworks.

Filters Attributes (conditional) and Edge (conditional) allow using rework metrics filter
per event.



See also
Process map overview



Process animation overview
Article • 07/18/2023

With process animation, you can visualize process development over time. You can
watch the animation play over your process map or social graph on the Animation
screen.

Adjust animation control settings
Control animation speed, advanced settings, and more on the Animation screen.

Legend:

1. Animation speed slider: Move the slider to adjust the animation playback speed.
The information displayed in the animation frame remains unchanged.

2. Right arrow icon: Select to open the Animation screen.

3. Animation level dropdown menu: There are two options: Select Immediate to
indicate that actual dynamics in the process will be shown during playback. Select



Aggregated to indicate that the process dynamics aggregated in the time period
around the currently monitored time point will be shown during playback.

The length of the time period used to aggregate information for the current view is
part of process mining. It depends on the duration of the process and the
simulation speed setting. For example, the higher the simulation speed, the longer
the time period is aggregated.

4. Simulation speed slider: Move the slider to adjust the process simulation speed
which the displayed animation information is based on. The simulation speed
change has an impact on the degree of detail in the displayed process dynamics.
Depending on the nature of the process in question, its duration, and the objective
of the analysis, dynamics with a higher or lower degree of detail may be preferred.

Alternatively, if you have a long-lasting process and need a detailed analysis of
dynamics over a shorter period, you might want to use a filter to restrict the
process under analysis only to the period in question.

5. Show significance values: Set the mode with the color highlighting of edges and
nodes in the animation. Two options: Select Globally to highlight the current value
in color in chart edges and nodes compared to all values of all nodes and edges in
the entire simulated process. Select Locally to highlight in color in chart edges and
nodes compared to the current values of all nodes and edges in the simulated
process.

To learn more, go to Display the significance of values.

6. Hide inactive connections: Turn On or Off to show or hide the connections that
aren't currently active. Hiding inactive connections makes the animation less
cluttered.

Use the playback control
The animation playback control is located in the bottom part of the screen. Use it to
start the animation, pause it, or skip to any position in the process.

The information about the actual time in the process appears to the right of Play
animation.

1. To play the animation, select Play animation. As the automation plays, the node
numbers and edge colors on your process simulation change. To learn more, go to



Functions of animation elements.

When you select Play animation, the button turns into Pause automation.

2. To temporarily stop the automation from playing, select Pause automation.



Understand process animation controls
Article • 07/18/2023

This article explains the meaning of the various changes (colors, numbers, and more) in
the controls for your process during animation play.

Display the significance of values
The Show significance values options set the mode with the color highlighting of edges
and nodes in the animation.

Setting for all nodes and edges: Select Global to highlight the current value in
color in chart edges and nodes compared to all values of all nodes and edges in
the entire simulated process. This means that the thickest edge or the most
highlighted node represents the global maximum for the whole duration of the
process.

A node is highlighted if the number of currently incoming events is significant
compared to the global maximum of all events ongoing at the same time or in
the aggregated interval in one node.

An edge is highlighted if the number of its currently ongoing transitions is
significant compared to the global maximum of all transitions ongoing at the
same time or in the aggregated interval in one edge.

Setting for current nodes and edges: Select Locally to highlight the current value
in color in chart edges and nodes compared to the current values of all nodes and
edges in the simulated process. Thus, the thickest edge or the most highlighted
node represents the local maximum for the present moment.

A node is highlighted if the number of currently incoming events is significant
compared to the current maximum of events ongoing at the same time or in the
aggregated interval in one node.

An edge is highlighted if the number of its currently ongoing transitions is
significant compared to the current maximum of transitions ongoing at the
same time or in the aggregated interval in one edge.

Understand number and color highlight of a
node



The number at the chart node represents how many events of the given activity are
currently in progress. The color highlight makes it possible to easily distinguish how
many events are dealing with the activity at the moment. During the animation, you can
easily see which activities often take place in parallel.

To learn more about color highlighting, go to Display the significance of values in this
topic.

Understand number and color highlight of the
edge
The number at the chart edge represents how many transitions between activities are
currently in progress. This tells you how many pending cases are waiting for the next
event to take place. The color highlight of the edge allows you to easily identify if there
are too many cases concurrently waiting for an activity to take place.

To learn more about color highlighting, go to Display the significance of values in this
topic.

Activity Progress



The following example shows the highlighted progress indicator for an activity in the
process. This indicates the proportion of the count of already performed events of the
activity compared to the total count of events of this activity in the process. If all events
of the given activity being present in the process in question have already been played
back in the animation, the indicator will fill the entire circle.

Related information
Process animation

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Statistics overview
Article • 07/18/2023

This article provides an overview of the properties of the process undergoing analysis.
This includes the information about the process through summary charts and statistics.
Statistics are shown in the top panel. The listings of specific records displayed in the
statistics appear in the bottom panel.

The statistics always reflect the data after filters, if any, have been applied.

Types of statistics
To open the statistics screen, select Statistics on the left panel in the opened view. The
following types of statistics are available:

Case overview: Statistics per single cases with case level metrics. To learn more, go
to Case overview statistics.

Activity statistics: Activities that display their various event level properties. To
learn more, go to Activities (event-level) statistics.

Attributes imported with the process marked as Others and Source have the
same statistical summary as the statistics for the activity.

Edge statistics: Process paths (edges) metrics. To learn more, go to Edge statistics.

Cases duration influence: Analytical insight that evaluates the influence of case-
level attributes (including financial) on the mean case duration. To learn more, go
to Case duration influence in this article.

Business rules: Overview of defined business rules. To learn more, go to Business
rules overview.

Export statistics
You can export your statistics chart in .png format, or your table of records in .csv
format.

To export, select an option in the Export dropdown menu.

Stastistics samples



Statistics allow you to quickly identify issues in the process. The following sections
provide examples.

Average resource activity time
Show the average activity time of resources. As in the following screenshot, it's apparent
that some resources need much longer time to complete their activities than others. You
can narrow your list of resources to get more data.

To choose specific resources:

1. In the Category dropdown menu, select activityName.

2. Select Enable filter.

3. In the Filtered by dropdown menu, select Associate.

4. Open the Attribute value list by selecting the blank values field.

5. Select the associates names. The names are added to the values field.

6. Select Apply.

Cases duration
Show the number of cases with varying duration intervals. If the chart shows that there
are rare cases in the data that distort the average values, such cases might require
attention, or possibly should be excluded from process analysis as non-standard.

To select case duration:

1. In the Category dropdown menu, select Case overview.

2. In the Active cases dropdown menu, select Cases duration.



Filtering in statistics charts
You can filter selected values in the summary charts in the statistics of process instances
and in the statistics of attributes by selecting each column. When you make a selection,
the Filtering screen opens with the preset values of the filter.

Sort in the statistics grid
You can sort the statistics grid by selecting the up or down arrow in the header of a
column where sorting is available. This will change ascending and descending sorting
order.

Case duration influence
Case duration influence is a complex analytical insight that evaluates the influence of
case-level attributes (including financial) on the mean case duration. The Power
Automate Process Mining desktop app takes all case-level attribute values and, based
on the mean duration of the cases having the specific case-level attribute value
weighted by the volume of cases having this value, calculates the percentile influence of
cases having this value on the overall mean case duration.



For example, if the Article is Software Licenses, the mean duration is longer than for
article Hardware, but the influence on the overall case duration is not so strong. This is
because the case frequency is much smaller for Software Licenses than it is for
Hardware.

A positive percentage number in red means that the corresponding attribute value is
slowing the process. A negative percentage number in green is making the process
faster. Its influence on the mean duration is represented by the percentage value.

To access the case duration influence, select Case duration influence statistics from the
selection control in the top left corner.



Gather case overview statistics
Article • 07/18/2023

Case overview statistics provide information for case-level metrics. They also contain a
table of cases in the actual view with standard and custom case-level metrics, including
generated case cost metrics, which are based on the financial attributes in the process.

Statistical charts
The metrics in the following table are available in the chart.

Metric Description

New events Number of started events for the duration of the process.

Active Number of active events for the duration of the process.
events over
time

Cases over Number of new cases.
time

Active cases Number of active cases for the duration of the process.

Variants Distribution of cases per process variant. To learn more, go to Variants overview.

Events per Number of events recorded in the process instance data. The statistics value
case reflects the number of lines in the log per case.

Cases Occurrence of cases with varying duration. The total spread of case duration is
duration divided into intervals of equal size (the X-axis on the chart). The chart displays the

quantity of cases whose duration falls in these intervals.

Case Efficiency of cases can be used as an indicator of the time spent performing an
utilization activity relative to the time between performing activities in the case. If the value is

100%, all time of the case is used for the performance of activities.

This chart is available if there are two timestamps recorded in the data and
imported with the process.

Mean active This chart is available if there are two timestamps recorded in the data and
time imported with the process. The average duration of the activity shows the average

amount of time spent on activities in each process instance. The total spread of
activity times in cases is divided into intervals of equal size (the X-axis on the chart).
The chart displays the quantity of cases whose activity time falls in these intervals.



Metric Description

Mean Average waiting time indicates the average amount of time spent between the
waiting performance of activities in each process instance. The total spread of waiting
time times in cases is divided into intervals of equal size (the X-axis on the chart). The

chart displays the number of cases whose waiting time falls in these intervals.

Self-loop Distribution of cases per self-loops within the case.
count

Loop count Distribution of cases per loops within the case.

Rework Distribution of cases per rework (loops and self-loops together) within the case.
count

Besides these standard statistics, the list contains all defined Case level custom metrics
with continuous output data type and Case(cost) metrics, which are automatically
generated by the Power Automate Process Mining desktop app for each finance
attribute.

Summary header and table of cases
The summary provides an overview of standard metrics provided by the Process Mining
desktop app. The list of these metrics isn't configurable and no additional metrics can
be included in this summary row. The table of cases contains standard metrics,
generated case cost metrics, and custom metrics applicable on the case level.

The metrics in the following table are available in the summary header.

Metric Description

Event Count, Total number of events and cases in actual view.
Case count

Activities Number of unique activities in the actual view. The activity attribute is defined in
process import/configuration. This metric is not affected by the selection of the
mining attribute on the process map.

Resources Number of unique resources in the actual view. Resource attribute is defined in
process import/configuration. In the case of multiple resource attributes, the
first one (according to the order of process attributes) is used.

Variant count Number of variants generated by process activity. Selection of mining attribute
or variant mining attribute (on Variants screen) does not affect this metric.

Median case Median and average case duration.
duration,



Metric Description

mean case
duration

Mean active Average duration of all events in one case calculated over all cases. This metric is
time calculated only for event logs with defined event duration (event has start and

end timestamps or start timestamp and event duration). For one timestamp, the
event logs duration of events isn't known and the Process Mining desktop app
isn't able to calculate active time. In such an event log, active time for all cases is
zero.

Mean waiting Average waiting time is calculated as the time difference between the end of the
time previous activity and the start of the current activity. In the event log, without

event duration, the all-time difference between the start of two events is
considered as waiting time.

Mean Average utilization of cases. Utilization is calculated as the ratio between case
utilization duration and duration of case events. This metric is calculated only for event

logs with defined event duration. In processes without event duration, utilization
per case and thus mean utilization for all cases is zero.

Start, end Date of the start of the earliest case and date of the end of the latest case in the
actual view.

Self-loop Percentage of cases that involve particular amounts of self-loops relative to the
cases total number of cases in the process.

Loop cases Percentage of cases that involve particular amounts of loops relative to the total
number of cases in the process.

Rework cases Percentage of cases that involve particular amounts of reworks relative to the
total number of cases in the process.

Case cost
The value represents the case cost of the financial attribute that is present in the
brackets. Whenever one or more financial attributes are specified during the import
process, they automatically become available in the statistics table both as additional
columns in the table and as parameters available for the chart.

Case information export
Case information can be exported from the Case overview.

1. In the open view, select Export on the left panel.



2. In the Export type dropdown menu, select Cases.

3. Verify that the Export as selection is CSV and the Delimiter field is a comma.

4. Select statistics to be exported.

5. Select Export.



See also
Statistics overview



Customize activities (event-level)
statistics
Article • 07/18/2023

The Power Automate Process Mining desktop app provides statistics at the level of
activities, or events, in both chart and table form. You can customize many aspects of
the chart and the tabular data.

1. On the left panel in the Processes screen, select Statistics.

2. In the Category group, select the attribute from the dropdown menu. In the
following screenshot, the selected attribute is activityName.

3. Select Enable filter.

4. In the Filtered by dropdown menu, select the filter data. In the following
screenshot, the filtered data is caseid.

5. Select the empty values field.

6. Select all values by hovering over the area to the left of Attribute value and
selecting the circle.

7. Select Apply,

Statistical chart and table of activities
The metrics in the following table are in the chart and the table of activities.



Metric Description

Case frequency Number of cases in which an activity occurs

Case frequency Percentage of cases in which an activity occurs relative to all cases in the
(%) process

Event frequency Number of times an activity occurs in the process

Event frequency Percentage of occurrences of an activity relative to all activities in the process
(%)

Maximum Largest number of activity repetitions in process instances
repetitions

Total duration Total duration of each activity in the process; available only if two timestamps
are recorded in the data and imported with the process

Total duration Percentage of the total duration of each activity relative to the total duration
(%) of all cases in the process; available only if two timestamps are recorded in the

data and imported with the process

Mean duration Average duration of each activity in the process; available only if two
timestamps are recorded in the data and imported with the process

Mean duration Percentage of each activity's average duration relative to the average duration
(%) of all cases in the process; available only if two timestamps are recorded in the

data and imported with the process

Minimum Shortest duration of each activity in the process; available only if two
duration timestamps are recorded in the data and imported with the process

Maximum Longest duration of each activity in the process; available only if two
duration timestamps are recorded in the data and imported with the process

Duration range Difference between the longest and shortest duration of each activity in the
process; available only if two timestamps are recorded in the data and
imported with the process

Duration Standard deviation of each activity in the process; available only if two
standard timestamps are recorded in the data and imported with the process
deviation

Self-loop count Number of self-loops on an activity

Self-loop (%) Percentage of self-loops on an activity relative to the total occurrence of that
activity in the process

Loop count Number of times an activity is involved in a loop

Loop (%) Percentage of involvements of an activity in a loop relative to the total
occurrence of that activity in the process



Metric Description

Rework count Number of times an activity involved in rework

Rework (%) Percentage of involvements of an activity in rework relative to the total
occurrence of that activity in the process

Loop inflow Value of loop inflow of an activity in the process

Loop inflow (%) Percentage of loop inflow of an activity relative to the total occurrence of that
activity in the process

Loop outflow Value of loop outflow of an activity in the process

Loop outflow Percentage of loop outflow of an activity relative to the total occurrence of
(%) that activity in the process

Net loop gain Value of net loop gain of an activity in the process

Net loop gain Percentage of net loop gain of an activity relative to the total occurrence of
(%) that activity in the process

Along with these standard statistics, the chart displays all event-level custom metrics
that have the continuous output data type.

The table of activities displays event-level standard and custom metrics. In the table, all
event-level custom metrics are available, whether their output data type is discrete or
continuous.

Metrics in the summary row
The metrics in the following table are in the summary row.

Metric Description

Activities (value) Total number of unique values for activities or event-level attributes
The Activity attribute is defined during process import and
configuration and isn't affected by the selection of mining attribute on
the process map.

Minimum frequency Smallest number of occurrences of a given activity (attribute value) in a
single case

Maximum frequency Largest number of occurrences of a given activity (attribute value) in a
single case

Median frequency Median number of occurrences of a given activity (attribute value) in a
single case



Metric Description

Mean frequency Mean number of occurrences of a given activity (attribute value) in a
single case

Count std. deviation Standard deviation of activity (attribute value) occurrences in a view

Minimum duration and Global minimum and maximum duration of a single event
maximum duration

Mean duration Average duration of events

Duration standard Standard deviation of activity (attribute value) durations in a view
deviation

Self-loop events Percentage of events in self-loops relative to the total number of
events in the view

Loop events Percentage of events in loops relative to the total number of events in
the view

Rework events Percentage of events in rework relative to the total number of events in
the view

See also
Statistics overview



Review edge statistics
Article • 07/18/2023

These statistics refer to edges in the process undergoing analysis and display their
various properties. Edge statistics can be reviewed from the perspective of activities
(process map-related edges) as well as from the viewpoint of resources (social chart-
related edges).

To review edge statistics:

1. On the left panel in the opened view, select Statistics.

2. In the Category dropdown menu, select Edge statistics.

3. Select the metric for your chart in the dropdown menu in the chart.

Statistical chart
The metrics in the following table are available in the chart.

Metric Description

Case frequency Total number of cases containing a particular edge in the process.

Case frequency (%) Percentage of cases containing a particular edge in the process relative to
all cases in the process.

Event frequency Total number of each edge occurrence in the process.

Event frequency (%) Percentage of each edge occurrence in the process relative to all edges.

Maximum Largest number of edge repetitions in process instances.
occurrence in case

Total duration Total duration of each edge in the process.



Metric Description

Total duration (%) Percentage of the total duration of each edge in the process relative to the
total duration for all cases in the process.

Mean duration Average duration of each edge in the process.

Mean duration (%) Average duration of each edge in the process relative to the average
duration for all cases in the process.

Minimum duration Shortest duration of each edge in the process.

Maximum duration Longest duration of each edge in the process.

Duration range Difference between the longest and shortest duration of the occurrence of
each edge for each edge in the process.

Duration std. dev. Standard deviation of each edge duration in the process.

Self-loop count Number of occurrences of self-loop edges.

Self-loop (%) Percentage of occurrences of self-loop edges relative to their total
occurrences in the process. To learn more, go to Rework metrics.

Loop count Number of occurrences of edges in loops.

Loop (%) Percentage of occurrences of edges in loops relative to their total
occurrences in the process.

Loop inflow Value of the loop inflow of edges in the process.

Loop inflow (%) Percentage of loop inflow of edges relative to their total occurrences in the
process.

Loop outflow Value of loop outflow of edges in the process.

Loop outflow (%) Percentage of loop outflow of edges relative to their total occurrences in
the process.

Besides these standard statistics, the list contains all defined edge-level custom metrics
with the continuous output data type.

Summary header and table of edges
The summary provides an overview of standard metrics provided by Power Automate
Process Mining. The list of these metrics isn't configurable and no additional metrics can
be included in this summary row. The table of edges contains standard edge-level
metrics, and custom metrics applicable on edge-level. In the table, all mentioned
custom metrics are available regardless of their discrete or continuous output data type.



The metrics in the following table are available in the summary header.

Metric Description

Edges Total number of unique edges in the view.

Minimum frequency Minimal number of occurrences of an edge in a single case.

Maximum frequency Maximum number of occurrences of an edge in a single case.

Median frequency Median number of occurrences of an edge in a single case.

Mean frequency Mean number of occurrences of an edge in a single case.

Count std. deviation Standard deviation of edge occurrences in a view.

Minimum duration, The global minimum and maximum duration of a single edge.
maximum duration

Mean duration The average duration of edges.

Duration std. The standard deviation of edges durations in a view.
deviation

Self-loop events Shows the percentage of self-loop edges relative to the total number of
edges in the view. A self-loop edge is an edge with the same starting and
ending node (activity).

Loop events Shows the percentage of edges in loops relative to the total number of
edges in the view. An edge is in the loop if its ending node (activity) is
repeated within a case.

Rework events Shows the percentage of edges in rework relative to the total number of
edges in the view. Rework edge is edge either in a loop or in a self-loop.

See also
Statistics overview



Root cause analysis overview
Article • 04/03/2023

Root cause analysis (RCA) allows you to find hidden connections in your data. For
example, it helps you understand why some cases take longer to complete than others,
or why some cases get stuck in reworks while others run smoothly. RCA will show you
the key differences between such cases.

Required data
RCA can use all your case level attributes, metrics and custom metrics to find
connections among them, and a metric of your choosing.

The best sample is to include all data you can as a case level attribute and let RCA do
the choosing of which attribute actually influences the metric and which doesn't.

How RCA works
The RCA algorithm will compute a tree structure where each node will split the dataset
into two smaller parts. This is based on one variable where it finds the best correlation
between the variable split and the target metric. From this, you can see the hidden
connections in the data. This is where it will tell you which combination of attributes will
influence the case in which way.

How RCA finds the best split
First, we generate hundreds to thousands of combinations of possible splits. Then we try
each split to discover how well will it actually split the dataset into two parts. We
calculate the variance of the main metric in each part of the split and calculate the score
for each split with the following calculation:

scoresplit_x = varianceleft * number of casesleft + varianceright * number of casesright

Then, we sort all splits by this score and the best splits are taken from the beginning,
with the lowest score. For the categorical main metric (string), we calculate Gini impurity
instead of variance.

RCA example



In this example, we want to see the root cause behind the case duration. In the data, we
have case level attributes supplier country, supplier city, material, total amount, and cost
center. The average case duration is 46 hours.

By looking at each value of each attribute separately, we can see that the highest
influencer of case duration is when supplier city is Graz, which on average increases the
duration of the case by additional 15 hours. From this initial analysis, we can see that the
other values of attributes influence the target metric far less. However, when we
compute the tree model, we can see that the computation above is misleading (as in the
following screenshot).

The tree structure looks like this:

The first split is the data along the material variable. The data with aluminium is on
one side and all other materials is on the other side.

The aluminium branch is split further by supplier country into Germany and
Austria.

The Austria branch continues with a split by supplier city, with Graz on one side
and Vienna on the other.

In the node Graz, the average case was 36 hours slower than the overall average
duration of 46 hours.

In the same tree, we can see that if we have another material than aluminium, it also
splits by the variable supplier city, where on one side is Graz and on the other is Vienna,



Munich or Frankfurt. But here, the values are the opposite. Graz has much better
statistics than Vienna or any German city, with average case in Graz being 15 hours
faster than the overall average for all cases.

From this, we can see that the initial statistics are misleading because Graz is performing
poorly when the material is aluminium, It is, however, performing above average when
the material is other than aluminium and is completely opposite for other cities.

Case Duration Influence statistics takes into account only one value and sometimes can
be misleading. RCA takes into account combinations of them to give you more insights
into your process.



Find hidden connections
Article • 07/18/2023

Find hidden connections in your data with root cause analysis (RCA) in the Power
Automate Process Mining desktop app.

To create a new RCA, create an analysis.

1. In the open view, select Root cause analysis on the left panel.

2. In the Metric dropdown menu, select a metric.

3. On the Influenced by panel, select which attributes you think are important for
that metric.

If you're not sure which attributes should be influencing your metric, choose all of
them and the algorithm will find the best one. To select all attributes, select the
circle to the left of the Metric name heading.

4. Select Analyze. The Analysis tab opens.

If you choose a main metric, you can't choose the same metric in Influenced by. Also,
don't choose similar metrics in Influenced by as the main metric, as the algorithm will
choose those metrics on every split. For example, if your main metric is Case duration,
don't select Case Active Time in the Influenced by section, as this will provide you no
new information.

Change options in the Analysis tab
You can customize the view to your preferences.

See more or less information in a node
Nodes are connected by arches (rules). Each node is a collection of data filtered by the
rules in the arches connecting it to the root node.

To expand or collapse a node, select the plus or minus sign. The expanded view allows
you to see more information about that part of the data.



Choose another split
If the split that is chosen as the best one by the algorithm is on an attribute which you
don't want to use at that point, you can choose another split from the list. In the list,
there is a best split for each selected attribute in the analysis.

To open the available splits you can choose from, select the down arrow in the node
heading.

Change the view size
If the tree is too large and can't be navigated easily, you can open the Diagram preview
to navigate around the tree. You can also change the layout as you wish.



７ Note

When you find the correct part of dataset that you need to explore further, you can
convert the rules that lead up to that node into a set of filters.

If you do this, the original analysis becomes view only, as the underlying data has
changed (filters applied).

Use categorical main metric
If you want to explore why some cases have gone one way or another, it's easy to
analyze this with RCA using a custom metric returning string values.

For example, if you want to analyze why some cases end in some activities and others in
different ones, you can use the formula LAST(CaseEvents, Activity)  as your custom
metric.

For other use cases, you might want to explore why cases that went through an activity
X are then going to one of direct descendants of activity X. For this, you can use custom
metric FIRSTIF(CaseEvents, Activity == "Process start", NEXT(Activity)) . This metric
returns the name of the activity after activity "Process start". If a case goes through this



activity multiple times, it will only take into account the first pass. If you want the last
one, you can use LASTIF  instead of FIRSTIF .

The same can be achieved with FIRSTIF(CaseEvents, Activity == "Check order
numbers", MOVE(1, Activity)) , where you can specify the number of events that it has
to move down the case.

For other similar use cases, you can use custom metrics to get event attributes on a case
level so it can be used in RCA. To do this, get the value of an event attribute Y at an
activity X. This is done by using custom metric FIRSTIF(CaseEvents, Activity== "X", Y) .

All of these metrics, can be also used in Influenced by.

To learn more about custom metrics, go to List of other operations.

See also
Root cause analysis overview



Analyze processes with variants
Article • 07/18/2023

With process variants, you can accurately explore all possibilities of how a process can
develop and identify problematic scenarios (for example, a transition variant with an
unusually high number of events). The quantity of variants makes it possible to
accurately identify the most frequent scenarios occurring in the process. This way, you
can easily and quickly determine which process scenarios require your attention.

The careful examination of process variants can help you uncover various scenarios and
situations that occur in the process. With filtering by variants, the analyzed process can
be easily restricted to only those parts or scenarios that are of interest for achieving the
final objective of the analysis. A process variant is an organized sequence of activities
that corresponds to the course of at least one case in the process under analysis. All
cases in the process in which the same activities are performed in the same sequence
fall under one variant.

The decisive condition for determining the respective variant and the arrangement of
events is the event start time.

Variant mining attribute
Similar to a process map, which is by default generated using activities but can be
switched to a resource viewpoint (similar to a social chart in the process map), the list of
variants is generated using the selected mining attribute. In the same way, the variants
overview can be generated using different relevant event log attributes (for example,
department, plant, or region). This selection is independent of the selection of mining
attributes on the process map.

Variant names
Process variants are among the results of process mining. They're labeled by a number
that's used consistently on all process analysis screens regardless of any applied filters.

Components of the Variants screen
To open the Variants screen, go to the open view and select Variants on the left menu.



The default screen contains three panels:

Attribute

Variant overview

Legend

Attribute panel
In the first panel next to the menu, you'll see a list of process variants. This is sorted by
the count of occurrences of cases under the variant by default.

Select (...) to sort the list of variants by Event count or Performance. You might also see
a Finance option. This is available only when there is a finance attribute in the process.
Performance and finance sorting criteria contain a list of available sub-criteria, which
enables further options for sorting.

Sorting by Case Count displays a total number of cases for a variant in a single case.
Select the up or down arrow next to the sorting criteria name to change the sort order
(ascending or descending).



Variants overview panel (variant DNA)
All cases for the selected variant appear in the center panel. This is lso where you can
see variant DNA.

The variant DNA view allows you to:

Get a visual overview of all the process variants found in the current open process
view

Get a glimpse of process characteristics and variations of the process

Get a glimpe of process standardization level

Identify differences or repeated patterns

Identify similarities of variations

To display Variant DNA:

1. Make sure that no variant is selected in the list.

2. Select any of the available variants by selecting it in the list on the first panel next
to the menu.

Legend panel
Lists the full names of the abbreviations in the Variants overview panel.

Search for case specific data
You can get specific data for a variant. When you select a variant in the left panel Case
Count column, you'll see three tabs:

Variant overview



Cases table

Cases gantt

Variant overview tab
Get a map of activities on the left, where you can observe the duration of activities and
edges of the variant in the Variant Overview tab. The statistical indicators of selected
variant metrics are present on the right. The graph shows the distribution of cases over
time. The blue part represents the overall distribution. The orange part represents the
selected variant.

Cases table tab
Explore each issue individually in the Case table tab. In the center panel, there's a list of
all cases under the variant sorted by their case ID. Each issue can be explored
individually.

To see the details of its development, select a case number in the Case ID column. The
events of the selected case appear on the right column.

Cases gantt tab
Development of the case on a timeline in the Cases gantt tab. The following information
about each case is available:

1. Start and end time for the case

2. Name of the performed activity

3. Visualization of the duration of the activity on the timeline

4. The parallel flag means that the activity runs in parallel with another activity.

5. The parallel conduct of the two activities can be clearly seen on the timeline.

6. Waiting time for another activity after the completion of the current activity

When you select the black dot within the time progress of the activity, all information
about the activity displays.

Customize settings



Change the setting in any panel or tab in the Variants screen.

1. On the menu at the top-right, select View Settings.

2. Choose from General settings, Duration settings, Activity label, and Calendar
settings.

By default, each activity has its own color. Use the Activity label to display the
same color for all activities with the same label.

3. Select Save.



Compare process views for compliance
Article • 07/18/2023

Comparison of the processes allows an intuitive and efficient comparison of processes.
You can compare the processes at the level of the process map, where the generated
visualization allows you to identify the differences in the flow and frequency, or time
metrics.

You can also change the complexity of the map, zoom, or nodes offset in the Customize
and Visualize icons on the far right.

You can compare in detail values of metrics and attributes at the level of activities and
edges. You can also compare the views of various processes or different views generated
from a single process (for example, for different periods of time) by selecting a process
in the Compare box.

Add views
A view, from which the functionality was displayed, is the basis for comparison. All
added views as layers are constantly compared to the view you're currently working on.

To add a layer:

1. On the Compare box, select Add layer.

2. In the Views dropdown menu, select a process.

3. (If your process is in a blueprint format) Select BPMN and then select a properly
formatted BPMN diagram. The BPMN diagram will be transformed and compared



to the currently open view.

Changing the view
List of all available layers is shown in the Compare box. The individual layers can be
switched on and off by checking or unchecking them. The currently open view and the
Compare layer are switched on by default. Unchecking the currently open view will
highlight those activities and transitions which are common in both compared layers.
Select (-) to remove the layer from the list.

Each layer/view has an associated color. Activities and edges that form an intersection of
the compared layers/views are colored as the Compare key.



Export process data
Article • 07/18/2023

Export process data to an external file. After you choose your export type, you can
choose to export data as a CSV, XES, or an MXML file. You can also choose to export as
a zip file, and enter the delimiter to use. If you choose to export cases (as opposed to
events), you'll see a list of statistics you can choose to export.

Choose export options
1. On the left menu in the open view, select Export.

2. In the Export as dropdown menu, select Events or Cases.

3. If you select Cases, also de-select the statistics you don't want to include in your
export in the Statistics to export list.

4. If you want to export as a zip file, place a check in the Export as ZIP checkbox.

5. If you want to use a delimiter other than the default comma, enter it in the
Delimiter field.

6. Select Export.



Export option details
The options in the following table are available for your export file.

Option Description

Apply filters Specify if set filters in the currently open view should be applied to the process
before export. If the filters aren't applied, all records in the process will be
exported.

Export type Select either Cases or Events. When you export events, the entire process log is
exported. When you export cases, the selected information about cases
without respective individual events is exported.

Export as Share specific findings in the process, for example when filtering is applied.
Data can be imported again by another user who has the resource file (export).
The following formats are supported: CSV (comma separated records), XES
(Extensible Event Stream), and MXML (Mining eXtensible Markup Language).

Export as ZIP Compress the exported file into ZIP format. If you select this, select the type of
compression to use. Choose from among Optimal, Fastest, or No
compression.

Delimiter Enter a record separator When exporting to the CSV format.



Option Description

(For exporting Select which metrics and attributes will be exported with individual cases. The
cases) Statistics attributes exported with the case must be imported as the case-level attributes.
to export



Filtering overview
Article • 07/18/2023

Use filters to adjust which cases will be included in the process analysis. For example,
you can use filters to define only a certain time period, only specific resources or
scenarios in the process, or modify cases by excluding activities that aren't important for
the current analytical problem. Filtering can also be helpful in identifying and focusing
on the problematic parts of the process.

Filter components
A filter is a rule or a set of rules determining which cases and/or events from the process
will be later included in process mining. There are two groups of filters available in the
Power Automate Process Mining desktop app: event level and case level. To learn more
about each filter, select the link.

Event level filters
Event level filters modify cases by removing events based on the applied filter criteria.

Event level filter types:

Event attributes

Subprocess

Event metrics

Case level filters
Case level filters are always applied to complete cases in the process.

Case level filter types:

Timeframe
Case attributes
Attributes (conditional)
Edge (conditional)
Variants
Case metrics
Sequence



End events
Conflict of interests

Case and event level filters can be combined to form a single combined filtering criteria
in a view. There are filters that have the same syntax, but different semantics based on
the type. For example, the Event attributes filter can be applied on the event and case
level.

The combined filter criteria order is defined as criteria are added. The order is modifiable
inside of the filter category by using drag-and-drop. Filters are evaluated in the final
defined top-down order. Input for the first filter is the whole data set. Its output—
filtered data set—serves as input for the next filter. The output (filtered) data set from
the last filter in the order defines the process view.

７ Note

Event filters are always applied first, before any case filter is applied to the resulting
dataset. You can't mix order between event level and case level filters. Ordering is
modifiable only within its group.

Filters can be exported and imported to be re-used in different views or processes. To
learn more, go to Export and import filters.

Add a filter
A filter is a convenient tool in a process analysis, as we can use it to focus only on
certain parts of the process in analysis. For example, it can be used to define only a
certain time period, only specific resources or scenarios in the process, or modify cases
by excluding activities that aren't important for the current analytical problem. It can
also be helpful in identifying and focusing on the problematic parts of the process.

To add a filter:

1. In the open view, select Filter in the lower-left corner below the menu.

2. On the menu at the top, select the Add filter dropdown menu.

3. Select a filter.

4. On the Filtering screen, select the options for the filter.

5. If you want to give the filter another name, select (double-click) the filter in the
filter list column in the left panel, enter the new name in the Filter name field, and



select Save.

6. Select Apply.

Customize your filters
The following table lists common actions that you can use in the filtering screen to
customize your filtering experience.

Action Description

Show details To see the filter configuration details for all filters, turn on Show details at the
top of the screen.

Delete a filter Select the filter you want to delete and then select X.

Delete all On the menu at the top of the screen, select the Remove all filters.
filters in the
list

Disable a filter If you don't want to delete a filter completely from the list, but prefer to disable
temporarily it temporarily, turn off Enable filter next to the selected filter.

Invert a filter Some filtering rules may be difficult to express. It's often more convenient to
define the rule in an inverted form and then to invert the filter. An inverted filter
also changes how the filtering results are calculated. Particularly for more



Action Description

complex rules and large-scale processes, inverted rules might simplify and speed
up the calculation of the filtering results.

To invert a filter, use the filter rule by changing the Filter result option
(includes/does not include) in the center panel.

Apply filters After the filters have been configured, select Apply. The new mining of the
process will start only after the filters are applied.

Combine Filters are applied in the order in which they are defined in the list of filters.
filters However, event level filters are always evaluated before case level filters. It's

possible to change the order in the respective category using drag-and-drop.
The final filtering result consists of the cases that fulfill the criteria of all active
filters applied in the order.

Filtering indicators
When analyzing the process by means of filters, you can see the size of the data set
you're working with.

Data size indicators provide information about the data set, like the number of filtered
events and cases. The indicators are located on the bottom of the application on each
screen of an open view.



Timeframe filter
Article • 07/18/2023

The timeframe filter lets you specify time related options for your analysis. On the left
side, you can edit the filter rule. The right side shows the visualization of the course of
the process divided into equal time intervals.

1. On the left panel, select your timeframe filter.

2. On the Level row, select the detail level of the chart by selecting number.

3. On the center panel, specify you filter results.

4. On the center panel, select the cases to display in the chart (ongoing, started, and
ended).

The colors of your selections match the colors in the visual on the right.

5. Select Apply.

Evaluation of presence in a timeframe
Specify the evaluation method to determine if a case falls in the specified timeframe.

The following list describes the options:



Fit in: The case must start and finish within the specified timeframe.

Finish in: The case must finish within the specified timeframe and start outside the
specified timeframe.

Start in: The case must start within the specified timeframe and finish outside the
specified timeframe.

Intersecting: Cases extend to the time frame. They might be contained, start, or
finish in it.

Pass through: The case must start before the beginning of the specified timeframe
and finish after the end of the specified timeframe.

Timeframe specification
To specify a timeframe, enter its start and finish time.

1. In the in range field, select the calendar icon and select the start date.

2. At the bottom of the calendar, set the start time by selecting the hour, minute, and
AM or PM.

3. In the and field, select the calendar icon and select the end date.

4. At the bottom of the calendar, set the end time by selecting the hour, minute, and
AM or PM.



Case attributes filter
Article • 07/26/2024

The Attributes filter selects cases that contain—or don't contain—a specific attribute.

Filter values from a list
Use the filter to select cases that include a certain activity or resource.

1. On the left panel, select your attributes filter.

2. In the Filter result dropdown menu, select if the cases you select for the filter
should or shouldn't be included.

3. In the cases in which attribute dropdown menu, select an attribute.

4. In the holds any of the values dropdown menu, select one or more values in the
List tab to the right.

5. Select Apply.

Filter values from an expression
Use the filter to select cases that include an expression. You can include both string and
numeric attributes in an expression.

1. Follow steps 1 through 3 in Filter values from a list in this article.

2. On the panel to the right, select Expression.

3. In the first dropdown menu, select the operator for your expression.



4. In the field next to the operator, enter the value.

5. Select Apply.

Enter a custom expression
You can switch between a constant value and a custom expression by selecting Fx in the
Expression tab.

To learn how to use a custom expression, go to Custom metrics overview.

Related information
Custom metrics overview
Tips and examples

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Case attributes conditional filter
Article • 07/18/2023

The Attributes (conditional) filter adds conditions to the Attribute filter. Use it, for
example, to find all cases where an approval activity occurs, but only if a specific
resource executed the approval or the duration of the activity exceeds a certain KPI.

1. On the left panel, select your attributes (conditional) filter.

2. In the Filter result dropdown menu, select if the cases you select for the filter
should or shouldn't be included.

3. In the cases in which attribute dropdown menu, select an attribute.

4. In the holds any of the values dropdown menu, select one or more values in the
List tab to the right.

5. In the and at the same time dropdown menu, select a criteria type, either
Attribute, Metric, or Process Metric.

If you select Metric or Process Metric, you'll need to complete additional fields. To
learn more, go to Process metric in this article.

6. In the next dropdown menu, select an attribute or metric.

7. Based on the characteristics of the selected attribute or metric, complete the
filtering criteria using the offered controls or use the Expression tab, select an
operator, and enter a value.

8. Select Apply.



Process metric
Process metric calculates the total value for all cases in the process. In the view filtering,
it returns either empty (0% cases) or full (100% cases) for data set coverage. Use process
metrics for filters in business rules, where you can deactivate or activate the business
rule by filtering out the whole data set.



Edge conditional filter
Article • 07/18/2023

This case-level filter is similar to the attribute (conditional) filter, only it's related to
edges instead of events. Both activity-based process map and resource-based social
chart edges are supported. Activity attribute name is the first process map based
attribute.

If there are defined resource attributes in the active process, the dropdown offers to
select Resource attributes.

As we are dealing with edges, the available condition is limited to either case-Level
attributes or edge-related metrics. For example, you want to find all cases where edge
Approving -> Demand for information occurs, but only those where this edge happened
for a certain supplier or region, or the mean duration of this edge exceeds a certain KPI.
(If we used a resource-based attribute, the list of edges follows resource transitions,
such as Lara Obrien -> Azalia Hansen.)

1. Select the additional criteria type (Case-Level Attribute, Edge Metric, or Process
metric):

2. Complete the filter by specifying the values for it.



Variants filter
Article • 07/18/2023

Use this filter to restrict the mining in the process only to the cases following a certain
scenario (variant).

In the Values pane, there's the visualization of the dependence of the number of
variants on the number of cases falling in each variant.

Variant mining attribute
Variants may be calculated using activity attribute (default one) or any mining attribute
(any non-case level attribute). Choosing a variant mining attribute in filters doesn't
depend on, nor modifies the selected mining attribute on the process map.

The process map can be calculated using the activity attribute, while data may be
filtered by the most common variants (scenarios) based on the resource attribute.

Variant selection
Variants can be selected by marking them on the chart in the center part of the filter.
The chart can be used to distinguish variants with high case count from variants with



low case count. The height of chart bars depends on the number of variants with equal
case count.

The following example show the results of 50 variants containing 3% of all cases in the
process.

The following example show the results of one variant containing 50% of all cases in the
process.



To select a discontinuous group of variants or to select variants by their number, you
can select specific variants on the right. Select a variant to select and remove it from the
list. To make the selection of variants easier, use the selection buttons to select all
variants, and to cancel the selection of all variants.



Case metrics filter
Article • 07/18/2023

This case-level filter can be used to filter cases based on various metrics. The case count
based on the selected metrics is visualized on the right. The number of intervals (for
example, chart detail level), can be changed by the switch. You can select different types
of metrics.

Case metric: Evaluation of the case by the selected case metric.

Event metric: Evaluation of the case when at least one or all events meet the event
metric.

Edge metric: Evaluation of the case when at least one or all edges meet the edge
metric.

In all types of metrics, you can select between standard default metrics found in the
Power Automate Process Mining desktop app and custom metrics created within the
process context.

Select the case metric
The selection of the case metric and filter values represents a simpler form of the case
metric filter.



You can select from the following types of standard metrics:

Case duration: Case duration, which is the time from case start to case finish.

Case active time: Time during which an activity was in progress in the case, which
is the total duration of all events in the case.

Case waiting time: Total time without any ongoing activity in the case.

Case utilization: Ratio of the time spent on an activity to the total duration of the
case. Maximum case utilization is 1 (100%), which means that no waiting has
occurred in the case.

Case cumulative utilization: Ratio of the total time spent on activities to the total
duration of a case.

Event count: Number of events.

Self loop count: Number of occurrences of activities in self loop.

Loop count: Number of occurrences of activities involved in loops.

Rework count: Value of rework count of all activities in the process.

Case cost: Whenever one or more finance attributes are specified during the
import process, they automatically become available as additional metrics filtering
options.

Apart from the standard metrics, the dropdown menu automatically offers all custom
metrics which meet the case metric requirements. To learn more, go to Calculation
context.

Select the event and edge metrics
Selection of event or edge metric requires additional setting to specify validity of metric
over all or at least one element (event or edge) in the case:

You can specify the filtering values in two ways. You can either enter a range of values or
use the slider. The examples in this section are valid for Event count.

To specify a range:

1. In the is in range field, enter the minimum value.

2. In the and field, enter the maximum value.



As an alternative, you can select the range of values by dragging the sliders in the
chart.

Specify values in the Expression tab
The selection options differ according to the selected metrics type.

1. Go to the Expression tab.
2. From the dropdown menu, select one of the operators (for example, Equal to).
3. Enter the value. You can select fx again to use custom metrics.



Sequence filter
Article • 07/18/2023

This case level filter applies to the sequence in which events are performed in a case.
You can use it to define the sequence in which two events with specific attribute values
are performed and to specify further requirements for the progress of events in a case.

The following screenshot shows the filter configuration in which we are only interested
in the cases where Riley started to work on a case immediately after Alex.



Define the sequence filter
The sequence filter doesn't take the waiting time into account. It takes into account only
the event start sequence.

1. From the for attribute dropdown menu, select an attribute of interest for sequence
filtering.

2. Select the an event with the attribute value in field, and then select the attribute
values for the first event in sequence in the List tab to the right. Your selections
appear in the field.

3. In the next field, specify the requirements for the chronological arrangement of
events (for example, is directly followed by).

For a list of other requirements, go to Event attribute requirements for sequence
filtering in this article.

4. Select the an event with the attribute value in field, and then select the attribute
values for the second event in sequence in the List tab to the right. Your selections
appear in the field.

5. In the next field, define other requirements for the same or different properties of
the first and second event. For example, select if the given property (attribute) is to
be the same or different.

If you leave the setting as [the same/different], this condition won't be taken into
consideration.

6. From the the values of attribute dropdown menu, select which event attribute
should have the same/different value.

7. From the and the time between the events is dropdown menu, select the time
span between the first and second event.

If you leave the first field as [shorter/longer/equal], this condition won't be taken
into consideration.

Event attribute requirements for sequence
filtering
Following are the selections and their descriptions:

Is directly followed by: Event 2 occurred immediately after event 1.



Is followed by: Event 2 occurred some time after event 1. Another event may or
may not have occurred between the two events.

Is not directly followed by: Event 2 didn't occur immediately after event 1, but it
may or may not have occurred at a later time.

Is not followed by: Event 2 didn't occur at any time after event 1.

Is parallel with: Event 2 did occur at least partly during the time of event 1.

Is not parallel with: Event 2 didn't occur any time during the time of event 1.

Is directly followed by or parallel with: Event 2 did occur immediately after event
1, or during the time of event 1.

Is followed by or parallel with: Event 2 occurred some time after event 1 or during
the time of event 1. Another event may or may not have occurred between the two
events.



End events filter
Article • 07/18/2023

Use this filter to restrict cases according to the property of the event that occurred at
the beginning or at the end of the case.

The filter in the following screenshot will only select the cases starting with the Confirm
order activity and ending with the Mark order as complete activity.

In the same way, you can create a resource-based condition (for example, if you want to
select only the cases that Anna started to deal with).

Define the end events filter
1. From the attribute dropdown menu, select which attribute is of interest when

assessing events.

2. Select the on a starting event of the single case holds any of the values field, and
then select the attribute value for the end event in the List tab to the right. Your
selections appear in the field.



Only the values that are present in the starting events of the process are available
for selection. If the attribute values of the starting event are of no interest, all
values should remain active/selected.

3. Select the and on a finishing event of the single case holds any of the values
field, and then select the attribute value for the end event in the List tab to the
right. Your selections appear in the field.

Only the values that are present in the finishing events of the process are available
for selection. If the attribute values of the finishing event are of no interest, all
values should remain active/selected.



Conflict of interests filter
Article • 07/18/2023

Use this filter to expose cases with conflict of interests. A typical example is the violation
of rules for assigning roles in performing critical tasks.

By means of the filter, you can specify two sets of events which should happen in the
process in given order and should or shouldn't have the same value of an attribute. All
events from the first group are always compared with all events from the second group.
If there is the intersection of the two groups, the filter result will always return all such
events.

The screenshot shows a situation where this filter is used to find out if there's been a
customer who was charged by the same person as the one who actually collected
payment. For this purpose, the filter is set to select all cases where these two activities
occurred and were carried out by the same person.

Define the conflict of interests filter



1. From the 2 consecutive events exist with attribute dropdown menu, select the
attribute on the basis of which the events in the case are selected.

2. Select the for the first event, values field, and then select the attribute values in
the List tab to the right. Your selections appear in the field.

3. Select the for the second event, values field, and then select the attribute values in
the List tab to the right. Your selections appear in the field.

4. From the and both events have equal value of attribute dropdown menu, select
which attribute is decisive for assessing the conflict of interests.



Event attributes filter
Article • 07/18/2023

Use this event level filter to only select those events in cases that contain/don't contain
a specific attribute value – such as only certain activities or events performed by a
certain department (for example, First line support department for ServiceDesk).

Define the event attributes filter
1. From the events in which attribute dropdown menu, select an attribute for the

filter rule.

2. Select the holds any of the values field, and then select the attribute values in the
List tab to the right. Your selections appear in the field.

Use list and expression values
There are two possibilities to define the values for filter criteria. This is done in the List
or Expression tab.

List: Available for string attributes. Select or remove values to and from the list. If
the list is long, you can use search to find specific values.

Expression: Available for both string and numeric attributes. Specify an expression
such as „Starts with", „Contains"  for string and, an expression such as „Greater
than", „Equal"  for numeric attributes.



You can also select fx to use custom metrics.



Subprocess filter
Article • 07/18/2023

Use this event level filter to „cut out"  a part of the process from all the cases. Where
the criteria for the subprocess doesn't apply, the case is completely excluded. For
example, in a purchase order approval process, you want to focus on the part from
purchase order creation until the purchase order is marked as approved. Another
example is, in a service center ticket solving process, you want to see only the part being
dealt with by the second level support department.

The following screenshot depicts the settings for the subprocess from the first
occurrence of Mark order as complete or Suggest relevant options to the last
occurrence of Notify customer that bike is ready for pickup activity.

Define the subprocess filter
In general, this filter can be defined as extracting events of each case in chronological
order from the first occurrence of event with a specific value(s) of first attribute until the
last occurrence of event with specific value(s) of second attribute.

1. From the events located between the first occurrence of event with attribute
dropdown menu, select the attribute on the basis of which the events in the case
are selected.



2. Select the having one of these values field, and then select which events belong to
the first group of events in the List tab to the right. Your selections appear in the
field.

3. Select the and the last occurrence of event having one of these values field, and
then select which events belong to the second group of events in the List tab to
the right. Your selections appear in the field.

Use list and expression values
There are two possibilities to define the values for filter criteria. This is done in the List
or Expression tab.

List: Available for string attributes. Select or remove values to and from the list. If
the list is long, you can use search to find specific values.

Expression: Available for both string and numeric attributes. Specify an expression
such as „Starts with", „Contains"  for string and, an expression such as „Greater
than", „Equal"  for numeric attributes.

You can also select fx to use custom metrics.



Event metrics filter
Article • 07/18/2023

Use this event level filter to filter events based on various metrics. Only event metrics are
applicable here.

Specify metrics values
You can specify the filtering values in different ways. Value selection depends on the
type of selected metric.

When specifying the range in the is in range/and fields, you can enter the minimum and
maximum values. Alternatively, you can select the range of values by using the sliders in
the chart.

The selection options differ according to the selected metrics type.

To define the values using an expression, select the Expression tab, select one of the
available operators (for example, Equal to) and enter the value. You can also select fx to
use custom metrics.

Create a custom metric



You can choose between standard default metrics found in the Power Automate Process
Mining desktop app and custom metrics created in the process context. To create a
custom metric, select (...) > Add.



Export and import filters
Article • 07/18/2023

The Power Automate Process Mining desktop app offers an option to export existing set
of filters in the view and re-use them in another view or process. To export or import
filters, select (...) in the menu at the top of the Filtering screen.

Filter export
Filter export saves filter definitions into a file on a disk. The file extension is mfltr. The
exported file can be re-used by another user on different Process Mining desktop app
installation.

All the filter types are exportable, except for the variant filters which are dependent on
the actual data set (Variant 1 in two different processes may mean totally different
process variants). Only enabled view filters are exported, so it's possible to manage the
set of filters for export without deleting any filter.

Filter import
Filter import enables you to load previously exported filters and apply them into the
current view. As filters might contain references to attributes or custom metrics which
aren't available in the current view (process), there's a mapping wizard for filter import.
It helps align the filter definition with the actual process data structure and definitions.

There are three categories of filters in terms of import mappings:

No dependencies to data structure
Attribute references
Custom metric references

No dependencies to data structure



In some cases, filters don't depend on the actual data structure but on the reference to
general metrics like case duration, case start, or end time. Such filters are valid in all
processes and no mapping activity is needed during the filter import.

Attribute references
A filter using references to process attributes requires the user mapping of which
attribute in the active process will be used instead of the original one saved in the filter.
For example, the original attribute filter might be using "CostCenter Code" attribute.
Such attribute doesn't exist in the current process, but if you're using mapping
to "CC.Code" attribute, the imported filter will be valid using reference to new attribute.

If straightforward mapping between attributes isn't possible, the option to delete
attribute reference is available. After such import, the filter will be saved in the view with
a missing reference to any attribute.

The Process Mining desktop app notifies you of the missing attribute reference and the
filter is marked with asterisk.

The filter definition is saved in the view, but all the original values from filter are lost, just
as is the missing attribute reference. You'll need to assign the relevant attribute and
relevant filter values to create working filter again.

Custom metrics references
Filters using references to custom metrics require two-step mapping. First, you need to
map the custom metric, then the referenced attributes within the custom metric. The
attributes mapping is the same as previously described. Custom metric mapping offers
three options:

Custom metric mapping to existing one.
Create new custom metric.
Delete custom metric reference.

Custom metric mapping to existing one
If there's a custom metric in the current process which can be replaced with the original
one, you can map these two custom metrics. The imported filter will contain a reference
to the existing custom metric in the active process.

Create a new custom metric



If you're able to recreate an original custom metric using attributes from the active
process, you can select the NEW option. In the first step, the name of the new custom
metric is confirmed. To see what attributes need to be mapped, the custom metric
formula may be displayed in the mapping wizard panel.

If the custom metric doesn't contain reference to any process specific attribute, this is
the end of mapping wizard. If the custom metric is referencing a process-specific
attribute like "CostCenter Code", in next step, you need to map the used attributes in
the original custom metric to the attributes in the active process. Notice that the
attribute mapping is the only available operation. The custom metric formula isn't
updated in any other way.

The filter is imported using reference to newly created custom metric and is ready to
use.

If you select to create a new custom metric, yet are unable to map referenced attributes
in the custom metric, the filter import isn't possible. The option to delete the attribute
reference works only for attributes mapping. For attributes mapping, it's possible to
delete attribute reference, but not for a new custom metric. In such a situation, the
creation of new custom metric is stopped and you're not able to import the filter.

Delete a custom metric reference
The last option is to delete reference to the custom metric in original filter.

The Process Mining desktop app notifies you of the missing custom metric reference in
the filter. In the filter, the original custom metric reference is empty. Also, the filter
values are lost. Until a new metric and filter values are selected by the user, the filter isn't
valid.



Settings overview
Article • 07/18/2023

The Settings in options allow you to set the general options and default configuration
of the Power Automate Process Mining desktop app, define the working hours calendar
templates, and update the application or license.

Set options
Change various settings in the Process Mining desktop app.

1. On the title bar, select the gear icon > Options.

2. Select you settings.

3. Select Save.

Unsaved changes are indicated by an asterisk next to the section name.

To learn about the Options tabs, go to Application settings.



Set task history
View the history of performed tasks such as publish to Power BI or data export from a
view.

1. On the title bar, select the gear icon > Tasks history.

2. To show or hide task history details, turn the Task history slider off or on.

3. Select Save.



If a task couldn't be completed, select Retry to restart. Alternatively, you can edit its
parameters before restart by selecting Edit. You can also display the result of the task by
selecting View result.

Set working hours
The Working hours screen allows you to define calendar templates that can be applied
to process views in order to influence the performance analysis calculation. The default
setting is 24 hours, 7 days per week.

1. On the title bar, select the gear icon > Working hours.

2. To create a new template of working hours, select Create new calendar template.

To learn about the Calendar template tabs, go to Working hours.

3. In the General tab, enter a name in the Template name field.

4. In the Working week and Non-working days tabs, customize your new calendar.

5. Select Save.

To delete a calendar, select the ellipses (...) > Delete.

If you have an existing calendar and want to make a new calendar based on it, select the
ellipses (...) > Create duplicate. This way, you don't need to create a calendar from
scratch.

To learn more, go to Working hours.

About
Display the Process Mining desktop app version information.



1. On the title bar, select the gear icon > About.

2. When you're done, select Close.



Application settings
Article • 12/17/2024

You can change the application settings in the Options tab.

Change general settings: In the General tab, change general settings such as the
user interface language or set where the exported files are stored. You can also
define the default duration format used for newly created processes and views.
Learn more in View settings.

Change viewing preferences: In the Process explorer tab, change the default
settings for view creation processes. These settings are used whenever you create a
new process view.

Change process map and social chart settings: In the Process map tab, change
the default settings for displaying the process map and social graphs, such as
spacing between nodes, displaying the start and end nodes, or chart alignment.
These settings are used whenever you create a new process view.

Change process animation settings: In the Animation tab, change settings for
process animation. These settings are used as default, whenever you create a new
process view.

Keep and analyze process model in cloud
(preview)
[This article is prerelease documentation and is subject to change.]

You can decide if the desktop application downloads the process model to your client
computer and analyzes it locally, or keeps and analyzes it in the cloud. The second
option allows you to eliminate limitations on your local hardware resources. It also
allows you to analyze process models that are beyond your local computer capacity.

） Important

This is a preview feature.
Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.



To choose this option, follow these steps:

1. In the checkbox next to Keep process model in the cloud (preview), place a
checkmark.

2. Select Save.
3. Restart the application as prompted.



When you check the option, the following sections are made hidden and not relevant
after the application restart:

Data storage location
Automatic download process data

Related information
Settings overview

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Working hours
Article • 07/18/2023

The Working hours tab allows you to define calendar templates, which can be applied
to process views in order to influence the performance analysis calculation. The default
setting is 24 hours, 7 days per week.

You can define a new calendar template by selecting Create new calendar template in
the upper right corner. You can also define a new calendar by duplicating an existing
calendar by selecting the ellipses (...) > Create duplicate to the right of the calendar
template name.

To edit the calendar template, select the template name. After you make changes,
remember to select Save.

Define basic parameters
On the General tab, define basic parameters.

Template name: The name of the calendar template.

Calendar type: You can choose from two options, which influence how calendar
template influences the performance calculations, when applied to the process
view.

Resource specific (nodes only): The calendar template is applied only to work
performed by resources (activities/nodes) in the process map (relevant for event
logs with two timestamps). Waiting times between activities are calculated on a
24 hour, seven days a week basis.

SLA specific (nodes and edges): The calendar template is applied to both
activities and edges (relevant for all event logs). Both active and waiting time are
recalculated with the applied calendar template configuration.

Define your working week time
On the Working week tab, define the structure of your working time during a standard
working week.

Calendar type: Specify the behavior of the working time setting controls:

Mo, Tu, We, Th, Fr, Sa, Su: Time for each working day is set separately.



Mo-Fr, Sa, Su: Monday through Friday share the same settings. Time for
Saturday and Sunday is set separately.

Mo-Su: Monday through Sunday share the same settings.

Working/not working: To set the specific day as non-working, uncheck the
Working checkbox on the right side of the item. To set the working time, drag the
left and right side of the blue slider corresponding to the respective working day.

Define your non-working days
On the Non-Working days tab, define special non-working days such as bank holidays,
national holidays, or company specific holidays.

There are two main types of non-working days:

Recurring: Non-working for each year, regardless of where you set it.

Non-recurring: Non-working only for the respective year.

To set the days as working or non-working, select the desired day or range of days
in the calendar view and select the relevant item below the calendar.

To switch the displayed year, select the arrows next to the year label above the
calendar view.

Holidays: Simplify the definition of bank and national holidays by importing them
all at once. To initialize the import, select Import holidays below the calendar view.
A window opens where you can choose the specific calendar and specify the year
range. The Power Automate Process Mining desktop app automatically sets
holidays for the defined range. You can import as many countries as needed.

If you imported a set of holidays by mistake, you can delete them from the
calendar template by selecting Remove holidays below the calendar view.

See also
Settings overview



Custom metrics overview
Article • 07/18/2023

Custom metrics (also known as calculated metrics) allow you to use the following to
define your own custom metrics:

Pre-defined metrics in the application.

Different aggregations, mathematical, datetime, string, and other operations.

Functions and constants in a formula editor.

It's then possible to visualize them in the process map or according to their context in
other parts of the application in a similar way as the static ones.

If you already have custom metrics defined, you see a list in the Process context screen.
To view the formula for a custom metric, select the right arrow next to its name. The
arrow turns into a down arrow.

Define a custom metric
Define custom metrics in the context of the current process. They can be used and
evaluated only if they're valid in the particular context.

1. In the Processes screen, select a process.

2. On any screen selected from the left panel, select Process context on the menu at
the top-right.

3. Select Create new custom metric.

4. In the Custom metric name field, enter a name.

5. In the Metric formula field, write your formula.

The editor offers full syntax editing features including the following:



Syntax highlighting

Intellisense with function overload hints

Formula validation - syntax errors, datatype issues

Resulting metrics data type identification

6. Select Save.

7. Select a Metric type to see further details to verify the applicability of the
expression for various functions.

To learn more about the requirements for using custom metrics for various
purposes, go to Requirements for application.

Apply a custom metric to a process map
The process map visualization will adjust to the selected metric based on the context
and datatype you select, and show the calculated values.

1. On the panel to the right, select the Customize (the first icon).

2. On the toolbar in the Customize panel, select Custom (the fx icon).

3. Below the toolbar, select the desired metrics from the dropdown menus.



The top dropdown menu is used for selecting the custom metric on the activities
and the bottom one for edges. The link icon in between will lock the metric for
activities and edges to show the same metric for both elements.

Use the ellipses (...) next to the dropdown menu to add a new custom metric to
process context, edit the formula of the selected metric, or delete it.

Apply a custom metric to filters
You can use custom metrics for all types of filters except for Timeframe, Edge
(conditional), and Variants.

To enter a custom metrics formula:

1. Select or add a filter in the Add filter dropdown menu.

2. Select the filter setting you want to define (for example, for the Attributes filter).

3. Select the holds any of the values field.

4. Select the Expression tab.

5. Select the appropriate operator (for example, select Equal to), and then select fx to
enter a custom metrics formula in the Expression field.

The editor supports syntax highlighting, intellisense, and formula validation.

For the Metrics filter type, you can also apply custom metrics stored in the process
context or create a new one.

6. To select existing custom metrics, use the metric dropdown menu. Custom metrics
are available at the end of the list.

7. To create a new custom metric, select (...) next to the metric dropdown menu and
select Add.

This opens the standard custom metrics editor (see previous step). You can also
edit and delete existing custom metrics here.

Use a custom metric in the Statistics view
Once a custom value or case type metric is defined in the process map, it also becomes
available in the Statistics view as a new column. It also can be visualized in the graph.



Use a custom metric in root cause analysis
(RCA)
Custom metrics that return values on case level can be used in RCA either as a main
metric, or in the influenced by section. Supported custom metrics are any returning
numerical, time, or boolean value and metrics returning string values with less than 50
unique values for the data used in RCA.

Custom metrics can be also created in RCA settings screen by selecting (...) next to the
main metric in the Metric field.



Tips and examples
Article • 07/18/2023

Metric formula
Define the metric formula in a text form. It can consist of predefined operations.

Individual operations are divided into two basic groups:

Aggregation operations: Input of aggregation operation is a set of values for
which the resulting value will be calculated (for example, average, maximum, and
more).

Scalar operations: The input of scalar operation is one or more values for which
the resulting value will be calculated (for example, absolute value of the number,
obtaining part of the tax, and more).

Operations can use constants, can be combined using unary or binary operators (for
example, addition, subtraction, and more), or be nested.

Scalar operations also include operations to obtain a value, either directly available in
the form of an attribute or in the form of derived statistics (event duration).

Some operations also support specifying the context for which the operation is
evaluated. This is important for aggregation operations that can aggregate values, for
example, only for a specific activity, or for all activities or events. The implicit context
resulting from the metric context or the parent operation context is also supported.

A metric formula can return one of the supported data types. Data types for specific
formulas are defined in this article next to the formula syntax definition.

Aggregation operations
Aggregation operations are the basis of each metric. The most commonly used
aggregation operations are:

COUNT: Returns the number of aggregated values ( incl. COUNTIF, COUNTUNIQUE ).
SUM: Returns the sum of aggregated values ( incl. SUMIF ).
AVG: Returns the average of aggregated values.
MIN: Returns the minimum of aggregated values.
MAX: Returns the maximum of aggregated values.



The voluntary parameter of the aggregation operations will be the operation context
and the scalar operation for modification of the input value. The complete list of
supported calculation contexts is described in Calculation context.

Scalar operations
The purpose of scalar operations is to get one value and its transformation to the
desired state. Currently supported operations can be divided into several types:

Mathematical: Includes operations to obtain the absolute value of a number,
rounding, and more.
Date and Time: -Includes operations to work with the date, such as getting part of
the date, adding up dates, and more.
String: - Includes operations to work with string data, such as getting a substring,
splitting strings, and more.
Statistical: Includes operations to get different statistics such as number of cases,
case waiting time, and more.
Other: Includes other operations, for example, operations accessing event, case,
derived statistics, and more.

Attribute names
If an attribute name is used as a parameter for operation, there are three ways for how
to reference it:

Use the attribute name directly (for example, Resource ).

Use the GETVALUE("attribute name") operation (for example,
GETVALUE("Resource") ).

Use the shortened attribute name directly (for example, attribute "Resource ID"
might be referenced as ResourceID ).

The second form is used when the attribute name doesn't fulfill the naming convention.
The attribute naming convention is defined as following:

The Attribute name should start with a letter character or underscore.

The Attribute name can contain only characters from the following Unicode
standard classes: letter character (Lu, Ll, Lt, Lm, Lo, or Nl), combining character (Mn
or Mc), decimal digit character (Nd), connecting character (Pc), or formatting
character (Cf).



For information on the Unicode character classes mentioned above, see The
Unicode Standard, Version 3.0, section 4.5.

The third form is used optionally when the attribute name fulfills the naming
convention, but also contains space characters. Instead of using the second form
GETVALUE("attribute name" ), it's possible to remove space characters and use the
shortened version, attributename . Both forms are equivalent.

Examples of VALID attribute names
DocumentCategory

DocCat

DocCat23

Examples of INVALID attribute names
Document.Category

Document Category

23DocCat

Metric formula examples
To calculate the relative duration of activity in a map:

AVG (DURATION()) / AVG (VIEWCASES, DURATION())



Requirements for application
Article • 04/16/2024

Custom metrics can be applied in Process map, Statistics, and Filtering. You can see
where your metrics are applicable directly on the editor screen.

The sections in this article list the specific requirements for their application.

Process map
Following are the requirements for the process map metric type:

Node: Requires aggregation. Uses event context functions. For example, standard
total count metric can be implemented via custom metric
expression  COUNT(EventsPerAttribute)

Edge: Requires aggregation and functions valid for edges. It's not possible to
access the values of event-level attributes. The standard calculation for total count
per edges with custom metric is  Count(EdgesPerAttribute)

Statistics
Following are the requirements for the statistics metric type:

Event Level Attribute: Requires aggregation. Uses event context functions. For
example,  AVG(AllInView,DURATION())  returns the average duration of all
activities/edges.

Case Level Attribute: Requires aggregation. Uses case context functions. It's not
possible to access the values of event-level attributes. For
example,  AVG(CaseEvents, PriceUSD)  returns the average value of the
attribute PriceUSD.

Case Duration Influence: Requires aggregation. Uses case context functions. It's
not possible to access the values of event-level attributes. For
example,  AVG(CasesPerAttribute,DURATION())  returns the average duration of cases
for selected case level attribute value.

Case Overview: Aggregation isn't needed since Case Overview displays results per
individual cases. Uses functions valid for cases. If you want to calculate statistics of
all cases and use them in a metric, you need to define the scope of aggregation.



For example,  DURATION()/AVG(ViewCases,DURATION())  returns the ratio between the
specific case duration to the average case duration.

Edges: Requires aggregation and functions valid for edges. It's not possible to
access the values of event-level attributes. For example,
AVG(AllInView,START())  returns the average start date for a given edge.

Filter
Following are the requirements for the filter metric type:

Attribute Conditional (event-level attribute): The requirements are the same as
for Statistics - Event Level Attribute.

Attribute Conditional (case-level attribute): The requirements are the same as
for Statistics - Case Level Attribute.

Edge Conditional: The requirements are the same as for Statistics - Edges.

Metric: The requirements are the same as for Statistics - Case Overview.

Root Cause Analysis
Following are the requirements for the process root cause analysis metric type:

RCA: The requirements are the same as for Statistics - Case Overview in the Statistics
section in this article.



List of data types for custom metrics
Article • 03/10/2025

The following table lists the data types for custom metrics.

７ Note

These operations are available in Power Automate Process Mining desktop app
only. They aren't available in other parts of Power Automate, which use Power Fx
operations.

ﾉ Expand table

Data Description Allowed value range
type

INT Integer -9,223,372,036,854,775,808 -
9,223,372,036,854,775,807

FLOAT Real numbers, value with a ±5.0 × 10−324 - ±1.7 × 10308 with precision
fractional value ~15-17 digits

BOOL True/False True, False

STRING String

DATE Date and Time 1.1.0001 00:00:00 - 31.12.9999 23:59:59

TIME Time Interval -10675199.02:48:05.4775808 -
10675199.02:48:05.4775807

Feedback
Was this page helpful?  Yes  No

Provide product feedback



List of constants
Article • 03/10/2025

The following table lists the constants in the Power Automate Process Mining desktop
app.

７ Note

These operations are available in Power Automate Process Mining desktop app
only. They aren't available in other parts of Power Automate, which use Power Fx
operations.

ﾉ Expand table

Constant Data type Description

PI FLOAT Mathematical constant π = 3.14159265358979

E FLOAT Euler's number e = 2.71828182845905

Feedback
Was this page helpful?  Yes  No

Provide product feedback



List of unary and binary operators
Article • 03/10/2025

The following tables describe unary and binary operators.

７ Note

These operations are available in Power Automate Process Mining desktop app
only. They aren't available in other parts of Power Automate, which use Power Fx
operations.

Unary operators
The following table describes unary operators.

ﾉ Expand table

Operator Description Input Output
data type data type

+x Returns the value x INT, INT, FLOAT,
FLOAT, TIME
TIME

-x Returns negation of the value x (its opposite value) INT, INT, FLOAT,
FLOAT, TIME
TIME

!x Returns negation of the value x (produces a value of true BOOL BOOL
when its operand is false and a value of false when its
operand is true)

Binary operators
The following table describes binary operators.

ﾉ Expand table

Operator Description Input data type Output data type

x + y Adds the arguments INT, FLOAT, DATE, INT + INT = INT, INT + FLOAT =
TIME FLOAT, FLOAT + INT = FLOAT, FLOAT +



Operator Description Input data type Output data type

FLOAT = FLOAT, DATE + TIME = DATE,
TIME + TIME = TIME

x - y Subtracts the INT, FLOAT, DATE, INT - INT = INT, INT - FLOAT = FLOAT,
arguments TIME FLOAT - INT = FLOAT, FLOAT - FLOAT

= FLOAT, DATE - DATE = TIME, DATE -
TIME = DATE, TIME - TIME = TIME

x * y Multiplies the INT, FLOAT, TIME INT * INT = INT, INT * FLOAT = FLOAT,
arguments FLOAT * INT = FLOAT, FLOAT * FLOAT

= FLOAT, TIME * INT = TIME, INT *
TIME = TIME, TIME * FLOAT = TIME,
FLOAT * TIME = TIME

x / y Divides the arguments INT, FLOAT, TIME INT / INT = INT, INT / FLOAT = FLOAT,
FLOAT / INT = FLOAT, FLOAT / FLOAT
= FLOAT, TIME / TIME = FLOAT, TIME /
FLOAT = TIME, TIME / INT = TIME,

x % y Finds the remainder INT, FLOAT, TIME INT % INT = INT, INT % FLOAT =
after division of x by y FLOAT, FLOAT % INT = FLOAT, FLOAT

% FLOAT = FLOAT, TIME % TIME =
TIME

x == y Returns TRUE only if x INT, FLOAT, BOOL, BOOL
is equal to y, else STRING,DATE,
returns FALSE TIME

x != y Returns TRUE only if x INT, FLOAT, BOOL, BOOL
is NOT equal to y, else STRING,DATE,
returns FALSE TIME

x > y Returns TRUE only if x INT, FLOAT, DATE, BOOL
is greater than y, else TIME
returns FALSE

x >= y Returns TRUE only if x INT, FLOAT, DATE, BOOL
is greater than OR TIME
equal to y, else returns
FALSE

x < y Returns TRUE only if x INT, FLOAT, DATE, BOOL
is less than y, else TIME
returns FALSE

x <= y Returns TRUE only if x INT, FLOAT, DATE, BOOL
is less than OR equal to TIME
y, else returns FALSE



Operator Description Input data type Output data type

x && y Returns TRUE only if BOOL BOOL
BOTH x and y are
TRUE, else FALSE

x | | y Returns TRUE if either x BOOL BOOL
OR y is TRUE, else
FALSE

Feedback
Was this page helpful?  Yes  No

Provide product feedback



List of aggregations
Article • 03/10/2025

This article describes the aggregations you can use in custom metrics.

７ Note

These operations are available in Power Automate Process Mining desktop app
only. They aren't available in other parts of Power Automate, which use Power Fx
operations.

AVG([context],[value])
Calculates the average of values grouped according to the [context].

[context]: The context in which the operation is calculated

[value]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, DATE, TIME

Output data type: FLOAT, DATE, TIME

AVGIF([context],[condition],[value],[default])
Calculates the average of values that meet the [condition], grouped according to the
[context].

[context]: The context in which the operation is calculated (supported: process,
case, event, edge)

[condition]: The condition under which the [value] is included in the calculation

Data type: BOOL

[value]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, DATE, TIME

[default]: Default value returned by operator when no element in defined [context]
meets the [condition]



Data type: INT, FLOAT, DATE, TIME

Output data type: INT, FLOAT, DATE, TIME

Example: AVGIF(ViewEvents, userName == "Laura", eventCost)

Custom metric can be used anywhere in the application. Returns the average event cost
for events associated with the user "Laura".

COUNT([context])
Counts the number of values grouped according to the [context].

[context]: The context in which the operation is calculated

Output data type: INT

COUNTIF([context],[condition],[default])
Counts the number of values fulfilling the [condition], grouped according to the
[context].

[context]: The context in which the operation is calculated

[condition]: The condition under which the [value] is included in the calculation

Data type: BOOL

[default]: Default value returned by operator when no element in defined [context]
meets the [condition]

Data type: INT

Output data type: INT

COUNTUNIQUE([context],[value])
Counts the number of unique values, grouped according to the [context].

[context]: The context in which the operation is calculated

[value]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, BOOL, STRING, DATE, TIME



Output data type: INT

COUNTUNIQUEIF([context],[condition],[value],
[default])
Counts the number of unique [value] that meet the [condition], grouped according to
the [context].

[context]: The context in which the operation is calculated

[condition]: The condition under which the [value] is included in the calculation

Data type: BOOL

[value]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, TIME

[default]: Default value returned by operator when no element in defined [context]
meets the [condition]

Data type: INT

Output data type: FLOAT, TIME

MAX([context],[value])
Returns the maximum of [value], grouped according to the [context].

[context]: The context in which the operation is calculated

[value]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, DATE, TIME

Output data type: INT, FLOAT, DATE, TIME

MAXIF([context],[condition],[value],[default])
Returns the maximum of [values] that meet the [condition], grouped according to the
[context].

[context]: The context in which the operation is calculated



[condition]: The condition under which the [value] is included in the calculation

Data type: BOOL

[value]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, TIME

[default]: Default value returned by operator when no element in defined [context]
meets the [condition]

Data type: INT, FLOAT, DATE, TIME

Output data type: FLOAT, TIME

MAXVAL([context],[value1],[value2])
Selects item with maximum value from [value1] and returns its calculated value defined
by [value2], grouped according to the [context].

[context]: The context in which the operation is calculated (supported: process,
case, event, edge)

[value1]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, TIME, DATE

[value2]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, STRING, TIME, DATE

Output data type: INT, FLOAT, STRING, TIME, DATE

Example: MAXVAL(EventsPerAttribute, Duration(), userName)

Can be used on the process map Returns the username of a user who worked on the
longest event per activity.

MAXVALIF([context],[condition],[value1],
[value2],[default])
Selects item with the maximum value defined by [value1] that meets the [condition] and
returns its calculated value defined by [value2], grouped according to the [context].



[context]: The context in which the operation is calculated (supported: process,
case, event, edge)

[condition]: The condition under which the [value1] is included in the calculation

Data type: BOOL

[value1]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, DATE, TIME

[value2]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, STRING, TIME, DATE

[default]: Default value returned by operator when no element in defined [context]
meets the [condition]

Data type: INT, FLOAT, DATE, TIME

Output data type: INT, FLOAT, STRING, TIME, DATE

MIN([context],[value])
Returns the minimum of [value], grouped according to the [context].

[context]: The context in which the operation is calculated

[value]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, DATE, TIME

Output data type: INT, FLOAT, DATE, TIME

MINIF([context],[condition],[value],[default])
Returns the minimum of [value] that meets the [condition], grouped according to the
[context].

[context]: The context in which the operation is calculated

[condition]: The condition under which the [value] is included in the calculation

Data type: BOOL

[value]: An attribute name, nested operation, or expression



Data type: INT, FLOAT, TIME

[default]: Default value returned by operator when no element in defined [context]
meets the [condition]

Data type: INT, FLOAT, DATE, TIME

Output data type: FLOAT, TIME

MINVAL([context],[value1],[value2])
Selects item with the minimum value defined by [value1] and returns its calculated value
defined by [value2], grouped according to the [context].

[context]: The context in which the operation is calculated (supported: process,
case, event, edge)

[value1]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, DATE, TIME

[value2]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, STRING, TIME, DATE

Output data type: INT, FLOAT, STRING, TIME, DATE

MINVALIF([context],[condition],[value1],
[value2],[default])
Selects item with the minimum value defined by [value1] that meets the [condition] and
returns its calculated value defined by [value2], grouped according to the [context].

[context]: The context in which the operation is calculated (supported: process,
case, event, edge)

[condition]: The condition under which the [value1] is included in the calculation

Data type: BOOL

[value1]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, DATE, TIME

[value2]: An attribute name, nested operation, or expression



Data type: INT, FLOAT, STRING, TIME, DATE

[default]: Default value returned by operator when no element in defined [context]
meets the [condition]

Data type: INT, FLOAT, DATE, TIME

Output data type: INT, FLOAT, STRING, TIME, DATE

RANGE([context],[value])
Returns the range (maximum-minimum) of [value], grouped according to the [context].

[context]: Defines the context in which the operation is calculated

[value]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, DATE, TIME

Output data type: INT, FLOAT, TIME

RANGEIF([context],[condition],[value],[default])
Returns the range (maximum-minimum) of [value] that meets the [condition], grouped
according to the [context].

[context]: The context in which the operation is calculated

[condition]: The condition under which the [value] is included in the calculation

Data type: BOOL

[value] - An attribute name, nested operation, or expression

Data type: INT, FLOAT, TIME

[default]: Default value returned by operator when no element in defined [context]
meets the [condition]

Data type: INT, FLOAT, DATE, TIME

Output data type: FLOAT, TIME

STDEV([context],[value])



Calculates the standard deviation of [value], grouped according to the [context].

[context]: The context in which the operation is calculated

[value]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, DATE, TIME

Output data type: FLOAT, TIME

STDEVIF([context],[condition],[value])
Calculates the standard deviation of [value] that meets the [condition], grouped
according to the [context].

[context]: The context in which the operation is calculated

[condition]: The condition under which the [value] is included in the calculation

Data type: BOOL

[value]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, TIME

[default]: Default value returned by operator when no element in defined [context]
meets the [condition]

Data type: INT, FLOAT, DATE, TIME

Output data type: FLOAT, TIME

SUM([context],[value])
Calculates the sum of [value], grouped according to the [context].

[context]: The context in which the operation is calculated

[value]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, TIME

Output data type: FLOAT, TIME

SUMIF([context],[condition],[value],[default])



Calculates the sum of [value] that meets the [condition], grouped according to the
[context].

[context]: The context in which the operation is calculated

[condition]: The condition under which the [value] is included in the calculation

Data type: BOOL

[value]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, TIME

[default]: Default value returned by operator when no element in defined [context]
meets the [condition]

Data type: INT, FLOAT, DATE, TIME

Output data type: FLOAT, TIME

FIRST([context],[value])
Returns the first [value], grouped according to the [context].

[context]: The context in which the operation is calculated

[value]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, TIME

Output data type: FLOAT, TIME

FIRSTIF([context],[condition],[value],[default])
Returns the first [value] that meets the [condition], grouped according to the [context].

[context]: The context in which the operation is calculated

[condition]: The condition under which the [value] is included in the calculation

Data type: BOOL

[value]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, TIME, STRING

[default]: Value to be returned, when condition is not met



Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

Output data type: BOOL, INT, FLOAT, STRING, DATE, TIME

LAST([context],[value])
Returns the last [value], grouped according to the [context].

[context]: The context in which the operation is calculated

[value]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, TIME

Output data type: FLOAT, TIME

LASTIF([context],[condition],[value],[default])
Returns the last value that meets the [condition], grouped according to the [context].

[context]: The context in which the operation is calculated

[condition]: The condition under which the [value] is included in the calculation

Data type: BOOL

[value]: An attribute name, nested operation, or expression

Data type: INT, FLOAT, TIME

[default]: Value to be returned, when condition is not met

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

Output data type: BOOL, INT, FLOAT, STRING, DATE, TIME

SELFLOOP([context],[attributeName])
Calculates a count of self-loop events, grouped according to the [context]; short version
of COUNTIF(ISSELFLOOP()) expression.

[context]: The context in which the operation is calculated

[attributeName]: An attribute name; if no attribute is defined, the current activity
(mining) attribute is used



Data type: STRING

Output data type: INT

LOOP([context],[attributeName])
Calculates a count of loop events, grouped according to the [context]; short version of
COUNTIF(ISLOOP()) expression.

[context]: The context in which the operation is calculated

[attributeName]: An attribute name; if no attribute is defined, the current activity
(mining) attribute is used

Data type: STRING

Output data type: INT

REWORK([context],[attributeName])
Calculates a count of rework events, grouped according to the [context]; short version of
COUNTIF(ISREWORK()) expression.

[context]: The context in which the operation is calculated

[attributeName]: An attribute name; if no attribute is defined, the current activity
(mining) attribute is used

Data type: STRING

Output data type: INT

LOOPINFLOW([context],[attributeName])
Calculates a count of loop inflows, grouped according to the [context]; short version of
COUNTIF(ISLOOPINFLOW()) expression.

[context]: The context in which the operation is calculated

[attributeName]: An attribute name; if no attribute is defined, the current activity
(mining) attribute is used

Data type: STRING



Output data type: INT

LOOPOUTFLOW([context],[attributeName])
Calculates a count of loop outflows, grouped according to the [context]; short version of
COUNTIF(ISLOOPOUTFLOW()) expression.

[context]: The context in which the operation is calculated

[attributeName]: An attribute name; if no attribute is defined, the current activity
(mining) attribute is used

Data type: STRING

Output data type: INT

NETLOOPGAIN([context],[attributeName])
Calculates the sum of loop gains, grouped according to the [context]; short version of
SUM(LOOPGAIN()) expression.

[context]: The context in which the operation is calculated

[attributeName]: An attribute name; if no attribute is defined, the current activity
(mining) attribute is used

Data type: STRING

Output data type: INT

MODE([context],[value])
Returns the most common [value] from [context].

[context]: The context in which the operation is calculated

[value]: An attribute name, nested operation, or expression

Data type: STRING, INT, FLOAT, DATE, TIME, BOOL

Output data type: STRING, INT, FLOAT, DATE, TIME, BOOL

MODEIF([context],[condition],[value],[default])



Returns the most common [value] from data elements that meet the [condition] in the
[context].

[context]: The context in which the operation is calculated

[condition]: The condition under which the [value] is included in the calculation

[value]: An attribute name, nested operation, or expression

Data type: STRING, INT, FLOAT, DATE, TIME, BOOL

[default]: Default value returned by operator when no element in defined [context]
meets the [condition]

Data type: INT, FLOAT, DATE, TIME

Output data type: STRING, INT, FLOAT, DATE, TIME, BOOL

ALL([context],[condition])
Returns true if all values, grouped according to the [context], meet the [condition].

[context]: The context in which the operation is calculated (supported: process,
case, event, edge)

[condition]: The condition under which the [value] is included in the calculation

Data type: BOOL

Output data type: BOOL

Example ALL(CaseEvents, eventCost > 0)

Can be used on case metrics filters or case overview statistics. Returns true if all events
in the case have an event cost greater than zero.

ANY([context],[condition])
Returns true if any of the values, grouped according to the [context], meet the
[condition].

[context]: The context in which the operation is calculated (supported: case
[implicit])

[condition]: The condition under which the [value] is included in the calculation



Data type: BOOL

Output data type: BOOL

Example: ANY(CaseEvents, eventCost > 0)

Can be used on case metrics filters or case overview statistics. Returns true if any event
in the case has an event cost greater than zero.

Related information
All calculation contexts for aggregation operations

Feedback
Was this page helpful?  Yes  No

Provide product feedback



List of date and time operations
Article • 03/10/2025

７ Note

These operations are available in Power Automate Process Mining desktop app
only. They aren't available in other parts of Power Automate, which use Power Fx
operations.

TODATE([year],[month],[day])
Creates a date from specified date parts.

Parameters:- [year] - the year part of the date Data type: INT

[month] - the month part of the date Data type: INT

[day] - the day part of the date

Data type: INT

Output Data Type: DATE

TODATE([year],[month],[day],[hour],[minute],
[second],[millisecond])
Creates a date from specified date parts along with time.

Parameters:- [year] - the year part of the date

Data type: INT

[month] - the month part of the date

Data type: INT

[day] - the day part of the date

Data type: INT

[hour] - the hour part of the date



Data type: INT

[minute] - the minute part of the date

Data type: INT

[second] - the second part of the date

Data type: INT

[millisecond] - the millisecond part of the date

Data type: INT

Output Data Type: DATE

TODATE([year],[month],[day],[time])
Creates a date from specified date parts along with time.

Parameters:- [year] - the year part of the date

Data type: INT

[month] - the month part of the date

Data type: INT

[day] - the day part of the date

Data type: INT

[time] - the time part of the date

Data type: INT

Output Data Type: DATE

TOTIME([hour],[minute],[second],[millisecond])
Creates a timespan from the specified date parts.

Parameters:- [hour] - the hour part of the date

Data type: INT

[minute] - the minute part of the date



Data type: INT

[second] - the second part of the date

Data type: INT

[millisecond] - the millisecond part of the date

Data type: INT

Output Data Type: TIME

TOTIMEFROMDAYS([value])
Creates a time interval from the total number of days.

Parameters:- [value] - attribute name, nested operation, or expression to create a
timespan

Data type: INT

Output Data Type: TIME, FLOAT

TOTIMEFROMHOURS([value])
Creates a time interval from the total number of hours.

Parameters:- [value] - attribute name, nested operation, or expression to create a
timespan

Data type: INT

Output Data Type: TIME, FLOAT

TOTIMEFROMMILLIS([value])
Creates a time interval from the total number of milliseconds.

Parameters:- [value] - attribute name, nested operation, or expression to create a
timespan

Data type: INT

Output Data Type: TIME



TOTIMEFROMMINUTES([value])
Creates a time interval from the total number of minutes.

Parameters:- [value] - attribute name, nested operation, or expression to create a
timespan

Data type: INT, FLOAT

Output Data Type: TIME

TOTIMEFROMSECONDS([value])
Creates a time interval from the total number of seconds.

Parameters:- [value] - attribute name, nested operation, or expression to create a
timespan

Data type: INT, FLOAT

Output Data Type: TIME

ADDDAYS([date],[count])
Adds the specified number of days to the date / time interval.

Parameters:- [date] - a specific date to which days are added

Data type: DATE, TIME

[count] - the number of days that are added to the date

Data type: INT, FLOAT

Output Data Type: DATE, TIME

ADDHOURS([date],[count])
Adds the specified number of hours to the date / time interval.

Parameters:- [date] - a specific date to which hours are added

Data type: DATE, TIME

[count] - the number of hours that are added to the date



Data type: INT, FLOAT

Output Data Type: DATE, TIME

ADDMILLIS([date],[count])
Adds the specified number of milliseconds to the date / time interval.

Parameters:- [date] - a specific date to which milliseconds are added

Data type: DATE, TIME

[count] - the number of milliseconds that are added to the date

Data type: INT, FLOAT

Output Data Type: DATE, TIME

ADDMINUTES([date],[count])
Adds the specified number of minutes to the date / time interval.

Parameters:- [date] - a specific date to which minutes are added

Data type: DATE, TIME

[count] - the number of minutes that are added to the date

Data type: INT, FLOAT

Output Data Type: DATE, TIME

ADDMONTHS([date],[count])
Adds the specified number of months to the date / time interval.

Parameters:- [date] - a specific date to which months are added

Data type: DATE, TIME

[count] - the number of months that are added to the date, ignores fractional
values

Data type: INT, FLOAT



Output Data Type: DATE, TIME

ADDSECONDS([date],[count])
Adds the specified number of seconds to the date / time interval.

Parameters:- [date] - a specific date to which seconds are added

Data type: DATE, TIME

[count] - the number of seconds that are added to the date

Data type: INT, FLOAT

Output Data Type: DATE, TIME

ADDYEARS([date],[count])
Adds the specified number of years to the date / time interval.

Parameters:- [date] - a specific date to which years are added

Data type: DATE, TIME

[count] - the number of years that are added to the date, ignores fractional values

Data type: INT, FLOAT

Output Data Type: DATE, TIME

DATE([date])
Returns the date part of the date without a timespan.

Parameters:- [date] - the date from which the date part is returned

Data type: DATE

Output Data Type: DATE

DAY([date])
Returns the day of the month from the date.



Parameters:- [date] - the date from which the day part is returned

Data type: DATE

Output Data Type: INT

DAYOFWEEK([date])
Returns the day of the week from the date.

Parameters:- [date] - the date from which the day of the week is returned

Data type: DATE

Output Data Type: INT

DAYOFYEAR([date])
Returns the day of the year from the date.

Parameters:- [date] - the date from which the day of the year is returned

Data type: DATE

Output Data Type: INT

HOUR([date])
Returns an hour from the date.

Parameters:- [date] - the date from which the hour is returned

Data type: DATE

Output Data Type: INT

MILLISECOND([date])
Returns a millisecond from the date.

Parameters:- [date] - the date from which the millisecond is returned

Data type: DATE



Output Data Type: INT

MINUTE([date])
Returns a minute from the date.

Parameters:- [date] - the date from which the minute is returned

Data type: DATE

Output Data Type: INT

MONTH([date])
Returns a month from the date.

Parameters:- [date] - the date from which the month is returned

Data type: DATE

Output Data Type: INT

QUARTER([date])
Returns the quarter from the date.

Parameters:- [date] - the date from which the quarter is returned

Data type: DATE

Output Data Type: INT

SECOND([date])
Returns the seconds part from the date.

Parameters:- [date] - the date from which the second is returned

Data type: DATE

Output Data Type: INT

TIMEOFDAY([date])



Returns the time part of the date.

Parameters:- [date] - the date from which the time part is returned

Data type: DATE

Output Data Type: TIME

WEEKOFYEAR([date])
Returns the week number of the year from a date according to ISO 8601 standard.

Parameters:- [date] - the date from which the week number of the year according to
ISO 8601 standard is returned

Data type: DATE

Output Data Type: INT

YEAR([date])
Returns the year from the date.

Parameters:- [date] - the date from which the year is returned

Data type: DATE

Output Data Type: INT

ISLEAPYEAR([year])
Returns TRUE if the year is leap, otherwise returns FALSE.

Parameters:- [year] - the year which I'm checking whether it is a leap one or not

Data type: INT

Output Data Type: BOOL

DAYS([time])
Returns the day part from the timespan.

Parameters:- [time] - the date from which the day part is returned



Data type: TIME

Output Data Type: INT

HOURS([time])
Returns the hour part from the timespan.

Parameters:- [time] - the date from which the hour part is returned

Data type: TIME

Output Data Type: INT

MILLISECONDS([time])
Returns the millisecond part from the timespan.

Parameters:- [time] - the date from which the millisecond part is returned

Data type: TIME

Output Data Type: INT

MINUTES([time])
Returns the minute part from the timespan.

Parameters:- [time] - the date from which the minute part is returned

Data type: TIME

Output Data Type: INT

SECONDS([time])
Returns the second part from the timespan.

Parameters:- [time] - the date from which the second part is returned

Data type: TIME

Output Data Type: INT



TOTALDAYS([time])
Returns the value of the timespan expressed in whole and fractional days.

Parameters:- [time] - the date from which the timespan expressed in whole and
fractional days is returned

Data type: TIME

Output Data Type: FLOAT

TOTALHOURS([time])
Returns the value of the timespan expressed in whole and fractional hours.

Parameters:- [time] - the date from which the timespan expressed in whole and
fractional hours is returned

Data type: TIME

Output Data Type: FLOAT

TOTALMILLIS([time])
Returns the value of the timespan expressed in whole and fractional milliseconds.

Parameters:- [time] - the date from which the timespan expressed in whole and
fractional milliseconds is returned

Data type: TIME

Output Data Type: FLOAT

TOTALMINUTES([time])
Returns the value of the timespan expressed in whole and fractional minutes.

Parameters:- [time] - the date from which the timespan expressed in whole and
fractional minutes is returned

Data type: TIME

Output Data Type: FLOAT



TOTALSECONDS([time])
Returns the value of the timespan expressed in whole and fractional seconds.

Parameters:- [time] - the date from which the timespan expressed in whole and
fractional seconds is returned

Data type: TIME

Output Data Type: FLOAT

ISWORKINGHOUR([dateTime])
Returns true when time date belongs to working hours defined in the actual calendar.

Parameters:- [dateTime] - the date to be evaluated

Data type: DATE

Output Data Type: BOOL

ISWORKINGDAY([date])
Returns true when date belongs to working day defined in the actual calendar.

Parameters:- [date] - the date to be evaluated

Data type: DATE

Output Data Type: FLOAT

ISPUBLICHOLIDAY([date])
Returns true when date belongs to public holiday defined in the actual calendar.

Parameters:- [date] - the date to be evaluated

Data type: DATE

Output Data Type: FLOAT

DURATIONCALENDAR([startDate], [endDate])
Returns working time duration between two dates calculated actual calendar.



） Important

The calculations associated with the work calendar work correctly only in the range
from the start of the process minus 6 months to the end of the process plus 24
months. Calculating calendar values such as working days or working hours outside
this range will return an error and a default value. This calendar range can't be set
by you in the application and is automatically applied after each data refresh.
Parameters: - [startDate] - start date of timespan.

Data type: DATE

[endDate] - end date of timespan

Data type: DATE

Output Data Type: FLOAT

ADDWORKINGDAYS([date],[count])
Adds the specified number of working days to the date. Exact number of defined
working hours is not relevant. Any day which is marked as working day is counted as
one.

） Important

The calculations associated with the work calendar return correct results only in the
range from 6 months prior to the process start until 24 months past the process
end date. Calculating calendar values (for example, working days and working
hours) outside this range will return an error and a default value. This range is
automatically applied after each data refresh and isn't available for you to change.
Parameters: - [date] - a specific date to which days are added.

Data type: DATE

[count] - the number of working days that are added to the date

Data type: INT

Output Data Type: DATE

ADDWORKINGHOURS([date],[count])



Adds the specified number of working hours to the date.

） Important

The calculations associated with the work calendar return correct results only in the
range from 6 months prior to the process start until 24 months past the process
end date. Calculating calendar values (for example, working days and working
hours) outside this range will return an error and a default value. This range is
automatically applied after each data refresh and isn't available to change.
Parameters: - [date] - a specific date to which working hours are added.

Data type: DATE

[count] - the number of working hours that are added to the date

Data type: INT

Output Data Type: DATE

ADDWORKINGMINUTES([date],[count])
Adds the specified number of working minutes to the date.

） Important

The calculations associated with the work calendar return correct results only in the
range from 6 months prior to the process start until 24 months past the process
end date. Calculating calendar values (for example, working days and working
hours) outside this range will return an error and a default value. This range is
automatically applied after each data refresh and isn't available for you to change.
Parameters: - [date] - a specific date to which working minutes are added.

Data type: DATE

[count] - the number of working minutes that are added to the date

Data type: INT

Output Data Type: DATE

Feedback



Was this page helpful?  Yes  No

Provide product feedback



List of mathematical operations
Article • 03/10/2025

７ Note

These operations are available in Power Automate Process Mining desktop app
only. They aren't available in other parts of Power Automate, which use Power Fx
operations.

ABS([value])
Returns the absolute value of the number.

Parameters:

[value] - input value

Data type: FLOAT, INT

Output Data Type: FLOAT, INT

CEIL([value])
Returns the smallest integer greater that or equal to the given number.

Parameters:

[value] - input value

Data type: FLOAT, INT

Output Data Type: FLOAT, INT

FLOOR([value])
Returns the greatest integer smaller than or equal to the given number.

Parameters:

[value] - input value

Data type: FLOAT, INT



Output Data Type: FLOAT, INT

MAX([value1],[value2])
Returns the maximum of the given values (value1 and value2).

Parameters:

[value1] - input value

Data type: FLOAT, INT, DATE, TIME

[value2] - input value Date type: FLOAT, INT, DATE, TIME

Output Data Type: FLOAT, INT, DATE, TIME

MIN([value1],[value2])
Returns the minimum of the given values (value1 and value2).

Parameters:

[value1] - input value

Data type: FLOAT, INT, DATE, TIME

[value2] - input value

Data type: FLOAT, INT, DATE, TIME

Output Data Type: FLOAT, INT

LOG([value],[base])
Returns the logarithm of the number to the specified base.

Parameters:

[value] - input value

Data type: FLOAT, INT

[base] - base of the logarithm

Data type: FLOAT, INT



Output Data Type: FLOAT

POWER([value],[exponent])
Returns the value of the specified expression to the specified power.

Parameters:

[value] - input value

Data type: FLOAT, INT

[exponent] - specified power

Data type: FLOAT, INT

Output Data Type: FLOAT

ROUND([value],[digits])
Rounds a number to a specified number of digits.

Parameters:

[value] - input value

Data type: FLOAT, INT

[digits] - number of digits

Data type: INT

Output Data Type: FLOAT

SIGN([value])
Returns -1 if value is smaller than 0, 0 if value is 0, 1 if value is greater than 0.

Parameters:

[value] - input value

Data type: FLOAT, INT

Output Data Type: INT



SQR([value])
Calculates the square of the value (second power).

Parameters:

[value] - input value

Data type: FLOAT, INT

Output Data Type: FLOAT

SQRT([value])
Calculates the square root of the value.

Parameters:

[value] - input value

Data type: FLOAT, INT

Output Data Type: FLOAT

TRUNCATE([value])
Returns the integer part of the number (rounded to the nearest integer toward zero).

Parameters:

[value] - input value

Data type: FLOAT, INT

Output Data Type: FLOAT

Feedback
Was this page helpful?  Yes  No

Provide product feedback



List of statistical operations
Article • 03/10/2025

This article lists statistical operations in the Power Automate Process Mining desktop
app.

７ Note

These operations are available in Power Automate Process Mining desktop app
only. They aren't available in other parts of Power Automate, which use Power Fx
operations.

START()
Returns the start of a process/event/case/path.

Supported context: process, event, case, edge

Output Data Type: DATE

END()
Returns the end of a process/event/case/path.

Supported context: process, event, case, edge

Output Data Type: DATE

DURATION()
Returns the duration of a process/event/case/path.

Supported context: process, event, case, edge

Output Data Type: TIME

EVENTCOUNT()
Returns number of the events in the case/process.



Supported context: process, event

Output Data Type: INT

CASECOUNT()
Returns number of the cases in the process.

Supported context: process

Output Data Type: INT

ACTIVETIME()
Returns case active time.

Supported context: case

Output Data Type: TIME

WAITINGTIME()
Returns case waiting time.

Supported context: case

Output Data Type: TIME

ISPARALLEL()
In the case context, it returns TRUE if at least one event occurred in parallel with another
event, otherwise FALSE. In the event context, it returns TRUE if the event occurred in
parallel with another event, otherwise FALSE.

Supported context: case, event

Output Data Type: BOOL

ISPARALLELWITH([condition])
Returns TRUE if the event occurred in parallel with another event which fullfilla given
condition, otherwise FALSE.



Supported context: event

Parameters:

[condition] - condition under which is parallelism accepted

Data type: BOOLEAN

Output Data Type: BOOL

UTILIZATION()
Returns case utilization (number from 0 to 1).

Supported context: case

Output Data Type: FLOAT

PARALLELUTILIZATION()
Returns the cumulative case utilization (a number from 0 to 1 to N). A value above 1 is
due to parallel events that last longer than the case itself.

Supported context: case

Output Data Type: FLOAT

REWORKCOUNT([attributeName])
Returns the total count of all reworks (loops and self-loops) within the case.

Supported context: case

Parameters:

[attributeName] - Attribute to calculate repetitions. If none is entered, the default
attribute is mining attribute (activity attribute), optional.

Data type: STRING (only fixed string is allowed)

Output Data Type: INT

LOOPCOUNT([attributeName])



Returns count of loops within the case.

Supported context: case

Parameters:

[attributeName] - Attribute to calculate repetitions. If none is entered, the default
attribute is mining attribute (activity attribute), optional

Data type: STRING (only fixed string is allowed)

Output Data Type: INT

SELFLOOPCOUNT([attributeName])
Returns count of self-loops within the case.

Supported context: case

Parameters:

[attributeName] - Attribute to calculate repetitions. If none is entered, the default
attribute is mining attribute (activity attribute), optional

Data type: STRING (only fixed string is allowed)

Output Data Type: INT

OCCURRENCE([attributeName])
Returns occurrence index of a given event attribute value within the case.

Supported context: event

Parameters:

[attributeName] - Attribute to calculate repetitions. If none is entered, the default
attribute is mining attribute (activity attribute), optional

Data type: STRING (only fixed string is allowed)

Output Data Type: INT

ISSELFLOOP([attributeName])



Returns true when event/edge has self-loop repetition.

Supported context: event, edge

Parameters:

[attributeName] - Attribute to calculate repetitions. If none is entered, default
attribute is mining attribute (activity attribute), optional

Data type: STRING (only fixed string is allowed)

Output Data Type: BOOL

ISLOOP([attributeName])
Returns true when event/edge has loop repetition.

Supported context: event, edge

Parameters:

[attributeName] - Attribute to calculate repetitions. If none is entered, the default
attribute is mining attribute (activity attribute), optional

Data type: STRING (only fixed string is allowed)

Output Data Type: BOOL

ISREWORK([attributeName])
Returns true when event/edge has any kind of rework (self-loop or loop).

Supported context: event, edge

Parameters:

[attributeName] - Attribute name to calculate repetitions. If none is entered, the
default attribute is mining attribute (activity attribute), optional

Data type: STRING (only fixed string is allowed)

Output Data Type: BOOL

ISLOOPINFLOW([attributeName])



Returns true when event/edge has loop inflow.

Supported context: event, edge

Parameters:

[attributeName] - Attribute to calculate repetitions. If none is entered, the default
attribute is mining attribute (activity attribute), optional

Data type: STRING (only fixed string is allowed)

Output Data Type: BOOL

ISLOOPOUTFLOW([attributeName])
Returns true when event/edge has loop outflow.

Supported context: event, edge

Parameters:

[attributeName] - Attribute to calculate repetitions. If none is entered, the default
attribute is mining attribute (activity attribute), optional

Output Data Type: BOOL

LOOPGAIN([attributeName])
Returns difference between the event's loop outflow and loop inflow. Value +1 when the
event has loop outflow and no loop inflow. Value -1 when the event has no loop outflow
and loop inflow. Otherwise returns 0.

Supported context: event

Parameters:

[attributeName] - Attribute name to calculate repetitions. If none is entered, the
default attribute is mining attribute (activity attribute), optional

Data type: STRING (only fixed string is allowed)

Output Data Type: INT

MEDIAN([context],[value],[compression])



Calculates the approximate median of values grouped according to the defined context.

Supported context: process, case, event, edge

Parameters:

[context] - defines the context in which the operation is calculated

Data type: STRING (only fixed string is allowed)

[value] - value over which the median is calculated

Data type: STRING (only fixed string is allowed)

[compression] - controls the estimation accuracy and memory utilization. High
compression values increase the accuracy of estimation but make the operation
slower. The value must be between 20 and 1000, the default value is 200.

Data type: FLOAT

Output Data Type: INT, FLOAT, DATE, TIME

QUANTILE([context],[value],[q],[compression])
Calculates the approximate q-th quantile of values grouped according to defined
context. The q-th quantile of a data set is defined as that value where a q fraction of the
data is below that value and (1-q) fraction of the data above that value.

Supported context: process, case, event, edge

Parameters:

[context] - defines the context in which the operation is calculated

Data type: STRING (only fixed string is allowed)

[value] - value for evaluation

Data type: INT, FLOAT, DATE, TIME

[q] - quantile to compute, must be between 0 and 1 inclusive.

Data type: FLOAT (only constant value is allowed)

[compression] - controls the estimation accuracy and memory utilization. High
compression values increase the accuracy of estimation but make the operation
slower. The value must be between 20 and 1000, the default value is 200.



Data type: FLOAT

Output Data Type: INT, FLOAT, DATE, TIME

CDF([context],[value],[x],[compression])
Calculates the estimated cumulative distribution function (cdf) for the given value from
values grouped according to the defined context.

Supported context: case, event, edge

Parameters:

[context] - defines the context in which the operation is calculated

Data type: STRING (only fixed string is allowed)

[value] - value for evaluation for cumulative distribution.

Data type: INT, FLOAT, DATE, TIME

[x] - threshold value Data type: INT, FLOAT, DATE, TIME (need to be the same data
type as [value] parameter)

[compression] - controls the estimation accuracy and memory utilization. High
compression values increase the accuracy of estimation but make the operation
slower. The value must be between 20 and 1000, the default value is 200.

Data type: FLOAT

Output Data Type: INT, FLOAT, DATE, TIME

ISFINISHED()
Returns true when the case is categorized as finished (as defined in Process Context –
Case Categorization).

Supported context: case

Output Data Type: BOOL

ISRUNNING()



Returns true when the case is categorized as running (as defined in Process Context –
Case Categorization)

Supported context: case

Output Data Type: BOOL

ISSTUCK()
Returns true when the case is categorized as stuck (as defined in Process Context – Case
Categorization).

Supported context: case

Output Data Type: BOOL

ISINCOMPLETEIMPORT()
Returns true when the case is categorized as import incomplete (as defined in Process
Context – Case Categorization)

Supported context: case

Output Data Type: BOOL

STATS([Aggregate]*,[Type]**)
Returns calculated process statistics according to the selected aggregation and type of
statistics.

Supported context: process

Parameters:

[Aggregate] – aggregation by which the process statistics will be calculated (eg:
sum, average, minimum, maximum, range, standard deviation)

[Type] - the type of statistics used in the calculation

Output Data Type: INT, FLOAT, TIME, DATE

Types of Aggregations



Following are the allowed aggregation types:

Sum
Avg
Min
Max
Range
Stdev

Types of Statistics
ﾉ Expand table

Name Description

CaseStart Case start

CaseEnd Case end

CaseDuration Case Duration

CaseActiveTime Case Active Time

CaseWaitingTime Case Waiting Time

CaseUtilization Case Utilization

EventCount Event Count

Feedback
Was this page helpful?  Yes  No

Provide product feedback



List of string operations
Article • 03/10/2025

Following are the string operations that you can use in the Power Automate Process
Mining desktop app.

７ Note

These operations are available in Power Automate Process Mining desktop app
only. They aren't available in other parts of Power Automate, which use Power Fx
operations.

CONCAT([string1],...,[stringN])
Concatenates given strings.

Parameters:

[string1] - input string

Data type: STRING

[stringN] - last input string

Data type: STRING

Output Data Type: STRING

CONTAINS([string],[value])
Returns TRUE if the string contains the given value, else returns FALSE.

Parameters:

[string] - input string

Data type: STRING

[value] - value to be matched in input string

Data type: STRING

Output Data Type: BOOL



ENDSWITH([string],[value])
Returns TRUE if string ends with the given value, else returns FALSE.

Parameters:

[string] - input string

Data type: STRING

[value] - value to match end of input string

Data type: STRING

Output Data Type: BOOL

LEFT([string],[count])
Extracts a given number of characters from the left side of a supplied text string.

Parameters:

[string] - input string

Data type: STRING

[count] - number of characters

Data type: INT

Output Data Type: STRING

LEN([string])
Returns the length of the string.

Parameters:

[string] - input string

Data type: STRING

Output Data Type: INT

LOWER([string])



Returns a lower-case version of a given text string.

Parameters:

[string] - input string

Data type: STRING

Output Data Type: STRING

LTRIM([string])
Removes whitespace from the beginning of the string.

Parameters:

[string] - input string

Data type: STRING

Output Data Type: STRING

RIGHT([string],[count])
Extracts a given number of characters from the right side of a supplied text string.

Parameters:

[string] - input string

Data type: STRING

[count] - number of characters

Data type: INT

Output Data Type: STRING

RTRIM([string])
Removes whitespace from the end of the string.

Parameters:

[string] - input string



Data type: STRING

Output Data Type: STRING

STARTSWITH([string],[value])
returns TRUE if string starts with the given value, else returns FALSE

Parameters:

[string] - input string

Data type: STRING

[value] - value to be matched

Data type: STRING

Output Data Type: BOOL

SUBSTRING([string],[start],[count])
Returns substring from the specified start position and by the specified number of
characters.

Parameters:

[string] - input string

Data type: STRING

[start] - start position of substring

Data type: INT

[count] - length of substring

Data type: INT

Output Data Type: STRING

TOINT([string],[default])
Converts a string to an integer. Returns 0 or default value (optional) if conversion error.
occurs



Parameters:

[string] - input string to be converted

Data type: STRING

[default] - default value

Data type: INT, FLOAT

Output Data Type: INT

TOSTRING([int],[format]*)
Converts an integer to a string according to the formatting string (if an optional
parameter is specified).

Parameters:

[int] - input int value

Data type: STRING

[format]* - formatting string

Learn more about formatting strings

Data type: STRING (only fixed string is allowed)

Output Data Type: STRING

TOSTRING([float],[format]*)
Converts a float to a string according to the formatting string (if an optional parameter
is specified).

Parameters:

[float] - input float value

Data type: FLOAT

[format]* - formatting string

Learn more about formatting strings

Data type: STRING (only fixed string in allowed)



Output Data Type: STRING

TOSTRING([bool])
Converts boolean to a string - "True" or "False".

Parameters:

[bool] - input boolean value

Data type: BOOL

Output Data Type: STRING

TOSTRING([date],[format]*)
Converts a date to a string according to the formatting string (if an optional parameter
is specified).

Parameters:

[date] - input date

Data type: STRING

[format]* - formatting string applied on date

Learn more about formatting strings

Date type: STRING (only fixed string is allowed)

Output Data Type: STRING

TOSTRING([time],[format]*)
Converts a time to a string according to the formatting string (if an optional parameter
is specified).

Parameters:

[time] - input time

Data type: STRING

[format]* - formatting string applied on time



Learn more about formatting strings

Data type: STRING (only fixed string is allowed)

Output Data Type: STRING

TRIM([string])
Removes whitespace at the beginning and at the end of the string.

Parameters:

[string] - input string

Data type: STRING

Output Data Type: STRING

UPPER([string])
Returns upper-case version of a given text string.

Parameters:

[string] - input string

Data type: STRING

Output Data Type: STRING

Feedback
Was this page helpful?  Yes  No

Provide product feedback



List of other operations
Article • 03/10/2025

Following are other operations that you can use in Power Automate Process Mining.

７ Note

These operations are available in Power Automate Process Mining desktop app
only. They aren't available in other parts of Power Automate, which use Power Fx
operations.

attributeName
Returns the event/case attribute value.

Output Data Type: BOOL, INT, STRING, FLOAT, TIME, DATE

Example: MAX(eventCost)

Metric applicable on process map calculates the maximum cost of the event per activity.
Attribute name - eventCost - is case insensitive, valid formats are also for example
EVENTCost, eventcost, or EventCOST.

GETVALUE([attributeName])
Returns the event/case attribute value.

Parameters:

[attributeName] - attributeName

Data type: STRING (only fixed string is allowed)

Output Data Type: BOOL, INT, FLOAT, TIME, DATE

Example: GetValue("invoice total")

If the attribute contains space in the name, it isn't possible to write it directly as part of
the custom metric expression. In such cases, use the operator GetValue to access the
value of a given attribute.



IF([condition],[valueIfTrue],[valueIfFalse])
Returns the first or second value based on the condition.

Parameters:

[condition] - boolean value or expression

Data type: BOOL

[valueIfTrue] - value to be matched in input string

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

[valueIfFalse] - returned value if condition is not met

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

Output Data Type: BOOL, INT, FLOAT, STRING, DATE, TIME

Example: IF(EventCount() > 10, "Complex", "Simple")

Metric applicable on case overview statistics screen. If the case contains more than 10
events, the returned value is "Complex", otherwise "Simple".

SOURCE([operation])
Changes the context of the operation to initial event path (only allowed for paths).

Supported context: edge

Parameters:

[operation] - value to be returned from the initial event path

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

Output Data Type: BOOL, INT, FLOAT, STRING, DATE, TIME

Example: SUM(SOURCE(Duration())+Duration())

Metric applicable on process map calculates the sum of the initial event duration in the
path and the path duration itself.

TARGET([operation])



Changes the context of the value to ending event path (only allowed for paths).

Supported context: edge

Parameters:

[operation] - input string

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

Output Data Type: BOOL, INT, FLOAT, STRING, DATE, TIME

Example: SUM(SOURCE(Duration())+TARGET(Duration()))

Metric applicable on process map calculates total duration of path's starting and ending
events for each path.

CASE([operation])
Changes the context of the operation to case event/path (only allowed for events and
paths).

Supported context: event, edge

Parameters:

[operation] - value to be calculated on the case level of a current event or edge

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

Output Data Type: BOOL, INT, FLOAT, STRING, DATE, TIM

Example: Duration() / CASE(Duration())

Metric applicable on event-level filter calculates the ratio of event duration to case
duration.

FIRSTEVENT([operation])
Changes the context of the operation to the first event case (only allowed for cases).

Supported context: case

Parameters:

[operation] - value to be calculated on the context of the first event in the case



Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

Output Data Type: BOOL, INT, FLOAT, STRING, DATE, TIME

Example: FIRSTEVENT(Duration())

Metric applicable on case overview statistic calculates the duration of the first case's
event per each case.

LASTEVENT([operation])
Changes the context of the operation to the end event case (only allowed for cases).

Supported context: case

Parameters:

[operation] - value to be calculated on the context of the last event in the case

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

Output Data Type: BOOL, INT, FLOAT, STRING, DATE, TIME

Example: LASTEVENT(Duration())

Metric applicable on case overview statistic calculates the duration of the last case's
event per each case.

PROCESS([operation])
Changes the context of the operation to a process.

Supported context: process, case, event, edge

Parameters:

[operation] - value to be calculated in the context of the actual process

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

Output Data Type: BOOL, INT, FLOAT, STRING, DATE, TIME

Example: PROCESS(EventCount())

Metric applicable for any custom metric usage within the application. Returns total
number of events in the current process (in actual view).



IN([operation], value1, value2, value3, ....,
valueN)
returns TRUE if the operation is equal to any of given values. It is a shortened version of
the logical operation OR.

Parameters:

[operation] - value to be calculated in the context of the actual process

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

[value1], [value2], .., [value3] - list of values for compare. All values need to be the
same data type and the same data type as the operation

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

Output Data Type: BOOL

Example: COUNTIF(IN(userName, "Peter", "Martin", "Laura"))

Metric applicable on process map for activities. Returns the total count of events with
users named "Peter" or "Martin" or "Laura" per activity.

NEXT([value],[default])
Returns the value of the next event in the case. If the next event doesn't exist, returns
the default value.

Supported context: case (implicit)

Parameters:

[value] - value to be calculated in the context of the next event within the actual
case

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

[default] - default value to be returned if there is no next event in the actual case.

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

Output Data Type: BOOL, INT, FLOAT, STRING, DATE, TIME

Example: NEXT(eventCost, 0)



Metric applicable on filter metrics. Returns event cost of the next event in the case. If the
current event is the last event in the case, returns zero.

NEXTIF([condition], [value], [default])
Returns the value of the first next event in the case which met the condition. If no such
next event exists, returns default value.

Supported context: case (implicit)

Parameters:

[condition] - the condition which needs to be met for the event selection

Data type: BOOL

[value] - value to be calculated in the context of the first next event which matches
the [condition] within the actual case

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

[default] - default value to be returned if there is no next event in the actual case
which matches the condition

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

Output Data Type: BOOL, INT, FLOAT, STRING, DATE, TIME

Example: NEXTIF(userName == "Laura", eventCost, 0)

Metric applicable on any custom metric usage within the application. Returns total
number of events in the current process (in the actual view).

PREVIOUS([value], [default])
Returns value of the previous event in the case. If previous event doesn't exist, returns
default value.

Supported context: case (implicit)

Parameters:

[value] - value to be calculated in the context of the previous event within the
actual case



Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

[default] - default value to be returned if there is no previous event in the actual
case.

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

Output Data Type: BOOL, INT, FLOAT, STRING, DATE, TIME

Example: PREVIOUS(userName, "n/a")

Metric applicable on metrics filter. Returns value of userName attribute for the previous
event in the case. If the previous event does not exist (for example, for the first event in
case), it returns "n/a".

PREVIOUSIF([condition], [value], [default])
Returns value of the first previous event in the case which met the condition. If no such
previous event exists, returns the default value.

Supported context: case (implicit)

Parameters:

[condition] - the condition which needs to be met for the event selection

Data type: BOOL

[value] - value to be calculated in the context of the first previous event which
matches the [condition] within the actual case

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

[default] - default value to be returned if there is no previous event in the actual
case which matches the condition

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

Output Data Type: BOOL, INT, FLOAT, STRING, DATE, TIME

Example: PREVIOUSIF(eventCost > 0, userName, "n/a")

Metric applicable on metrics filter. Returns value of userName attribute for the first
previous event in the case with the eventCost greater than zero. If no such previous
event exists, it returns "n/a".



MOVE([offset], [value], [default])
Returns the value of the event in the case retrieved by the offset. Offset 1 means next
event, offset -1 previous, offset 0 current. If the event does not exist on the given offset,
it returns the default value.

Supported context: case (implicit)

Parameters:

[offset] - offset to current event

Data type: INT

[value] - value to be calculated in the context of the specified event within the
actual case

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

[default] - default value to be returned if there is no such event in the actual case

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

Output Data Type: BOOL, INT, FLOAT, STRING, DATE, TIME

Example: SUM(MOVE(2, eventCost, 0) + MOVE(1, eventCost, 0))

Metric applicable on the process map. Returns the sum of event cost for the next two
(subsequent) events calculated per activity.

MOVEIF([offset], [condition], [value], [default])
Returns the value of the event satisfying the condition retrieved by the offset. Offset 1
means the next following fulfilling event, offset -1 the nearest previous fulfilling event,
offset 0 the current fulfilling event. If such an event doesn't exist, it returns the default
value.

Supported context: case (implicit)

Parameters:

[offset] - event offset

Data type: INT

[condition] - the condition which needs to be met for the event selection



Data type: BOOL

[value] - value to be calculated in the context of the specified event within the
actual case

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

[default] - default value to be returned if there is no such event in the actual case

Data type: BOOL, INT, FLOAT, STRING, DATE, TIME

Output Data Type: BOOL, INT, FLOAT, STRING, DATE, TIME

Example: MOVEIF(3, userName == "Laura", eventCost, 0)

Metric applicable on metrics filter. Returns event cost for the third next event which was
done by the user "Laura" in the current case.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



List of calculation context
Article • 03/10/2025

In aggregation functions, the calculation context defines the data scope that's used as
the source for the aggregation. The Power Automate Process Mining desktop app
provides several data calculation modes, which are described in Requirements for
application.

７ Note

These operations are available in Power Automate Process Mining desktop app
only. They aren't available in other parts of Power Automate, which use Power Fx
operations.

Custom metrics can include nested aggregations, or aggregations used in an expression.
For example, the expression AVG(DURATION()/AVG(AllInView, DURATION()))  returns the
ratio of the average duration of certain activities or edges to the average duration of all
activities or edges.

Available contexts
ﾉ Expand table

Context Description

Implicit Default context; no need to specify. Aggregation is calculated for each
unique value; that is, for each activity or edge in the map.

AllInView Aggregation is calculated for all values in the view.

ViewCases Aggregation is calculated for all cases in the view.

ViewEvents Aggregation is calculated for all events in the view.

ViewEdges Aggregation is calculated for all edges in the view.

AllInProcess Aggregation is calculated for all values in the process.

ProcessCases Aggregation is calculated for all cases in the process.

ProcessEvents Aggregation is calculated for all events in the process.

ProcessEdges Aggregation is calculated for all edges in the process.



Context Description

AllInBR Aggregation is calculated for all values in the business rule scope.

BRCases Aggregation is calculated for all cases in the business rule scope.

BREvents Aggregation is calculated for all events in the business rule scope.

BREdges Aggregation is calculated for all edges in the business rule scope.

EventsPerAttribute Aggregation is calculated for all events with the same value for the selected
attribute.

EdgesPerAttribute Aggregation is calculated for all edges with the same value for the selected
attribute.

CasesPerAttribute Aggregation is calculated for actual cases, with each case calculated one
time.

CaseEvents Non-aggregated evaluation of events in a single case.

CaseEdges Non-aggregated evaluation of edges in a single case.

Use different calculation contexts
AVG(DURATION()): Returns the average duration of a specific activity or edge. When
visualized in the process map, the value differs for different activities or edges. In other
words, the average duration is calculated in the context of the activity or edge that's
visualized.

AVG(AllInView, DURATION()): Returns the average duration of all activities or edges in
the view. When visualized in the process map, one value is used for all activities and a
different value is used for all edges. In other words, there are two different values.

AVG(ProcessCases, DURATION()): Returns the average duration of all cases in the
process, regardless of the view filters. When visualized in the process map, the value is
the same for all activities and edges. In other words, there's one value for all activities
and edges.

AVG(ViewEvents, DURATION()): Returns the average duration of all events in the view.
When visualized in the process map, the value is the same for all activities and edges. In
other words, there's one value for all activities and edges.

AVG(ViewEdges, DURATION()): Returns the average duration of all edges in the view.
When visualized in the process map, the value is the same for all activities and edges. In
other words, there's one value for all activities and edges.



AVG(CasesPerAttribute, DURATION()): Returns the average duration of all cases that
flow across the activities and edges. It's the same value for all activities and edges that
contain the same set of cases.

AVG(CasesPerAttribute, DURATION()): The same metric as the one above, now used in
the Statistics case-level attribute. It returns the average duration of all cases in the view
that have the same value for the attribute Supplier.City, with each case calculated once.

AVG(EventsPerAttribute, DURATION()): Returns the average duration of all events in the
view that have the same activity value. This is a standard metric in the Performance view
- Mean Duration. This metric is unavailable for edges. The calculation context is limited
to events only.

AVG(EventsPerAttribute, DURATION()): The same metric as the previous one, now used
in the Statistics event-level attribute. It returns the average duration of all events in the
view that have the same value for the attribute Resource. Refer to the last column,
EventsPerAttribute-Avg.

AVG(EdgesPerAttribute, DURATION()): Returns the average duration of all edges in the
view for a process map path. This is the standard metric in the Performance view - Mean
Duration on edges. This metric is unavailable for events. The calculation context is
limited to edges only.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Custom metrics calculation methods
Article • 07/18/2023

Use this article if you're already familiar with the basic functionality of the Power
Automate Process Mining desktop app and understand the basics of process mining. It
offers a methodical introduction to the calculation methods after which you'll be able to
define the desired calculation scope.

Metrics in Power Automate Process Mining
The Process Mining desktop app offers a wide set of predefined standard metrics (for
example, number of events, number of cases, average duration of cases, number of
variants, and more). These metrics might be separated in two basic groups: ​

Aggregated metrics: Most common result. Display calculated values grouped by
selected context across the Process Mining desktop app.

Non-aggregated metrics: Display values per individual data element like event,
edge, or case.

Aggregated metrics
Aggregation or calculation is done over certain calculation scope or context.  Scope is
defined by different analytical views in the Process Mining desktop app.​This example
uses the process map.

Process map is the most common type of display for process mining analysis. Each
element of the map - node (activity) or path (edge) displays an aggregated value for all
events with the same activity value. In the example below, you see the representation of
two activities: Assemble bicycle and Send parts to engineering. For both nodes, the
displayed value represents 109 single events in the data set and displays the aggregated
value for all of it. In this case, it's the total number of events.



When you select another metric (maximum duration) in the right panel, the process
map displays the maximum duration which occurred among 109 events with activity
Assemble bicycle and maximum duration among 109 events with activity Send parts to
engineering.

The statistics panel per single attributes uses the same aggregation as the process map,
which aggregates the results per attribute value. If you have a resource (for example, a



user attribute in statistic panel), you're able to see result per each ​user occurred in actual
view.

The Process Mining desktop app displays aggregated results in three main categories:

Single result: Usually a single global value per actual data set, for example, number
of cases. Input is a whole data set and output is a single result.

Aggregation per single case: In Statistics, the Case overview panel results are
calculated per single case. Calculation scopes for such aggregations are case
events or case edges. Input is set of events or edges within case. Output is a set of
results, and single result per single case.

Aggregation per attribute value: Most common calculation scope, and is
represented by Process map or Statistics panel for any attribute. Input is a set of
events or edges with the same value of selected attribute. Output is set of results,
single result per each attribute value. The default Process map uses attribute
activityName to calculate results per each set of events with the same activityName
value.

In the Statistics Case overview panel, you can see a global single result for the total
count of all events in view. In the same panel, there's a list of all cases. In a table of
cases, there's a column named Event count. This time, the value represents the number
of events in the case. This grouping is called aggregation by single case.

In the Statistics activityName panel, there's a list of all activities. The table of activities
contains a column named Event frequency. This time, the event count is calculated per
each activity. This grouping is called aggregation by attribute value.

We've seen value 109 for activities Assemble bicycle and Send parts to engineering in the
Aggregated metrics section previously in this article. Calculation for all three metrics
categories is the same, and the only difference is calculation scope. The first example
uses all view events and calculates single result. The second one generates the result per
single case and uses per each result only for events within given case. The last one



generates the result per each activity and uses per each result only events with the given
activity value.

Non-aggregated metrics
The major difference to aggregated metrics is that calculation is done per single
element: either case, event, or edge. An example is if an event has assigned a resource
attribute, or if case duration is outside defined working hours. There are only a few
places where non-aggregated metrics (and attribute values) are displayed and available:

 Statistics panel for case overview where values per single case are displayed. Be
aware, the displayed metrics are result of aggregation per single case (over events
within given case), but from case level perspective these are non-aggregated
metrics as represents single case.

Case/event metric filters are among a few places where non-aggregated values are
displayed and available to user.​

The Event metrics filter is a good example of where duration of single events is
displayed and evaluated. Event filters take each event individually and evaluate its
attribute or metric value as it is. All other standard visualizations in the Process Mining
desktop app display event duration in some aggregated way (for example, mean, total,
minimum, or maximum).

Custom metrics
Custom metric is a named calculation formula defined by user per process. This custom
metric is applied by the standard ways for how the Process Mining desktop app displays
the data. It displays standard metrics in an aggregated and non-aggregated way.
Custom metrics must follow the same rule. Therefore, there are two main different types
of custom metrics:

Scalar (non-aggregated) formulas—Calculation over single element like case,
edge or event: Simple scalar formulas don't contain aggregation operation in its
formula. In more complex examples, it's possible to use aggregation as part of
nested expression (for example, compare event duration to average duration of all
events). The important rule is the result of scalar formula is generated per single
case, edge or event. Individual results aren't further grouped nor processed by
application into aggregated results.

Aggregated formulas—Calculation over certain calculation scope or ‘context'.
User can alternate context in formula: Aggregated formulas contain aggregation



operator (for example, AVG ) at a top evaluation level. The Process Mining desktop
app offers a set of standard aggregation operators - see Custom metrics help for
reference. Aggregation operation as first argument takes calculation scope. This
determines two properties:

Input set of data taken into account

Grouping or granularity of the results

Input set of data
You determine what part of the data set is taken into calculation. Calculation of average
event duration for the process map is required to take into calculation only events which
belong to the same activity.

Grouping or granularity of the result
Another aspect of the calculation scope is to determine the granularity of result.
Average event duration in the whole view is a single number, and the count of results is
exactly one. Calculating values for the process map requires the number of results to
match number of nodes (for example, activities) in the process map. We already know
there are three main categories for how results are grouped:

Single global result
Aggregation per single case
Aggregation per attribute value

Generic form for custom metric formulas
Consider the following task:​​Calculate average revenue per hour for invoice processing in
cases when order number was entered manually, and invoice status was never rejected.

Logical breakdown for a generic form
The following table provides examples and descriptions of custom metrics.

Example Description

Aggregation​ Aggregation converts multiple results (for example, per case) into a single value. ​If
the aggregation part is missing, we have scalar, non-aggregated metric.​



Example Description

Calculation Standard calculations in the Process Mining desktop app are: Total(sum) ,
Mean(avg) , min , `max. ​Advanced calculations like ratio of two attributes need to be
done with custom metrics.​

Data Filtration in the Process Mining desktop app can be done with filters, custom
filtration metrics with conditional operators, or business rules with filters.

The example shows the possibility to perform advanced filtering in custom metrics. To
make the example easier, we'll focus on the aggregation and calculation part. When we
create the view, filters which fit the requirements of "order number was
entered manually, and invoice status was never rejected" we might simplify the task.​

The simplified task
Calculate average revenue per hour for invoice processing for cases in actual view.​

Logical breakdown for a simplified task
The following table provides examples and descriptions of custom metrics.

Example Description

Aggregation Aggregation converts multiple results (for example, per case) into a single value.
Scope of aggregation is defined by context definition.​​

Calculation Standard calculations in the Process Mining desktop app are: Total(sum) ,
Mean(avg) , min , max .​Advanced calculations like ratio of two attributes need to be
done with custom metrics.​

Data Simplified filtering means the scope or context definition.​
filtration

​Generic formula for aggregated custom metrics​
Aggregation([Data filtration/scope], calculation)​

Replace the generic placeholders with actual operators and expressions:

Avg(ViewCases, 1.0 * InvoiceTotalAmountWithoutVAT / TOTALHOURS(Duration()))​

The aggregation part is represented by the simple average operator (avg).



Calculation scope is the first part to define in the formula itself. We're looking for a
single global result using all cases in the view. This is easily achieved by selection of
ViewCases  value for context definition. Other types of using aggregated results, like per
single case or per attribute value, have no use in this example.

Core calculation is completely done through an expression that contains four elements:

Conversion to float ("1.0 *") ​

Attribute specification ("InvoiceTotalAmountWithoutVAT")​

(Case) duration converted to time unit ‘hour'​(TOTALHOURS)

Division to calculate ratio



Basic examples
Article • 07/18/2023

The following examples show various calculation methods for custom metrics with a
focus on proper context/aggregation selection. For a complete list of
supported operators (like statistical, calendar or math functions), go to Custom metrics.​

​Dataset description
​The examples use a tiny data set. It contains three cases, 10 events, and there's one view
defined—two out of three cases. For easy manual calculations, we assume zero waiting
time between events; therefore, case duration is a simple sum of events duration. Also,
there's no parallelism among events.​

1. Event level aggregation (view)
What's the total duration of events in the view? We're looking for a single result for the
whole data set in actual view.

Calculation for example 1



We need to run across all available events in the view. Assignment of events to cases
isn't taken into account. Such calculation provides single result in the whole view.​When
we manually sum all event duration, we arrive at the requested result.

Result for example 1
 4:30 hours (events in case 1 = 90 minutes + events in case 2 = 180 minutes = 270
minutes, in total 4:3 hours)

Expression in the custom metric formula



Usage for example 1
The custom metric editor indicates the result is applicable everywhere in the Power
Automate Process Mining desktop app. The reason is that a single result is a numerical
constant, which can be used in any expression and any place where the metric is
displayed. Such metric - returning single value may be displayed in process map,
statistics for case overview, statistics for attributes, filters, or root cause analysis.

​2. Event level aggregation (process)
What's the total duration of events in the process?​We're looking for a single global result,
but not on scope of view, but on scope of complete process data.

Calculation for example 2
In this example, we need to run across all available events in process regardless cases or
any filtering by view.​Such calculation provides single result in whole view (process).​
When we manually sum all event duration, we arrive at the requested result.

Result for example 2
8:00 hours (events in case 1 = 1 hour 30 minutes + events in case 2 = 3 hours + events
in case 3 = 3 hours 30 minutes, in total 8:00 hours)



Expression in the custom metric editor

Usage for example 2
Result is applicable everywhere in the Process Mining desktop app. The same logic for
application as for previous example.

3. Case events aggregation



What's the total duration of events per case? We're asking for the result per case, not a
single global result.

Calculation for example 3
We need to calculate events duration per single case. As the view contains two cases,
the number of results is two (2). Each result is calculated as sum of event duration across
the single case.

Result for example 3
The result is per case. It's calculated by events in case1 and events in case2, but most
important is that the result is per case.

Case 1 = 1:30 hours (events in case 1)
Case 2 = 3:00 hours (events in case 2)



Expression in the custom metric editor

Calculation context CaseEvents (and CaseEvents) is very useful as it allows to create
additional case level metric calculated using the case events. User is then able to
evaluate the single cases based on calculated value.

Usage for example 3
As we have single result per each case in current view,​results are available only in
screens with results per single case:​



Case Metric filter​

Case Overview Statistic panel

Root cause analysis

Results for CaseEvents or CaseEdges are not applicable on Process map. Theoretically
Process map is able to display results per case, but default aggregation (industry
standard) is per activity.

4. Attribute aggregation
What's the total duration per activities? We're interested in evaluation of activities. This is
a different calculation compared to previous example.

Calculation for example 4
How do you calculate results per activity properly? We're not concerned with the
distribution of events among cases. All we take into consideration is distribution of
events among activities. All events in view are grouped according to activity value. We
have activities 'A', 'B' and 'C'. Per each set of events, we calculate result separately - sum
of event durations.

Result for example 4



A = 50 minutes
B = 40 minutes
C = 3 hours

Expression in the custom metric editor

Usage for example 4
We have single result per activity in current view.​Results are available on screens with
aggregated events per activity value:​

Process Map (nodes)



Statistics – Activities​

Attribute conditional filter (To learn more, go to ​7 Bonus: Attribute conditional
filter.)​

Process map and Statistics panels for any attribute (including activity) share the same
calculation scope. Despite different visuals, both screens display results grouped by
activity value.

Attribute conditional filter contains the attribute aggregation inside the single case. For
example, Case 2 contains two events with activity 'C'. Attribute conditional filter does
aggregation over these events and aggregated value is evaluated. To learn more about
behavior for this filter go to ​7 Bonus: Attribute conditional filter.

5 Generic attribute aggregation
What's the total duration per user? What we care about is the total time spend, not by
activities but by users.

Calculation for example 5
This example is similar to previous one. We again take into consideration distribution of
events among one of its attributes. This time, it's user attribute. We have users 'Peter',



'Michal' and 'Denis'. Per each set of events, we calculate result separately - sum of event
durations.

Result for example 5
Peter = 50 minutes (Events in case 1 =10 minutes + events in case 2 = 40 minutes,
in total 50 minutes)
Michal = 2:20 hours (events in case 1 =1:20 hours + events in case 2 = 1 hour, in
total 2:20 hours)
Denis = 1:20 hours (Events in case 2 = 1:20 hours)

Expression in custom metric editor:



Why the expression is the same as for previous one? It's simple. The calculation per
attribute value is the same for any event attribute. Activity is just a special mandatory
event attribute. All metrics calculations are applied in the same way for activity as for
any other attribute.

Usage for example 5
We again have single result per attribute value in current view.​Results are available on
screens with aggregated events per attribute value:​

Process map (why?)

Statistics – any attribute

Attribute Conditional filter ((To learn more, go to ​7 Bonus: Attribute conditional
filter.)

If you want to see results per user in the Process Mining desktop app, go to Statistics for
user attribute. There are displayed events aggregated by user attribute. What if we open
process map or statistic panel for another attribute. In such case the results will be
aggregated by selected attribute. For example, in Process map, it's by default activity
attribute.

6 Attribute by case aggregation
What's the total duration of cases processed per user? We're again interested in results
per user, but this time we want to know total duration of cases in which users were
involved.



Calculation for example 6
The calculation logic for this request is very similar to previous one. We group users by
value of user attribute. We have users 'Peter', 'Michal' and 'Denis'. The difference is in the
values we are going to summarize. Per each event, we take duration of case, not
duration of event. User 'Denis' worked only on case 2, so the answer for him is duration
of case 2. Users 'Peter' and 'Michal' were involved in both cases, so the answer is
combined the duration of case 1 and case 2.

Result for example 6
Peter = 4 hours 30 minutes
Michal = 4 hours 30 minutes
Denis = 3 hours



As you can see, we don't care how many events were done by user in case. One or
multiple events done by given user, the length of case isn't obviously changed. We don't
want to take duration of single case multiple times for the same user. Result is
calculated per user (attribute value), takes case level metric (duration of case, no
duration of events), and takes each case into result once at most.

While this calculation seems odd, it is a very basic calculation used for standard financial
case level metrics. Total of invoice is still the same regardless how many events, how
many reworks occurred in the case. Invoice total is not multiplied because some events -
activities or users occurred multiple times in invoice processing.

Expression in the custom metric editor



Usage for example 6
Single result is generated per attribute value so all displays for attribute aggregations
are available. As we use case level metrics the results are also applicable for edges (both
in process map and in statistic):​

Process map​(nodes & edges)

Statistics attribute panels (why not in Case overview?)​

Attribute/Edge Conditional filters

The results are not calculated per single case, but per attribute value, so Case overview
and Case/Event metrics are not usable for such calculations.

​7 Bonus: Attribute conditional filter
Attribute conditional filter contains the attribute aggregation inside the single case. This
explains the applicability of metrics using aggregation by attribute value in this filter.

How do I filter cases with total duration for C activities longer than 1 hour and 30
minutes? The number of events with activity C is not important inside the case. The only
criteria is total duration for such events.

Calculation for example 7



The question requires to evaluate data set by single cases. In each case, we look into
total duration of all events with activity C and compare it defined limit 1 hour 30
minutes. Case may contain zero, one, or multiple events with activity C, but it isn't
relevant.

Result for example 7
Case 2

Attribute conditional filter is case level filter, it evaluates the single cases. For each case
it calculates the result per selected attribute value (activity C in our example) and
compares the calculated result to filter requirement (greater than 1 hour 30 minutes). As
case may contain multiple events, which fits the criteria (activity C), these event level
values are (have to be) aggregated according to filter requirements (total of all events)
to provide single value before comparison to filter requirement.

Filter definition
The filter evaluation at first calculates aggregated result (total) per attribute value
(activity C) per case and afterward this result is compared to filter requirements (greater
than 1 hour 30 minutes). Therefore, any standard or custom metric that aggregates the
results per attribute value is applicable also in attribute conditional filter.



Advanced examples
Article • 07/18/2023

Due to complex examples, this article uses some specific custom operators like
DURATIONCALENDAR  or FIRSTIF . No specific knowledge of these operators is required.

For easy examples of how to create custom metrics, go to Basic examples.

​Recapitulation of previous examples
The following table provides descriptions and examples of custom metrics.

Description Example

Aggregation per attribute value AVG(Duration())​
(For example, result per activity = all events with the AVG(EventsPerAttribute, Duration())​
same activity value) AVG(EdgesPerAttribute, Duration())​

Aggregation within cases AVG(CaseEvents, Duration())
(result per single case)

Aggregation over cases​ SUM(CasesPerAttribute, invoTotal)​
(aggregation per attribute value, case is taken into AVG(CasesPerAttribute, Duration())
calculation one time)

Global aggregation​ COUNTIF(ProcessEvents, user ==
(over all elements in view/process/business rule) "Peter")​

AVG(ProcessEvents, Duration())

​Dataset description
The new tiny data set is used for easy calculation for the remaining examples. It contains
four cases and 12 events.​

​For easy manual calculations, we assume zero waiting time between events.
Therefore, case duration is simple sum of events duration. Also, there's no parallelism
among events.​

In total, we have five attributes: activity, start, end, user, and county. Country is a case
level attribute. The other attributes are event level.

1 Event level non-aggregation



How do I filter out through CM events with positive duration? Evaluate single events and
remove the ones with corrupted timestamps.

Calculation for example 1
​Run and evaluate each event one-by-one.​Generate a single result per event. No
aggregation operation is required. Compare end and start attribute values in each event.

Result for example 1
Per each event:

1x False
11x True



Expression in custom metric editor

Usage for example 1
As we have a single result per each event in the current view,​results are available only in
screens that display and process an event metric:



Event metric filter

Case metric filter

The event metric filter is the obvious option, as it allows you to filter events based on
attribute or metric values. Case metric filter by default uses case level metrics. It also
allows you to select the event metric filter with additional specification if all or at least
one event in the case has to meet the event metric. This switch allows the case level
metric filter to switch to event level metrics.

７ Note

Event attribute values are displayed also in the Variant cases table panel, but this
view displays only event attributes and doesn't display event metrics.

1.1 Event level non-aggregation (alternative)
Alternative: How do I filter out via CM events with negative duration? Instead of using
attributes 'end' and 'start' write the expression using generic metrics.

It's a best practice to use generic metrics instead of process attributes.​

Better performance​

Portability​

One formula fits more applications (for example, case overview and root cause
analysis)​

Aggregated form works with case/event/edge​



Expression in custom metric editor

2 Case level non-aggregation
How do I filter out cases with empty (zero) duration? After we removed corrupted events,
you need remove invalid cases. Remove complete cases with zero duration.



Calculation for example 2
​Run and evaluate each case one-by-one.​Generate a single result per case. As there is
operator Duration() , which is applied on case level, no aggregation operation is
required.

Result for example 2
Per each event:

Case 1 - true
Case 2 - true
Case 3 - true
Case 4 - false



Expression in custom metric editor

Usage for example 2



As you have single result per case,​results are available only in screens that display
results per case:

Case metric filter

Statistics case overview

Root cause analysis

Event metric filter

Usage of case level metric (aggregated or non-aggregated) in Statistics Case overview,
Root cause analysis or Case metric filter is no surprise.

To answer why there is an indication for usage for Event metrics, it doesn't offer any
advanced setting to switch to case level. The answer is in the expression formula, which
uses Duration()  operator. The Power Automate Process Mining desktop app offers the
same operator Duration()  on event and on case level. Therefore, the same expression is
applicable on both the case and event level.

3 Edge aggregation
What's the number of user changes per path (edge)? Instead of looking on events values,
you'll ask for changes occurred between events. So you're looking for result per edge.

Edge (path) : Transition between two directly followed events.



Calculation for example 3
You're evaluating how often you've changed when case was progressing though events.
You want to identify on which transitions (edges) occurs user switching. First, identify set
of edges in our data. For case 1, there are two edges A->B and B->C. In case 2 we have
A->C and C->C. For case 3, you only one edge C->C. In total, you have four (4) unique
edges (based on activity values) - A->B, B->C, A->C and C->C. Per each of these edges,
you need to aggregate number of user changes. For example, you have only one
instance of edge B->C where user Michal on starting event and also on the on ending
event, so there is no user change for this edge at all.

Result for example 3
A->B = 1
B->C = 0
A->C = 1
C->C = 2



Expression in custom metric editor

Operators TARGET()  and SOURCE()  return values of the requested attribute for ending
and starting node to the actual edge.

Usage for example 3



Defined custom metrics generates result per edge (attribute) value, so it's applicable
everywhere when aggregated results per edge are used:

Process Map edges

Statistics edges

Edge conditional filter

4 Case events aggregation II
In the previous section, you've had a simple example of using CaseEvents  aggregation.
Here you'll take another example with a more complex formula.

What's the duration from first C start and last C end activity in cases? Youre looking for a
result per case and to do some conditional aggregation over case events.

Calculation for example 4
Run across all available events within its case. Get the first and last activity 'C' in a case
and measure the duration between start of first one and end of last one.



Result for example 4
Case 1 = 1 hour 00 minutes
Case 2 = 1 hour 20 minutes
Case 3 = 2 hours 00 minutes

Expression in custom metric editor



This time the expression is little more complicated but shows how to combine multiple
aggregations into single formula. Operators FIRSTIF()  and LASTIF()  are aggregation
operators, which return first/last event based on input criteria over defined calculation
scope (this time CaseEvents ).

Usage for example 4
Application of custom metric follows the standard requirements for single case
aggregation (regardless complexity of expression).

4.1 Case events aggregation II (alternative)
What's the duration from first C start and last C end activity, but calculated only over
working hours? The example is the same as the previous one, but here you want to
calculate time difference only over working hours. Previously, the simple difference
between timestamp values was enough.

Calculation for example 4.1



Run across all available events within its case. Get the first and last activity 'C' in a case
and measure the duration between start of first one and end of last one. For measuring
the duration, use working hours defined in the applied calendar.

Result for example 4.1
Case 1 = ???
Case 2 = ???
Case 3 = ???

Expression in custom metric editor

To calculate duration over working hours, the DURATIONCALENDAR()  operators have been
used. Operators to find first and last events are used as operator arguments creating a
nested expression. Notice the complexity of the expression doesn't affect or modify the
selected calculation scopes.

Usage for example 4.1
Application of custom metric follows the standard requirements for single case
aggregation regardless complexity of expression.

5 Categorical vs. quantitative results
Does the case contain C->C path? This is simple question when you need to categorize
single cases based on existence edge C->C.



Calculation for example 5
Run across all available edges within its case. If case contains C->C edge, it passes the
criteria. Results are generated per case. Count of such edges isn't important.

Result for example 5
Case 1 = False
Case 2 = True
Case 3 = True ​



Expression in custom metric editor

Operator ANY()  returns boolean true/false value when at least one element in a given
context meets the criteria. See also operator ALL() *k, which returns a true value when
all elements in the given context meets the criteria.



Usage for example 5
Application of custom metric follows the standard requirements for single case
aggregation: ​

Case Metric filter

Root cause ​analysis

Case overview statistic panel​

5.1 Categorical vs. quantitative results
(alternative)
How many C->C paths are within the case? Change the previous question from if case
contains edge C->C to how many such edges are there.

Calculation in example 5.1



Run across all edges within its case. Count any edges C->C found. If no such edge is
found, count is zero for given case.

Result in example 5.1
Case 1 = 0
Case 2 = 1
Case 3 = 2

Expression in custom metric editor



In comparison to the previous formula, you've just replaced operator ANY()  with
COUNTIF() .

Usage for example 5.1
Application of custom metric follows the standard requirements for single case
aggregation.

6 Event or edge-case aggregation using case-
wide context
How many cases in DE contains edge C->C? This request contains two values. The first
one is the value of country attribute 'DE' and second one is the value for edge 'C->C'.

The limitation for 'C->C' edge describes the domain requirement and why country 'DE'
is one of attribute values.



Calculation for example 6
Why not calculate the result for all countries/regions? At first, re-think the original
question. It's possible to generate results per attribute value (for example, for attribute
country), but there's no way (except for business rules) to create a calculation for a
single attribute value. In your using business rules, you can skip this section. Knowing
this, you can update the original question to generic form:

How many cases contains C->C edge per country?

Now the calculation consists of two steps. At first, run though each case and check
existence of 'C->C' edges. The exact number of 'C->C' edges in the case isn't important.
After it, in the second step, aggregate the results per single case according to a value of
the case level attribute country. There are two values 'DE' and 'SK', so there will be two
results.

Both cases for country attribute 'SK' contain 'C->C' edge, so the result for 'SK' is 2. The
total number of edges is 3, but we don't count number of edges.

Result for example 6



DE = 0
SK = 2

Expression in custom metric editor

The nested formula contains a two-step aggregation. The inner one runs over all edges
within case. The outer one aggregates cases by attribute value. The outer aggregation
uses context CasesPerAttribute because the result per case is exactly one. The context



EventsPerAttribute also groups the result per attribute value, but it may involve the same
case multiple times (per each involved event) into the result.

Usage for example 6
Custom metric is applicable on every screen where values are displayed per attribute
value. Attribute value may be grouped using event level (EventsPerAttribute) or case
level (CasesPerAttribute) context. These two calculation contexts provide a different
calculation, but share the same applicability of the calculation (custom metric):

Process map (both nodes and edges)

All statistics except for Case overview, which requires results per case.

Attribute and edge conditional filters.

For an expression with nested aggregations, the most outer aggregation context
determines the application in the Process Mining desktop app.

6.1 Event or edge-case aggregation
(alternative)
Convert the previous example from categorical evaluation to quantitative.

How many C->C edges are in cases in DE? Convert the question to a generic form: How
many C->C edges are in cases per country?



Calculation in example 6.1
Again, the calculation consists of two steps. At first, run though each case and count 'C-
>C' edges. After it, in the second step, aggregate the results per single case according to
the value of case level attribute country. There are two values: 'DE' and 'SK', so there will
be two results.

Both cases for country attribute 'SK' contains 'C->C' edges. The result for 'SK' and total
count for these edges is 3 (1 + 2).

Result in example 6.1
DE = 0
SK = 3



Expression in custom metric editor

The expression again contains two step (nested) aggregation. The inner one runs over
all edges within case and the outer one aggregates cases by attribute value.

Usage for example 6.1
Custom metric is applicable on every screen where values display per attribute value.



7 Switch from event to case context
What's average activity duration to case duration? How much time do we spend in
average in activities is one of standard performance metrics.

But what if we need to calculate the average ratio of how much time we spend in
activities in comparison to case duration? Where do we spend relatively the most time?
Is it over the threshold?

Calculation for example 7
What exactly are we going to calculate? We want result per activity, so we get results per
'A', 'B', and 'C'. Activity 'B' is only in case 1. Case 1 duration is 90 minutes and activity 'B'
duration is 20 minutes. The result for case 1 and activity 'B' is 20/90 = ~ 0.22. Because 'B'
isn't included in other cases, this is also the final result for 'B'.

Do the calculation for activity 'A', for case 1 the ratio is 10/90, for case 2 the ratio is
40/120, with average value 0.22 (0.11 + 0.33 divided by 2). In the same manner, we
calculate 6 individual results per each of events 'C' and make the average.



In terms of aggregation, it's nothing new. We generate results per attribute value, but
for calculation, we used metric (value) from case.

Result for example 7
A = 0.22
B = 0.22
C = 0.375

Expression in custom metric editor



The expression is simple, but uses the important operator CASE() , which allows you to
switch context for case level. This is the only way how to calculate event level metrics
and ask for metrics (values) from its case.

Usage for example 7
Application of custom metric follows the standard requirements for aggregation per
attribute value. Because the expression uses Duration() and not attribute value, it's also
applicable on edges (both in process map and statistics).

8 Event-case-event aggregation
Generic relation between events inside case.

How many events done by Michal were in cases touched by Peter? Imagine 'Peter' is a
senior team member who is usually involved only in some troubles. We want to know
how many times 'Peter' had to perform action when another user 'Michal' was involved
in the same case.

​Change the question to a generic form: How many events per user were done in cases
with Peter?



Calculation in example 8
Event is valid for this question, if it's within case, where there's at least one event done
by user 'Peter'. Evaluate each event and group results per attribute user value - 'Michal',
'Peter', and 'Denis'.

Result in example 8
Michal = 1
Peter = 2
Denis = 3



Expression in custom metric editor

Expression is short but requires some knowledge to understand it. The most inner part
Any(CaseEvents, user=="Peter") is a simple result per single case. It evaluates if case
contains user 'Peter' or not. The most outer part COUNTIF() does simple aggregation by
attribute value. The requirement is to do aggregation on event level attribute user, but



the calculated value is case level metric. Switch between these two contexts is done by
CASE() operator in the middle.

７ Note

In this example, the EventsPerAttribute context isn't specified. Custom metric then
applied implicit calculation context.

Usage for example 8
Application of custom metric follows the standard requirements for aggregation per
attribute value.

8.1 Event-case-event conditional aggregation
Relation between two event level attributes within case with condition.

How many times Michal worked on repeated C with Peter in case? This is a similar
question to previous one, but there is added conditional.

Convert the question to a generic one: How many times Michal (per user) worked on
repeated C in cases with Peter?



Calculation for example 8.1
Evaluate each event and group results per attribute user value: 'Michal', 'Peter', and
'Denis', like in the previous example. Event evaluation is more complicated, as there's
limitation only for repeated activities 'C'.

In case 1, there aren't repeated activities 'C', in case 2 is one repeated activity 'C' done
by 'Michal', and in case 3 are two repeated activities 'C' done by 'Denis'.

Result for example 8.1
Michal = 1
Peter = 0
Denis = 2



Expression in custom metric editor

Two step (nested) aggregation—inner one evaluates the single case, the outer one
group results per attribute value. Conditions are also separated between these to
aggregation. The inner one handles case requirement if it contains user 'Peter'. The
outer one groups events so it contains the event related condition if activity is 'C' and if
it is repeated.



Operator OCCURRENCE()  returns occurrence index of a given event attribute value within
the case.

Usage for example 8.1
Application of custom metric follows the standard requirements for aggregation per
attribute value.

9 Extra: Value specific custom metrics
Is it possible to avoid operator CASE() ? Is there way to simplify the expressions? Yes,
it is, but there are tradeoffs. See the following example.

How many events done by Michal (per user) were in cases with Peter? The same
question like in 8 Event-case-event aggregation.

Is it possible to answer question without using CASE()  operator?​

Generic solution using CASE() operator



It is possible to skip CASE()  operator at the cost of creating value specific custom
metric? In such a custom metric, we have to specify requested custom value 'Michal' and
have drop calculations for other attribute values (per user) and grouping by another
attributes.

Custom metric limited to specific custom value

Reasoning behind the latter one:

1. Select cases with ‘Peter' (operator ANY() )

2. Convert boolean result to numeric zero or one (operator IF() )

3. Count number of activities with requirement (operator COUNTIF() )

4. Apply result per case per each case exactly once (calculation context
CasesPerAttribute)

5. At last Sum count of events per case (operator SUM() )

The custom metric without CASE()  operator is maybe easier to read by humans, but it
brings some disadvantages.

Per each resulting attribute value ("Michal"), we need a separate custom metrics.
For other attribute values, the metric returns zero.

Operator COUNTIF()  is locked for user attribute. Results grouped by another
attribute, for example, country requires change of condition to specific country
code, for example, COUNTIF(CaseEvents, country == "DE") .



Business rules overview
Article • 07/18/2023

The Power Automate Process Mining desktop app allows you to define business rules
that evaluate your key performance indicators (KPI). Business rules set thresholds that
are associated with a category flag—Error, Warning, or OK—to help you quickly spot
problems in your processes.

Thresholds apply to all business rules in the process context. However, each business
rule can have its own calculation formula and filters. Because business rules are part of
the process context, they're available in any view you create for that process.

View, duplicate, or delete business rules
You can view, duplicate, or delete business rules in the Process content screen.

1. On the upper-right in the top menu, select Process context.

2. On the panel to the left, select Business rules.

The Business rules screen lists all the business rules you've defined in the current
context.

3. To delete or duplicate a business rule, select the ellipses (...) in the last column of
the business rule row, and then select either Delete or Create duplicate.

Define business rules
You can define business rules in the Process content screen.

1. On the upper-right in the top menu, select Process context.

2. On the panel to the left, select Business rules.

3. Select Create new business rule.

4. In the Rule name field, enter a name for the business rule.

5. In the Scope field, select the calculation scope in the dropdown menu.

6. Add a filter:

a. Select Add filter, and then select the desired case or event.



b. On the Attributes screen, complete the field and select Save.

To learn more, go to Define filters detail in this article.

7. Define custom output:

a. Select the Output tab.

b. Select Number of cases or Custom result formula.

c. In the Custom result formula field, enter your formula and select Save.

To learn more, go to Define custom output detail in this article.

8. Add a severity:

a. Select the Severities tab.

b. Select Add new severity and select a type of severity from the dropdown menu.

c. Select an expression from the dropdown menu, enter a value, and select Save.

To learn more, go to Define severities detail in this article.

9. Select Save.

Define filters detail
Filters that you define in the business rule apply on top of any filters that you've applied
to the process view. If no filters are defined in the business rule, the business rule data
set is the same as the process view data set.

Additional options
To exclude a filter from the business rule without deleting it, turn off Enabled.

To delete all the filters in the business rule, select Remove all filters.

To save the filters to a file, or to import saved filters into another business rule,
select the ellipses (...) and select Export Filter or Import Filter.

Indicators at the bottom of the business rule panel show you at a glance how much of
the view data set the business rule will cover. Hover over an indicator to view the
number of cases or events that will be covered out of the total number of cases or
events.



Define custom output detail
All business rule scopes, other than the process scope, have one default output. It's the
count of cases, events, or edges that are in the business rule data set. You can also
define a custom result formula output using custom metrics.

For all custom formulas in the business rule, you can specify a calculation context.

Define severities detail
Define severities, or thresholds and limits, to score the results of the business rule
outputs and assign a performance category flag. Three categories are available: Error,
Warning, and OK.

Thresholds and limits can include both constant values and custom expressions that are
dynamically calculated. For example, you might assign an Error flag when the duration
of a case is longer than the average case duration.

You must define severities before you can save the business rule. The simplest definition
of a severity category is the expression Any.

If the business rule doesn't have a custom output defined, severities are applied over the
default output, count.

See also
Process context
Business rules for process maps
Business rules statistics
Custom metrics overview



Business rule scope
Article • 07/26/2024

Select a Scope when you define a business rule. It determines the scope to which the
output result is delivered.

Event scope
Event scope provides results per activity. The data element over which the formula is
calculated is events. The default output is the number of events that fit into the business
rule data set.

The calculation result displays in the Statistics and Process map screens. In the detail
view for a business rule, the results display per activity. Each activity is categorized
according to the defined severities. In the process map, the results display per activity, in
the same way as in the detailed view for a single business rule in Statistics.

Case scope
Case scope provides a single result per business rule data set. The data element over
which the formula is calculated is cases. The default output is the number of cases that
fit into the business rule data set.

The calculation result display in the Statistics and Process map screens. The process
map highlights all activities and edges that belong to any of the cases in the business
rule.

Process scope
Process scope is the most generic. It provides a single result per business rule data set.

For a process scope, define the custom result formula with an explicit calculation context
to determine over which data elements the formula is calculated—events, edges, or
cases. The default business rule result—count of elements—isn't available.

The calculation result isn't relevant to activities and edges. It displays in the Statistics
screen only.

An example of process scope is average case or event duration. When it's longer than
two days, the value is assigned the category flag Error.



Edge scope
Edge scope is the same as event scope, except that results are provided per edge. The
calculation result displays in the Statistics and Process map screens.

Related information
Business rules overview

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Business rules for process maps
Article • 07/18/2023

To select business rules to view in the process map, select the Customize icon on the
panel on the right in the Process map screen. You can display results per single business
rule, or by severity over all business rules. Process scope business rules aren't available
in the process map.

Single business rule display
If you select Single business rule, results are displayed for the business rule you select in
the events and edges lists. You can select different business rules for events and edges.

Legend:

1. Business rule views icon.
2. Metric at node: Event scope and case scope business rules.
3. Metric at edge: Edge scope and case scope business rules.
4. Value switch icon and business rule actions (...).

Because case scope business rules represent complete cases, you can select case scope
business rules from both the events and edges lists. Event scope and edge scope
business rules are available only in the corresponding list.

To switch between the default output—count—and a custom formula result, select the
value switch icon to the right of the business rule list. Hover over the icon to show which



value is being displayed in the process map. You can show any combination of default
and custom output values for the business rules you selected.

Severity display
If you select a severity, the process map displays the total number of occurrences of
each element with that severity. That is, it shows the total number of cases, activities,
and edges that are in the data sets for each business rule that resulted in the selected
severity.

Details display
Select an activity in the process map to view its details. In the Business rules section of
the Details panel, you can select one or more business rules to display for the activity.
The detailed view shows both default and custom results.



See also
Business rules overview



Business rules statistics
Article • 07/18/2023

Along with statistics about your cases, activities, and edges, the Power Automate
Process Mining desktop app collects statistics on each of your business rules. You can
view them in the Statistics screen.

1. In the left panel, select Statistics.

2. In the dropdown menu, select Business rules.

3. (Optional) Select a scope. By default, the display includes all scopes.

Statistics are available at two levels:

Summary view: Displays a row of metrics for each business rule of the selected
scope

Detailed view: Displays metrics per activity or edge for a single business rule

Summary view
The summary view displays a single row of metrics for each business rule you defined
for the process or for business rules of the selected scope. The category isn't evaluated
for event and edge business rules when you display them in the summary view. To
display metrics per activity or edge, use the detailed view.

If you select a scope other than All, the list of business rules is limited to rules of the
selected scope.

Detailed view
Event scope and edge scope business rules calculate results per event or edge. To
display the details of events or edges, select the scope and then select a business rule of
that scope.



1. In the Scope dropdown menu, select Event or Edge.

2. To add a filter, select Enable filter.

3. In the dropdown menu, select a business rule.

The table shows metrics for each activity or edge in the data set of the selected
business rule.

See also
Statistics overview
Business rule scope



Process simulations overview
Article • 03/20/2025

Process simulations enable users to define simulation scenarios to validate business
hypotheses. You define these scenarios through settings like resource allocation, arrival
of cases, duration of activities, and modeling sequence of activities. You can simulate the
impact of proposed changes before you apply the changes into production.

Process simulations in Power Automate process mining use machine learning statistical
modeling over process model to mimic real world behavior. Modifications to a process
snapshot for simulation scenario don’t affect the existing process. These modifications
allow you to continue with process mining analysis with original data without
interruptions.

Process simulations are part of Power Automate Process Mining desktop app. The
articles in the Process simulations section provide an overview of the simulation
process, how to set up a simulation scenario, and how to run a simulation scenario.

Next step
Create a simulation scenario

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create a simulation scenario
Article • 03/20/2025

A simulation scenario is a named set of modifications over an existing process model. By
default, a simulation scenario creates the scenario based on actual process view data.
You don’t need to define the entire scenario from the scratch. The simulation scenario
creates only modifications to an existing statistical process model snapshot.

The modifications applied in the simulation scenario have no effect on process data.
They don't change the output of process model or process analysis.

To run simulation, you need to create a simulation scenario first. To create a simulation
scenario, follow these steps:

1. On the Power Automate Process Mining desktop app navigation bar, select
Process simulation.

2. Select Add simulation.

The Process simulation screen displays with three tabs:

General settings
Activities
Result Details

Define scenario settings
This section explains some of the settings for your simulation scenario in the General
settings tab. For example, general settings include name, description, currency, arrival
time settings, and timetables/work schedules.



1. In the Name field, enter a name for the simulation scenario.

2. In the Description field, enter a description for the simulation scenario.

3. In the Currency dropdown menu, select the currency used for financial KPIs.

4. In the Arrival time section, define the settings that determine the arrival of cases in
simulation.

In the Instances field, select the instance number.
In the Scenario start at field, select the date on the calendar to represent
when the simulation scenario starts.
In the Exclude at the start and Exclude from the end fields, select the up or
down arrow to exclude cases from the start and end of simulation when
there's increasing and decreasing inflow of new cases. Exclusions filter out
periods when there's no full workload or inflow from the simulated cases.

5. (Optional) In the Timetables/Work schedules section, select Add new timetable to
add new timetables for working hours. These timetables can be assigned to
Resources used in the simulation.

6. In the Resources group, add resources to the simulation scenario by following the
instructions in the Manage the workforce section.



Manage the workforce
A table resource allows you to manage the workforce for a simulation scenario. You can
add, modify, or remove resources from the pool.

To define a new resource, select Add new resource.
To modify an existing resource, select a resource name.
To remove resource, select the x in the fifth column of the resource.

To create and edit the workforce, enter the properties in the Resource edit screen.

The following table list the fields and a description or example:

ﾉ Expand table

Field Description or example

Name Name of the resource.

Finance attribute Attribute used to calculate hourly cost. When no such financial attribute
exists, select the Simulation value and enter hourly cost in Cost per hour
field.

The value in this field can't be empty. Either select the Simulation value or
any finance per hour attribute. If you use the Simulation value, the value
from the Cost per hour field is used. Also, when you select a finance
attribute but you updated a preloaded value in the field, that value for
Finance attribute is changed to Simulation.

Cost per hour Hourly cost for a resource when there’s no financial attribute. The value
from the field is used when you select the Simulation value in the Finance
attribute field.

Parallel tasks The maximum number of parallel tasks a given resource can handle.
amount

Task processing How much more or less efficient the resource is compared to the default
efficiency resource. A value above 1.0 means more efficient. A value below 1.0 means

less efficient.

Timetables/Work Which working hours apply for a given resource.
schedules



Modify activities
To modify activities in a simulation scenario, select the Activities tab on the Process
simulation screen. The Activities tab displays a list of activities in the process model.

To display the screen for a specific activity, select the activity from the Name column.

The Activity screen contains three tabs:

General settings
Resources
Sequence flows

Learn more about the tabs in the following sections.

General settings
In the General settings tab, you can set the following items:

Modification (difference) for activity duration: Activity duration is modeled based
on original process. This setting allows you to change duration of each occurrence
by defined difference.
Cost per activity: To simulate cost of activity, it's possible to specify a process
attribute that defines base cost of activity. Total cost per activity is base cost per
activity plus cost of resource (duration multiplied by cost per hour).



Resources
The Resources tab lists all resources and their work distribution on the activity for a
given resource.

To add a resource for a given activity, select Add.

To remove a resource for a given activity, select the x at the end of the resource's
row.

To change work distribution for a selected resource, type the distribution number
directly in the field, or use the up and down arrows.

） Important

The sum of all work distributions (probabilities) must be 100 percent.



Sequence flows
Use the Sequence flows tab to modify probabilities for the next activities and their
waiting times.

For each activity in the Next activity name column, enter the following fields:

Probability (%): The probability of the next activity in terns of percentage.

Next activity waiting time: The time between the end of the current activity and
the start of the next activity.

Start a simulation
Start the simulation and get an estimation of its duration in the Process simulation
screen.

1. Return to the Process simulation screen.
2. To start the simulation, select Simulate.
3. View the expected estimation of the simulation duration next to Simulate.

The status of the simulation scenario is indicated below the scenario’s tile. Examples of
the status are Queued for start and Completed.

Next step
Run a simulation and generate results

Feedback



Was this page helpful?  Yes  No

Provide product feedback



Run a simulation and generate results
Article • 03/20/2025

After you create a simulation scenario, you can run it and generate results. This article
shows you how to run a simulation scenario and get detailed results, including global
Key Performance Indicators (KPIs).

Start the simulation
Run the simulation scenario and generate results.

1. In the Process simulation screen, select Simulate. If you already ran a simulation
for this simulation scenario, the button name is Re-simulate.

The status of the simulation scenario appears at bottom of the scenario’s tile.
Examples of status are Queued for start and Completed. There are other
descriptions depending on the simulation scenario.

When simulation is finished, the simulation tile shows two (2) global KPI results:

Average case cost difference: Can be zero, when no financial attributes are
selected.
Average case duration difference: This KPI is always calculated.

2. View the simulation results.

Understand simulation results
In your simulation scenario, select the Result Details tab.

The top section shows three global KPIs:

Case count difference: Difference between the number of simulated cases and
cases in the original process view.
Average case cost difference: Difference between simulated case cost and original
case cost in the original process view.
Average case duration difference: Difference between simulated case duration
and the original one in the process view.

The bottom section shows a table in each of the three tabs:



Activities: Comparison between the simulation and the original process view KPIs
per activity.

Resources: Comparison between the simulation and the original process view KPIs
per resource.

KPIs: Lists the global (process) KPIs.

Modify a simulation scenario
To modify a simulation scenario, select a scenario tile in the Process simulation hub. You
can modify all simulation settings.

Until you start a new simulation, the Result Details tab shows results for the original
simulation scenario. A new simulation overrides the results of the previous run. Only the
most recent simulation results are always available in one simulation scenario.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Overview of task mining
Article • 07/18/2023

Task mining is a technology that enables organizations to capture detailed steps for
tasks performed on users' desktops, either independently or collaboratively with
colleagues.

By analyzing recorded user actions, the task mining capability in Power Automate allows
organizations to gain insights into how they perform tasks, identify common mistakes
made during task performance, and pinpoint tasks that can be automated, all of which
can help optimize their business processes.

Benefits of the task mining capability
The task mining capability helps busunesses to:

Streamline workflows.
Identify inefficiencies and bottlenecks in workflows.
Reduce costs.
Foster a culture of continuous improvement where employees are encouraged to
optimize their work processes.

Business example
A retail company can use the task mining capability to analyze the order fulfillment
process. By recording and analyzing user actions, the organization can gain insights into
how orders are processed, identify inefficiencies and bottlenecks, and pinpoint tasks
that can be automated.

The task mining capability can automatically produce a process map that visualizes the
order fulfillment process, allowing the organization to identify which activities take the
longest, how many variations of the order fulfillment process exist, and which variations
and actions take the most time.

In addition, the application analytics report can show which applications teams spend
the most time in and which activities can be optimized. With this information, the
organization can create flows with automation recommendations that reveal which
connectors to use based on the analysis done with task mining.

Using insights from task mining, the retail company can streamline the order fulfillment
process, reduce errors, and improve customer satisfaction. The company can also



automate repetitive tasks, freeing employees to focus on more value-added activities
such as customer service and inventory management.

Components
Following are the main components for the task mining capability:

Prepare processes and recordings
Analyze processes
Visualize processes
Identify automation recommendations
Share processes



Tutorial: Get started with the task
mining capability
Article • 07/18/2023

This tutorial with sample data allows you to experience task mining in the process
mining capability. In this tutorial, you will:

Import a solution
View sample recordings
Analyze a process
Gather insights with a process map
View metrics with activity combinations and variants
Identify automation opportunities

For the task mining tutorial, download User recording demo data . For the process
mining tutorial, go to Tutorial: Get started with the process mining capability.

Get ready for task mining
1. Sign in to Power Automate .

2. Select your environment.

3. On the navigation pane to the left, select Process mining > Processes.

Import a solution
In this tutorial, you'll import a solution which already has sample recordings.

1. On the navigation pane to the left, select Solutions.

2. In the toolbar at the top, select Import solution.

3. Select Browse.

4. Download the RPA in a Day  .zip file and open it.

5. Select Next.

6. Select Import and wait for the solution to import.



View sample recordings
1. Once you've successfully imported the .zip file, on the navigation pane to the left,

select Process mining > All processes below the process cards.

2. Select the Invoice submission process.

７ Note

If this is the first time you're accessing the process mining capability, make
sure you've selected Processes at least once and waited until the Getting
things ready loading spinner has disappeared before importing. If you try to
import the RPA in a Day solution without first initializing the Processes section
of the process mining capability, you see only a couple of recordings in the
imported solution.

You can see some of the existing recordings under Recordings.

3. To be sure you see the entire list of existing recordings, select See all.

4. Go back to the Invoice submission process by selecting it from the breadcrumbs
at the top of the page.

Explore the features
You'll see the following features:

New recording: Create a new recording.

Analytics: See the process map and insights.

Share: Share your processes with your team members.

Process owners can pick two role options when sharing with other users:
contributor and co-owner. The Contributor role gives the user the ability to upload
their own recording to the process. The Co-owner role gives the user the ability to
upload recordings and edit other recordings.

Analyze: Analyze a process.

Create activity names: Create activity names for your process.

Delete process: Delete your process.



Analyze a process
When you analyze a process, the process mining capability analyzes existing recordings
to identify any bottlenecks within the business process.

1. Select Analyze.

The analysis will take a few minutes to complete. During this process, a status
message displays under the New recording button.

2. If you run into an error during the analysis stage, select Analyze to trigger this
action again.

3. Once it's done, you see the Process analysis status change to Analyzed. Select
Analytics to see the process map and insights.

This step may take a couple minutes to complete after the analysis has been
performed.

Analytics page layout
This section explains what you can do on the Analytics screen.



Legend:

1. Automate activities: To streamline the automation process, you can use the
Automate activities feature. This feature detects if the user performed actions
using an application that has Power Automate actions available, such as Microsoft
Outlook or Excel. Upon selecting Automate activities, a draft Power Automate
process containing the relevant actions is generated. The user can then modify and
customize the draft process to create the final automated process.

2. Legend: Additional information about the report, helping them to better
understand the visualizations and data presented.

3. Process: In-depth information about the analyzed process, including the process
map, time analytics for each variant and each recording author.

4. Application: Information about the apps used in recordings. This includes what
apps were used by authors, how often were they used, and what the transitions
were between them. This report explains which connectors should be used when
implementing automation for the process, and where to potentially use desktop
flows, as there’s no existing connector.

Business process step relationships
In the previous example, you see the various steps in the business process and their
related durations. These steps include:

Download invoice attachment from email (48 seconds)

Open Excel invoice list (11.5 seconds)

Open invoice from OneDrive (21 seconds)

Enter invoice details (53.6 seconds)

Save and submit (9 seconds)

Notify team of submission (26.67 seconds)

Gather insights with a process map
Visualizing and analyzing processes is made possible through the process map. By
examining a graphical representation of how business processes are performed, you can
gather insights about potential areas for improvement..



Go to the process map by selecting Analytics > Process map.

View metrics with activity combinations and
variants
This section explains the Variants by frequency bars on the right panel. The
corresponding process map is on the left panel.

On the process map, you can observe various activity combinations and variants that are
displayed individually. A process variant represents a distinct sequence from the start to
the end of the process. It is like a 'trail' through the process that varies from other
variants by at least one activity. The process map also provides additional metrics such
as activity frequency and throughput time. Activity frequency indicates the total number
of recordings or cases that pass through it. Throughput time measures the duration
between the first event of the case and the last event.

By selecting the first bar on the process map, you can view the most frequent process
variant, which is the invoice coming through email. It may take some time for any
changes to reflect on the chart.

Identify automation opportunities
You can see that people spend a lot of their time entering the information in the
application. This helps identify an opportunity to automate the process.



View analytics data
1. Deselect Var 1 by selecting any blank space within the Variant by frequency area.

2. Look at the top analytics data. The average process time is 1.47 minutes out of five
recordings.

3. Analyze other time-based metrics dashboards.

Activity by average time in sec: Notice that Enter invoice details and
Download invoice are taking the most time.



Recording by average time in min: Notice that some people (Preston
Morales and Shakti Menon) are taking more time than others.

4. Select the Application tab to see details on which applications were used.

It might take a while to load the reports.

By providing information on the applications utilized in a business process,
their frequency of usage, and the amount of time spent on each application,
this report is crucial for gaining insights into the process.

For example, the dashboard shows that a legacy invoicing app, Outlook, and
Excel have significant contributions to time spent and actions by applications.

Take time to get familiar with the different reports.



5. Go back to the process map by selecting Process.

6. Look at the automate activities feature. From the process map, you can see that
the process mining capability has highlighted several activities as potential
candidates for automation based on applications.

7. Start to create a flow for automation by selecting Automate activities at the top.

A tab opens in the browser and shows the flow designer. The recommended
actions that match to the activities from the process map automatically appear on
the right panel. For example, several email connectors are suggested for you to use
in order to automate the Download invoice attachment from email activity.






Prepare processes and recordings
Article • 07/18/2023

Before you can use the task mining capability to visualize and analyze your processes,
you need to:

Create your process in the process mining capability in Power Automate.
Record the activities that make up the process using the Power Automate recorder.
Prepare the recording for analysis.
(Optional) Create recommended activity names to make it easier for you and
others to prepare the recording for analysis.

Learn more about processes in the following video.

https://www.microsoft.com/en-us/videoplayer/embed/RWKx7r?postJsllMsg=true

Create a process
In general, processes you think might be inefficient or repetitive are good candidates for
analysis.

1. Sign in to Power Automate .

2. On the left-side navigation pane, select Process mining.

3. In the Create a new process section, select the Start here tile.

4. Enter a name for your process and description, and then select Recordings.

5. Select Create.

Record your process
Create a recording in one of two ways:

Right after process creation.
From the process details page.

Create a recording right after process creation
After you create a process, you see a screen with two options as next steps.



Select Add a recording.

Create a recording from the process details screen
To create a recording from the details screen, find and select your process.

1. Select Process mining > All processes below the tiles to the right.

2. Select the name of the process to go to the process details screen.

3. On the menu at the top, select New recording.

4. Select Open recorder.

Launch the recorder in Power Automate
By using any of the methods described previously, you should receive a message that
says Launching the recorder in Power Automate.

1. You should've downloaded Power Automate  before you started. However, you
can also select Get the app to install it.

2. If you've installed Power Automate, you should see an Open Power Automate
browser pop-up window. Select it to open the app.

3. If Power Automate is installed but doesn’t open correctly, select Open again.

Use the Power Automate recorder
Start recording your process in just one step.



1. On the Desktop recorder screen, select Record.

2. Perform the actions that you want to record, and then select Finish at the bottom
of the recorder screen.

3. After the recording has been saved successfully, select View recording to view the
recorded steps and prepare the recording for analysis.

７ Note

Depending on the length of the recording, it might take some time before the
actions are available.

Recorder features
As you record your actions, the action descriptions are listed on the recorder screen.

To delete any action from your recording, select the trash can icon.

To temporarily stop recording, select Pause recording at any time.

To continue recording from where you left off, select Start recording again.

To erase all the recorded actions and start over, select Reset recording.



Recording tips
Use these tips to improve your recording experience.

Be methodical in your actions. This includes waiting for the red box to focus on the
item you're trying to interact with before selecting it, as there may be a slight
delay.

If there were any selections made by mistake, delete the action in the recorder
screen.

If you record a step that's not intended to be a part of the process, delete the step
with the trash icon.

Prepare a recording for analysis
Once the recording is finished, the recorded actions can be viewed on the recording
details screen. It's important to prepare the recording for analysis before proceeding.

The actions that were recorded during the process can be very detailed and specific. In
order to make sense of them and create a clear process map, these actions need to be
grouped together into larger activities. The process mining capabilitiy is now able to
automatically group similar actions into activities.

Ensure that any sensitive information is removed from the recording before analysis.
This can be done to protect data privacy and security. For more information on how to
protect your data, go to Protect your data.

Here's a short video on how to prepare a recording for analysis.

https://www.microsoft.com/en-us/videoplayer/embed/RWN6PQ?postJsllMsg=true

Grouping actions into activities
Once you have completed the recording process, you might notice that some activities
have already been automatically created for you. You have the option to keep these
activities as they are, or you can modify them to better suit your needs.

Edit an existing activity
Here are some tips on editing an existing activity.



1. To change the starting action of an activity, drag the header of the activity up or
down the list of actions to the desired starting point.

2. To change the name of an activity, select it and a combo box appears on the right.

3. You can choose from existing activity names in the dropdown menu, or create your
own if needed.

Add a new activity
You can add an activity to a process after you recorded it.

1. Select Add activity to add an activity header. All actions below the header and
before the next activity header are part of the group.

2. Move the activity header up or down the actions list to where you want the activity
to start.

3. Name the activity on the right, using the dropdown menu to find existing activity
names or create a new one.

Delete an activity
To analyze, you need at least two activities. Otherwise, the process map wouldn't be
meaningful.

1. If you don't want an auto create activity or made a mistake and want to delete an
activity, select Delete activity in the command bar.

2. If you don’t want any of the auto created activities or just want to start over from
scratch, select Delete all activities in the command bar.

3. At any time, select Save on the top right to save your work.

Save and analyze
1. When you finish grouping, select Save and analyze on the top right.

2. Once analyzed, select View analytics in the notification bar to go to the analytics
page.

To learn more, go to Analyze processes.



3. Alternatively, you can save without analyzing by selecting the caret next to Save
and analyze, and then select Save.

4. Select Close to return to the process details screen.

Grouping tips
Here are some tips to group actions into activities, which may be helpful for your use
case.

1. Use existing activity name: This creates a more consistent and accurate process
map. Activity names are available in the dropdown menu whenever a recording is
saved. To remove an activity name from the menu after it's removed from all
recordings that use that name, you need to analyze the recording.

2. Look for patterns: Analyze the recorded actions for patterns that occur frequently,
such as similar steps taken to complete a task or common applications used.
Grouping these actions together can help identify common activities.

3. Use discretion: Group actions together that make sense to you and are related to
the overall process. For example, if you are analyzing a sales process, you might
group actions related to lead generation, outreach, and closing deals.

4. Consider frequency: You may want to group actions that occur frequently
together. This can help identify bottlenecks in the process or areas where
automation could be beneficial.

5. Think about dependencies: Consider grouping actions that have dependencies on
each other. For example, if you need to download a file before uploading it, these
two activities could be grouped together.

6. Use feedback: Collaborate with other stakeholders in the process, such as
employees who perform the tasks or supervisors who oversee the process, to get
feedback on the grouping of actions. Their insights can help improve the accuracy
and usefulness of the process map.

Create recommended activity names
As a process owner or co-owner, you can create recommended activity names for a
process. This ensures more consistency in naming across recordings.

1. On the process details screen, select Create activity names.

2. To add a new activity name entry to the recommended list, select New name.



3. When you're done, select Save.

The activity names you added now appear under Recommended names in the
dropdown menu when grouping actions for a recording. Any activities that aren't
defined in the recommended list appear under Custom names.



Analyze tasks and processes
Article • 07/18/2023

You can access most of your tasks and process management activities in the task mining
capability.

1. On the left navigation pane in Power Automate, select Process mining > All
Processes.

2. Select your process to go to the Details screen.

７ Note

The TDS endpoint setting for your organization needs to be enabled. This feature
is enabled by default, but if it's disabled for any reason, ask your Microsoft Power
Platform administrator to enable it in the Power Platform admin center.

View your process map and related analytics
To begin analyzing your process, start by checking the status of your recordings and
using Analyze on the command bar. This button adds the selected recording into the
process map and related analytics. The analytics reports the insights only from
recordings that have the Analyzed status.

After the task is analyzed, the process map and related analytics are available when
you select Analytics in the menu.

On the Details pane, you can check the status of the analysis for your process and
whether it has been previously analyzed.



Analysis happens at the process level for all recordings that are ready to be
analyzed.

Pay attention to the recording status, which you can find under the Status column
of the Recordings pane. Only recordings with the Ready to analyze status are
considered for analysis.

Here's a short video on how to view analytics:

https://www.microsoft.com/en-us/videoplayer/embed/RWMYVy?postJsllMsg=true

View your recording status
The status of each recording can be found under the Status column of the Recordings
pane. Recordings can have one of the following statuses:

-In progress: This means that the recording is currently being made, or it might not
have started yet. The web portal can't determine the status of the recording until it's
been saved because the recording happens in the desktop client. Even after a recording
has been saved, it's possible to see the "In progress" status because some processing is
required to make the recording ready to view.

Failed: An error occurred while processing the recording. You need to create a new
recording.

Not analyzed: The recording has been processed and is available to view and edit,
but it hasn't been marked as ready for analysis.

Ready to analyze: The recording has been marked as ready for analysis and is
included in the report and analytics the next time you analyze the process.

Analyzed: The recording has been analyzed and is included in the analytics output
that can be viewed through the Analytics screen.

An analyzed recording might have one of the following icons next to it:

Icon Description

Indicates that the recording has been analyzed, but has been marked not ready to analyze.
It won't be included if the process is analyzed again.

Indicates that the recording has been modified and might be out of sync with the previous
analysis. If you analyze the process again, the recording is synchronized with the analysis
output and the process map.



Visualize processes
Article • 07/18/2023

The process map is a powerful tool that can help you visualize and analyze your
business processes. It provides a graphical representation of how your processes are
performed, making it easier to identify areas for improvement.

Process map
You can access the process map by selecting the Analytics > Process tab. From there,
you can see a detailed view of your processes, including each step in the process and
how they are connected. The process map can help you identify inefficiencies or
bottlenecks in your processes, allowing you to make improvements that can save time
and resources.

Activities are tasks or actions that form a business process, and they can be performed
by humans or machines. In the process map, activities are represented as nodes and
transitions between them as edges, with each sequence having a start and an end.

The process map displays different combinations of activities as separate process
variants. Each process variant is a unique sequence of activities from the start to the end
of the process. Each variant differs from the others by at least one activity. The process
map provides metrics such as the frequency of activities and throughput time for each



variant. Frequency indicates the total number of recordings/cases that pass through an
activity, while throughput time is the time between the first and last event of a case.

There are various filters available for you to drill down into the process:

Variant selector: You can activate this filter by selecting one or multiple bars in the
Variants bar graph. It allows you to select one variant or a set of process variants
to visualize in your process map.

Recording selector: You can activiate this filter by clicking one or multiple bars in
the Recording by time bar graph. It allows you to select one recording or a set of
recordings to visualize in your process map.

Start date filter: Allows you to see the process visualization in a particular period.

Furthermore, there are specific metrics provided as key performance indicators that can
help you gain a better understanding of your process. These metrics are discussed in
more detail below.

Process KPIs
Number (#) of recordings: This KPI displays the total number of recordings of the
same process that were submitted to analyze the process. The more recordings
available, the more insights can be gained. For instance, if you only provide a few
recordings of a process that has multiple paths to completion, you may not gain
insights into all the possible process variations.

Number of variants: This KPI indicates the number of paths a process could take.
For example, if a process has one additional activity, it would be counted as one
more variant of the process.

Average time: This KPI displays the average time taken to complete a process
across all the recordings associated with the process. It is a crucial data point for
process mining because examining the duration of a process can reveal any
bottlenecks.

Process map visualizations
Variants by frequency: Displays how frequently a specific process path was
followed by the process.

Variants by time: Shows the average time spent to finish the process per variant.



Activity by average time: Displays the average time taken for each activity. A quick
glance at this visual can help identify the most time-consuming activities of a
process.

Recordings by time: Displays the time taken for each recording in a process.

Start date: Shows you Shows you the date range for the analytics and process
maps shown in the report.

Application analytics
Application analytics allow you to gain more insights from recordings by understanding
application usage. This report informs you about:

The top apps used.

Access patterns and what apps are used together.

App insights for each activity or recording.

Application analytics KPIs
Apps used: The total number of apps used in a process.

Number (#) of times accessed: The number of app accesses. Times accessed is
when an app comes back into focus.



Time spent: The amount of time spent using apps. This doesn't count time spent
when not focused on an app—for example, desktop.

Actions: The count of actions within apps.

Application analytics visualizations
Application usage: This scatter plot shows the time spent and times accessed for
each app used, with the size of the circles representing how many recordings use
that app. The goal of this plot is to understand usage patterns. Some apps may be
used frequently but only for short periods, indicating the recorder is jumping back
and forth between this application and others. Other applications may be used for
a longer period of time, and the process relies heavily on actions occurring within
that application, without requiring extensive of other applications.

The size of the circles in the scatter plot indicates the frequency of usage of each
application across all recordings. Applications that are used in most or all recordings
have larger circles. This information can be helpful in identifying essential applications in
a process that may require optimization or automation to improve overall efficiency.

Application switching: This bar chart is used to display the frequency of pairs of
applications used together. It complements the application usage scatter plot by
providing additional information on what two applications are most frequently
used in conjunction. The insights gained from this chart can help identify any data
transfers or manual input between these applications, which is important to
consider when optimizing or automating the process.

Time spent by application: This is a pie chart that is used to represent the
distribution of time spent on each application. This visual provides a clear
understanding of which applications are being utilized the most in terms of time
spent on them.

Actions by application: This is a pie chart that is hows the distribution of actions
performed on each application. This visual helps identify which applications have
the most actions or manual inputs, providing insight into areas that may require
further optimization or automation.

See also
Connector overview
Overview of cloud flows



Identify automation opportunities
Article • 07/26/2024

The automation recommendation feature in the process mining capability helps you
identify automation opportunities and guides you through automating your processes
using Microsoft Power Automate. You can watch this short video to learn how to use the
feature:

https://www.microsoft.com/en-us/videoplayer/embed/RWN6PS?postJsllMsg=true

The blue recommendation icons on the process map activities indicate automation
opportunities.

To automate an activity, select the +Automate activities option above the process map.
This takes you to the Power Automate form designer, where you can see the connector
recommendations for the activities in your process map. From there, you can select and
add the connectors to your flow to automate your process.



Related information
Connector overview
Visualize processes



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Share task mining processes
Article • 07/18/2023

When you create a process in the process mining capability, only you can see it. But
getting input from others is a key to understanding different ways to accomplish the
process you've created. Share your processes with others in your organization so they
can also manage or contribute to them.

Here's a short video on how to share a process.

https://www.microsoft.com/en-us/videoplayer/embed/RWN6PP?postJsllMsg=true

There are two primary ways to share a process:

Share a process with a co-owner.

Share a process with a contributor.

If you're the co-owner or contributor of a process, you'll find it listed on the Processes
screen.

） Important

You must be the owner or co-owner to add or remove owners and contributors to a
process.

Share action
The share action can be done by selecting Share on the Processes screen. Alternatively,
select Manage on the Details screen for the following:

Each process where you're an owner or co-owner.

The system administrator in the environment.

Any security role that has share permissions on system entities of the process
mining capability.

Share panel



After selecting the share action, a share panel appear. This is where you can select
Microsoft Dataverse users within your organization to share your process with. You can
search for any user within the Dataverse tenant and invite them to your process.

When sharing a process with others, an option to automatically send an email invitation
is available. Co-owners or contributors will be asked to help manage the process or add
new recordings, respectively. The email invitation will contain a link to the shared
process.

Share a process with a contributor
The most common way to share a process is by adding a contributor. A contributor of a
process has the following abilities:

View the details of the process.
Add and label recordings.
Manage their own recordings that have been added to the process, including
labeling and deleting recordings.



Share a process with a co-owner
When you add a co-owner to a process, you enable them to assist you in labeling and
validating contributors' recordings, managing the process, and visualizing the process
analytics and dashboard. Here are the actions that any co-owner of a process can
perform:

View your process map and related analytics

Update properties, such as name and description

Invite co-owners and contributors

Add and label recordings

Manage all recordings that have been added to the process (including labeling and
deleting others' recordings)

View the analytics of an analyzed process

Delete the process

） Important

Only the owners of a process can analyze it.
Removing all process roles from a user (such as co-owner and contributor)
doesn't remove that process from the user's process list view. They can't
perform any actions on the process.
The admin experience for processes they don't own isn't supported.



Security and privacy
Article • 10/30/2023

The process mining capability relies on environment security and Microsoft Dataverse
security roles and privileges to grant access to its features in Power Automate. For more
information, go to Power Platform security overview.

Security
Some privileges are set by default in Dataverse. This allows built-in security roles to use
the process mining capability without further actions from system administrators.
Specifically:

The Environment maker role can use the process mining capabilities to create,
share, and contribute to processes.

Administrators and system customizers can access all processes created in the
environment.

The Process Mining User security role can only view created process reports.

） Important

The Process Mining Application is an internal security role that process mining
uses. (Process mining was formerly named process advisor). Don't assign this
security role to users. Don't modify the set of privileges in the Process Mining User
or Process Mining Application security roles.

The Process Mining User security role won't suffice to create, share, and contribute
to processes.

If you’re using Conditional Access polices to limit access to Power Automate and its
features, the following apps must be included in Cloud apps policy application:

Power Apps
Power Automate

Currently, having conditional access to only Power Automate isn't enough. To learn
how to set up Conditional Access policies, go to Plan a Conditional Access
deployment and Control Access to Power Apps and Power Automate with
Microsoft Entra Conditional Access Policies .



Privacy
Sharing processes and their recordings is essential to create rich analysis and insights in
the process mining capability. Users can add recordings to a process. They can then use
Power Automate to record processes and then import the processes into the process
mining capability. Owners and contributors can see some data from the process and its
recordings.

While most of the information process recordings capture can be essential to the
understanding of the process activities, some steps might contain sensitive information.
You can modify and delete sensitive information such as personally identifiable
information (PII) from your recordings.

In Power Automate, users can:

Delete sensitive steps or modify input data information.

Pause and resume recording to avoid recording sensitive information and PII.

After you import the recording into the process mining capability, you can remove
sensitive information by doing the following:

Rename step names or descriptions.

Delete screenshots.



Protect your data
Article • 07/18/2023

To ensure that sensitive data is not exposed, the process mining capability allows you to
remove screenshots and text entries stored during the recording session in the task
mining capability. Before preparing your recordings, you can also remove any
confidential information in the text or images to further protect your data.

Delete screenshots
To remove screenshots from your recording, follow these steps:

1. Open the recording in the process mining capability.
2. Select the step that contains the screenshot you want to remove.
3. Select Delete screenshot. This procedure removes the selected screenshot from

the recording. Make sure to save the changes before exiting the recording.

Remove text
In the process mining capability, you can protect sensitive data by removing it from any
text entries recorded during a session. To do this, select the text entry that contains the
sensitive information and modify the step description to remove it. For example, you
could replace the sensitive data with a generic term or placeholder. Be sure to save your
changes before sharing or analyzing the recording.






Export and import your process
Article • 07/18/2023

You can copy or move process mining processes from one environment to another
using Microsoft Power Platform solutions. You need to be an owner or co-owner of a
process to export it.

７ Note

Only the export and import of task mining (recordings) processes are currently
supported. Process mining (data) processes can't currently be exported and
imported.

To learn more about solutions from Microsoft Power Platform, go to Overview of
solution-aware flows.

Export a process
1. Sign in to Power Automate .

Make sure you've selected the environment where the process you want to export
has been created.

2. Select Solutions in the navigation pane on the left.

3. In the list, select the solution you want to use to add your process, or create a
solution and select it.

4. Select Add existing > PM Inferred Task.

5. Search for and select the process you want to export, and then select Add.

You can now export your solution and import it in another environment.

For more information about solution export, go to Export a solution.

Import a process
To import a process into another environment:

1. Make sure you've exported your process with a solution.



2. Go to the environment where you want to import your process.

3. Follow the instructions in Import a solution.



Known issues in the process mining
capability
Article • 07/18/2023

We'll continue to add issues here. If you're experiencing an issue not mentioned, check
the Process Mining community forums .

Unable to access the process mining capability
If you can't see the process mining capability in Power Automate, receive error
messages, or if you can’t access the home page, verify that:

You have a Power Automate license.

If you don’t have a license, you can activate your trial license from Desktop flows
in Power Automate.

You have access to the Power Automate environment and the permissions required
by the process mining capability described in the Security and privacy article.

Your browser has the feature to accept third-party cookies enabled. You can enable
it in your browser settings.



Troubleshoot issues in the process
mining capability
Article • 02/06/2025

This article explains common issues and error messages in the process mining capability.
You find solutions to troubleshoot with procedures and helpful tips.

Issues with dataflow refresh

"There was an issue with a recent dataflow refresh, check
your dataflow refresh history."
When you go through setup, the process mining capability creates a dataflow that's tied
to the process. Normally you don’t need to interact with the dataflow, but if there are
issues with the dataflow refresh, you might need to troubleshoot them. Dataflow refresh
is what reads the data source and makes it ready to be analyzed.

To troubleshoot:

1. Make a note of the environment in the environment display on the upper-right
corner of the page.

2. Make a note of the value of Name in the Data Source card below the Details card.

3. Sign in to Power Apps .

4. Select the same environment that you noted in step 1.

5. Select More > Dataflows.

6. Find the dataflow name that you noted in step 2.

7. View the issue by selecting the Warning icon in the Last refresh column.



8. Download the report by selecting the Download icon in the Actions column.

9. Open the report to see details of the issue.

"There was an issue with your Dataverse access privileges
for dataflows"
When you go through setup, the process mining capability creates a dataflow that's tied
to the process. A dataflow requires certain sets of Dataverse privileges. If these
privileges are revoked or altered, it might result in this issue.

To troubleshoot, system administrators can review the privileges on the dataflow tables
for the environment Maker role, and ensure they have the default privileges at the
Organization level set.

Issues with analyze

Failure when analyzing
If you encounter an error message while attempting to create and analyze a process, it
might be due to a missing security role. To resolve this, contact the administrator of your
environment and request that they assign you the Environment Maker security role.

Analyze a process
Once you're done with setup, select Analyze. You're able to view the Analytics page
when the analysis is complete. Analysis typically takes a few minutes but might be faster
or slower depending on how much data needs to be analyzed.

７ Note



If you don't visit the Analytics page for 14 days, you need to re-analyze the process
to access the Analytics page again.

For more information and a short video of analytics, go to Use KPIs and visualizations
for analytics.

"The process can't be analyzed because there are too
many processes in this environment. To fix this, delete
some of the processes, use a different environment, or
use your own Power BI workspace."
Currently, Dataverse-managed Power BI workspaces allow only 1,000 reports for each
environment. This means you need to delete a few processes from the current
environment, or create a new environment to analyze the process in. To learn more
about limitations, go to Workspaces in Power BI—Considerations and limitations.

To delete a process, follow these steps:

1. Select Processes from the breadcrumbs on the analytics or details page, or select
All procesess from the Process mining home page.

2. Select the vertical ellipses (⋮) for the process you want to delete, and then select
Delete process from the dropdown menu.



3. To delete the process, select Confirm.

Another option is to use your own Power BI workspace to store the generated
reports. This option surpasses the limit of the Dataverse-managed Power BI
workspace.

To learn more, go to Create your own custom Power BI workspace.

"You must have one case with at least two activities to
analyze your process. Please change your data."
Process mining isn't normally helpful when there's only one activity name in the data.
This is because the process map visualizes the flow of the process from one activity to
the next. In this case, you should do the steps in the following list:

Check the column that's been mapped to activity name.
Confirm that there's only one value for that column.
Determine if there's another column that contains something with more than one
possible value that can represent activities of the process.

"Following column(s) don't have the right data types: [x].
Please check your data and try again."
The case ID and activity name columns should be of the Text data type. The timestamp
columns should be of the Date/Time data type. One of the most frequent causes of
invalid format is in the timestamp column. To fix the format, return to setup and select
the icon next to the timestamp column, and ensure it's been mapped to Date/Time.



If the format is incorrect, you see something like this:

One possibility is that although the timestamp column has a valid datetime format, the
format is valid for a different locale than the locale that the process is created in. A
typical example is this datetime format being used in the United States locale:
dd/mm/yyyy hh:mm:ss. In this case, we won't automatically detect that column as a
datetime column. One way to fix this issue is by manually changing the locale. To do
this:

1. Delete the Changed column type step that you did previously. Do this by selecting
X next to the last applied step in the Query settings pane on the right.

2. On the toolbar, select Options > Project options.

3. On the Locale dropdown list, select the correct locale and then select OK.

4. Use the same method to set the timestamp column to the Date/Time data type
again.



Where the format is dd/mm/yyyy hh:mm:ss, setting the locale to English (Canada)
should result in successful conversion of the column type. For other cases, find the
correct locale that supports your specific datetime format.

"More than 50% of your data has invalid format. Please
check your data and try again."
To fix this issue, go to Following column(s) don't have the right data types: [x]. Please
check your data and try again.

"Following column(s) are missing from your dataflow: [x].
Please check your data and try again."
This issue should occur only if you didn't properly map the columns in your data source
to the columns. For more information, go to Map data.

"Your entity contains no data, check your dataflow and
try again."
This issue should occur only if there's no data. Either the data source that you're
connecting to has no data, or the power query expression you used filtered out all the
data. Check your query and ensure that you can see some data rows in the preview
table.

"The number of rows in your data exceeds the limit. [x]
rows have been ignored."
To fix this issue using Power Query, learn more in Reduce the number of total records.

"Analysis failed, please try again."
You might have run into other analyze issues. For more ways that we can support you,
go to Support , or post your issue in the Community Forums .

Issues with your own Power BI workspace

"You must be an admin of the Power BI workspace to use
it with this report."



You must be an admin of your Power BI workspace. To learn more about user access and
permissions, go to Give users access to workspaces.

"You must be an admin of the Power BI workspace to use
it with this report. After you become an admin, try to
reanalyze the report."
This is the same as the previous issue, but the error occurred during process analysis.
Once you become an admin using the fix from the previous issue, reanalyze the report.

"The process mining service principal must be an admin
of the Power BI workspace to refresh this report."
Enable admin access for the process mining capability prod service principal. To learn
how to give the service principal admin access, go to Create your own custom Power BI
workspace.

"The process mining service principal must be an admin
of the Power BI workspace to refresh this report. After the
problem is fixed, try to reanalyze the report."
This is the same as the previous issue, but the error occurred during process analysis.
After ensuring the process mining capability service principal is the admin of the
workspace, reanalyze the report.

"The process mining service principal can't access the
Power BI workspace."
Set up the process mining capability service principal for your Power BI workspace. To
learn how to set up, go to Set up your workspace.

"The process mining service principal can't access the
Power BI workspace. After the problem is fixed, try to
reanalyze the report."
This is the same as the previous issue, but the error occurred during process analysis.
After ensuring that the process mining service principal is added to the workspace and
has admin access, reanalyze the report.



"The selected Power BI workspace needs premium
capacity to work with this report."
Assign a premium license to your workspace. To learn how to enable premium capacity,
go to Premium capacity settings.

"The selected Power BI workspace needs premium
capacity to work with this report. After the problem is
fixed, try to reanalyze the report."
This is the same as the previous issue, but the error occurred during process analysis.
After ensuring that your workspace has premium capacity per Premium capacity
settings, reanalyze the report.

Optimized data model isn't created
Confirm the Allow XMLA endpoints and Analyze in Excel with on-premises semantic mode
setting is enabled (this setting is enabled by default). You can find this setting in Power BI
admin portal > Tenant-level settings > Integration Settings. If an admin doesn't want
to enable this setting for all users, it's necessary to add the Process Insights service
principal to a security group where the setting is enabled.

Issues with your own Azure Data Lake Storage
Gen2 and incremental data refresh

If you encountered an error message, "Couldn’t connect
to container"
Revisit the prerequisites to make sure settings are correct.

How can I check if a CORS issue exists or not?
You can check the network logs in your browser with developer tools while connecting
data lake storage. Some HTTP requests failed with a 403 error and it could state "CORS
not enabled, or no matching rule found for this request."

Although I set CORS setting correctly, why do I still get
the error and am unable to access?



The browser cached CORS settings. Retry after flushing out browser cache. As the client
browser does cache the CORS setting, you need to remove the cache if you have trouble
even after you set the CORS properly. You can also adjust the max age of CORS settings.

Your header row is larger than 1 MB
Check the event log file and rename the column headers so that their aggregated length
including separator (comma) is less than 1 MB.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Power Platform and Azure Logic Apps
connectors documentation
A Power Platform connector allows the underlying service to talk to Microsoft Power
Automate, Microsoft Power Apps, Microsoft Copilot Studio, and Azure Logic Apps. It
provides a way for users to connect their accounts and leverage a set of prebuilt actions
and triggers to build their apps and workflows.

About connectors

ｅ OVERVIEW

Connectors overview

Connectors architecture

List all connectors

Connector reference by product

ｉ REFERENCE

Power Apps connectors

Power Automate connectors

Logic Apps connectors

Connector reference by tier

ｉ REFERENCE

Standard connectors

Premium connectors

Connector reference by release status

ｉ REFERENCE



Preview connectors

Production connectors

Connector reference by publisher

ｉ REFERENCE

Microsoft published connectors

Verified published connectors

Create a custom connector

ｆ QUICKSTART

Create a custom connector from the custom connector wizard

Create a custom connector from an OpenAPI definition

Create a Logic Apps connector

Create custom connectors in solutions

Custom connector FAQ

ｓ SAMPLE

Custom connector samples

Certification

｀ DEPLOY

Certification overview

Prepare connector and plugin files for certification

Verified publisher certification process

Independent publisher certification process

Test your connector post certification



Update your certified connector

Move your connector from preview to general availability

Advanced tutorials

ｇ TUTORIAL

Extend an OpenApi definition

Create and update a custom connector using CLI

Authenticate with Microsoft Entra ID

Use a custom polling trigger

Use a webhook trigger

Learn best practices for string fields

Implement a test connection

Versioning operations

Specifying connection parameters

Create oAuth2 Permission Grant PowerShell script

Use a custom connector

ｃ HOW-TO GUIDE

Use a custom connector from a logic app

Use a custom connector from a flow

Use a custom connector from a Power Apps app

Policy templates

ｉ REFERENCE

Policy templates overview



Online training

ｄ TRAINING

Build custom connectors for Power Automate



Manage connections in Power
Automate
Article • 03/10/2023

Power Automate uses connections to make it easy for you to access your data while
building flows. Power Automate includes commonly used connections, including
SharePoint, SQL Server, Microsoft 365, OneDrive for Business, Salesforce, Excel, Dropbox,
Twitter, and more. Connections are shared with Power Apps, so when you create a
connection in one service, the connection shows up in the other service.

Here's a quick video on managing connections.
https://www.microsoft.com/en-us/videoplayer/embed/RWKZQq?postJsllMsg=true

You can use connections to perform these tasks:

Update a SharePoint list.
Get data from an Excel workbook in your OneDrive for Business or Dropbox
account.
Send email in Microsoft 365.
Send a tweet.

You can create a connection in multiple scenarios, including:

Creating a flow from a template.

Creating a flow from a blank, or updating an existing flow.

Creating a connection in Power Automate .

 Tip

For detailed information about using SharePoint with Power Automate, see
the SharePoint documentation.

Add a connection
1. Sign in to Power Automate .

2. On the left navigation pane, select Data > Connections.



3. At the top of the page, select New connection.

4. In the list of available connections, choose the connection that you want to
set up
(such as SharePoint) by selecting the plus sign (+).



5. To find a particular connection option, enter the connector name into the search
box that's located in the top right corner of the page, below the settings and help
buttons.

6. Follow the steps to enter your credentials to configure the connection.

 Tip

You can find all the connections that you've created under Data >
Connections.

Connect to your data through an on-premises
data gateway
Some connectors, such as the SharePoint connector, support the on-premises data
gateway. To create a connection that uses a gateway:

1. Follow the steps earlier in this topic to add a connection.

2. In the list of available connections, select SharePoint.

3. Select the Connect using on-premises data gateway option.



4. Provide the connection's credentials, and then select the gateway that you want to
use. More information: Manage gateways and Understand gateways

７ Note

After the connection is configured, it's listed in Connections.

Delete a connection
When you delete a connection, it's removed from both Power Apps and Power
Automate.

1. Go to Data > Connections, and select the connection that you want to delete.

2. Select … to view more commands, and then select Delete.

3. Select Delete to confirm that you would like to delete the connection.



Update a connection
You can update a connection that isn't working because your account details or your
password changed. When you update a connection, it's updated for both Power Apps
and Power Automate.

1. Go to Data > Connections, and then select the Fix connection link for the
connection that you want to update.

2. When prompted, update your connection with new credentials.

Find which apps and flows use a connection
You can identify the apps and flows that use a connection to understand how the
connection is used.

1. Go to Data > Connections, and then select the connection that you want to learn
more about.

2. Select … to view more commands, and then select Details to see the details for the
connections, including the status and the date it was created.

3. To view apps that use the connection, select Apps using this connection.

4. To view flows that use the connection, select Flows using this connection.

Troubleshoot connections

Connection ownership by a different account
Per the policies in your organization, you might need to use the same account to sign in
to Power Automate and to create a connection to SharePoint, Microsoft 365, or
OneDrive for Business, for example.

For example, you might sign in to Power Automate with yourname@outlook.com but
receive an error when you try to connect to SharePoint with yourname@contoso.com.
You can instead sign in to Power Automate with yourname@contoso.com and you'll be
able to connect to SharePoint.



Deprecation of the Power Automate Management
connector's third-party authentication option
The Power Automate Management connector authentication option of third party was
deprecated in June 2020 and will no longer work after October 1, 2022.

Follow these steps to replace third party authentication connections.

1. Find the third party authentication connection you want to replace, and then
delete it.

2. Create a "first party authentication" connection.
3. Add the new connection on the flows that need it.

Find Power Automate Management connections as an admin
If you are an admin, you can find these problematic connections using a repeatable
pattern that can be automated in a flow with the help of some admin connectors:

1. Find the environments using List environments as admin.
2. Find the connections in those environments using Get Connections as admin.
3. Find the connections to be replaced with id="shared_flowmanagement" and

properties.connectionParametersSet.name="thirdParty" using a Parse JSON
action with conditions .

4. Then finally, get the connection details, including the connection display name and
the creator who should replace the connection.

After you have that list of connections, contact the connection owners to let them know
that the connections should be replaced.

Find Power Automate Management connections as a user
If you are a non-admin user, you can find your Power Automate Management
connections and learn about the apps and flows that use each connection before
replacement.

If you don't know what authentication option was used on the Power Automate
Management connection, you could create a flow and use the List my connections
action to see the advanced connection metadata, or delete the existing connection and
replace it with a new connection using the Authentication Type of First Party.

Deprecation of the Power Automate Management connector's
legacy default authentication option



The default authentication option was also deprecated in June 2020, however, it was
immediately hidden so that it couldn't be used from that date. All connections with the
authentication of default were created prior to June 2020. Those connections should
also be replaced. If you use the Get Connections as admin action, those connections will
have id="shared_flowmanagement" and properties.connectionParametersSet.name="".



Manage an on-premises data gateway
in Power Automate
Article • 07/17/2024

Install and manage an on-premises data gateway to securely integrate a variety of
cloud-based apps with your on-premises data and apps through Power Automate.

With a gateway, you can connect to on-premises data over the following connections.

Apache Impala
BizTalk Server
Custom connectors that you create
DB2
File System
Http with Microsoft Entra ID
Informix
MySQL
Oracle Database
PostgreSQL
SAP ERP
SharePoint
SQL Server
Teradata

） Important

Microsoft SharePoint data gateways now support both HTTP and HTTPS traffic.

Prerequisites
The user name and password that you used to sign up for Power Automate.

Administrative permissions on a gateway.

You have these permissions by default for each gateway that you install. Also, an
administrator of another gateway can grant you these permissions for that
gateway.

A license that supports gateways. For more information, see the “Connectivity”
section of the pricing page .



 Tip

You can create a gateway and an on-premises connection for any environment.

Install a gateway
To install a gateway, follow the steps in Install an on-premises data gateway. Install the
gateway in standard mode because the on-premises data gateway (personal mode) is
available only for Power BI.

View your gateways
Sign in to Power Automate , and then select Data > Gateways in the navigation pane
on the left side.

７ Note

If you created or were given access to a gateway in Power Apps, that gateway
appears in the My gateways list in Power Automate.

Cluster your gateways
You can create high availability clusters of on-premises data gateway installations to
avoid single points of failure in accessing on-premises data resources.

By default, Power Automate uses the primary gateway in the cluster. If the primary
gateway isn't available, the service switches to the next gateway in the cluster, and so
on.

Once you've set up a gateway cluster, you can allow traffic to be distributed across all
gateways in the cluster.

Follow these steps to distribute your traffic across your gateways:

1. Select Data on the navigation bar on the left side.
2. Select Gateways.
3. Select any of your gateways.
4. Select Distribute requests across all active gateways in this cluster.
5. Select Apply to save your changes.



For more information, see Understand gateways.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



What is an on-premises data gateway?
Article • 12/16/2022

The on-premises data gateway acts as a bridge to provide quick and secure data
transfer between on-premises data (data that isn't in the cloud) and several Microsoft
cloud services. These cloud services include Power BI, Power Apps, Power Automate,
Azure Analysis Services, and Azure Logic Apps. By using a gateway, organizations can
keep databases and other data sources on their on-premises networks, yet securely use
that on-premises data in cloud services.

How the gateway works

For more information on how the gateway works, see On-premises data gateway
architecture.

Types of gateways
There are two different types of gateways, each for a different scenario:

On-premises data gateway allows multiple users to connect to multiple on-
premises data sources. You can use an on-premises data gateway with all



supported services, with a single gateway installation. This gateway is well-suited
to complex scenarios with multiple people accessing multiple data sources.

On-premises data gateway (personal mode) allows one user to connect to
sources, and can’t be shared with others. An on-premises data gateway (personal
mode) can be used only with Power BI. This gateway is well-suited to scenarios
where you’re the only person who creates reports, and you don't need to share
any data sources with others.

Use a gateway
There are four main steps for using a gateway.

1. Download and install the gateway on a local computer.
2. Configure the gateway based on your firewall and other network requirements.
3. Add gateway admins who can also manage and administer other network

requirements.
4. Troubleshoot the gateway in case of errors.

Next steps
Install the on-premises data gateway



What is the SAP Procurement template for
Power Platform?
Article • 03/28/2025

SAP enterprise resource planning (ERP) is a centralized system of record that facilitates the
management of data and business processes between departments in an organization.
Microsoft Power Platform can help you transform the way you view and work with your SAP
data. Enhanced functionalities in the on-premises data gateway and the SAP ERP connector
make it easier for you to manage your SAP integration with Power Platform.

The SAP Procurement template accelerates the integration of data between SAP and Power
Platform to drive efficiencies in your procure-to-pay processes. The template contains the
building blocks needed to streamline all the SAP screens and attributes related to a core
process into one simple screen in Power Apps, with further automation of processes behind the
scenes using Power Automate flows. With little to no training, procurement team members can
manage SAP data in less time, reduce inefficiencies in current manual processes, and avoid
data entry mistakes.

The template's starter apps, flows, and other components are ready for you to extend and
customize to meet your organization's unique needs. It consists of the following layered
solutions:

SAP Base contains base components used by the SAP Procurement solution templates
and future SAP solution templates.
SAP Procurement contains components that help transform your procure-to-pay
business processes connected to SAP.

Streamline and automate SAP procurement
processes
The SAP Procurement template contains the building blocks necessary to:

Streamline all the SAP screens and attributes related to core SAP procurement processes
into one simple screen in Power Apps.
Automate core processes behind the scenes using Power Automate flows.



Extend the SAP Procurement solution
The solution template's starter apps, flows, and other components are ready to be built upon
and customized to meet your organization's unique needs. You can:

Install and set up a SAP Supplier Self Service site to work with the SAP Procurement
solution.
Customize your solutions to meet your organization's unique needs.
Integrate your system of record with other features, applications, and systems.
Incorporate additional controls over how your users interact with data.



Experience the benefits
The SAP solution template is a framework designed to help you quickly and easily configure,
deploy, and manage SAP solutions on Power Platform so your organization can experience a
swift return on investment.

During the design phase, the solution template helps you:

See how your system's data can be accessed and organized in a streamlined view in
Power Apps.
Realize how workflows can be automated by Power Automate cloud flows operating
behind the scenes.
Learn how you can enhance these solutions to meet your organization's needs.

Once deployed, you'll see your procurement team members quickly and easily adapt to
working with SAP data using Power Apps and experience:

Enhanced user experiences
Improved operational efficiencies
Fewer errors
Greater insights into data

Access the SAP Procurement template
You can access the SAP Procurement template in two ways:

Microsoft AppSource
Template for Power Platform on GitHub

） Important

Before accessing and installing the SAP Procurement template solution files, you must
integrate SAP with Power Platform.

Get started with SAP Setup Assistant
Power Platform integration with SAP requires many considerations and steps. You can use the
SAP Setup Assistant. to walk through a checklist of manual and automated steps that help you
get up and running with the SAP Procurement template.



Support
Enterprise templates for Power Platform are published as is. However, we do provide template
support to help you be successful.

Support can be accessed at Templates for Power Platform  on GitHub. It's a dedicated
support space for you to:

log questions
access template assets
access template release updates
access template support resources

Related content
Get started with SAP Procurement template
Frequently asked questions about SAP integration with Power Platform
SAP Vendor Management app
SAP Requisition Management app
SAP Purchase Order Management app
SAP Goods Receipt Management app
SAP Vendor Invoice Management app
SAP Vendor Payment Management app



Use AI Builder in Power Automate
Article • 10/09/2024

AI Builder is a Microsoft Power Platform capability that enables you to add intelligence
to your automated processes, predict outcomes, and help improve business
performance. AI Builder is a turnkey solution that brings the power of Microsoft AI
through a point-and-click experience and is directly integrated into Power Apps and
Power Automate. More information: What is AI Builder?

You can build AI models by using the AI models option from the left navigation pane of
Power Automate . More information: AI model types

Use your AI Builder models in your flows to add intelligence to your organization. More
information: Use AI Builder in Power Automate

Related information
Training: Use AI Builder in Power Automate (module)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Power Automate for enterprise
developers, ISVs, and partners
Article • 10/30/2023

As a developer, you can extend Power Automate, enabling even more powerful
solutions for organizations and customers.

Power Automate for enterprise developers
As an enterprise developer, empower your organization to build robust tailored
solutions on Power Automate:

Build custom connectors: Develop custom connectors to connect to your
organization's data and web services through Power Automate. Learn more

Build Azure Functions: Craft Azure Functions to extend apps with custom server-
side logic. Learn more

Embed Power Automate: Embed Power Automate directly into your website
experiences to create integrated solutions, surfacing workflows or processes where
people in your organization already do their work. Learn more

Run desktop flows: Integrate desktop flows directly into your product to enable
robotic process automation in your solutions. Learn more

Power Automate for ISVs and Microsoft
partners
As a Microsoft partner or Independent Software Vendor (ISV), accelerate customer
adoption by extending your products to integrate with your customers' data and
business processes, and add and customize workflows to automate business processes
as part of your application. After you've completed the below eight steps, your
application will have the ability to use a robust cloud-scale workflow engine that can
connect to 200+ different services.

ﾉ Expand table



Phase Step When needed?

Development 1. Build a custom connector to your If you want to expose your own ISV
data data to Power Apps or Power

Automate

Development 2. Add support for your application to If you want to embed the Power
authenticate users with Microsoft Entra Automate UI, integrate with desktop
ID flows or list in Microsoft AppSource

Development 3. Embed the Power Automate UI into If you want to include flow creation or
your application using our web-based management in your application
IFrame

Development 4. Integrate with desktop flow APIs If you want to include desktop flow
(RPA) capabilities programmatically
within your applications

Development 5. Create and publish flow templates If you want to pre-build flows for your
customers

Development 6. Add application logic to If you want to automatically deploy
programmatically deploy flows your pre-built flows for your customers

Distribution 7. Grant your customers licenses to If your customers don’t have Office 365
Microsoft Flow through the Microsoft or Dynamics 365 licenses
Cloud Solution Provider program

Distribution 8. List your solution on Microsoft It's recommended to increase the
AppSource visibility of your ISV solution

1. Connecting to your APIs OR Enabling customers to
connect to your APIs
As an ISV, you often have proprietary data that you would like customers to access
through your flows. You can expose access to any of your data through a custom
connector. Learn more

Once created, there are two ways to make the connector available to your customers:

The connector can be deployed into the customer’s tenant via REST APIs or
PowerShell.
To make the custom connector publicly available for all users, you can submit your
connector for certification. Learn more

2. Authentication



To call REST APIs and embed authenticated UI, your application needs to use Microsoft
Entra federated single sign-on to authenticate end users and customers. Go to Microsoft
identity platform  for information on how to enable Microsoft Entra federated SSO. We
don't have support for unauthenticated access, or access with identity providers other
tha Microsoft Entra.

3. Embedding UI components
Embed Power Automate within your app to enable deep, in-context integration between
your app and all the other services that Power Automate supports. Learn more

4. Running desktop flows
Integrate desktop flow capabilities to enable robotic process automation through your
applications, listing, running and canceling desktop flows created by you or your
customers. Learn more

5. Create and publish flow templates
Once you have a connector, you should publish templates that demonstrate how to use
your service. These templates will serve as examples that users can use to learn and then
extend to their own unique workflows. Learn more

6. Deployment
To give end users access to flows that they can use automatically, deploy them into the
Microsoft Entra tenant of the user. Use a deployment package that you deploy using our
REST APIs or PowerShell. Learn more

7. Licensing
If your customers already have either Office 365 or Dynamics 365, and these licenses are
associated with the identities that users sign in with Microsoft Entra ID, there are no
other licensing requirements for them to use standard connectors. Your users will need
one of the Power Automate licenses  to use premium and custom connectors. If your
customers don't use Office 365 or Dynamics 365, then you must acquire use rights on
their behalf for Power Automate, so that they're licensed to use those embedded
components in your application.



We offer the Microsoft Cloud Solution Provider  program to acquire licenses on behalf
of your customers. There are different pricing plans  available for Power Automate,
which you should check for plan and feature details.

See also: Overview of Power Automate licensing

8. List on AppSource
Once you have integrated Power Automate into your application, you can list it on
AppSource. With AppSource, you can generate new leads for your business by building
an app and publishing it to AppSource for new customers to test-drive. Learn more



Extend apps with Power Automate
Article • 06/23/2023

Here are some of the ways you can extend your application with Power Automate:

Create and connect to a custom connector.
Share your custom connector with all Power Automate users.
Embed the flow experience within an app.
Highlight all custom connectors so that users can interact with Power Automate in
the best way for them.

Prerequisites
A Power Automate  account.

Create a custom connector
If you have a web service to which you want to connect from Power Automate, you'll
first need to create a custom connector. When you register a custom connector, you
teach Power Automate about the characteristics of your web service, including the
authentication it requires, the triggers and actions that it supports, and the parameters
and outputs for each of those actions.

To learn about how to create custom connectors, go to Build and certify custom
connectors. After you register your custom connector, you can share it within your
organization for testing.

Share a custom connector with all Power
Automate users
After you fully test your custom connector, get your connector certified to have it
approved by Microsoft for sharing with all other Power Automate users.

Embed the flow experience into your website
or app
You can embed Power Automate into your app to enable deep, in-context integration
between your app and all other services that Power Automate supports. For example,



you can:

Browse all templates that relate to your service and let users select a template.
Manage the flows that users have related to your app.

Next steps
Learn how to embed Power Automate into your app.



Work with cloud flows using code
Article • 10/29/2024

All flows are stored in Dataverse and you can use either the Dataverse SDK for .NET or
Web API to manage them.

This article covers the management of flows included on the Solutions tab in Power
Automate. Currently, managing flows under My Flows aren't supported with code.

Interact with Dataverse APIs
Dataverse provides equivalent capabilities using either the Dataverse SDK for .NET or
Web API.

Which method should I use?
The best method depends on the project technology and the skills you have.

SDK for .NET

If your project uses .NET, we recommend using the SDK. The SDK simplifies your
development experience by providing a typed object model and methods to
authenticate.

More information: Use the Organization service

How to connect?
How to connect depends on whether you're using the Dataverse SDK for .NET or Web
API.

SDK for .NET

With the SDK, you need to connect with a client application to get access to an
IOrganizationService instance. IOrganizationService  is an interface that provides
methods you can use to interact with Dataverse.

More information:

Quickstart: Execute an Organization service request (C#)



Use the Organization service
IOrganizationService Interface

Workflow table
Cloud flows are stored in the Process (Workflow) table that is represented in the Web
API as the workflow EntityType

The following table describes important columns in the workflow table:

ﾉ Expand table

Logical Name Type Description

category Choice The category of the flow. Here are the different categories.
0  - Classic Dataverse workflows.
1  - Classic Dataverse dialogs.
2  - Business rules.
3  - Classic Dataverse actions.
4  - Business process flows.
5  - Modern Flow (Automated, instant or scheduled flows).
6  - Desktop flows.

clientdata String A string-encoded JSON of the flow definition and its
connectionReferences.

createdby Lookup The user who created the flow.

createdon DateTime The date when the flow was created.

description String The user-provided description of the flow.

ismanaged Bool Indicates if the flow was installed via a managed solution.

modifiedby Lookup The last user who updated the flow.

modifiedon DateTime The last time the flow was updated.

name String The display name that you gave the flow.

ownerid Lookup The user or team who owns the flow.

statecode Choice The status of the flow. The status can be:
0  - Draft (Off)
1  - Activated (On)
2  - Suspended.



Logical Name Type Description

type Choice Indicates if the flow is a running flow, or a template that can be
used to create more flows.
1  - Definition,
2  - Activation
3  - Template.

workflowid Guid The unique identifier for a cloud flow across all imports.

workflowidunique Guid The unique identifier for this installation of the flow.

７ Note

With Web API, Lookup values are single-valued navigation properties that can be
expanded to get details from the related record.

Lookup columns also have corresponding GUID lookup properties that can be
used in queries. Lookup properties have this naming convention: _<logical
name>_value . For the workflow entitytype in Web API you can reference these
lookup properties: _createdby_value , _modifiedby_value , and _ownerid_value .

List flows
To retrieve a list of cloud flows, you can query the workflow table. The following query
returns the first automated, instant, or scheduled flow that is currently 'on':

SDK for .NET

This static OutputFirstActiveFlow  method requires an authenticated client that
implements the IOrganizationService. It uses the
IOrganizationService.RetrieveMultiple method.

C#

/// <summary>
/// Outputs the first active flow
/// </summary>
/// <param name="service">Authenticated client implementing the 
IOrganizationService interface</param>
public static void OutputFirstActiveFlow(IOrganizationService service)
{
   var query = new QueryExpression("workflow")
   {



         ColumnSet = new ColumnSet("category",
                                    "createdby",
                                    "createdon",
                                    "description",
                                    "ismanaged",
                                    "modifiedby",
                                    "modifiedon",
                                    "name",
                                    "ownerid",
                                    "statecode",
                                    "type",
                                    "workflowid",
                                    "workflowidunique"),
         Criteria = new FilterExpression(LogicalOperator.And)
         {
            Conditions = {
            {  new ConditionExpression(
               "category",
                     ConditionOperator.Equal,
                     5) }, // Cloud Flow
            {  new ConditionExpression(
                     "statecode",
                     ConditionOperator.Equal,
                     1) } // Active
         }
         },
         TopCount = 1 // Limit to one record
   };

   EntityCollection workflows = service.RetrieveMultiple(query);

   Entity workflow = workflows.Entities.FirstOrDefault();

   Console.WriteLine($"category: 
{workflow.FormattedValues["category"]}");
   Console.WriteLine($"createdby: 
{workflow.FormattedValues["createdby"]}");
   Console.WriteLine($"createdon: 
{workflow.FormattedValues["createdon"]}");
   // Description may be null
   Console.WriteLine($"description: {workflow.GetAttributeValue<string>
("description")}");
   Console.WriteLine($"ismanaged: 
{workflow.FormattedValues["ismanaged"]}");
   Console.WriteLine($"modifiedby: 
{workflow.FormattedValues["modifiedby"]}");
   Console.WriteLine($"modifiedon: 
{workflow.FormattedValues["modifiedon"]}");
   Console.WriteLine($"name: {workflow["name"]}");
   Console.WriteLine($"ownerid: {workflow.FormattedValues["ownerid"]}");
   Console.WriteLine($"statecode: 
{workflow.FormattedValues["statecode"]}");
   Console.WriteLine($"type: {workflow.FormattedValues["type"]}");
   Console.WriteLine($"workflowid: {workflow["workflowid"]}");
   Console.WriteLine($"workflowidunique: 



{workflow["workflowidunique"]}");
}

To retrieve more records, remove the TopCount limit.

Output

Console

category: Modern Flow
createdby: SYSTEM
createdon: 5/20/2020 9:37 PM
description:
ismanaged: Unmanaged
modifiedby: Kiana Anderson
modifiedon: 5/6/2023 3:37 AM
name: When an account is updated -> Create a new record
ownerid: Monica Thomson
statecode: Activated
type: Definition
workflowid: d9e875bf-1c9b-ea11-a811-000d3a122b89
workflowidunique: c17af45c-10a1-43ca-b816-d9cc352718cf

More information:

Build queries with QueryExpression
Access formatted values

Create a cloud flow
The required properties for automated, instant, and scheduled flows are: category ,
name , type , primaryentity , and clientdata . Use none  for the primaryentity  for these
types of flows.

SDK for .NET

This static method requires an authenticated client that implements the
IOrganizationService. It uses the IOrganizationService.Create method.

C#

/// <summary>
/// Creates a cloud flow
/// </summary>
/// <param name="service">Authenticated client implementing the 



IOrganizationService interface</param>
/// <returns>The workflowid</returns>
public static Guid CreateCloudFlow(IOrganizationService service)
{
   var workflow = new Entity("workflow")
   {
         Attributes = {
            {"category", new OptionSetValue(5) }, // Cloud flow
            {"name", "Sample flow name"},
            {"type", new OptionSetValue(1) }, //Definition
            {"description", "This flow reads some data from Dataverse." 
},
            {"primaryentity", "none" },
            {"clientdata", "{\"properties\":{\"connectionReferences\":
{\"shared_commondataserviceforapps\":{\"impersonation\":
{},\"runtimeSource\":\"embedded\",\"connection\":{\"name\":\"shared-
commondataser-114efb88-a991-40c7-b75f-2693-
b1ca6a0c\",\"connectionReferenceLogicalName\":\"crdcb_sharedcommondatase
rviceforapps_109ea\"},\"api\":
{\"name\":\"shared_commondataserviceforapps\"}}},\"definition\":
{\"$schema\":\"https://schema.management.azure.com/providers/Microsoft.L
ogic/schemas/2016-06-
01/workflowdefinition.json#\",\"contentVersion\":\"1.0.0.0\",\"parameter
s\":{\"$connections\":{\"defaultValue\":
{},\"type\":\"Object\"},\"$authentication\":{\"defaultValue\":
{},\"type\":\"SecureObject\"}},\"triggers\":{\"manual\":{\"metadata\":
{\"operationMetadataId\":\"76f87a86-89b3-48b4-92a2-
1b74539894a6\"},\"type\":\"Request\",\"kind\":\"Button\",\"inputs\":
{\"schema\":{\"type\":\"object\",\"properties\":{},\"required\":
[]}}}},\"actions\":{\"List_rows\":{\"runAfter\":{},\"metadata\":
{\"operationMetadataId\":\"9725b30f-4a8e-4695-b6fd-
9a4985808809\"},\"type\":\"OpenApiConnection\",\"inputs\":{\"host\":
{\"apiId\":\"/providers/Microsoft.PowerApps/apis/shared_commondataservic
eforapps\",\"connectionName\":\"shared_commondataserviceforapps\",\"oper
ationId\":\"ListRecords\"},\"parameters\":
{\"entityName\":\"accounts\",\"$select\":\"name\",\"$top\":1},\"authenti
cation\":\"@parameters('$authentication')\"}}}}},\"schemaVersion\":\"1.0
.0.0\"}" }
         }
   };

   return service.Create(workflow);
}

More information: Create table rows using the Organization Service

The statecode  of all flows created this way are set to 0  (Draft or 'Off'). The flow needs
to be enabled before it can be used.

The most important property is the clientdata , which contains the
connectionReferences  that the flow uses, and the definition of the flow. The



connectionReferences  are the mappings to each connection that the flow uses.

JSON

{
  "properties": {
    "connectionReferences": {
      "shared_commondataserviceforapps": {
        "runtimeSource": "embedded",
        "connection": {},
        "api": { 
         "name": "shared_commondataserviceforapps" 
         }
      }
    },
    "definition": {
      "$schema": 
"https://schema.management.azure.com/providers/Microsoft.Logic/schemas/2016-
06-01/workflowdefinition.json#",
      "contentVersion": "1.0.0.0",
      "parameters": {
        "$connections": { "defaultValue": {}, "type": "Object" },
        "$authentication": { "defaultValue": {}, "type": "SecureObject" }
      },
      "triggers": {
        "manual": {
          "metadata": {},
          "type": "Request",
          "kind": "Button",
          "inputs": {
            "schema": { "type": "object", "properties": {}, "required": [] }
          }
        }
      },
      "actions": {
        "List_rows": {
          "runAfter": {},
          "metadata": {},
          "type": "OpenApiConnection",
          "inputs": {
            "host": {
              "apiId": 
"/providers/Microsoft.PowerApps/apis/shared_commondataserviceforapps",
              "connectionName": "shared_commondataserviceforapps",
              "operationId": "ListRecords"
            },
            "parameters": {
              "entityName": "accounts",
              "$select": "name",
              "$top": 1
            },
            "authentication": "@parameters('$authentication')"
          }
        }



      }
    }
  },
  "schemaVersion": "1.0.0.0"
}

Update a cloud flow
To update a flow, set only the properties you want to change.

SDK for .NET

This static method requires an authenticated client that implements the
IOrganizationService. It uses the IOrganizationService.Update method to update a
flow description and set the owner.

C#

/// <summary>
/// Updates a cloud flow
/// </summary>
/// <param name="service">Authenticated client implementing the 
IOrganizationService interface</param>
/// <param name="workflowid">The ID of the flow to update.</param>
/// <param name="systemuserid">The id of the user to assign the flow to.
</param>
public static void UpdateCloudFlow(IOrganizationService service, Guid 
workflowid, Guid systemuserid) {

   var workflow = new Entity("workflow",workflowid)
   {
         Attributes = {

            {"description", "This flow will ensure consistency across 
systems." },
            {"ownerid", new EntityReference("systemuser",systemuserid)},
            {"statecode", new OptionSetValue(1) } //Turn on the flow.
         }
   };

   service.Update(workflow);
}

More information: Update and delete table rows using the Organization Service >
Basic update



Delete a cloud flow
The following examples show how to delete the workflow record that represents a cloud
flow.

SDK for .NET

The static DeleteCloudFlow  method deletes a workflow record.

C#

/// <summary>
/// Deletes a workflow
/// </summary>
/// <param name="service">Authenticated client implementing the 
IOrganizationService interface</param>
/// <param name="workflowId">The id of the cloud flow to delete.</param>
public static void DeleteCloudFlow(IOrganizationService service, Guid 
workflowId) { 

service.Delete(entityName:"workflow",id: workflowId);

}

More information: Delete a record using the SDK

Get all users with whom a cloud flow is shared
Use the RetrieveSharedPrincipalsAndAccess  message to get a list of all the users that a
cloud flow is shared with.

With the SDK, use the RetrieveSharedPrincipalsAndAccessRequest Class, and with the
Web API use the RetrieveSharedPrincipalsAndAccess Function.

More information: Get principals with access to a record

Share or unshare a cloud flow
Share a cloud flow like any other Dataverse record using the GrantAccess  message. With
the SDK, use the GrantAccessRequest Class and with the Web API use the GrantAccess
Action. More information: GrantAccess example



If you want to change the access rights you grant when you share a record, use the
ModifyAccess  message. With the SDK, use the ModifyAccessRequest Class and with the
Web API use the ModifyAccess Action. More information: ModifyAccess example

To unshare a record, use the RevokeAccess  message. With the SDK, use the
RevokeAccessRequest Class and with the Web API use the RevokeAccess Action. More
information: Revoking access

Export flows
When a flow is part of a solution, you can export it by exporting the solution that
contains the flow using the ExportSolution  message.

SDK for .NET

The following static ExportSolution  example method uses the
ExportSolutionRequest to retrieve a byte[]  containing the ZIP file of the
unmanaged solution with the specified UniqueName.

C#

/// <summary>
/// Exports an unmanaged solution
/// </summary>
/// <param name="service">Authenticated client implementing the 
IOrganizationService interface</param>
/// <param name="solutionUniqueName">The uniquename of the solution.
</param>
/// <returns></returns>
public static byte[] ExportSolution(
   IOrganizationService service, 
   string solutionUniqueName) 
{
   ExportSolutionRequest request = new() { 
         SolutionName = solutionUniqueName,
         Managed = false
   };

   var response = (ExportSolutionResponse)service.Execute(request);

   return response.ExportSolutionFile;
}

Import flows



When you have a solution ZIP file, you can import it using the ImportSolution  message.

When you import flows, you should set the following parameters:

ﾉ Expand table

Property name Description

OverwriteUnmanagedCustomizations If there are existing instances of these flows in Dataverse,
this flag needs to be set to true  to import them. Otherwise
they aren't overwritten.

PublishWorkflows Indicates if classic Dataverse workflows are activated on
import. This setting doesn't apply to other types of flows.

CustomizationFile A base 64-encoded zip file that contains the solution.

SDK for .NET

The static ImportSolution  sample method shows how to import a solution file using
the ImportSolutionRequest Class

C#

/// <summary>
/// Imports a solution.
/// </summary>
/// <param name="service">Authenticated client implementing the 
IOrganizationService interface</param>
/// <param name="solutionFile">The byte[] data representing a solution 
file. </param>
public static void ImportSolution(
   IOrganizationService service, 
   byte[] solutionFile) {

   ImportSolutionRequest request = new() { 
         OverwriteUnmanagedCustomizations = true,
         CustomizationFile = solutionFile
   };

   service.Execute(request);
}

FAQ

What about the API at api.flow.microsoft.com?



The API at api.flow.microsoft.com isn't supported. Customers should instead use the
Dataverse Web APIs for Power Automate documented previously in this article.

Alternatively, customers can use the management connectors: Power Automate
Management or Power Automate for Admins.

Customers can use the unsupported APIs at api.flow.microsoft.com  at their own risk.
These APIs are subject to change, so breaking changes could occur.

Related information
Entity class operations using the Organization service
Perform operations using the Web API
Sharing and assigning
Verifying access in code
Work with solutions using the Dataverse SDK

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Work with desktop flows using code
Article • 02/19/2024

Developers can add desktop flows functionality to their applications, including
programmatically triggering and canceling desktop flows. These capabilities are offered
as part of the Microsoft Dataverse platform.

Prerequisites
1. Knowledge of Dataverse Web API, authentication with Dataverse and using OAuth

with Dataverse.
2. Knowledge of Dataverse environment and organization notions, and how to

retrieve the organization URL manually or programmatically.
3. Knowledge of desktop flows notions and of what connections are and how to

create them.

） Important

In this article, you must replace all squared brackets [...] in URLs and input/output
data with values specific to your scenario.

List available desktop flows
All desktop flows scripts are in Dataverse as part of the workflow entity.

Filter the list of workflows based on the category to identify desktop flows.

Request to get desktop flows
HTTP

Authorization: Bearer eyJ0eXAiOi...
Accept: application/json

GET https://[Organization URI]/api/data/v9.2/workflows?
$filter=category+eq+6&$select=name,workflowid&$orderby=name HTTP/1.1  

Response to the request to get desktop flows



JSON

{
    "@odata.context": "https://[Organization 
URI]/api/data/v9.2/$metadata#workflows(name,workflowid)",
    "value": [
        {
            "@odata.etag": "W1069462",
            "name": "Desktop flow 1",
            "workflowid": "f091ffab-58bb-4630-a115-659453d56f59",
        },
        {
            "@odata.etag": "W1028555",
            "name": "Desktop flow 2",
            "workflowid": "eafba1a2-e8d4-4efa-b549-11d4dfd9a3d1",
        }
    ]
}

Get the schema for desktop flows
If you need to retrieve the flow schema for inputs and/or outputs, you can use the
clientData field for the target workflow.

Request inputs schema for desktop flows
HTTP

Authorization: Bearer eyJ0eXAiOi...
Accept: application/json

GET https://[Organization URI]/api/data/v9.2/workflows([Workflow 
Id])/inputs/$value HTTP/1.1  

Response to the request to get the desktop flows inputs
schema

JSON

{
    "schema": {
        "properties": {
            "inputText": {
                "default": "",
                "description": "",
                "format": null,



                "title": "inputText",
                "type": "string",
                "value": ""
            },
            "inputInteger": {
                "default": "",
                "description": "",
                "format": null,
                "title": "inputInteger",
                "type": "number",
                "value": "0"
            }
        },
        "type": "object"
    }
}

Request outputs schema for desktop flows
HTTP

Authorization: Bearer eyJ0eXAiOi...
Accept: application/json

GET https://[Organization URI]/api/data/v9.2/workflows([Workflow 
Id])/outputs/$value HTTP/1.1  

Response to the request to get the desktop flows outputs
schema

JSON

{
    "schema": {
        "properties": {
            "outputText": {
                "default": "",
                "description": "",
                "format": null,
                "title": "outputText",
                "type": "string",
                "value": null
            },
            "outputInteger": {
                "default": "",
                "description": "",
                "format": null,
                "title": "outputInteger",
                "type": "number",



                "value": null
            }
        },
        "type": "object"
    }
}

Get the status of a desktop flow run
Dataverse stores all desktop flow runs in the flowsession entity.

Request the status of a desktop flow run
HTTP

Authorization: Bearer eyJ0eXAiOi...
Accept: application/json

GET https://[Organization URI]/api/data/v9.2/flowsessions([Flow session 
ID])?$select=statuscode,statecode,startedon,completedon HTTP/1.1  

Response for the status of a desktop flow run
JSON

{
    "@odata.context": "https://[Organization 
URI]/api/data/v9.2/$metadata#flowsessions(statuscode,statecode,startedon,com
pletedon)/$entity",
    "@odata.etag": "W1276122",
    "statuscode": 8,
    "statecode": 0,
    "startedon": "2022-06-16T12:54:40Z",
    "completedon": "2022-06-16T12:57:46Z",
}

Get desktop flow outputs
If the desktop flow has outputs, you can query the outputs field to retrieve them.

Request for desktop flow outputs
HTTP



Authorization: Bearer eyJ0eXAiOi...
Accept: application/json

GET https://[Organization URI]/api/data/v9.2/flowsessions([Flow session 
ID])/outputs/$value HTTP/1.1  

Response to the request for desktop flow outputs
JSON

{
    "Output1": "My output value"
}

Trigger a desktop flow run
By using Dataverse, you can add the functionality of triggering a desktop flow through
your application. To implement this functionality, you need to use the RunDesktopFlow
action.

To call the action, you'll need the following information.

The ID  of the desktop flow that you want to run. You can get this ID via the API as
the List available desktop flows section outlines earlier in this article.

 Tip

Alternatively, you can retrieve the ID manually from the desktop flow details
URL in Power Automate. The URL format is:
https://make.powerautomate.com/manage/environments/[Environment

ID]/uiflows/[Desktop Flow ID]/details .

For more information, see Manage desktop flows.

The name  of the desktop flow connection (targeting a machine/machine group) to
use to run your flow. The name can be retrieved from the URL of the same
connection page in Power Automate. The URL format is:
https://make.powerautomate.com/manage/environments/[Environment

ID]/connections?apiName=shared_uiflow&connectionName=[Connection Name] .



７ Note

For more information, see Create desktop flow connections.

 Tip

Alternatively, you can use a connection reference's logical name as the input
of the connection instead of the connection name (usage example described
below). The connection references are stored in the Dataverse table
connectionreference and can be listed programmatically in the same way as
desktop flows detailed in the List available desktop flows section.

For more information, see Use a connection reference in a solution and
connectionreference table/entity reference.

Request to trigger a desktop flow
HTTP

Authorization: Bearer eyJ0eXAiOi...
Accept: application/json

POST https://[Organization URI]/api/data/v9.2/workflows([Workflow 
ID])/Microsoft.Dynamics.CRM.RunDesktopFlow HTTP/1.1  
{
    "runMode": "attended",
    "runPriority": "normal",
    "connectionName": "[Connection Name]",
    "timeout": 7200,
    "inputs": "{\"Input1\":\"Value\", \"Input2\":\"Value\"}"
}

Request to trigger a desktop flow with a connection
reference

HTTP

Authorization: Bearer eyJ0eXAiOi...
Accept: application/json

POST https://[Organization URI]/api/data/v9.2/workflows([Workflow 
ID])/Microsoft.Dynamics.CRM.RunDesktopFlow HTTP/1.1  
{



    "runMode": "attended",
    "runPriority": "normal",
    "connectionName": "[Connection Reference Logical Name]",
    "connectionType": 2,
    "timeout": 7200,
    "inputs": "{\"Input1\":\"Value\", \"Input2\":\"Value\"}"
}

Response from request to trigger a desktop flow
JSON

{
    "@odata.context": "https://[Organization 
URI]/api/data/v9.2/$metadata#Microsoft.Dynamics.CRM.RunDesktopFlowResponse",
    "flowsessionId": "d9687093-d0c0-ec11-983e-0022480b428a"
}

The inputs of the script are viewable in the run details page on the Power Automate
portal (in Preview).

２ Warning

When using the API, there are some limitations to be aware of:

Triggering a desktop flow run with an account having "User" privileges will
work. However, canceling the run and querying the status needs "Owner"
privileges.

Dataverse impersonation isn't supported.

The input field content size is limited to 2 MB.

Receive notification on script completion
An optional parameter "callbackUrl" is available in the body of the RunDesktopFlow
action. You can use it if you want to be notified of your script completion. A POST
request will be sent to the provided URL when the script is complete.

Request received by the callback endpoint
HTTP



User-Agent: EnterpriseConnectors/1.0
Content-type: application/json; charset=utf-8
x-ms-workflow-id: [Workflow ID]
x-ms-run-id: [Flow session ID]

POST [yourCallbackURL]  

JSON

{
    "statuscode": 4,
    "statecode": 0,
    "startedon": "2022-09-05T08:04:11Z",
    "completedon": "2022-09-05T08:04:41Z",
    "flowsessionid": "d9687093-d0c0-ec11-983e-0022480b428a"
}

If no callback URL parameter is provided, the flow session status should be polled from
Dataverse (refers to Get the status of a desktop flow run).

７ Note

You can still use the status polling as a fallback mechanism even if you
provide a callback URL parameter.
Your callback endpoint operation should be idempotent.
The POST request will be retried three times with one second interval if your
endpoint responds with a Server Error response (code 500 and above) or a
"Request Timeout" response (code 408).

Requirements for the callback URL parameter

Your server must have the current TLS and cipher suites.
Only the HTTPS protocol is allowed.
Access to localhost (loopback) isn't permitted.
IP addresses can't be used. You must use a named web address that requires DNS
name resolution.
Your server must allow connections from Power Platform and Dynamics 365
services IP address values specified under the AzureCloud service tag.

 Tip

As the callback call isn't authenticated, some precautions should be taken



Check the flow session Id validity when the callback notification is received.
Dataverse is the source of truth.
Implement a rate limit strategy on your server side.
Try to limit the callback URL sharing between several organizations.

Cancel a desktop flow run
Similar to the Trigger functionality, you can also cancel a queued/running desktop flow.
To cancel a desktop flow, use the CancelDesktopFlowRun action.

Request to cancel a desktop flow run
HTTP

Authorization: Bearer eyJ0eXAiOi...
Accept: application/json

POST https://[Organization URI]/api/data/v9.2/flowsessions(d9687093-d0c0-
ec11-983e-0022480b428a)/Microsoft.Dynamics.CRM.CancelDesktopFlowRun HTTP/1.1  

Response from a request to cancel a desktop flow
JSON

HTTP/1.1 204 No Content

Errors
When an error occurs, the response has a different format that matches Dataverse error
messages. The http error code and the message should provide enough information to
understand the issue.

HTTP

HTTP/1.1 403 Forbidden

{
    "error": {
        "code": "0x80040220",
        "message": " Principal user (Id=526..., type=8) is missing 
prvReadworkflow privilege (Id=88...*)”



    }
}

Known limitations
We currently support up to 70 desktop flows runs per minute for every connection.



Build and certify custom connectors
Article • 03/25/2024

Without writing any code, you can build workflows and apps with Azure Logic Apps ,
Power Automate , and Power Apps . To help you integrate your data and business
processes, these services offer 1000+ connectors - for Microsoft services and products,
as well as other services, like GitHub, Salesforce, Twitter, and more.

Sometimes though, you might want to call APIs, services, and systems that aren't
available as prebuilt connectors. To support more tailored scenarios, you can build
custom connectors with their own triggers and actions. We have a complete set of basic
and advanced tutorials for custom connectors on the Connectors documentation site.
We recommend that you start with the custom connector overview, but you can also go
straight to the following topics for details on a specific area:

Create a custom connector from an OpenAPI definition

Create a custom connector from scratch

Use a custom connector from a cloud flow

Share custom connectors in your organization

Submit your connectors for Microsoft certification

Custom connector FAQ



Integrate Power Automate with websites and
apps
Article • 10/10/2024

Embed Power Automate into your app or website using flow widgets to give your users a simple way to automate
their personal or professional tasks.

Flow widgets are iframes located in a host document. This document points to a page in the Power Automate
designer. These widgets integrate specific Power Automate functionality into the third-party application.

Widgets can be simple. For example, a widget that renders a list of templates with no communication between the
host and iframe. Widgets can also be complex. For example, a widget that provisions a cloud flow from a template
and then triggers the flow via two-way communication between the host and the widget.

Prerequisites
A Microsoft Account or
A work or school account

Use the unauthenticated widget
To use the unauthenticated templates widget, embed it directly into the host application using an iframe. You don't
need the JS SDK or an access token.

Show templates for your scenarios
To start, add this code to show the Power Automate templates on your website:

HTML

<iframe src="https://make.powerautomate.com/{locale}/widgets/templates/?q={search term}
&pagesize={number of templates}&destination={destination}&category={category}"></iframe>

ﾉ Expand table

Parameter Description

locale The four-letter language and region code for the template view. For example, en-us  represents US English,
and de-de  represents German.

search term The search term for the templates that you want to show in the view. For example, search SharePoint  to
show templates for SharePoint.

number of The number of templates that you want to show in the view.
templates

destination The page that opens when users select the template. Enter details  to show the details about the template,
or enter new  to open the Power Automate designer.

category Filters to the given template category.

parameters. Additional context to pass into the flow.
{name}



If the destination parameter is new , the Power Automate designer opens when users select a template. Users can
then create a cloud flow in the designer. See the next section if you want to have the full experience from the
widget.

Passing additional parameters to the flow template
If the user is in a specific context in your website or app, you might want to pass that context to the flow. For
example, a user might open a template for When an item is created while looking at a certain list in SharePoint.
Follow these steps to pass in the list ID as a parameter to the flow:

1. Define the parameter in the flow template before you publish it. A parameter looks like
@{parameters('parameter_name')} .

2. Pass the parameter in the query string of the iframe src. For example, add &parameters.listName={the name of
the list}  if you have a parameter called listName.

Full sample
To show the top four SharePoint templates in German and to start the user with myCoolList, use this code:

HTML

<iframe src="https://make.powerautomate.com/de-de/widgets/templates/?
q=sharepoint%20&pagesize=4&destination=details&parameters.listName=myCoolList"></iframe>

Use the authenticated flow widgets
The following table shows the list of Power Automate widgets that support the full experience within the widget
using user authentication access token. You will need to use Power Automate's JavaScript Software Developer Kit
(JS SDK) to embed the widgets and provide the required user access token.

ﾉ Expand table

Widget type Supported feature

flows Shows a list of flows in a tab for personal and shared flows. Edit an existing flow or create a new flow from a
template or blank.

flowCreation Creates a cloud flow from a template Id that the host application provides.

runtime Triggers a manual or hybrid-trigger flow that the host application provides.

approvalCenter Embeds approval requests and sent approvals.

templates Shows a list of templates. The user chooses one to create a new flow.

Use the authenticated Flow SDK to allow users to create and manage flows directly from your website or app
(instead of navigating to Power Automate). You'll need to sign the user in with their Microsoft Account or Microsoft
Entra to use the authenticated SDK.

７ Note

There is no way to hide the Power Automate branding when you use widgets.



Widget architecture
Power Automate widgets work by embedding an iframe that references Power Automate into a host application.
The host provides the access token that's required by the Power Automate widget. Power Automate's JS SDK
enables the host application to initialize and manage the widget life cycle.

JS SDK details
The Power Automate team provides the JS SDK to facilitate integrating Flow widgets in third-party applications.
The Flow JS SDK is available as a public link in the Flow service and lets the host application handle events from the
widget and interact with the Flow application by sending actions to the widget. Widget events and actions are
specific to the widget type.

Widget initialization
The Flow JS SDK reference needs to be added to the host application before initializing the widget.

HTML

<script src="https://flow.microsoft.com/Content/msflowsdk-1.1.js"></script>

７ Note

The recommended way to include the Flow JS SDK in your application is using the above reference.
Adding a local copy of the Flow JS SDK to your application or web page can result in you using an older
unsupported version of the SDK over time causing breaks in functionality.
Power Automate stores some data such as user identity and preferences locally leveraging your browsers
capabilities. Problems occur if the browser blocks storage of such local data, or third-party cookies set by
Power Automate. Users need to enable third party cookies in their browser in order for the widget to
load correctly.

Create a JS SDK instance by passing optional hostName and locale values in a JSON object.



JavaScript

var sdk = new MsFlowSdk({
    hostName:'https://make.powerautomate.com',
    locale:'en-US'
}); 

ﾉ Expand table

Name Required/Optional Description

hostName Optional Power Automate host name, for example, https://make.powerautomate.com

locale Optional Client locale for the widget (defaults to en-Us  if not specified)

Once the JS SDK instance is created you can initialize and embed a Power Automate widget in a parent element in
the host application. To do so, add an HTML div:

HTML

<div id="flowDiv" class="flowContainer"></div>

Then, initialize the Power Automate widget with the JS SDK renderWidget()  method. Be sure to provide the widget
type and corresponding settings.

JavaScript

var widget = sdk.renderWidget('<widgettype>', {
        container: 'flowDiv',
        flowsSettings: {},
        templatesSettings: {},
        approvalCenterSettings: {},
        widgetStyleSettings: {}
});

Here's a sample style for the container that you can modify to match with the host application's dimensions.

HTML

<head>
    <style>
        .flowContainer iframe {
            width: 400px;
            height: 1000px;
            border: none;
            overflow: hidden;
    }
    </style>
</head>

These are the parameters for renderWidget() :

ﾉ Expand table

Parameter Required/Optional Description

container Required Id of a DIV element on the host page where the widget will be embedded.



Parameter Required/Optional Description

environmentId Optional Widgets need an environment Id. If you don't provide an Id, a default
environment is used.

flowsSettings Optional Power Automate settings object

templatesSettings Optional Template settings object

approvalCenterSettings Optional Approval settings object

Access tokens
After the JS SDK renderWidget()  runs, the JS SDK initializes an iframe which points to the Power Automate widget
URL. This URL contains all the settings in the query string parameters. The host application needs to get a Power
Automate access token for the user (Microsoft Entra ID JWT token with audience
https://service.flow.microsoft.com ) before it initializes the widget. The widget raises a GET_ACCESS_TOKEN  event to
request an access token from the host. The host needs to handle the event and pass the token to the widget:

JavaScript

widget.listen("GET_ACCESS_TOKEN", function(requestParam, widgetDoneCallback) {
    widgetDoneCallback(null, {
        token:  '<accesstokenFromHost>'
    });
});

The host application is responsible for maintaining the token and passing it with a valid expiry date to the widget
when requested. If the widget is open for longer periods, the host should check if the token is expired and refresh
the token if it's needed before passing it to the widget.

Detecting if the widget is ready
After successful initialization, the widget raises an event to notify that the widget is ready. The host can listen to the
WIDGET_READY  event and execute any additional host code.

JavaScript

widget.listen("WIDGET_READY", function() {
    console.log("The flow widget is now ready.");
    // other host code on widget ready
});

Widget settings
FlowsSettings
FlowsSettings can be used to customize the functionality of the Power Automate widget.

JavaScript

flowsSettings?: {
    createFromBlankTemplateId?: string;
    flowsFilter?: string;sc



    tab?: string;
};

ﾉ Expand table

Parameter Required/Optional Description

createFromBlankTemplateId Required Use the template's GUID when the user selects the Create from blank
button on the Flow widget

flowsFilter Optional The Power Automate widget applies the provided filter when listing flows.
For example, show flows that reference a specific SharePoint site.
flowsFilter: "operations/any(operation: operation/sharepoint.site eq
'https://microsoft.sharepoint.com/teams/ProcessSimple' )"

tab Optional Defaults the active tab to show in the Power Automate widget.
For example,
tab:'sharedFlows' displays the Team tab
and tab:'myFlows'  Displays the My flows tab.

TemplatesSettings
This applies to all widgets that enable you to create flows from a template, including Flows, FlowCreation, and
Templates widgets.

JavaScript

templatesSettings?: {
    defaultParams?: any;
    destination?: string;
    pageSize?: number;
    searchTerm?: string;
    templateCategory?: string;
    useServerSideProvisioning?: boolean;
    enableDietDesigner?: boolean;
};

ﾉ Expand table

Parameter Required/Optional Description

defaultParams Optional Design time parameters to use when creating a cloud flow from a template, for
example:
defaultParams: {'parameters.sharepoint.site':
'https://microsoft.sharepoint.com/teams/ProcessSimple',
'parameters.sharepoint.list': 'b3a5baa8-fe94-44ca-a6f0-270d9f821668' }

destination Optional Valid values are 'new' or 'details'. When set to 'details', a detail page is shown when
creating a cloud flow from a template.

pageSize Optional Number of templates to display. Default size = 6

searchTerm Optional Display templates that match the provided search term

templateCategory Optional Display templates in a specific category

ApprovalCenterSettings
Applies to ApprovalCenter widgets.



JavaScript

approvalCenterSettings?: {
   approvalsFilter?: string;
   tab?: string;but
   showSimpleEmptyPage? boolean;
   hideLink?: boolean
};

ﾉ Expand table

Parameter Required/Optional Description

hideLink Optional When set to true , the widget hides the received and the sent approval links

approvalsFilter Optional The approval widget will apply the specified approval filter when listing the approvals,
for example: The approval widget will apply the specified approval filter when listing
the approvals, for example:
approvalsFilter: 'properties/itemlink eq
\'https://microsoft.sharepoint.com/teams/ProcessSimple/_layouts/15/listform.aspx?
PageType=4&ListId=737e30a6-5bc4-4e9c-bcdc-
d34c5c57d938&ID=3&ContentTypeID=0x010010B708969A9C16408696FD23801531C6\''

approvalsFilter: 'properties/itemlinkencoded eq \'{Your base64 encoded item link
url} \''

tab Optional Default active tab to show in the Flow widget.
Valid values : 'receivedApprovals', 'sentApprovals'

showSimpleEmptyPage Optional Shows an empty page when there are no approvals

hideInfoPaneCloseButton Optional Hides the info-pane Close button (or the host already has a Close button)

Widget events
The Power Automate widget supports events that let the host listen to widget life-cycle events. The Power
Automate widget supports two types of events: one-way notification events (for example, Widget_Ready) and
events raised from the widget to fetch data from the host (Get_Access_Token). The host needs to use the
widget.listen() method to listen to specific events raised from the widget.

Usage
JavaScript

widget.listen("<WIDGET_EVENT>", function() {
    console.log("The flow widget raised event");
});

Supported events by widget type
ﾉ Expand table

Widget event Details

WIDGET_READY Widget loaded successfully



Widget event Details

WIDGET_RENDERED Widget loaded and UI rendering is complete

GET_ACCESS_TOKEN Widget request for embed user-access token

GET_STRINGS Allows host to override a set of UI strings shown in the widget

Runtime widget
ﾉ Expand table

Widget event Details Data

RUN_FLOW_STARTED Triggered and the flow run was
started

RUN_FLOW_COMPLETED Flow run triggered successfully

RUN_FLOW_DONE_BUTTON_CLICKED User selected Done button on flow
run

RUN_FLOW_CANCEL_BUTTON_CLICKED User selected Cancel button on flow
run

FLOW_CREATION_SUCCEEDED The flow was created successfully { flowUrl: string, flowId: string, fromTemplate:
string }

WIDGET_CLOSE Fired when the host should close the
widget

Flow Creation widget
ﾉ Expand table

Widget event Details Data

FLOW_CREATION_FAILED Flow creation failed

WIDGET_CLOSE Fired when host should close the
widget

TEMPLATE_LOAD_FAILED The template failed to load

FLOW_CREATION_SUCCEEDED The flow was created successfully { flowUrl: string, flowId: string,fromTemplate?: string
}

Approval widget
ﾉ Expand table

Widget event Details

RECEIVED_APPROVAL_STATUS_CHANGED Received approval status changed

SENT_APPROVAL_STATUS_CHANGED Sent approval status changed



GET_STRINGS event lets you customize text for some of the UI elements shown in the widget. The following strings
can be customized:

ﾉ Expand table

String key Use in the widget

FLOW_CREATION_CREATE_BUTTON Text displayed on the create flow button in both flow creation and runtime widget

FLOW_CREATION_CUSTOM_FLOW_NAME The initial value to use for the flow name in the flow creation widget. Only used when the
allowCustomFlowName setting is enabled.

FLOW_CREATION_HEADER Header to use when creating a cloud flow in both the flow creation and runtime widget

INVOKE_FLOW_HEADER Header to use when invoking a cloud flow in the runtime widget

INVOKE_FLOW_RUN_FLOW_BUTTON Text displayed on the button used to invoke/run a cloud flow in the runtime widget

Example
Call widgetDoneCallback  passing a JSON object with key-value pairs of string key and text to override the default
value.

JavaScript

widget.listen("GET_STRINGS", function(requestParam, widgetDoneCallback) {
    widgetDoneCallback(null, {
         "FLOW_CREATION_HEADER": "<string override would go here>",
        "INVOKE_FLOW_RUN_FLOW_BUTTON":  "<string override would go here>"
    });
});

Widget actions
The host uses widget actions to send a specific action or message to the widget. Widget JS SDK provides the
notify()  method to send a message or a JSON payload to the widget. Each widget action supports a specific
payload signature.

Usage
JavaScript

widget.notify('<WIDGET_ACTION>', parameterMatchingParameterInterface)
    .then(result => console.log(result))
    .catch(error => console.log(error))

Example
Invoke a cloud flow by sending the following command to a runtime widget

JavaScript

widget.notify('triggerFlow', { flowName: flowName, implicitData:implicitData });  



Runtime widget
ﾉ Expand table

Widget action Details Parameter interface

triggerFlow Triggers a cloud flow run { flowName: string, implicitData?: string }

triggerFlowByTemplate Triggers a cloud flow run by template { templateId: string, implicitData?: string,
designTimeParameters?: Record<string, any> }

getTriggerSchema Gets trigger schema for a cloud flow { flowName: string, }

closeWidget Cancels any pending activity and raises
a WIDGET_CLOSE event

Flow Creation widget
ﾉ Expand table

Widget action Details Parameter interface

createFlowFromTemplate Creates a cloud flow for the selected { templateName: string,
template designTimeParameters?: Record<string, any> }

createFlowFromTemplateDefinition Creates a cloud flow for the selected { templateDefinition: string }
template definition

closeWidget Cancels any pending activity and raises
a WIDGET_CLOSE event

Approval widget
ﾉ Expand table

Widget action Details Parameter interface

closeInfoPane Closes the info-pane displaying approval details N/A

Configuring your client application
You will need to configure your client application with Flow Service Scopes (Delegated Permissions). If the
Microsoft Entra (Microsoft Entra ID) app used for the widget integration uses a 'code grant' authorization flow, the
Microsoft Entra app needs to be preconfigured with delegated permissions that are supported by Power Automate.
This provides delegated permissions that let the application:

Manage approvals
Read approvals
Read activities
Manage flows
Read flows

Follow these steps to select one or more delegated permissions:

1. Go to https://portal.azure.com



2. Select Microsoft Entra ID.
3. Select App registrations under Manage.
4. Enter the third-party application to be configured for Flow service scopes.
5. Select Settings. ![Screenshot locating the settings icon for the application.](../media/embed-flow-

dev/Microsoft Entra ID-App-Settings.png)
6. Select Required permissions under API access/
7. Select Add.
8. Choose Select an API. ![Screenshot locating required permissions, add, and select an A P I.](../media/embed-

flow-dev/Microsoft Entra ID-App-Select-an-API.png)
9. Search for Power Automate service and select it. Note: Before you can see Power Automate service, your

tenant needs to have at least one Microsoft Entra user signed into the Flow portal
(https://make.powerautomate.com )

10. Choose the required Flow scopes for your application then select Save. ![Screenshot showing the delegated
permissions.](../media/embed-flow-dev/Microsoft Entra ID-App-DelegatedPermissions.png)

Your application will now get a Flow Service token that contains delegated permissions in the 'scp' claim in the JWT
token.

Sample application embedding flow widgets
A sample JavaScript Single Page Application (SPA) is provided in the resources section so you can experiment with
embedding flow widgets in a host page. Using the sample application requires registering a Microsoft Entra
application with implicit grant flow enabled.

Registering a Microsoft Entra app
1. Sign in to the Azure portal .
2. In the left navigation pane, select Microsoft Entra, then select App registrations (Preview) > New registration.
3. When the Register an application page appears, enter a name for your application.
4. Under Supported account types, select Accounts in any organizational directory.
5. Under the Redirect URL section, select the web platform and set the value to the application's URL based on

your web server. Configure this value to http://localhost:30662/ to run the sample app.
6. Select Register.
7. On the app Overview page, note the application (client) ID value.
8. The sample requires implicit grant flow to be enabled. In the left navigation pane of the registered

application, select Authentication.
9. In Advanced settings, under Implicit grant, enable both ID tokens and Access tokens checkboxes. ID tokens

and access tokens are required since this app needs to sign in users and call Flow API.
10. Select Save.

Running the sample
1. Download the sample and copy it to a local folder on your device.
2. Open the index.html file under the FlowSDKSample folder and modify the applicationConfig  to update the

clientID  to the application ID you registered earlier.

3. The sample app is configured to use Flow scopes Flows.Read.All and Flow.Manage.All. You can configure
additional scopes by updating the flowScopes property in applicationConfig object.



4. Run these commands to install the dependency and run the sample app:

> npm install > node server.js

5. Open the browser and then enter http://localhost:30662
6. Select the Sign in button to authenticate to Microsoft Entra and acquire a cloud flow access token.
7. The Access Token text box contains the access token.

8. Select Load Flows widget or Load Templates widget to embed the corresponding widgets.

Resources
Widget test pages
Find out more about widget integration and settings:

Templates widget: <https://make.powerautomate.com/test/templateswidget/ >
FlowCreation widget: <https://make.powerautomate.com/test/flowcreationwidget/ >
Runtime widget: <https://make.powerautomate.com/test/runtimewidget/ >
Approvals center widget: <https://make.powerautomate.com/test/approvalcenterwidget/ >
Flows widget: <https://make.powerautomate.com/test/managewidget/ >



Supported widget locales
If the initialized locale isn't listed, Flow will default to the closest supported locale.

ﾉ Expand table

Locale Language

bg-bg Bulgarian (Bulgaria)

ca-es Catalan (Catalan)

cs-cz Czech (Czech Republic)

da-dk Danish (Denmark)

de-de German (Germany)

el-gr Greek (Greece)

en-Us English (United States)

es-es Spanish (Castilian)

et-ee Estonian (Estonia)

eu-es Basque (Basque)

fi-fi Finnish (Finland)

fr-fr French (France)

gl-es Galician (Galician)

hi-HU Hungarian (Hungary)

hi-in Hindi (India)

hr-hr Croatian (Croatia)

id-Id Indonesian (Indonesia)

it-It Italian (Italy)

jp-Jp Japanese (Japan)

kk-kz Kazakh (Kazakhstan)

ko-kr Korean (Korea)

lt-LT Lithuanian (Lithuania)

lv-lv Latvian (Latvia)

ms-my Malay (Malaysia)

nb-no Norwegian (Bokmål)

nl-nl Dutch (Netherlands)

pl-pl Polish (Poland)

pt-br Portuguese (Brazil)

pt-pt Portuguese (Portugal)

ro-ro Romanian (Romania)



Locale Language

ru-ru Russian (Russia)

sk-sk Slovak (Slovakia)

sl-si Slovenian (Slovenia)

sr-cyrl-rs Serbian (Cyrillic, Serbia)

sr-latn-rs Serbian (Latin, Serbia)

sv-se Swedish (Sweden)

th-th Thai (Thailand)

tr-tr Turkish (Türkiye)

uk-ua Ukrainian (Ukraine)

vi-vn Vietnamese (Viet Nam)

Use of the Power Automate Embed SDK is covered under the Microsoft Software License Terms .

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Let customers test drive your flows on
AppSource
Article • 03/06/2025

７ Note

Test Drives is deprecated. As an alternative to Test Drives, we encourage you to
consider transitioning to Free Trials, which allows you to fully engage with your
product using your personalized settings and configurations to meet your specific
requirements.

We recommend that you remove Test Drives from your offers and clean up your
test drive environments.

Do you want to show off how your app integrates with Power Automate? We now Test
Drive solutions on AppSource.com  as a way for you to share Power Automate
integration with customers, and generate leads for your business.

What is a Test Drive solution?
A Test Drive solution enables your customers to try out a real app without installing any
applications. Customers just sign into AppSource.com using their Microsoft Entra ID
(Microsoft Entra ID) account and run the app in a web browser. Without Test Drive,
customers can only read about your app or watch a video that describes it. With Test
Drive, customers get a better idea of what your solution is and what functionality your
app has. And they have the experience of actually using the app. Customers can't look
under the hood to see how your app is built, so your intellectual property is protected.
We collect and share lead information with you to help you grow your business.

How do I build a Test Drive solution?
Building an app for a Test Drive solution is just like building any app, but you need to
use a data source that the user can be granted access to as a read-only user. Using a
data source that is already set up means there's zero friction for them to try it out. The
full solution that you ultimately distribute to customers includes writable data, but read-
only data works well for a Test Drive solution.

Embed flow into your product



Once you have a data source that you can grant the user read-only access to, you can
embed Power Automate into your application. Read more about embedding here. You
likely want to use the search functionality to highlight templates that are unique to your
application. For example, if your application creates data in Dynamics 365, you can
highlight a Dynamics 365 template that pulls data and then sends an email to the user.

How do I list my Test Drive solution on
AppSource.com?
Now that your app is ready, it's time to publish it to AppSource.com. To start this
process, complete the application form . After you apply, you receive an email with
instructions on how to submit your app to be published on AppSource.com.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Work with business process flows using
code
Article • 12/16/2022

A business process flow lets you create more efficient and streamlined sales, service, and
other business processes. It creates a visualization of your business process by placing
special controls at the top of the table forms. Users are guided through various stages
of sales, marketing, or service processes towards completion. Each process supports
multiple stages and steps. You can add or remove steps, change the order of stages, or
add new tables to the business process flow.

Different business process flow instances can run concurrently against the same table
row. Users can switch between concurrent business process instances, and resume their
work at a current stage in the process.

This topic provides information about how you can programmatically work with
business process flows.

７ Note

You don't have to write code to work with business process flows. For information
about using the UI to create and manage business process flows, see Business
Process Flows overview

Prerequisites for business process flow
Custom tables and tables that have updated UI forms can participate in the business
process flow. The updated UI tables have the IsAIRUpdated property set to true .

To enable a table for the business process flow, set the IsBusinessProcessEnabled
property to true .

） Important

Enabling a table for business process flow is a one way process. You can’t reverse it.

Define business process flow



Use the visual business process flow designer to define a business process flow. More
information: Create a business process flow

By default, a business process flow row is created in the Draft  state.

A business process flow definition is stored in the workflow table, and the stage
information for the business process flow is stored in the processstage table.

Activate business process flow
Before you can use the process flow, you have to activate it. To activate it, you must
have the prvActivateBusinessProcessFlow  privilege for the Workflow  table. Use the
UpdateRequest message to set the state of the Workflow  table row to Activated . More
information: Perform specialized operations using Update

７ Note

You can also use the business process flow designer to activate a business process
flow.

Business process flow table
Once you activate a business process flow definition by changing the state of the
corresponding Workflow  table row or by using the business process flow designer, a
custom table with the following name is automatically created to store the activated
business process flow instances: "<activesolutionprefix>_<uniquename>", where the
uniquename is derived from the name you specify.

For example, if you specified "My Custom BPF" as the name of the business process flow
definition and are using the default publisher (new) for your active solution, the name of
the custom table created for storing process instances will be "new_mycustombpf".

If the uniquename  value isn't available for a business process flow definition, for example
if the business process flow was imported as part of solution from an earlier version, the
default name of the custom table will be " \
<activesolutionprefix>_bpf_<GUID_BPF_Definition> :

） Important



The sample business process flow rows use system tables to store the
corresponding business process flow instance rows.

However, any new business process flow definitions you create will use custom
tables to store its instance rows as explained earlier.

You can retrieve the name of your business process flow table using any of the following
ways:

Using the UI: Use the customization UI to browse to your business process flow
table:

Using the Web API: Use the following request:

Request

GET [Organization URI]/api/data/v9.0/workflows?$filter=name eq 'My 
Custom BPF'&$select=uniquename HTTP/1.1

Response

{  
"@odata.context":"[Organization 
URI]/api/data/v9.0/$metadata#workflows(uniquename)",
"value":[  
     {  
         "@odata.etag":"W/\"1084677\"",
         "uniquename":"new_mycustombpf",
         "workflowid":"2669927e-8ad6-4f95-8a9a-f1008af6956f"



     }
  ]
}

Using the Organization service: Use the following code sample:

c#

QueryExpression query = new QueryExpression
{
    EntityName = "workflow",
    ColumnSet = new ColumnSet("uniquename"),
    Criteria = new FilterExpression
    {
        Conditions =
        {
            new ConditionExpression
            {
                ColumnName = "name",
                Operator = ConditionOperator.Equal,
                Values = { "My Custom BPF" }
            }
        }
    }
};
Workflow Bpf = 
(Workflow)_serviceProxy.RetrieveMultiple(query).Entities[0]; 

７ Note

The IsBPFEntity property is true  for business process flow tables. You can retrieve
all the business process flow tables in your instance by running the following Web
API request:

HTTP

GET [Organization URI]/api/data/v9.0/EntityDefinitions?
$select=SchemaName,LogicalName,DisplayName&$filter=IsBPFEntity eq true 
HTTP/1.1

Manage security for business process flows
The custom table that is automatically created on activating a business process flow to
store business process flow instances adheres to the standard security model as for any



other custom table in Microsoft Dataverse. This implies that privileges granted on these
tables define the runtime permissions for users for business process flows.

The custom business process flow table has organization scope. The regular create,
retrieve, update and delete privileges on this table define the permission users would
have based on their assigned roles. By default, when the business process flow custom
table is created, only System Administrator and System Customizer security roles are
granted access to it, and you must explicitly grant permissions to the new business
process flow table (for example, My Custom BPF) for other security roles as required.

Create, retrieve, update, and delete business
process flow table rows (process instances)
The custom table that is automatically created on activating a business process flow
definition stores all the process instances for the business process flow definition. The
custom table supports the standard programmatic creation and management of rows
(process instances) using Web API and CRM 2011 endpoint.

） Important

Switching to another process instance for a table row is only supported through UI
(client) or programmatically using information available in this section. You can no
longer use the SetProcess  message (SetProcess Action or SetProcessRequest) to
programmatically switch processes (set another business process flow as the active
process instance) for the target table row.

Lets consider the following example where we have a cross-table business process flow,
"My Custom BPF," with 3 stages: S1:Account, S2:Account, and S3:Contact.



Retrieve all the rows (instances) for a business process
flow table
If the name of your business process flow table is "new_mycustombpf", use the
following query to retrieve all the rows (process instances) for your business process
flow table:

HTTP

GET [Organization URI]/api/data/v9.0/new_mycustombpfs HTTP/1.1 

At this point, you might not get any instances in your response as there are none. Run
this request after creating an instance of your business process flow definition later in
this topic.

７ Note

To know how to retrieve the name of your business process flow table, see the
earlier section, Business process flow table.

Create a business process flow table row (process
instance)
Create a business process flow table row (process instance) programmatically if you
want to switch to another business process flow for a table row without using the UI.

To create a business process flow table row, you need to specify the following values:



Associate the business process flow table row to a primary table row by setting the
single-valued navigation property using the @odata.bind  annotation. To find out
the navigation-property name that points to the primary table row for your
business process flow definition, use the CSDL $metadata document.

Associate the business process flow table row to a valid stage specified in the
business process flow definition by setting the single-valued navigation property
using the @odata.bind  annotation. To find out the navigation-property name
(typically activestageid ) that points to the stage row for your business process
flow definition, use the CSDL $metadata document.

Also, you can retrieve information about all the stages for a business process flow
definition by using the following Web API request assuming that the ID of your
business process flow definition is 2669927e-8ad6-4f95-8a9a-f1008af6956f:

Request

HTTP

GET [Organization URI]/api/data/v9.0/processstages?
$select=stagename&$filter=processid/workflowid eq 2669927e-8ad6-4f95-
8a9a-f1008af6956f HTTP/1.1

Response

HTTP

{
    "@odata.context": "[Organization 
URI]/api/data/v9.0/$metadata#processstages(stagename)",
    "value": [
        {
            "@odata.etag": "W/\"858240\"",
            "stagename": "S1",
            "processstageid": "9a9185f5-b75b-4bbb-9c2b-a6626683b99b"
        },
        {
            "@odata.etag": "W/\"858239\"",
            "stagename": "S3",
            "processstageid": "a107e2fd-7543-4c1a-b6b4-b8060ecb1a1a"
        },
        {
            "@odata.etag": "W/\"858238\"",
            "stagename": "S2",
            "processstageid": "19a11fc0-3398-4214-8522-cb2a97f66e4b"
        }
    ]
}



Next, use the following request to create an instance of your business process flow
definition for an account row (ID=a176be9e-9a68-e711-80e7-00155d41e206) and the
active stage set as the first stage of the process instance, S1 (ID=9a9185f5-b75b-4bbb-
9c2b-a6626683b99b):

Request

HTTP

POST [Organization URI]/api/data/v9.0/new_mycustombpfs HTTP/1.1 
Content-Type: application/json; charset=utf-8 
OData-MaxVersion: 4.0 
OData-Version: 4.0 
Accept: application/json 

{
    "bpf_accountid@odata.bind": "/accounts(a176be9e-9a68-e711-80e7-
00155d41e206)",
    "activestageid@odata.bind": "/processstages(9a9185f5-b75b-4bbb-9c2b-
a6626683b99b)"    
}

Response

HTTP

HTTP/1.1 204 No Content
OData-Version: 4.0
OData-EntityId: [Organization URI]/api/data/v9.0/new_mycustombpfs(00aa00aa-
bb11-cc22-dd33-44ee44ee44ee)

Note that if you want to create an instance of your business process flow definition with
the active stage set as a stage other than the first stage, you must also provide
traversedpath  in your request. Traversed path is the comma-delimited string of process
stage ids that represent visited stages of the business process flow instance. The
following request creates an instance for an account row (ID=679b2464-71b5-e711-
80f5-00155d513100) and active stage set as the second stage, S2 (ID=19a11fc0-3398-
4214-8522-cb2a97f66e4b).

HTTP

POST [Organization URI]/api/data/v9.0/new_mycustombpfs HTTP/1.1 
Content-Type: application/json; charset=utf-8 
OData-MaxVersion: 4.0 
OData-Version: 4.0 
Accept: application/json 



{
    "bpf_accountid@odata.bind": "/accounts(679b2464-71b5-e711-80f5-
00155d513100)",
    "activestageid@odata.bind": "/processstages(19a11fc0-3398-4214-8522-
cb2a97f66e4b)",
    "traversedpath":"9a9185f5-b75b-4bbb-9c2b-a6626683b99b,19a11fc0-3398-
4214-8522-cb2a97f66e4b"   
}

Update a business process flow table row (process
instance)
You can update a process instance to move to next or previous stage, abandon a
process instance, reactivate a process instance, or finish a process instance.

Stage navigation
To navigate to a different stage, you need to update a process instance row to change
its active stage ID and accordingly update the traversed path. Note that you must only
move to the next or previous stage while updating a business process flow instance.

To perform stage navigation, you will need the ID of the business process flow instance
that you want to update. To retrieve all the instances of your business process flow, see
Retrieve all the rows (instances) for a business process flow table earlier.

Assuming the ID of the process instance you want to update is dc2ab599-306d-e811-
80ff-00155d513100, use the following request to update the active stage from S1 to S2:

HTTP

PATCH [Organization URI]/api/data/v9.0/new_mycustombpfs(dc2ab599-306d-e811-
80ff-00155d513100) HTTP/1.1
Content-Type: application/json
OData-MaxVersion: 4.0
OData-Version: 4.0

{
    "activestageid@odata.bind": "/processstages(19a11fc0-3398-4214-8522-
cb2a97f66e4b)",
    "traversedpath": "9a9185f5-b75b-4bbb-9c2b-a6626683b99b,19a11fc0-3398-
4214-8522-cb2a97f66e4b"
}

Change the state of a process instance: Abort, Reactivate, or Finish



A process instance can have one of the following states: Active, Finished, or Aborted.
The state is determined by the following columns on the process instance row:

statecode: Displays the status of the process instance.

ﾉ Expand table

Value Label

0 Active

1 Inactive

statuscode: Displays information about status of the process instance.

ﾉ Expand table

Value Label

1 Active

2 Finished

3 Aborted

So, to Abort a process instance, use the following request set the statecode  and
statuscode  values appropriately:

HTTP

PATCH [Organization URI]/api/data/v9.0/new_mycustombpfs(dc2ab599-306d-e811-
80ff-00155d513100) HTTP/1.1   
Content-Type: application/json   
OData-MaxVersion: 4.0   
OData-Version: 4.0 
  
{ 
    "statecode" : "1", 
    "statuscode": "3" 
}

７ Note

You can abort a process instance at any stage.



Similarly, to reactivate a process instance, replace the statecode  and statuscode  values
in the above code with 0 and 1 respectively.

Finally, to set a process instance status as Finished, which is only possible at the last
stage of a process instance, replace the statecode  and statuscode  values in the above
code with 0 and 2 respectively.

Cross-table navigation
For cross-table navigation in this example, you must set the active stage of the process
instance to the last stage, S3 (ID=a107e2fd-7543-4c1a-b6b4-b8060ecb1a1a), update the
traversed path accordingly, and set a contact row as the primary table row as per the
business process flow definition.

HTTP

PATCH [Organization URI]/api/data/v9.0/new_mycustombpfs(dc2ab599-306d-e811-
80ff-00155d513100) HTTP/1.1   
Content-Type: application/json   
OData-MaxVersion: 4.0   
OData-Version: 4.0 
  
{
    "activestageid@odata.bind": "/processstages(a107e2fd-7543-4c1a-b6b4-
b8060ecb1a1a)",
    "traversedpath":"9a9185f5-b75b-4bbb-9c2b-a6626683b99b,19a11fc0-3398-
4214-8522-cb2a97f66e4b,a107e2fd-7543-4c1a-b6b4-b8060ecb1a1a",
    "bpf_contactid@odata.bind": "/contacts(0e3f10b0-da33-e811-80fc-
00155d513100)"
}

Delete a business process flow table row (process
instance)
Use the following Web API request:

Request

HTTP

DELETE [Organization URI]/api/data/v9.0/new_mycustombpfs(dc2ab599-306d-e811-
80ff-00155d513100) HTTP/1.1

Response



If the row exists, you’ll get a normal response with status 204 to indicate the delete was
successful. If the table isn’t found, you’ll get a response with status 404.

Use RetrieveProcessInstances and
RetrieveActivePath messages
Use the RetrieveProcessInstances  message (RetrieveActivePath Function or
RetrieveProcessInstancesRequest) to retrieve all the business process flow instances for a
table row across all business process definitions. The business process flow instances
returned for a table are ordered based on the modifiedon  column for the instance. For
example, the most recently modified business process flow instance will be the first row
in the returned collection. The most recently modified business process flow instance is
the one that is active on the UI for a table row.

Each business process flow instance row returned for a table row as a result of using the
RetrieveProcessInstances  message stores the ID of the active stage in the
processstageid  column that can be used to find the active stage, and then move to the
previous or next stage. To do so, you first need to find the active path of a business
process flow instance and the stages available in the process flow instance using the
RetrieveActivePath  message (RetrieveActivePath Function or
RetrieveActivePathRequest).

Once you have the active stage and the active path information for a business process
flow instance, you can use the information to move to a previous or next stage in the
active path. Forward navigation of stages must be done in sequence, that is, you should
only move forward to the next stage in the active path.

For the complete sample that code demonstrates the usage of these two methods and
stage navigation using the Organization service, see Sample: Work with business
process flows.

Apply business process flow while creating a
table row
This section provides information about the default behavior for applying business
process flows automatically to new table rows created in Dataverse, and how you can
override it to apply a business process flow of your choice for new table rows.

By default, for a table that has multiple business process flows defined for it, the system
applies a business process flow to the new table row using the following multi-step



logic:

1. Identify all business process flows applicable to the new table row based on the
Workflow.PrimaryEntity column of the business process flow definition rows.

2. Identify the business process flow definitions that the current user has access to.
For information about how access to a business process flow is determined and
managed, see Manage security for business process flows earlier in this topic.

3. All business process flow definitions in the system are subject to a global order per
table. The order of the business process flow is stored in the
Workflow.ProcessOrder column. The business process flow definitions for a table
are sorted based on this order, and the one with the least order value is picked.

4. Finally, if the table row is created from a business app (app module), one more
level of filtering is applied to pick the business process flow to be applied
automatically to the new table row. When working in an app, users can access only
relevant tables, business process flows, views and forms that they have access to
by virtue of the security roles assigned to the business app.

If the business app does not contain any business process flow then business
process flow is applied as explained until step 3.
If the business app has one or more business process flows then only the
business process flows present in the app would be applicable. In this case,
when the user is working within a business app context, the list of business
process flows from step 3 are filtered further to the ones that are part of the
business app that are present inside the app module, and are sorted based
on the process order.
If no business process flow is available in a business app for the table or one
that the user has access to then no business process flow is applied for the
new table row.

You can override the default logic of business process flows getting applied
automatically to new table rows. To do so, set the ProcessId column of the table to one
of the following values while creating a new table row:

Set to Guid.Empty to skip setting a business process flow for new table rows. You
might want to do that if you are bulk creating table rows, but don't want business
process flow to to be applied to them.
Set it to a specific business process flow table (as a table reference). In this case,
the system will apply the specified business process flow instead of the default
logic.

If you do not set a value for the ProcessId column while creating a new table row, the
system will apply the default logic as explained earlier.



７ Note

Overriding the default logic of business process flows getting applied automatically
to new table rows is only supported programmatically. You cannot do this using the
UI.

Legacy process-related columns in tables
The legacy process-related columns (such as ProcessId, StageId, and TraversedPath) on
tables enabled for business process flows are already deprecated. Manipulating these
legacy process related columns for target table rows does not guarantee consistency of
the business process flow state, and is not a supported scenario. The recommended way
is to use the columns of the business process flow table as explained earlier in the
section Create, retrieve, update, and delete business process flow table rows (process
instances)

The only exception to this is programmatically modifying the ProcessId column while
creating a table row to override the default application of the business process flow to
the new row as explained in the previous section: Apply business process flow while
creating a table row.

Client-side programmability support for
business process flows
There is a client-side object you can use to interact with business process flows in your
form scripts. Business process flows trigger client-side events every time a process is
either applied to a row, the stage is changed, or its status is changed to Active ,
Finished , or Aborted . More information: formContext.data.process (Client API reference)

Maximum number of processes, stages, and
steps
Per table, the default value for the maximum number of activated business process flows
is 10. You can specify a different value by using the
Organization.MaximumActiveBusinessProcessFlowsAllowedPerEntity  column. However, if
the value is greater than 10, you may see a decrease in your system’s performance when
you switch processes or open a row that has an assigned business process flow. This
may be especially noticeable if processes span multiple tables.



The following settings aren’t customizable:

The maximum number of stages per table in the process is 30.

The maximum number of steps in each stage is 30.

The maximum number of tables that can participate in the process flow is 5.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Sample: Work with business process
flows
Article • 12/16/2022

This sample demonstrates how to programmatically work with business process flows
such as retrieving the business process flow instances for a table row, retrieving active
path for a business process flow instance and its process stages, and changing the active
stage. For information about these concepts, see Work with business process flows
using code

This sample is available to download from Sample: Work with business process flows .

Prerequisites
Before you can run the sample:

1. Have access to a Dataverse environment.

2. Have appropriate privileges on the Lead, Opportunity, and Workflow tables and
business process flow definition table rows used in this sample.

3. Have Visual Studio 2015 or later to run the sample.

4. Have Internet connection to download the sample project and to restore the
NuGet packages used in the sample project.

What this sample does
1. Creates a sample Lead row. This automatically creates an instance of the "Lead To

Opportunity Sales Process" business process flow for the Lead row.

2. Converts the Lead row to an Opportunity row.

3. Retrieves the business process flow instances associated with the "Opportunity"
row using the RetrieveProcessInstances  message. The first row in the returned
collection is the active business process flow instance for the opportunity row,
which is "Lead To Opportunity Sales Process" in this case.

4. Retrieves the active path and the process stages for the "Lead To Opportunity Sales
Process" instance using the RetrieveActivePath  message.



5. Retrieves the currently active stage for the "Lead To Opportunity Sales Process"
instance, and prompts the user whether to move to the next stage. On
confirmation to move, sets the next stage in the active path as the active stage for
the "Lead To Opportunity Sales Process" instance.

6. Finally, prompts the user whether to delete the rows created during the sample
run.

Here is the output of the sample:

Run the sample
1. Download  the WorkWithBPF Visual Studio sample project, and extract it to a

folder on your computer.

2. Locate the WorkWithBPF.sln  file in your extracted folder, and open it in Visual
Studio.

3. The sample project uses NuGet packages that must be restored before running the
sample. Ensure that automatic restore of NuGet packages is enabled in Visual
Studio. More information: Enabling and disabling NuGet package restore

Alternatively, select Project > Manage NuGet Packages, and select Restore to
manually restore the packages used in the sample.

4. Press F5 or select Debug > Start Debugging.

5. If you have not previously run one of the samples before, you’ll need to enter
information to run the code, otherwise enter the number for one of the instances
you have previously set up.



ﾉ Expand table

Prompt Description

Enter a Dynamics 365 server Type the name of your Dynamics 365 server. The default
name and port is Dynamics 365 (online) (crm.dynamics.com) in North
[crm.dynamics.com] America.

Example:
crm5.dynamics.com

Is this organization provisioned Type y if this is a Microsoft online services provisioned
in Microsoft online services (y/n) organization. Otherwise, type n.
[n]

Enter domain\username Type your Microsoft account.

Enter password Type your password. The characters will show as “*” in
the window. Your password is securely saved in the
Microsoft Credential Manager for later reuse.

Specify an organization number From the list of organizations shown that you belong to,
(1-n) [1] type the corresponding number. The default is 1,

indicating the first organization in the list.

6. The sample will perform the operations described in What this sample does and
may prompt you with additional options.

7. When the sample is complete, press ENTER to close the console window.



Custom Dataverse workflow activities
(workflow assemblies)
Article • 12/16/2022

Dataverse supports the registration and execution of custom workflow activities in
addition to the out-of-box activities provided by Windows Workflow Foundation.

Windows Workflow Foundation includes an activity library that provides activities for
control flow, sending and receiving messages, doing work in parallel, and more.
However, to build applications that satisfy your business needs, you may need activities
that perform tasks specific to that application. To make this possible, Windows Workflow
Foundation supports the creation of custom workflow activities.

More information: Create a workflow extension

Related topics
Dataverse Developer Overview

Create a plug-in



Automation center
Article • 03/17/2025

The automation center provides comprehensive monitoring and troubleshooting
experiences for your automation processes across Power Automate, catering to various
personas involved in automation. Whether you're a maker, an operator, a Center of
Excellence (CoE) team member, or a business analyst, the automation center serves as a
centralized hub to monitor and manage automation activity within your environment.
With its user friendly interface and dashboard, the automation center enables you to
gain a holistic view of all automation related data, including recommendations,
execution logs, performance metrics, and an integrated copilot.

Data and visualization strategy
The information displayed on the Overview, Runs and Process map (preview) pages is
based on cloud and desktop flow run data that is stored in Microsoft Dataverse. These
pages are designed to provide you with a top-level view of your flow run activities,
including child cloud or desktop flow runs associated with a particular top-level flow.
This approach enables you to monitor the entire automation from start to end. It allows
you to determine whether the overall automation succeeded or failed, providing data on
the total of the runs, among many other metrics.

７ Note

Some filters might not be available for some tabs because of the nature of the
presented data.
Data under the Work queues tab is a premium feature, which requires a
Power Automate Premium license.
Recommendations is a premium feature, which requires a Managed
Environment.
When you navigate between tabs, the tab keeps the active filtering selection.
Select Clear filters to reset the applied filters.
Desktop flow related activities like desktop flow runs and work queues etc.
have always been available in Dataverse, however cloud flow run history has
only recently been introduced in Dataverse. Learn more.
Cloud flow run history shown on the overview and runs tab might take up to
an hour to be available in Dataverse and the automation center.



By default, visualizations are based on top-level cloud flow runs only. By using
filters, you can also see visualizations for child flows.

Required permissions
The Automation Center's underlying data is managed through Dataverse tables, secured
via role-based access control (RBAC). In standard Dataverse environments (production,
trial, sandbox, developer), necessary privileges are included in the default environment
maker role. Administrators can assign users to this role as needed. In Default
environments with a provisioned Dataverse database, all users automatically become
environment makers. Additionally, administrators can create custom security roles with
row-level privileges to control the data users can view and interact with.

Here are the main tables used in the Automation Center:

ﾉ Expand table

Table Privilege name Description
name

Process prvReadWorkflow Stores desktop flows and solution-aware cloud flows.

Flow prvReadflowsession Stores desktop flow run data.
Session

Flow Run prvReadflowrun Stores cloud flow run data ingested through the feature
Manage cloud flow run history in Dataverse.

Flow Log prvReadflowlog Stores atomic logs such as Power Automate desktop flow
run action logs (requires logs V2 enablement), machine run
logs, etc.

Flow Event prvReadflowevent Stores recommendation-related data and more.

Work prvReadworkqueue Stores work queue data.
Queue

Work prvReadworkqueueitem Stores work queue item data belonging to a particular work
Queue queue.
Item

７ Note



In Dataverse for Teams environments, users must be members of the
Dataverse for Teams environment to access the Automation Center. Learn
more. Consider upgrading your environment for more granular control over
privileges and additional features.
The Work Queue tab isn't available in Dataverse for Teams environments.

Overview tab
This tab provides an end-to-end automation health view within the environment and is
based on top-level flow reporting. The Recommendations section of this tab provides
actionable insights to your automation estate. You can prioritize and address the most
important issues and recommendations, based on their potential impact.

ﾉ Expand table

Visual Description

Recommendations List of automation health, compliance, best practice insights, and actionable
recommendations.

Activity

ﾉ Expand table

Visual Description

Top-level Number of top-level flows that had one or more runs based on selected filters.
flows Gives an overall automation health indication and helps identify which top-level

runs are failing the most.

Total runs Number of flow runs based on selected filters.

Flow runs Percentage of errors that occurred during flow execution based on selected filters.
error rate

Flow runs Tracks usage and reliability trends of top-level runs over time.
error trends

Top flow Quickly identify critical and regularly failing automations, in order to improve
runs health, resiliency, and exception handling.

Flow run Shows latest flows that failed and might need to be modified to reduce desktop
failures flow failures.



Recommendations
The recommendations section offers both proactive and reactive insights, along with
suggestions concerning various elements of your automation landscape. Suggestions
might include addressing sudden automation failures, work queues at risk of not
meeting their service level agreement (SLA) targets, and unused machines or machine
groups in the environment. These recommendations can help you identify areas for
improvement and take appropriate action based on their effect. For more information,
see automation center recommendations.

Copilot
Copilot is designed to assist with the analysis of automation activity, work queue
performance, and to provide answers to common questions about Power Automate
capabilities (generative answers). For example, users can ask about the number of flows
that ran yesterday, which queue items are put on hold, or how to analyze activity with
Copilot. In response, Copilot generates outputs that provide insights and answers to the
questions asked. For more information, see Use Copilot to analyze automation activity
and ask product questions.

） Important

This capability is powered by Azure OpenAI Service.
Copilot is a new technology that is still being developed. It's optimized for use
with English language and has limited support with other languages. As such,
parts of it might appear in English rather than your preferred language.
Read the responsible AI FAQs for Copilot in automation center to learn more
about this new copilot experience.

Runs tab
This tab presents a consolidated view of cloud and desktop flow run data displayed in a
hierarchical list view. The data is organized based on top-level flows. This view is useful
in scenarios where individual flow session runs succeeded, but other dependent runs
failed, ultimately resulting in the top-level flow's failure. By displaying these runs in
connection to their parent, we're enhancing automation monitoring and efficient root
cause analysis of exceptions.



Process map (preview) tab
This tab is designed to make troubleshooting and monitoring in Power Automate more
efficient and transparent. It provides a clear process-centric view of the main
orchestrating flow and all its child flows that run during a process run. It also
understands important structural details about the flows, like conditions, so it can show
flows that are part of the process but didn't run because of certain conditional logic or
errors. Learn more

Work queues tab
This tab provides metrics to monitor the health status of work queue items, including
throughput, average handling time, and distribution. These metrics help to identify areas
for improvement and track performance over time.



ﾉ Expand table

Visual Description

Work queue Shows the number of work queues with SLA-specific configuration,
distribution such as "default item expiration" applied.



Visual Description

Work queue volumes Shows the number of work queue items categorized by their
by status processing status, with a breakdown of exception types (available when

hovering over the exception category).

Work queue Shows the number of items successfully processed in a work queue
throughput within a specific time unit, along with their error rate and trend.

Work queue item error Shows the distribution of work queue items per error state, such as
distribution "Business exception," "IT exception," and "Processing timeout".

Work queue requeue Shows how often work queue items are being requeued for further
rate processing or manual handling.

Average handling time Shows the trend of average handling time for work queue items over
trend time.

Top work queues by Shows the top five work queues with the highest average handling time
average handling time in descending order.

Average handling time Shows the average handling time for items in a work queue.

Top work queue Shows the top five work queues with the highest number of items
handling by processor successfully processed per processor.

Top work queues by Shows the top five work queues ranked by the number of expiring
expiring items items in the work queue.

Top work queues by Shows the top five work queues with the highest number of items in
error frequency error state.

７ Note

If you filter work queue items by a specific item status, such as "Business
exception," any matching item that has already expired isn't considered in the
results. This is because expired items are deemed unprocessable unless their
expiration date is extended first, which takes precedence over lower-level exception
type searches.

Known limitations
The following are current limitations of the automation center and its underlying data
structure.



Cloud flow-based filtering only lists cloud flows that exist within a solution in the
current environment.
Only runs for solution-based cloud flows are available in the automation center.
Visibility of flows and their run history in automation center requires you to be the
owner (coownership isn't sufficient) of the flows or to have environment wide
access to the relevant data in the environment. The main Dataverse tables that
power the data shown in the automation center are:

workflow : Solution-aware cloud flow and desktop flows
flowrun : Cloud flow run history
flowsession : Desktop flow run history
flowevent : Recommendations and notifications
workqueue : Work queues
workqueueitem : Work queue items
businessprocess : Process map details and definition

Child cloud and desktop flow runs are shown under Runs.
Top-level desktop flow runs aren't supported yet (for local attended or API-based
scenarios)
Co-owned or shared flows aren't supported yet (users don't see runs of flows that
are shared with them).
Users with broader access to run data (such as admins or members of the CoE
team) might see Unknown flow as flow names. This name might appear if the
corresponding cloud flow isn't explicitly shared with the user or the flow was
deleted in the meantime.
Users with broader access to run data might encounter increased latency during
data load because of high cloud flow run volumes. Performance can be improved
by selecting more filters and reducing date ranges.
If there's a visual showing "Too many results," try to adjust your filter to limit the
amount of data that is being returned.
If you see Dataverse or cloud flow run-specific notifications, check the underlying
cloud flow run history documentation to learn more.
Older cloud flow run history might be missing for the selected date range filter.
Missing run history might be due to your current environment's time to live (TTL)
configuration, which is set to retain cloud flow runs for n-days only.

Related information
Use process map (preview)
Recommendations within automation center
Use Copilot in automation center
Manage cloud flow run history in Dataverse



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Improve automation monitoring with
process map (preview)
Article • 03/17/2025

[This article is prerelease documentation and is subject to change.]

Building on the robust monitoring and observability features of the Automation Center,
we're excited to introduce the process map (preview). This feature enhances
transparency by showing process-centric flow dependencies and offers an intuitive,
streamlined experience for monitoring and troubleshooting end-to-end automations.



） Important

Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.
For more information, go to our preview terms .
This feature is rolling out and might not be available in your area yet. To try it
out today, you can either use an existing preview environment or create a new
one. Learn more about how to create a preview environment in Early release
cycle environments.
Process map is considered a premium capability. Any flows that are part of a
process map are considered premium flows and require an appropriate



license. Learn more in Power Automate licensing.

Navigate the process map
The process map makes troubleshooting and monitoring in Power Automate more
efficient and transparent. It shows the main orchestrating flow and all its child flows
invoked during a process run. When a process map is created, it considers structural
details like conditions, so it can show flows that are part of the process but didn't run
because of certain conditional logic or errors. This helps you understand how a problem
in one part of the process can affect other parts and take the right countermeasures to
fix issues.

When you select a flow box on the map, its side panel opens, providing detailed
contextual information on run, connection, and design-time properties. This panel lets
you efficiently scan through the run history and better understand the root cause and
impact of errors without navigating to each run from the flow details page or the
Automation Center. This efficiency is especially helpful when troubleshooting flows
called in a loop by their parent, potentially producing tens or even hundreds of runs per
process run.

Runs vs overview
The Runs view provides a comprehensive look at the entire process by displaying both
the main flow run and its child runs. This feature helps you track and understand how
each part of the process is executed, identify issues or bottlenecks, and ensure that all
steps are completed successfully. It enhances visibility into complex workflows, making
them easier to manage and optimize.

The Overview view presents the design-time process structure, including all connected
children. This view is ideal for quickly understanding the various subprocesses within the
process, even if there are no runs yet.

Create or view a process map
To create or view a process map in Power Automate, you have two options:

Option 1: Use the runs tab
1. Go to the Automation center and select the Runs tab.



2. Hover over a top-level flow run and select the process map icon next to the name
to generate the map.

3. If this is your first time using the process map icon, you're prompted to provide a
process name and then select Create.

Option 2: Use the process map (preview) tab
1. Go to the Automation center and select the Process map (preview) tab.
2. On the map, you see a drop-down box in the upper left corner that lists the

processes you have access to.
3. Select the three dots (ellipsis) in the drop-down menu and select Create a new

process map.

Once the process map is generated in the backend, the process name appears next to
the flow name in the run list. If the process column isn't visible, you can add it by using
the Show/hide columns link located at the top-right corner of the runs list.

７ Note

Depending on the volume and complexity of child flow dependencies of your flow,
this process could take up to 10 minutes to complete. You can also close the dialog
that says 'Analyzing flow dependencies' and return later to view your runs in a
process-centric view.

Rename or delete a process map
To rename or delete a process in Power Automate, follow these steps:

1. Go to the Automation center and select the Process map (preview) tab.
2. Once on the map, you see a drop-down box in the upper left corner that lists the

processes you have access to.
3. To view the list of processes, select the three dots (ellipsis) next to the process

name in the drop-down menu.
4. From here, you can rename or delete your process.

７ Note

Deleting or renaming a process doesn't delete any of the flows or runs associated
with the process.



Process map visualizations

ﾉ Expand table

Icon Description

Represents the start and different end states of a process

Represents a cloud flow

Represents a desktop flow

Represents a loop scenario where a parent flow calls a child flow n-times

Represents the total number of times various parent flows ran this flow. Each flow
instance is triggered by a different parent flow run, instead of being repeatedly
called within a single parent run loop

Represents a conditional or optional flow. This means that the flow connected by
the dotted line isn't always executed but depends on certain conditions being met

Represents a missed or skipped flow based on conditional logic or an upstream
error

Represents an unattended desktop flow run

Represents an attended desktop flow run

７ Note

Preview features in the Automation Center, including this process map (preview),
can be disabled through the Power Platform admin center. The toggle for this
setting is located under the Power Automate Automation center section. However,



once the process map (preview) feature becomes generally available, it will be a
permanent part of the Automation center and can't be turned off anymore.

Known issues and limitations
Creating and viewing process maps requires users to have the Environment Maker
or similar roles with sufficient privileges on the business process table.
Runs for co-owned or shared flows aren't supported yet, which means users don't
see runs for flows shared with them.
Users with broader access (like admins or CoE teams) might see 'Unknown flow' as
the flow name. This happens if the flow isn't explicitly shared with them or it's
deleted.
Process maps for top-level desktop-flows aren't supported yet.
Child desktop flows aren't displayed yet on the map.
Parallelization features (for example, cloud flow 'Apply each' with concurrency or
'RunAfter' customizations) aren't visually represented. Such child runs appear in
the order they were defined.
Dynamic flow selection using a formula (instead of the standard picker) isn't
supported. Such child flows are ignored.
For any given run, only the first 100 child flows are loaded. For example, if flow A
triggers 150 instances of flow B, only the first 100 are processed.
Process map definitions might not remain fully current if more than 50 levels of
child flows exist.
Runs that were created with a previous structure of the process map don't show
flow runs of flows that aren't part of the current map anymore.
Generating a process map with moderate to large dependencies can take up to 10
minutes. During this time, an 'Analyzing flow dependencies' dialog is shown.
Updates to a process map after its dependent flow structures are modified might
take several minutes, and there’s currently no visual indicator to show the map is
updating.
Although process maps are solution-aware and can be exported or imported to
downstream environments, they can't currently be created directly from within the
solution explorer.

Feedback
Was this page helpful?  Yes  No



Provide product feedback



Automation center recommendations
Article • 01/14/2025

The automation center offers targeted recommendations aimed at enhancing the
reliability, efficiency, and general health of your automation. You can find actionable
insights such as:

real-time recommendation of automations starting to fail
warnings of work queues potentially failing to meet their service level agreement
(SLA) objectives
identification of unused machines or machine groups in the environment
many more

Key capabilities
Key features of recommendations:

Get proactive and reactive recommendations, grounded on best practices.
Enhance the overall health, compliance, and performance of automation across
your environment.
Take corrective actions directly from the list of affected automation artifacts.

Prerequisites
To see and use recommendations in automation center, the following are required:

From December 2024 (general availability), a Dataverse environment with
managed environment enabled.
Premium Power Automate license
Environment maker role (or other roles that include access to recommendation
data)

Recommendation details
Recommendations appear as cards in the carousel found at the top of the automation
center's overview page. Each recommendation is uniquely generated per
recommendation type, user, and refresh interval, and is stored in the Flow Events
(flowevent) table in Dataverse. This design provides important permission granularity,
ensuring that the recommendations each user receives align with their specific access
rights to the underlying artifacts. If a user doesn't have permission to view the



underlying flow, work queue, or any related artifact related to the recommendation,
those recommendations aren't generated for them.

Recommendation card
The recommendation card shown in the following image is the entry point to your
recommendations. Here’s a detailed breakdown of the card’s components:



Type: Indicated by an exclamation mark in a triangle, shows that this
recommendation is a warning or alert.
Title: "Work queue SLA at risk" – this value provides a concise title of the issue.
Refresh frequency: "HOURLY" – this value specifies the refresh frequency of the
recommendation data.
Impact: "Medium" – this value indicates the severity or importance of the issue.
Recommendation details: The short text that describes the recommendation.
Actions or details: Call to action or detail that provides more in-depth information
about the specific recommendation.
Card actions: Ability to hide recommendations for varying durations such as an
hour, day, week, or even indefinitely.

Recommendation details panel
The recommendation details panel shown in the following image provides a more
detailed view with inline, actionable insights. Here’s a detailed breakdown of the panel's
components:

Type: Indicated by an exclamation mark in a triangle, showing that this
recommendation is a warning or alert.
Title: "Work queue SLA at risk" – this value provides a concise title of the issue.



Refresh frequency: "HOURLY" – this value specifies the refresh frequency of the
recommendation data.
Recommendation timestamp: Shows the date when the recommendation was
generated.
Recommendation details: Provides context and specifics about the
recommendation, including an explanation and suggested actions.
Corrective actions or guidance: Specific actions recommended to mitigate the
issue.
Call to action or details: Provides buttons for immediate actions or for further
details.
Affected artifact details: A table or chart listing affected recommendation artifacts
such as flows, work queues, machines etc.

All recommendations panel
The all recommendations panel shown in the following image is used for viewing latest
and older recommendation with filtering capabilities. The recommendations are
categorized by type (Error, Warning, Information) and can be filtered by impact (High,
Medium, Low), status (Hidden), and date range. This panel is divided into two main
sections: one for displaying the most recent recommendations and another for showing
older recommendations along with their timestamps. The most recent
recommendations are initially displayed under 'Latest', but are replaced with refreshed
content based on the recommendation interval.



Category
The category classifies the recommendations based on the specific area of automation
they target.



ﾉ Expand table

Category Description

Orchestration Insights related to the orchestration of processes, work queues, and machines.

Monitoring Recommendations related to real-time tracking of automation health,
compliance, or performance.

Governance Recommendations related to the rules, policies, and processing compliance.

Licensing Recommendations related to the management of licenses and capacity.

Type
The type indicates the severity or urgency of the recommendations.

ﾉ Expand table

Type Description

Information Provides best-practice recommendations you might want to consider.

Warning Indicates a potential issue that might lead to a problem later if not addressed.

Error Indicates a problem that needs to be resolved.

Refresh frequency
The refresh frequency provides information on how often the recommendation data is
updated, ensuring users have the most recent and relevant information for decision
making.

ﾉ Expand table

Refresh Description
frequency

DAILY A new instance of the recommendation data is regenerated once a day.

HOURLY A new instance of the recommendation is regenerated every hour.

REAL TIME The recommendation is an actual live-query to the underlying automation
data.



List of recommendations
The following list of recommendations aims to provide proactive guidance and
actionable insights for optimizing and troubleshooting various aspects of your
automations. From addressing work queue SLA violations and capacity overages to
improving system resilience and efficiency, each recommendation offers a detailed
proposed solution or more details.

７ Note

Recommendations that don't have a real time refresh frequency hold data
snapshots from when the recommendation was generated. As a result, if you
revisit an older recommendation, the information displayed under artifact
details may no longer be accurate or applicable.
If you're a premium Power Automate user and it's your first time accessing the
automation center, we will begin generating recommendations for you. These
should be ready for your review in about an hour or two.
Generation of recommendations is paused if you don't return to the
automation center within 7 days, your premium license was unassigned by
your IT team, or your trial expired.
The recommendations shown as part of the automation center are intra-
environmental recommendations targeted to makers, operators, and CoE
team members. If you are looking for admin related, tenant-wide
recommendations in Power Platform admin center, these are part of a
separate feature called Power Platform Advisor.

Work queue SLA violation

７ Note

Initially, this recommendation will consider all work queue items with past expiry
dates for possible SLA violations. However, we will change this logic in a future
update to exclude items in a Processing  or Processed  state.

ﾉ Expand table



Category or object Details

Title Work queue SLA violation

Card details {number of work queues} work queues are out of compliance with their
service level agreement (SLA).

Recommendation One or more work queue items are queued but expired. This usually
details indicates an SLA violation.

Type Error

Refresh frequency Hourly

Category Orchestration

Recommended - Identify the root cause. Was it due to a technical issue, a lack of
actions resources, or some other factor?

- First identify the cause. Then notify all relevant stakeholders of the miss
and the steps being taken to address it.
- Determine which work is impacted by the SLA miss and prioritize it
accordingly.
- If necessary, allocate extra resources to address the SLA miss (adding
more machine capacity, licenses, or other solutions to improve
performance).
- Monitor progress to ensure the SLA is being met and that work is
completed within the agreed-upon time frame.

Work queue SLA at risk

７ Note

Initially, this recommendation identifies work queue items that expire within one
hour as potentially violating the work queue's SLA. However, we will change this
logic in a future update to include items that expire within one day instead, and
exclude items in a Processing  or Processed  state.

ﾉ Expand table

Category or Details
object

Title Work queue SLA at risk

Card details {number of work queues} work queues are close to breaching their service
level agreement (SLA) or are already breached.



Category or Details
object

Recommendation Based on average handling time, volume, available machine capacity, and
details expiration dates, {number of work queues} work queues are at risk of not

meeting their SLA targets. Investigate and adjust work queue capacity and
prioritization. All work queue items that are either already expired, or expire
within the next hour, will be included in this recommendation.

Type Warning

Refresh frequency Hourly

Category Orchestration

Recommended - Align work queue volumes with machine and license capacity and prioritize
actions processing of at-risk work queues.

- Increase machine group capacity where needed, and closely monitor work
queue item execution and expiration dates.
- Consider moving to a hosted machine group for scalability and cost-
effectiveness. Your machines scale automatically to match processing
demand and you only pay for what you use.

Power Automate Process capacity overage

ﾉ Expand table

Category or object Details

Title Power Automate Process capacity overage

Card details Your Power Automate Process capacity is insufficient. Consider requesting
{number of capacities} more capacity.

Recommendation Your current Power Automate Process capacity isn't enough to handle your
details workload. You need {number of capacity} additional Power Automate

Process capacity to meet your needs.

Type Error

Refresh frequency Real time

Category Licensing

Recommended We recommend requesting additional hosted process capacity to avoid any
action(s) potential issues and disruptions.

Power Automate Hosted process capacity overage



ﾉ Expand table

Category or object Details

Title Power Automate Hosted process capacity overage

Card details Your Power Automate Hosted Process capacity is insufficient. Consider
requesting {number of capacities} more capacity.

Recommendation Your current Power Automate Hosted Process capacity isn't enough to
details handle your workload. You need {number of capacities} additional Power

Automate Hosted Process capacity to meet your needs.

Type Error

Refresh frequency Real time

Category Licensing

Recommended We recommend requesting additional hosted process capacity to avoid any
action(s) potential issues and disruptions.

Desktop flow suspended due to DLP policy violation
ﾉ Expand table

Category or object Details

Title Desktop flow suspended due to DLP policy violation

Card details {number of flows} desktop flow(s) are suspended due to DLP policy
violations

Recommendation Investigate why suspended flows aren't in compliance with your
details organization's DLP (Data Loss Prevention) policy.

Type Error

Refresh frequency Hourly

Category Governance

Recommended - Your organization applied DLP policies that resulted in suspended flows
action(s) that you built or co-own. Review the following action list to get your flows

back on track:
- Identify the specific desktop flows that have been suspended and review
them to determine why they don't adhere to the DLP policy.
- Analyze the data being processed by the flows and identify any potential
risks or vulnerabilities.
- Modify the desktop flows to ensure that they adhere to the DLP policy.



Category or object Details

This may involve implementing additional security measures or changing
the way data is processed or stored.
- Test the modified desktop flows to ensure that they're functioning
correctly and that they adhere to the DLP policy.

Fix failing automations
ﾉ Expand table

Category or object Details

Title Fix failing automations

Card details One or more of your automation runs have failed. We'll show you why and
help you fix the affected automations.

Recommendation There are one or more runs that need your attention. The recommendation
details considers only failed automations from the past week. Any failures older

than one week are not included.

Type Error

Refresh frequency Real time

Category Monitoring

Recommended Review the list of runs and open flow or run details to troubleshoot.
action(s)

Unused or inactive machines

ﾉ Expand table

Category or object Details

Title Unused or inactive machines

Card details {number of machines} machines didn't have any runs in the last 30 days

Recommendation Remove inactive machines from this environment.
details

Type Information

Refresh frequency Daily



Category or object Details

Category Monitoring

Recommended Consider cleaning up any machine that you know isn't active or used
action(s) anymore.

Improve performance and resiliency

ﾉ Expand table

Category or Details
object

Title Improve performance and resiliency

Card details You currently have {number of flows} flows that are running frequently
throughout the day. These flows don't currently utilize work queues.
Implementing work queues could potentially enhance your processing
throughput, improve resiliency, and simplify troubleshooting.

Recommendation Consider using work queues for flows that run frequently throughout the
details day. This can improve your processing throughput, resilience, and your

ability to troubleshoot issues.

Type Information

Refresh frequency Daily

Category Orchestration

Recommended - Use work queues to group and process multiple work items in a run.
action(s) - Prioritize them based on their importance and expiration date, and

improve processing throughput, overall efficiency, and resiliency.
- You also get robust monitoring capabilities (including the ability to
reprioritize or reprocess work as needed).

Desktop flows not running

ﾉ Expand table

Category or object Details

Title Desktop flows not running

Card details A user session or a connection problem is preventing {number of flows} of
your desktop flows to run.



Category or object Details

Recommendation {number of flows} of your desktop flows need fixes. These flows were
details scheduled to run in unattended mode, but another user session or a

connection problem prevented them from completing.

Type Information

Refresh frequency Real time

Category Orchestration

Recommended Select the identified runs, open the disconnect user menu, and then choose
action(s) how to end other inactive user sessions on this machine.

Known limitations
Deletion of older recommendation isn't yet supported through the user experience
in automation center. If you want to clean-up recommendations, consider using
the Dataverse bulk-delete feature.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Use Copilot to analyze automation
activity and ask product questions
Article • 01/29/2025

Understanding automation activity and performance are key to achieving operational
excellence and reliability goals, regardless of the size of the automation estate, team, or
role within the organization. To reach those goals requires advanced and dynamic
monitoring capabilities that provide you with valuable insights that highlight areas of
success and identify potential bottlenecks, trends and areas for improvement. Having
more detailed insights allows you to make informed decisions that optimize your
automation processes, leading to increased efficiency and effectiveness.



） Important

This capability is powered by Azure OpenAI Service.
Copilot is a new technology that is still being developed. It's optimized for use
with English language and has limited support with other languages. As such,
parts of it might appear in English rather than your preferred language.
Read the responsible AI FAQs for Copilot in automation center to learn more
about this new Copilot experience.
More FAQs: Responsible AI FAQs for Power Automate, FAQ for Copilot data
security and privacy in Microsoft Power Platform



Prerequisites
A work or school account with access to a Power Automate environment located in
the United States.
Check known limitations for more information.

How does it work?
Copilot in automation center is able to answer questions about the following four skills:

ﾉ Expand table

Index Skill Questions skill can answer

1 Cloud flow run logs Cloud flow run status, trigger type, run duration,
failure rate.

2 Desktop flow run logs Desktop flow run status, used machine, run mode,
failure rate.

3 Work queue data Work queue items statuses, service level agreement
(SLA) attainment, processor counts.

4 Documentation (generative General Power Automate feature questions such as
answers - preview) how to analyze activity with Copilot.

The first three skills in the prior table translate natural language queries (questions)
entered by users into Microsoft Dataverse FetchXML query syntax. This translation
allows users to easily retrieve information about their automation data by asking
questions in natural language. Additionally, Copilot determines the most suitable output
visualization, such as a table, pie chart, bar chart, or line chart, to effectively present the
insights and information to the user.

Copilot skill selector
When Copilot opens (per session) the first time, the "cloud flow" skill is preselected. You
can modify the skill by choosing the dropdown next to the phrase Questions about and
selecting your preferred skill. The conversation history is reset each time you change the
skill.







High-level process
1. Once the user inputs a valid prompt, Copilot generates a FetchXML query based

on the input.
2. If the generated FetchXML is valid, the query is then executed against the

Dataverse backend under the current user's security context to retrieve matching
data. Retrieving the data as the user ensures that users only see data that they're
already authorized to access.

3. Copilot then determines the most suitable output visualization, such as a table, pie
chart, bar chart, or line chart, to effectively present the insights and data to the
user.

What are FetchXML queries?
Microsoft Dataverse FetchXML is a language used for retrieving data from a Dataverse
database. FetchXML is designed to be easy to create, use, and understand. For example,
you might want to ask Dataverse to give you a list of all flow runs for a specific flow. The
FetchXML query is the way you phrase that question so the database understands it and
can give you the right results.

Prompt best-practices
Be specific:

The more specific you are with your prompt, the better the AI understands and
responds.
If the AI isn't producing the desired output, don't worry. Try again by adjusting
your prompt.

Experiment with prompts:
If you're not getting the results you were expecting, try rephrasing your prompt
or provide more context.

Provide feedback:
If the AI produced great or unsatisfactory responses, let us know by selecting
the thumbs up or down with an option to provide more feedback via the Tell
Microsoft what you liked about this feature link that appears underneath.

Prompt examples



This section provides example prompts you can use as a starter prompt for your own
use cases. Some of these prompts might not be applicable or return incorrect results.
Model understanding or the actual prompt and the data available to you based on your
permissions might influence the accuracy. We recommend that you review and validate
the returned results and FetchXML query.

Cloud flow runs

７ Note

Cloud flow run history in Dataverse, which is built on the new Elastic Table feature,
has different known limitations for querying and aggregating data compared to the
desktop flow run history. These differences might impact the responses from
Copilot. You can find out more about these known limitations here.

How many runs last month were triggered by another cloud flow?
Who initiated flow runs during the last month?
How many flows failed yesterday?

Desktop flow runs
Which flows ran the most last week?
What were yesterday’s top five flows by number of completed runs?
What is the distribution of flow run statuses?

Errors
Show me the most frequent run errors last month.
Show me a distribution of successful versus failed flows last quarter.
What were the number of failed runs during the week before the last one?

Work queues
Show me number of items that are on hold.
Show me the number of items that are at risk of breaching SLA.
What's the average handling time per processor (machine) and queue?

Machines
Which bots had the most run failures today?



Which machines are in maintenance mode?
What are the machines with the most run failures?

Makers
Show me the top flows by number of runs together with their owner info.
Who were the top 10 users running flows last month?
When and by whom were desktop flows modified last week?

Documentation (generative answers - preview)
How can I add a condition in Power Automate desktop?
Can cloud flows handle approvals and decision-making processes?
Where can I find deleted flows in Power Automate?

Multi-turn prompts
In the context of AI, multi-turn prompts allow you to have an ongoing conversation with
Copilot, where it remembers the context of the previous messages in the conversation.
It's not just answering one-off questions; it's engaging in a dialogue with you, where
each response is based on what was said before.

７ Note

Generative answers (documentation skill - preview) doesn't support multi-turn
conversations yet.
When engaging in a multi-turn conversation, Copilot keeps track of the 10
most recent questions only. This means that Copilot starts clearing the
prompts that were entered first and only keeps the latest 10. To improve
response quality, we suggest limiting your follow-up questions or more
frequently restart the chat. For more information, see Clear previous prompt
context to start over.

Example

ﾉ Expand table



Turn Prompt and reply

User: Show me a distribution of successful vs failed flows last quarter

Copilot: Here's the distribution of successful vs failed flows during the last quarter.

User: What was the top error of the runs that failed?

Copilot: Here's the top error of the runs that failed.

User: On which machine names did they fail the most?

Copilot: Here are the machine names where the most failures occurred.

User: What was the average run duration of the flows that succeeded?

Copilot: Here's the average run duration of the flows that succeeded.



Influencing the output format
You can influence Copilot's output format by asking for explicit output types like "show
me failed vs succeeded flow run distribution as a bar chart." This prompt likely produces
the following outcome:





Clear previous prompt context to start over
If you wish to reset the conversation with Copilot, select the three dots ...  next to the
copilot name, and then select New chat.

Edit and rerun FetchXML queries returned by Copilot
You can fine-tune the queries returned by Copilot through in-place edits in the code
area. Just change the code to match your new search criteria and select Run. To
illustrate, let's consider the following prompt:

"How many flows were triggered by schedule in the last three days?"

Query results before any change

XML

<fetch version="1.0" mapping="logical" aggregate="true">
  <entity name="flowrun">
    <attribute name="flowrunid" alias="flowrun_count" aggregate="count"/>
    <filter type="and">
      <condition attribute="parentrunid" operator="null"/>
      <condition attribute="triggertype" operator="eq" value="Scheduled"/>
      <condition attribute="starttime" operator="ge" value="2024-05-
05T12:28:35.000Z"/>
    </filter>
  </entity>
</fetch>





Changed query results

XML

<fetch version="1.0" mapping="logical" aggregate="true">
  <entity name="flowrun">
    <attribute name="flowrunid" alias="flowrun_count" aggregate="count"/>
    <filter type="and">
      <condition attribute="parentrunid" operator="null"/>
      <condition attribute="triggertype" operator="eq" value="Instant"/>
      <condition attribute="starttime" operator="ge" value="2024-04-
01T12:28:35.000Z"/>
    </filter>
  </entity>
</fetch>





Validate FetchXML query results generated by
Copilot
The following steps guide you through the process to validate (and potentially reuse)
FetchXML queries in Power Automate cloud flows.

Step 1: Make a copy of the FetchXML query
After you submit your query to Copilot, you get a reply that includes a link labeled Show
code. To copy the code, select this link and then select the copy icon located in the
upper-right corner of the FetchXML box.

Step 2: Create a cloud flow and test the FetchXML query
1. Navigate to the Power Automate portal  and select My flows from the left

navigation menu.
2. Continue by selecting + New flow on the command bar, and then select Instant

cloud flow from the dropdown menu.
3. Enter a flow name, select Manually trigger a flow, and then select Create.
4. The cloud flow designer appears. Find and then select the + New Step button.
5. On the search bar that appears, enter Dataverse, and then select the Dataverse

connector from the results.
6. Various actions are displayed. Scroll through until you find and select the List rows

action.
7. Within the List rows action, select the Show advanced options link.



8. A FetchXML query field appears. This field is where you input the copied FetchXML
query that Copilot previously generated.

9. After pasting in your FetchXML, select Save.
10. Test your flow by selecting Test.
11. Follow the prompts on your screen to start your flow manually to review its results.

Step 3: Understand the results
Let's assume you asked Copilot 'how many failed vs succeeded flows did we have last
month?' This prompt produces a FetchXML query similar to the following example:

XML

<fetch version="1.0" mapping="logical" aggregate="true" count="3" page="1">
    <entity name="flowsession">
        <attribute name="flowsessionid" alias="flowsession_count" 
aggregate="count" />
        <attribute name="statuscode" alias="flowsession_statuscode" 
groupby="true" />
        <filter type="and">
            <condition attribute="completedon" operator="last-x-months" 
value="1" />
        </filter>
    </entity>
</fetch>

If data matches the given FetchXML query, the List rows Dataverse action configured in
step 2 returns data in a format called JSON  (JavaScript Object Notation), which is
essentially a method used to present data in a well organized manner, making it easy to
read and write digitally.

For distribution based questions like previously mentioned, data is grouped by one or
more fields ( statuscode ), together with an aggregation ( count ) that returns the number
for each group (that is, failed , succeeded , and so on).

Each record returned contains fields such as:

flowsession_count : The number of times the workflow ran.
flowsession_regardingobjectid : The unique identifier for the flow run.
flowsession_statuscode : The status of the flow run (for example, failed).
workflow_name : The name of the flow.

If you want to know how many times a specific flow ran, look at the flowsession_count
column of the record where workflow_name  is your flow name.



Understand Copilot replies on problematic
prompts
This table shows default responses that are returned when Copilot is unable to
understand your question, intent, or generate a valid answer.

ﾉ Expand table

Copilot reply Details

Sorry, something went wrong. Please try again. An unexpected error occurred.
Rephrase your question and try again.

Sorry, I couldn't find any results for that query. The question was understood and a
Please try again by refining your question, or valid query was generated, but there's
consider using a sample suggestion from the prompt no data available to be returned.
guide.

Sorry, I couldn’t understand your question. Rephrase Your question couldn't be translated
it and try again. I’m able to answer questions that into a valid FetchXML query. Rephrase
are about the data on this page. For more examples of your question and try again.
prompts that you can ask Copilot, you can visit the
prompt example section on our documentation page.

Sorry, Copilot is at capacity and temporarily There are resource constraints on the
unavailable — please try again in a little while. backend. Retry your question after a

short time.

Sorry, your message contains potentially harmful The backend service blocked your
content. Please ensure your input is appropriate and question because it might include
try again. potentially harmful content. Remove

any potentially harmful content from
your question and try again.

Sorry, I was not able to generate a valid answer The generated FetchXML is invalid or
based on your question. Please rephrase it and try that the query failed when Copilot
again. I’m able to answer questions that are about tried to execute it. Rephrase your
the data on this page. For more examples of prompts question and try again.
that you can ask Copilot, you can visit the prompt
example section on our documentation page.

Sorry, your search includes too many results. Please The filters applied to your query
refine your query and try again. For examples on how exceed current aggregation limits in
to limit search results returned by Copilot, visit FetchXML. Add more appropriate
our documentation page. filters such as only yesterday's or last

month's data to ensure the query
returns data within those limits.



Known issues and limitations
The following list contains known limitations of Copilot in automation center.

Copilot is a new technology that is still being developed. It's optimized for use with
English language and support with other languages is limited. As such, parts of it
might appear in English rather than your preferred language.
Copilot is currently only available in Dataverse environments based in the United
States.
Copilot might return wrong or incomplete data and FetchXML queries.
Copilot is initially only capable to answer questions about desktop flow activity,
cloud flow activity, work queues, and general product feature questions of Power
Automate.
In multi-turn conversations, Copilot keeps context of the last 10 question only. If
you encounter wrong or incomplete results, consider resetting the conversation.
Multi-turn conversations aren't supported for generative answers (documentation
skill -preview).
For queries that return large result-sets, Copilot might not be able return or render
the result.

Related information
Get started with Copilot in cloud flows
FAQs for Copilot in automation center
FAQ for Copilot in desktop flow activity
FAQ for Copilot in cloud flows
FAQ for Copilot in Power Automate Process Mining
FAQ for Copilot data security and privacy in Microsoft Power Platform

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Automation-centric data analytics with
Fabric
Article • 12/21/2024

Power Automate offers built-in monitoring and troubleshooting to help organizations
manage operations, view trends, and access recommendations through features like the
Automation Center and Desktop Flow Activity.

However, your organization likely has more advanced or custom monitoring, reporting,
and analysis needs that aren't covered within the product today. One key strength of the
Power Platform is its native integrations with other low-code tools and platforms like
Power BI, Microsoft Fabric, and Azure. Organizations can develop sophisticated, scalable,
and compliant analytics solutions using data from Power Automate and other sources.

Microsoft Fabric as your analytics platform
Microsoft Fabric is an end-to-end analytics and data platform designed for enterprises
that require a unified solution. It encompasses data movement, processing, ingestion,
transformation, real-time event routing, and report building. It offers a unified suite of
analytical services, including data engineering, data science, real-time analytics, and data
warehousing with advanced data governance and security control.



Dataverse direct link to Microsoft Fabric
The Link to Microsoft Fabric feature built into Power Platform makes all your Dynamics
365, Power Apps and Power Automate data available in Microsoft OneLake, the built-in



data lake for Microsoft Fabric. Key benefits of the Dataverse direct link:

No need to export data, build extract, transform, load (ETL) pipelines, or use our
partner integration tools.
With shortcuts from Dataverse directly into OneLake, your data stays in Dataverse
while authorized users get to work with data in Fabric.
Link data from all Dynamics 365 apps, including Dynamics 365 Finance and
Operations apps.
Build Power Apps and automations to drive action from insights in OneLake.

Get started
This guide explains how to use Dataverse shortcuts within Microsoft Fabric to create
powerful data analytics solutions. By the end of this guide, you have the skills to
understand automation-centric data models, and build sophisticated data queries to
generate insightful reports.

７ Note

According to this documentation, it can take up to 60 minutes to update data in
OneLake, including the conversion to delta parquet format. If you select a table that
contains a lot of data, the initial load time can take longer. When you open Fabric
lakehouse, the links appear as unidentified until the initial sync is completed. More
information: Troubleshooting common issues

Prerequisites
Before you continue, ensure you meet the following prerequisites:

1. Understand data modeling, Power Automate, Dataverse, and the Fabric ecosystem.

2. Have access to a Dataverse environment (in the same region as your Fabric
capacity) with a Power Automate premium license, (ideally) existing cloud, and
desktop flow runs, and System Administrator role in this environment.

3. Ensure that you meet the prerequisites before linking your Dataverse environment
with Fabric.

4. Follow these steps to link your Dataverse environment with Microsoft Fabric. After
linking the environment, you see a Lakehouse, a semantic model, and a SQL
analytics endpoint. These items are prefixed with "Dataverse," followed by your



environment name and a unique environment suffix, such as
dataverse_contosousap_cds2_workspace_unq111111111111111111111111 .



5. (Optional) Select Lakehouse settings and rename your Lakehouse to a meaningful
name, such as "contoso_westus_accounts_payable," and provide a brief
description. This change helps others quickly identify the specific automations and
data processed in the Lakehouse.



6. (Optional) Link other Dataverse environments within the same geographical region
to Fabric to create cross-environment analytics solutions.

7. (Optional) If you plan to follow the advanced section for Desktop flow action log-
level analytics, ensure that Desktop Flow Logs V2 is enabled in that environment
and you have existing desktop flow runs.

What's next
Create automation-related queries with Fabric



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Create automation-related queries with
Fabric
Article • 12/21/2024

７ Note

Disclaimer: The scenarios, query examples, and data used in this tutorial are
fictional, may include errors, inefficiencies, and are intended solely for
demonstration purposes.

List of automation-related tables
The following table lists automation-related tables frequently used for reporting and
observability.

ﾉ Expand table

Display Object name Purpose
name

Flow Log flowlog Contains a wide variety of logs, such as custom logs, desktop
flow action logs V2, machine run queue logs, unattended self-
heal requests/responses, and work queue processing logs etc.
The data is stored in a Dataverse elastic table, and depending on
the log type, can be configured with its own time-to-live (TTL)
setting in the Organization table (FlowLogsTtlInMinutes and
DesktopFlowQueueLogsTtlInMinutes), which defines when
records should be automatically deleted from the table.

Flow flowmachine Contains machine and hosted machine-related info.
Machine

Flow flowmachinegroup Contains machine group and hosted machine group-related
Machine info.
Group

Flow Run flowrun Contains cloud flow run-related data such start, end, duration,
parent flow context etc.

Flow flowsession Contains desktop flow run-related data such as start, durations,
Session status, machine, robot account, parent flow context etc.



Display Object name Purpose
name

Process workflow Contains desktop flows and solution-based cloud flows (along
with other workflow types).

User systemuser Represents the Dataverse user.

Work workqueue Represents an instance of a workflow execution.
Queue

Work workqueueitem Contains information about each run of a workflow.
Queue
Item

Simplified table relationship diagram
The image shows only the relevant table relations for automation.





Create your first query in Fabric
Follow these steps to create a sample SQL query on the SQL Analytical Endpoint in
Fabric for the contoso_westus_accounts_payable  Lakehouse.

1. Open your web browser, go to the Microsoft Fabric portal (https://powerbi.com ),
and sign in with your credentials.

2. Select the workspace where your Lakehouse is located, then select the desired SQL
Analytical Endpoint (a subnode of your Lakehouse).

3. In the SQL Analytical Endpoint, select New SQL query to open the SQL query
editor.

4. In the SQL query editor, enter your SQL query and select Run. The following
example query retrieves all desktop flow runs (flow sessions) associated with a
specific desktop flow and a machine ID that failed within the last seven days.

SQL

   SELECT   
       flowsessionid,  
       statuscode,  
       startedon, 
       completedon,
       errorcode,  
       errormessage,  
       sessionusername,  
       runexecutionduration,  
       runduration,  
       runwaitduration,  
       context
   FROM   
       flowsession  
   WHERE   
       regardingobjectid = '[specific_flow_id]' -- Replace with the 
actual flow ID  
       AND machineid = '[specific_machine_guid]'  -- Replace with the 
actual machine ID  
       AND statuscode = 8 -- 'Failed' sessions  
       AND createdon >= DATEADD(day, -7, GETDATE())  
   ORDER BY   
       createdon DESC;  

5. Here's a list of available status reasons (statuscode) for the Flow Sessions  (desktop
flow runs) table.

ﾉ Expand table



Status reason Value

Paused 1

Running 2

Waiting 3

Succeeded 4

Skipped 5

Suspended 6

Canceled 7

Failed 8

Faulted 9

TimedOut 10

Aborted 11

Ignored 12

6. Review the query results to ensure they meet your needs.



7. (Optional) Open a Live-query with results in Excel by highlighting the SQL query
and selecting Open in Excel in the query output section. This generates and
downloads an Excel file with a Live-query to the SQL Analytics endpoint for further
analysis.





8. (Optional) To store the SQL query for future use, select Save Query.

Basic flow queries

Retrieve cloud flows with their owner info
This query returns all cloud flows with their owner information.

７ Note

Only cloud flows that are part of a Dataverse solution are available in Fabric.

SQL

    SELECT   
        w.name AS 'Cloud flow',  
        w.workflowid AS 'Cloud flow Id',  
        w.createdon AS 'Created on',
        w.modifiedon AS 'Last modified on',
        w.clientdata AS 'Script',  
        w.ownerid AS 'Owner Id',  
        s.fullname AS 'Owner name',  
        s.internalemailaddress AS 'Owner email'
    FROM   
        workflow w  
    JOIN   
        systemuser s ON w.ownerid = s.systemuserid  
    WHERE   
        w.category = 5;  -- Only consider solution-cloud flows (category 5)  



Retrieve desktop flows with their owner info
This query returns all desktop flows with their owner information.

SQL

    SELECT   
        w.name AS 'Desktop flow',  
        w.workflowid AS 'Desktop flow Id',  
        w.createdon AS 'Created on',
        w.modifiedon AS 'Last modified on',
        w.definition AS 'Script',  
        w.ownerid AS 'Owner Id',  
        s.fullname AS 'Owner name',  
        s.internalemailaddress AS 'Owner email'
    FROM   
        workflow w  
    JOIN   
        systemuser s ON w.ownerid = s.systemuserid  
    WHERE   
        w.category = 6;  -- Only consider desktop flows (category 6)  

Performance-related query example
This query retrieves the minimum, mean (average), maximum, and standard deviation of
runtimes for desktop flow runs (Flow Sessions) of a specified desktop flow, with the
runtimes converted from milliseconds rounded up to the nearest full second. The query
groups the results by machine IDs and includes details such as machine names,
management types, maximum hosted machine counts, session capacity, and the last
heartbeat date from the Machine Group and Machine tables.

SQL

    SELECT   
        f.machineid,  
        fm.name AS machine_name,  
        CASE   
            WHEN mg.managementtype = 0 THEN 'Regular Machine (Group)'  
            ELSE 'Hosted Machine (Group)'  
        END AS managementtype,  
        mg.maxmanagedmachinecount AS maxmanagedmachinecount,  
        fm.lastheartbeatdate AS last_heartbeat_date,  
        fm.sessioncapacity AS 'Max Parallel Sessions',    
        CEILING(MIN(f.runduration) / 1000.0) AS min_runtime,  
        CEILING(AVG(f.runduration) / 1000.0) AS mean_runtime,  
        CEILING(MAX(f.runduration) / 1000.0) AS max_runtime,  
        CEILING(STDEV(f.runduration) / 1000.0) AS stdev_runtime
    FROM   
        flowsession f  



    JOIN   
        flowmachinegroup mg ON f.machinegroupid = mg.flowmachinegroupid  
    JOIN   
        flowmachine fm ON f.machinegroupid = fm.flowmachinegroupid  
    WHERE   
        f.regardingobjectid = '[specific_flow_id]' -- Replace with the 
actual flow ID
    GROUP BY   
        f.machineid, fm.name, mg.managementtype, mg.maxmanagedmachinecount, 
fm.lastheartbeatdate, fm.sessioncapacity  
    ORDER BY   
        mean_runtime DESC;  



Machine and licensing capacity-related query
This query identifies machine and licensing-related capacity issues for a specific desktop
flow to help in optimizing resource allocation and addressing performance constraints.

SQL

    SELECT   
        f.machineid,  
        fm.name AS machine_name,  
        CASE   
            WHEN mg.managementtype = 0 THEN 'Regular Machine (Group)'  
            ELSE 'Hosted Machine (Group)'  
        END AS managementtype,  
        mg.maxmanagedmachinecount AS maxmanagedmachinecount,  
        fm.lastheartbeatdate AS last_heartbeat_date,  
        fm.sessioncapacity AS 'Max Parallel Sessions',  
        fm.overcapacitysince,  
        CASE   
            WHEN fm.overcapacitysince IS NOT NULL THEN 'Over Capacity'  
            ELSE 'Within Capacity'  
        END AS capacity_status  
    FROM   
        flowsession f  
    JOIN   
        flowmachinegroup mg ON f.machinegroupid = mg.flowmachinegroupid  



    JOIN   
        flowmachine fm ON f.machinegroupid = fm.flowmachinegroupid
    WHERE   
        f.regardingobjectid = '[specific_flow_id]' -- Replace with the 
actual flow ID
    GROUP BY   
        f.machineid, fm.name, mg.managementtype, mg.maxmanagedmachinecount, 
fm.lastheartbeatdate, fm.sessioncapacity, fm.overcapacitysince  
    ORDER BY   
        capacity_status DESC, fm.lastheartbeatdate DESC;  

Governance-related query examples for desktop flows

Find scripts that include plain text passwords in connections
This query finds all desktop flows that use (OLEDB) database connection strings that are
configured to use a plaintext password.

SQL

    SELECT   
        w.name AS 'Desktop flow',  
        w.workflowid AS 'Desktop flow Id',  
        w.createdon AS 'Created on',  
        w.modifiedon AS 'Last modified on',  
        w.definition AS 'Script',  
        w.ownerid AS 'Owner Id',  
        s.fullname AS 'Owner name',  
        s.internalemailaddress AS 'Owner email'  
    FROM   
        workflow w  
    JOIN   
        systemuser s ON w.ownerid = s.systemuserid  
    WHERE   
        w.category = 6  
        AND w.definition IS NOT NULL  
        AND (LOWER(w.definition) LIKE '%;password=%');

Potential SQL injection risk
The query detects desktop flows that contain scripts potentially vulnerable to SQL
injection by searching for the use of database.executesqlstatement.execute  within the
flow definitions. Consider a scenario where, instead of directly writing the SQL code in
the Execute SQL statement action, the script uses a Power Automate desktop input
variable (for example, %LetsDeleteAllGeneralLedgerEntriesFromDB%) provided to the
script during runtime.





SQL

    SELECT   
        w.name AS 'Desktop flow',  
        w.workflowid AS 'Desktop flow Id',  
        w.createdon AS 'Created on',  
        w.modifiedon AS 'Last modified on',  
        w.definition AS 'Script',  
        w.ownerid AS 'Owner Id',  
        s.fullname AS 'Owner name',  
        s.internalemailaddress AS 'Owner email'  
    FROM   
        workflow w  
    JOIN   
        systemuser s ON w.ownerid = s.systemuserid  
    WHERE   
        w.category = 6  
        AND w.definition IS NOT NULL  
        AND LOWER(w.definition) LIKE 
'%database.executesqlstatement.execute%';
    



Advance API request usage
This query retrieves desktop flows that utilize advanced API request methods, such as
curl , Invoke-RestMethod , and other requests , to identify connectivity to external web
services or services.

SQL

    SELECT   
        w.name AS 'Desktop flow',  
        w.workflowid AS 'Desktop flow Id',  
        w.createdon AS 'Created on',  
        w.modifiedon AS 'Last modified on',  
        w.definition AS 'Script',  
        w.ownerid AS 'Owner Id',  
        s.fullname AS 'Owner name',  
        s.internalemailaddress AS 'Owner email'  
    FROM   
        workflow w  
    JOIN   
        systemuser s ON w.ownerid = s.systemuserid  
    WHERE   
        w.category = 6  
        AND w.definition IS NOT NULL  
        AND (
            LOWER(w.definition) LIKE '%curl%' OR 
            LOWER(w.definition) LIKE '%invoke-restmethod%' OR 
            LOWER(w.definition) LIKE '%invoke-webrequest%' OR 
            LOWER(w.definition) LIKE '%httpclient%' OR 
            LOWER(w.definition) LIKE '%requests.get%' OR 
            LOWER(w.definition) LIKE '%requests.post%' OR 
            LOWER(w.definition) LIKE '%fetch%' OR 
            LOWER(w.definition) LIKE '%axios%' OR 
            LOWER(w.definition) LIKE '%.ajax%'
        );
    

Web endpoints and URL shortcuts usage
This query detects desktop flows containing scripts that reference URL shorteners to
assess potential risks of restricted URL usage.

SQL

    SELECT   
        w.name AS 'Desktop flow',  
        w.workflowid AS 'Desktop flow Id',  
        w.createdon AS 'Created on',  
        w.modifiedon AS 'Last modified on',  
        w.definition AS 'Script',  



        w.ownerid AS 'Owner Id',  
        s.fullname AS 'Owner name',  
        s.internalemailaddress AS 'Owner email'  
    FROM   
        workflow w  
    JOIN   
        systemuser s ON w.ownerid = s.systemuserid  
    WHERE   
        w.category = 6  
        AND w.definition IS NOT NULL  
        AND (
            LOWER(w.definition) LIKE '%bit.ly%' OR 
            LOWER(w.definition) LIKE '%linkedin.com%' OR 
            LOWER(w.definition) LIKE '%aka.ms%' OR 
            LOWER(w.definition) LIKE '%tinyurl.com%' OR 
            LOWER(w.definition) LIKE '%goo.gl%' OR 
            LOWER(w.definition) LIKE '%t.co%' OR 
            LOWER(w.definition) LIKE '%fb.me%' OR 
            LOWER(w.definition) LIKE '%is.gd%' OR 
            LOWER(w.definition) LIKE '%buff.ly%'
        );
    

Missing error handling in scripts
This query searches for desktop flows that lack any error handling mechanisms, such as
on block error  or on error , to ensure robustness and reliability in script execution.

SQL

    SELECT   
        w.name AS 'Desktop flow',  
        w.workflowid AS 'Desktop flow Id',  
        w.createdon AS 'Created on',  
        w.modifiedon AS 'Last modified on',  
        w.definition AS 'Script',  
        w.ownerid AS 'Owner Id',  
        s.fullname AS 'Owner name',  
        s.internalemailaddress AS 'Owner email'  
    FROM   
        workflow w  
    JOIN   
        systemuser s ON w.ownerid = s.systemuserid  
    WHERE   
        w.category = 6  
        AND w.definition IS NOT NULL  
        AND NOT (LOWER(w.definition) LIKE '%on block error%' OR 
LOWER(w.definition) LIKE '%on error%');
    



Governance-related query examples for V2 action logs

７ Note

Before you continue with this section, ensure that Desktop Flow Logs V2 has been
enabled in your environment and that you have existing desktop flow runs.

Desktop flow runs with restricted URL access
This query finds web service invocations (Invoke Web Service action) within a specific
desktop flow over the past three weeks. This result is useful for identifying and analyzing
potentially suspicious endpoints or restricted API calls.

SQL

    SELECT   
        JSON_VALUE(f.data, '$.name') AS ActionName,  
        f.data AS 'Action log',  
        f.parentobjectid AS 'Parent object id',  
        f.createdon AS 'Log created on',
        w.name AS 'Desktop flow',  
        w.workflowid AS 'Desktop flow Id',  
        w.createdon AS 'Created on',  
        w.modifiedon AS 'Last modified on',  
        w.definition AS 'Script',  
        w.ownerid AS 'Owner Id',  
        s.fullname AS 'Owner name',  
        s.internalemailaddress AS 'Owner email'  
    FROM  
        [flowlog] f  
    JOIN  flowsession fs ON f.parentobjectid = fs.flowsessionid         
    JOIN  workflow w ON fs.regardingobjectid = w.workflowid  
    JOIN  systemuser s ON w.ownerid = s.systemuserid  
    WHERE   
        w.workflowid = '[specific_flow_id]' -- Replace with the actual flow 
ID
        AND f.createdon >= DATEADD(day, -21, GETDATE())
        AND JSON_VALUE(f.data, '$.name') = 'Invoke web service'  
        AND (  
            f.data LIKE '%contoso-default.crm.dynamics.com/api%'  
            OR f.data LIKE '%api.second-restricted-url.net%'  
            OR f.data LIKE '%api.third-restricted-url.de%'  
            OR f.data LIKE '%api.phishing-example.com%'  
        );

Desktop flow runs with cryptographic code



This query scans desktop flow runs for PowerShell script actions that included
cryptographic code over the past seven days.

SQL

    -- Queries actions logs named 'Run PowerShell script' that contain code 
that that uses cryptographic libraries 
    -- and terms such as "AES", "RSA", "encryption", or "decryption," which 
may indicate risky operations
    SELECT top(1)
        JSON_VALUE(data, '$.name') AS ActionName,
        JSON_VALUE(data, '$.inputs') AS Inputs,
        JSON_VALUE(data, '$.outputs') AS Outputs
    FROM 
        [flowlog]
    WHERE
        JSON_VALUE(data, '$.name') = 'Run PowerShell script'
        AND createdon >= DATEADD(day, -7, GETDATE())
        AND (
            JSON_VALUE(data, '$.inputs') LIKE '%AES%'
            OR JSON_VALUE(data, '$.inputs') LIKE '%RSA%'
            OR JSON_VALUE(data, '$.inputs') LIKE '%encryption%'
            OR JSON_VALUE(data, '$.inputs') LIKE '%decryption%'
        )
    ORDER BY
        ActionName
    

Desktop flow runs with pro-code usage
This query is a bit more advanced. It identifies and counts distinct desktop flow runs
(Flow Sessions) with pro-coding parts (such as VBScript, PowerShell, JavaScript, .NET, or
Python) from the last seven days, and groups the results by desktop flow.

SQL

WITH ProCodingSessions AS (  
    SELECT   
        fs.flowsessionid,  
        f.data AS 'Action log',  
        f.parentobjectid AS 'Parent object id',  
        f.createdon AS 'Log created on',  
        w.name AS 'Desktop flow',  
        w.workflowid AS 'Desktop flow Id',  
        w.createdon AS 'Created on',  
        w.modifiedon AS 'Last modified on',  
        w.definition AS 'Script',  
        w.ownerid AS 'Owner Id',  
        s.fullname AS 'Owner name',  
        s.internalemailaddress AS 'Owner email'  



    FROM [flowlog] f  
    JOIN flowsession fs ON f.parentobjectid = fs.flowsessionid  
    JOIN workflow w ON fs.regardingobjectid = w.workflowid  
    JOIN systemuser s ON w.ownerid = s.systemuserid  
    WHERE f.createdon >= DATEADD(day, -7, GETDATE())  
    AND (  
        LOWER(w.definition) LIKE '%runvbscript%' OR  
        LOWER(w.definition) LIKE '%runpowershellscript%' OR  
        LOWER(w.definition) LIKE '%runjavascript%' OR  
        LOWER(w.definition) LIKE '%rundotnetscript%' OR  
        LOWER(w.definition) LIKE '%runpythonscript%'  
    )  
),  
FlowCounts AS (  
    SELECT  
        p.[Desktop flow],  
        p.[Desktop flow Id],  
        p.[Created on],  
        p.[Last modified on],  
        p.[Script],  
        p.[Owner Id],  
        p.[Owner name],  
        p.[Owner email],  
        COUNT(DISTINCT p.flowsessionid) AS ProCodingSessionCount  
    FROM ProCodingSessions p  
    GROUP BY  
        p.[Desktop flow],  
        p.[Desktop flow Id],  
        p.[Created on],  
        p.[Last modified on],  
        p.[Script],  
        p.[Owner Id],  
        p.[Owner name],  
        p.[Owner email]  
)  
SELECT  
    f.[Desktop flow],  
    f.[Desktop flow Id],  
    f.[Created on],  
    f.[Last modified on],  
    f.[Script],  
    f.[Owner Id],  
    f.[Owner name],  
    f.[Owner email],  
    f.ProCodingSessionCount AS 'Runs with pro-code' 
FROM FlowCounts f  
ORDER BY f.ProCodingSessionCount DESC;  

Error and perfromance-related queries for V2 action logs



Top 10 failing desktop flow actions
This query returns the top 10 failing actions by number of errors over the past seven
days.

SQL

    SELECT TOP(10)   
        JSON_VALUE(data, '$.name') AS ActionName,  
        SUM(CASE WHEN JSON_VALUE(data, '$.status') = 'Failed' THEN 1 ELSE 0 
END) AS ErrorCount  
    FROM [flowlog]  
    WHERE createdon >= DATEADD(day, -7, GETDATE())  
    GROUP BY JSON_VALUE(data, '$.name')  
    HAVING SUM(CASE WHEN JSON_VALUE(data, '$.status') = 'Failed' THEN 1 ELSE 
0 END) > 0  
    ORDER BY ErrorCount DESC;  

Top 10 error codes with count
SQL

    SELECT TOP(10)  
        JSON_VALUE(data, '$.errorCode') AS ErrorCode,  
        COUNT(*) AS OccurrenceCount  
    FROM [flowlog]  
    WHERE createdon >= DATEADD(day, -7, GETDATE())  
      AND JSON_VALUE(data, '$.status') = 'Failed'  
    GROUP BY JSON_VALUE(data, '$.errorCode')  
    ORDER BY OccurrenceCount DESC;  
    

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Capacity utilization within Power
Automate
Article • 02/08/2025

The capacity utilization page provides you with insights into how your Hosted Process
capacity capacity, Process capacity, or legacy Unattended RPA capacity are being used
within your environment. Within the Power Automate platform, each capacity is based
on a purchased add-on or license. It's assigned to the environment and allows specific
Power Automate objects to carry out specific operations.

You manage the following capacity within the capacity utilization page:

ﾉ Expand table

Capacity Consuming Consumption Operation enabled
Power mode
Automate
object

Hosted Process Hosted Autoallocation To be created, each hosted machine
capacity machine requires a Hosted Process capacity

allocated.

Hosted Process Hosted Manual Every Hosted Process capacity
capacity machine group allocation of committed to a hosted machine group

committed bots guarantees the availability of a bot
during autoscaling.

Process capacity Machine Autoallocation Every capacity allocated to a machine
(or legacy allows it to carry out another
unattended RPA unattended desktop flow run
capacity) simultaneously.

Process capacity Cloud flow Manual Every capacity allocated to a cloud flow
allocation enables it, along with all its associated

cloud flows, to use premium connectors
and execute actions up to a daily limit of
250k Power Platform Requests
(stackable limit).

７ Note

We combined Process capacity and Unattended RPA capacity (legacy) into a single
pool. Machines can seamlessly use them.



Capacity utilization overview page
The capacity utilization page offers an overview of the environment-assigned capacities.
It details their usage and provides suggestions and insights for more efficient
management of automation and the desktop infrastructure.

The overview page provides insights for Hosted Process capacity, Process capacity, or
legacy Unattended RPA capacity including:

A breakdown of each capacity utilization (user's consumption / others'
consumption / capacity available / capacity in overage).
Insights and recommendation on compliance issues.

The two pie charts underscore the point that, within a given environment, capacity is a
limited resource that users are sharing, necessitating prioritization of use cases.

Per-capacity details pages

Hosted Process capacity utilization
Hosted Process capacity allows you to run desktop flows with zero infrastructure. It's
allocated to hosted machines or committed to hosted machine groups.

Process (or legacy unattended RPA) capacity utilization
Process capacity or legacy Unattended RPA capacity are needed to run desktop flows in
unattended mode. Every capacity allocated to a machine allows it to carry out another
unattended desktop flow run simultaneously. It can also be allocated to a cloud flow to
license it independently from user license.



Related information
Process and Unattended RPA capacity utilization

Hosted Process capacity utilization

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Hosted Process capacity utilization
Article • 02/05/2025

The Hosted Process capacity utilization page provides insight into how your Hosted
Process (previously Power Automate Hosted RPA add-on) capacity is being used within
your environment. As a reminder, within the Power Automate platform, each Hosted
Process capacity is based on a purchased Hosted Process license. It's assigned to the
environment and allows you to run desktop flows with zero infrastructure.

A Hosted Process capacity can be allocated to a hosted machine or committed to a
hosted machine group.

ﾉ Expand table

Consuming Description Consumption mode
object

Hosted To be created, each hosted machine requires a Hosted Hosted Process capacity
machine Process capacity allocated. is autoallocated to

hosted machine at its
creation.

Hosted Every Hosted Process capacity committed to a hosted Manual allocation of
machine machine group guarantees the availability of a bot committed bots on
group during autoscaling (= committed bot). The hosted machine group.

commitment ensures that the necessary resources are
always available for processing the desktop flows.

７ Note

A hosted machine group with a commitment has a priority of usage on its
committed bots over all concurrent hosted machine groups. More information:
Load balance hosted machine groups.

Hosted Process capacity overview
The Hosted Process capacity overview pie chart helps you understand what's your
share of the hosted capacity consumption within the environment compared to other
makers. It lets you know if there's still capacity to scale-up in the future and alerts you
when your objects are exceeding environment capacity.



ﾉ Expand table

- Legend Description

Allocated to my Compliant capacity allocated to hosted machines, which the user
hosted machines owns or which are shared with them.

Committed to my Compliant capacity committed to hosted machine groups, which
hosted machine the user owns or which are shared with them.
groups

Utilized by other Compliant capacity allocated or committed to objects, which the
makers user doesn't own and which weren't shared with them.

Available capacity Available capacity for new hosted machines or new committed
bots on hosted machine groups.

My overage utilization Sum of capacities over-allocated to hosted machines and over-
committed to hosted machine groups, which the user owns or
which are shared with them.

Overage by other Sum of capacities over-allocated and over-committed to objects,
makers which the user doesn't own and which weren't shared with them.

Hosted Process capacity insights
The 'Hosted capacity insights' card informs you of operation health and provides you
with recommendations if there are compliance issues.



ﾉ Expand table

Badge Message Insight

Sufficient There's available capacity for new hosted Scale-up is possible in the future.
capacity machines or new committed bots on

hosted machine groups.

Fully There's no more capacity for new hosted The capacity utilization rate is optimal
utilized machines or new committed bots on at 100% but there's no room for

hosted machine groups. scaling-up.

Capacity User has over-allocated capacity to their Uncompliant capacity usage exceeding
overage hosted machines or/and over-committed environment capacity.

bots to their hosted machine groups.

Sufficient There's a nonempty pool of capacity All hosted machine groups
pool shared by all hosted machine groups. theoretically have access to at least

one bot.

Empty pool The capacity pool shared by all hosted Hosted machine groups can't spin-up
machine groups is empty. bots when needed. All automations

based on them are going to fail.

７ Note

All hosted machine groups share a pool of hosted capacity made of the
available capacity and the compliant committed capacity within the
environment (which value can be retrieved on the overview pie chart).
For example, one available capacity (non-allocated to a hosted machine and
non-committed to a hosted machine group) is pooled between all the hosted
machine groups with a first arrived first served behavior.



Having a non-empty pool isn't always a guarantee of good health depending
on the number of hosted machine groups relying on the pool, the intensity of
runs they perform, and their relative schedule.

Hosted Process utilization details
In this section, you learn how to oversee and manage all hosted machines and hosted
machine groups you have access to (as owner or through sharing).

Hosted machines

７ Note

Every hosted machine gets auto-allocated one hosted capacity at creation
except for hosted machines based on trial user license and hosted machines
provisioned with an error.
Hosted machines can be, when necessary (in case of overage), prioritized
based on their attended and unattended runs.

Hosted machine groups

７ Note

The Active bots column refers to machines currently spin-up and consuming
hosted capacity from the shared pool.



Hosted machine groups can be, when necessary in case of overage, prioritized
based on their unattended runs.

Hosted Process capacity overage
Capacity overage in an environment occurs when the capacity utilized by hosted
machines and hosted machine groups surpasses the assigned capacity of the
environment. In such instances, specific hosted machines and/or hosted machine groups
might be identified as exceeding capacity. To prevent disruption, it's crucial to promptly
rectify the situation.

Hosted machine in overage
Hosted machines identified in overage risk being turned-off after a grace period.

Hosted machine group in overage
Hosted machine groups don't honor their over-committed bots expected behavior.



７ Note

A hosted machine group can have a subset of its committed bots identified as in
overage (= over-committed), in that case, only the compliant committed bots are
honored.

How to fix hosted capacity overage?
When you own some hosted machines or hosted machine groups in overage, or when
the hosted pool is empty, the Fix capacity button appears in the Hosted capacity
insights card:

ﾉ Expand table

Fix capacity - Button

It provides a list of corrective actions:

ﾉ Expand table



Fix capacity - Corrective actions

The Request capacity action submits a request to the tenant administrator for
assignation of capacity to the environment:

ﾉ Expand table



Fix capacity - Request capacity

７ Note

The preset value in the request capacity modal dialog is equal to the total
overage value in the environment (the user's overage and the other users'
overage).
This preset value ensures that when the additional capacity is assigned to the
environment, the user who made the request have their hosted machines or
hosted machine groups returned back to compliance.
If the user submits a smaller request, when the additional requested capacity
is provisioned to the environment, there’s no guarantee that their own hosted
machines or hosted machine groups will return to compliance. The extra
capacity might be allocated to other in-overage hosted machines / hosted
machine groups owned by different users.

What are the rules governing which objects are identified
as in overage?



When the total Hosted Process capacity assigned to an environment is inferior to the
combined capacity allocated to hosted machines and committed to hosted machine
groups:

First, the overage is identified on the committed capacity of hosted machine
groups, starting from the most recently created committed bot setting to the
oldest.
Second, the overage is identified on the allocated capacity of hosted machines,
starting from the most recently created machine to the oldest.

Permissions required to view and edit capacity
allocation
To view and edit capacity allocation, you need a security role with privileges to the Flow
Capacity Assignment table. For example, the Environment Maker role can view and edit
allocation of hosted capacity.

Using Hosted Process capacity as process
capacity
The Hosted Process capacity can be used as process capacity to enable standard
machines to run desktop flows in unattended mode. In an environment with Hosted
Process capacity, this Hosted Process capability enables the creation of overage process
capacity allocation to machines and/or cloud flows. These in-overage machine or cloud
flows operate as efficiently as any other process, without any performance issues. This
mechanism is temporary and will be replaced by a more explicit behavior.

Related information
Capacity utilization within Power Automate



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Process and Unattended RPA capacity
utilization
Article • 02/08/2025

The Process and Unattended RPA capacity utilization page provides you with insights
into how your Process capacity or legacy Unattended RPA capacity is being used within
your environment. As a reminder, within the Power Automate portal each Process
capacity is based on a purchased Process license and each legacy Unattended RPA
capacity is based on an Unattended RPA add-on. Those capacities are assigned to the
environment by the admin.

Process capacity or legacy Unattended RPA capacity can be allocated to a machine or to
a cloud flow. When allocated to a machine, it becomes an unattended bot. Each
unattended bot on a machine can carry one unattended desktop flow run at a time. So if
a machine needs to execute multiple unattended runs simultaneously, it needs as many
unattended bots as it has simultaneous unattended runs to perform. When allocated to
a cloud flow, it becomes a Process plan based on which the cloud flow is licensed to run
premium actions independently from the user license.

ﾉ Expand table

Before Consuming After Description Allocation mode
allocation object allocation

Process Machine Unattended Every unattended bot on a Capacity is auto-
capacity bot machine allows it to carry allocated to the

out an additional machine at unattended
unattended desktop flow desktop flow runtime,
run simultaneously. or the user can

manually allocate it.

Process Cloud flow Process Every Process plan Capacity is manually
capacity plan allocated to a cloud flow allocated to the cloud

allows it to run premium flow by the user.
actions independently
from the user license.

７ Note



Process capacity and Unattended RPA capacity have been combined in a single
capacity pool and can be used interchangeably within the Power Automate
platform. They have exactly the same value and role.

Process & Unattended RPA capacity overview
The Process & Unattended RPA capacity overview pie chart helps you understand the
capacity consumption within the environment, lets you know if there's still capacity to
scale-up in the future, and alerts you when the utilized capacity is exceeding
environment capacity (= overage).

ﾉ Expand table

- Legend Description

Allocated as unattended Compliant capacity allocated to machines, which the user
bots to my machines owns or which are shared with them.

Allocated to my cloud Compliant capacity allocated to cloud flows, which the user
flows owns or which are shared with them.

Utilized by other makers Compliant capacity allocated to objects, which the user
doesn't own and which weren't shared with them.

Available capacity Available capacity for new unattended bots on machines and
new process plan on cloud flows.

My overage utilization Sum of capacities over-allocated to machines or/and to cloud
flows, which the user owns or which are shared with them.

Overage by other makers Sum of capacities over-allocated to objects, which the user
doesn't own and which weren't shared with them.



Process and Unattended RPA capacity insights
The Process and Unattended RPA capacity insights card informs you of operation
health and gives recommendations when there are compliance issues.

ﾉ Expand table

Badge Message Insight

Sufficient There's available capacity for new Scale-up possible in the future.
capacity unattended machines or for new process

plans on cloud flows.

Fully utilized There's no more capacity for new The capacity utilization rate is optimal
unattended bots or for new process plans at 100% but there's no room for
on cloud flows. scaling-up.

Capacity User has over-allocated capacity to their Uncompliant capacity usage
overage machines or/and to their cloud flows. exceeding environment capacity.

Process and Unattended RPA utilization details
In this section, you learn how to oversee and manage all machines you have access to
(as owner or through sharing).



７ Note

By selecting a machine, you can edit its unattended bots setting and its auto-
allocation setting. Machines can be, when necessary (in case of overage), prioritized
based on their unattended runs. Cloud flows using process capacity will be added
to the page in a future release

Capacity overage
Capacity overage in an environment occurs when the capacity utilized by the
unattended bots on machines and the process plans on cloud flows surpasses the
assigned capacity of the environment. In such instances, specific machines and/or cloud
flows might be identified as exceeding capacity. To return to compliance, it's important
to promptly rectify the situation.

７ Note

Process capacity overage is only possible in an environment where some
Process capacity or Unattended RPA capacity has been allocated
Process capacity overage is also possible in an environment where some
Hosted RPA capacity has been allocated

Machine in overage
Machines identified in overage aren't compliant.



７ Note

A machine can have a subset of its unattended bots identified as in overage (=
uncompliant)

How to fix Process and Unattended RPA capacity overage
When some unattended machines are in overage, the Fix capacity button appears in the
Process & Unattended RPA capacity insights card.

The card provides potential corrective actions.

The Request capacity action submits a request to the tenant administrator for the
consideration of assigning capacity to the environment.



７ Note

The preset value in the request capacity modal dialog is equal to the total
overage value in the environment (the user's overage and the other users'
overage).
This preset value ensures that when the additional capacity is assigned to the
environment, the user who made the request have their machines or returned
back to compliance.
If the user submits a smaller request, when the additional requested capacity
is provisioned to the environment, there’s no guarantee that their own
machines will return to compliance. The extra capacity might be allocated to
other in-overage machines owned by different users.

What are the rules governing which objects are identified
as in overage?
When the total Process capacity assigned to an environment is inferior to the combined
capacity allocated to machines and cloud flows: the overage is identified, on machines



and cloud flows indistinctively, starting from the most recently created allocation to the
oldest.

Permissions required to view and edit capacity
allocation
To view and edit capacity allocation, you need a security role with privileges to the Flow
Capacity Assignment table. For example, the Environment Maker role can view and edit
allocation of hosted capacity.

Related information
Capacity utilization within Power Automate

Feedback
Was this page helpful?  Yes  No

Provide product feedback



How to use process capacity
Article • 02/08/2025

７ Note

Process capacity and Unattended RPA capacity have been combined in a single
capacity pool and can be used interchangeably within the Power Automate
platform. They have exactly the same value and role.

Within the Power Automate portal:

Process capacity is based on a purchased Process license.
Legacy Unattended RPA capacity is based on an Unattended RPA add-on.

Process capacity or legacy Unattended RPA capacity can be allocated to a machine or to
a cloud flow.

Allocate Process capacity to a machine
When Process capacity is allocated to a machine, it becomes an unattended bot. Each
unattended bot on a machine can carry one unattended desktop flow run at a time. So if
a machine needs to execute multiple unattended runs simultaneously, it needs as many
unattended bots as it has simultaneous unattended runs to perform.

To allocate Process capacity to a machine, go to the machine details page and select
Settings.



Use the Unattended bots slider to allocate some process capacity to the machine and
save.

You now have a machine that can perform unattended RPA.

７ Note

Machine max bot supported depends on your machine and its OS. The
maximum value this parameter can reach is 10 (for some Windows Servers).
Available capacity in the environment shows how many unattended bots can
still be created. Keep in mind that the process capacity is a shared resources
between all users within an environment and so use only what you need.
Enable auto-allocation lets unattended bots be automatically allocated to a
machine when an unattended run requires it. Multiple unattended bots can be
auto-allocated for simultaneous unattended runs. Once auto-allocated, the
unattended bots remain on the machine until manually deallocated.
For a global overview of how process capacity is used within the environment,
select the Manage capacity utilization link. It also provides an option to
request more capacity.

Allocate process capacity to a cloud flow
When process capacity is allocated to a cloud flow, it becomes a Process plan. This plan
licenses the cloud flow to run premium actions independently from the user license,
with a daily limit of 250,000 Power Platform requests.



To allocate process capacity to a cloud flow, go to the cloud flow details page and select
Edit.

７ Note

At creation, a cloud flow is by default based on the user plan.

Change the plan used by the flow to Process plan and save.

The cloud flow is now independent from the user license.

７ Note

Stacking multiple process capacities on a single cloud flow isn't enabled yet.



Related information
Process capacity utilization

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Power Automate sign-up FAQ
Article • 08/21/2023

This article answers some common questions about how users in your organization can
use Power Automate and how you can control the Power Automate service.

Sign up for Power Automate

What is Power Automate?
Power Automate is a public cloud service that helps you and your teams to set up
automated workflows between your favorite apps and services. Power Automate allows
you to synchronize, get notifications, collect data, and more.

How can I sign up for Power Automate?
1. Open Power Automate .
2. At the upper-right corner of the page, select Try free.
3. Enter your information.

Sign up for Power Automate.

What is the Power Automate free license?
The Power Automate free license is used only for tracking purposes. Enabling or
disabling it has no effect on your ability to create flows. If you disable the Power
Automate free license, it becomes enabled again when you sign in. This behavior is
expected.

Can I block another person from signing up for Power
Automate?
Power Automate is a fully public cloud service. Everyone in the world can sign up and
use it to automate their day-to-day tasks. There isn't a requirement that someone have
or use a Microsoft 365 account to use Power Automate. For that reason, there's no way
to block someone from using it.

If a person signs up for Power Automate who is outside your organization, they can't
incur costs to your company. When an individual signs up for Power Automate, the



relationship is between that individual and Microsoft. Many other cloud services from
Microsoft, such as Bing, OneDrive, and Outlook.com, operate the same way. Your use of
Power Automate doesn't imply that the service is provided by your organization.

A company can restrict the use of organization-only data inside of Power Automate
through data loss prevention (DLP) policies.

How can people gain access to the paid features of Power
Automate?
Individuals can gain access to the paid features of Power Automate in three ways:

1. They can individually sign up for a Power Automate trial license for 90 days at no
cost.

2. You can assign a Power Automate license to them in the Microsoft 365 admin
center .

3. They're assigned a Microsoft 365 and Dynamics 365 plan that includes access to
Power Automate. For the list of Microsoft 365 and Dynamics 365 plans that include
Power Automate capabilities, refer to the Power Automate pricing page .

Can I block another person from using the paid features
of Power Automate?
Any individual can try out the paid features of Power Automate for 90 days without
incurring any costs. You can manage assignment of your organization's perpetual paid
licenses in the Microsoft 365 admin portal.

As with the free offerings, if an individual signs up for the trial, the relationship is
between the individual and Microsoft.

Administrate Power Automate

Why has the Power Automate icon appeared in the
Microsoft 365 app launcher?
Power Automate is a fundamental part of the Microsoft 365 suite. It's enabled as a
service as part of all Microsoft 365 SKUs. Because users everywhere in the world can use
Power Automate, it appears in the app launcher for them.



How do I remove Power Automate from the app launcher
for my organization?
If a user was assigned a Power Automate license, unassign the user's license to remove
the Power Automate icon from the app launcher. This action removes the Power
Automate tile by default. A user may still choose to use Power Automate as an
individual.

1. Sign in to the Microsoft 365 admin center .
2. On the left side panel, select Users > Active Users.
3. Find and select the name of the user for whom you want to remove the license.
4. On the user details pane, select the Licenses and Apps tab.
5. Clear the license for Power Automate.
6. Select Save changes.

You can also use PowerShell to remove licenses in bulk and use PowerShell to disable
access to services.

７ Note

This action removes the Power Automate tile by default. A user might still choose
to use Power Automate as an individual.

Why did 10,000 licenses for Power Automate show up in
my Microsoft 365 tenant?
Any person can try out Power Automate for free. These licenses represent the available
capacity for new Power Automate users in your tenant. There isn't a charge for these
licenses.

If at least one user in your tenant has signed up for a Microsoft Power Automate Free
license, 10,000 licenses (minus any assigned) are available under Billing > Licenses for
your organization.

You can assign more licenses to users in the Microsoft 365 admin portal.

Is this free? Will I be charged for these licenses?
No user can incur any cost to your organization without your express consent. Free and
trial licenses can't cause any charges to your organization.



I removed the Power Automate free license. Why can
users still access it?
The Power Automate free license is included only for tracking purposes. It isn't possible
to prevent another person from using Power Automate for individual purposes.

Why can't I see all Power Automate licenses in the
Microsoft 365 admin portal?
Users can use Power Automate either as individuals or as a part of their organization.
Licenses at the organization level are always visible in the Microsoft 365 admin portal.
However, if a user signs up for a trial as an individual, then their Microsoft 365 admin
doesn't manage the trial and it doesn't show up in the portal.

How does an individual find out what plan they are on?
1. Sign in to Power Automate .
2. At the upper-right corner of the page, select your profile picture.
3. Select View account.
4. Select the Subscriptions tile.
5. Under the Licenses section, search for Power Automate.

Will Power Automate signup affect the identities in my
organization?
If your organization already has a Microsoft 365 environment and all users in your
organization have Microsoft 365 accounts, then identity management isn't affected.

If your organization already has a Microsoft 365 environment, but not all users in your
organization have Microsoft 365 accounts, then we create a user in the tenant. We also
assign licenses based on the user's work or school email address. The number of users
you're managing at any time grows as users in your organization sign up for the service.

If your organization doesn't have a Microsoft 365 environment connected to your email
domain, there's no change in how you manage identity. Users are added to a new,
cloud-only user directory, and you can take over as the tenant admin and manage them.

Power Automate created a tenant. How do I manage it?



First, join the tenant. Then, promote yourself to the admin role, if it hasn't already been
claimed, by verifying domain ownership.

1. Sign up for Power Automate using an email address domain that matches the
tenant domain you want to manage.

For example, if Microsoft created the contoso.com tenant, then join the tenant with
an email address that ends with @contoso.com.

2. Go to https://admin.microsoft.com .

3. Select the app launcher icon in the upper-left corner of the page, and then select
Admin.

4. Read the instructions on the Become the admin page, and then select Yes, I want
to be the admin.

If this option doesn't appear, a Microsoft 365 administrator is already in place.

> [!TIP]
> If this option doesn’t appear, an Office 365 administrator is already 
in place.

If I have multiple domains, can I control the Microsoft
365 tenant that users are added to?
If you do nothing, a tenant is created for each user email domain and subdomain.

If you want all users to be in the same tenant regardless of their email domain, create a
target tenant ahead of time or use an existing tenant. Add all the existing domains and
subdomains that you want consolidated in that tenant. Then all the users with email
addresses ending in those domains and subdomains automatically join the target tenant
when they sign up.

） Important

There isn't a supported automated way to move users across tenants. Learn about
adding users and domains to Microsoft 365 .



How can I restrict my users' ability to access my
organization's business data?
Power Automate allows you to create data zones for business and nonbusiness data, as
shown in the following screenshot. After you implement these data loss prevention
policies, users can't design or run Power Automate flows that combine business and
nonbusiness data.

There isn't a supported automated way to move users across tenants. To learn about
adding domains to a single Office 365 tenant, go to Add your users and domain to
Office 365 .

Manage Power Automate RPA licenses

How can I apply unattended RPA licenses to my flow?
1. The tenant admin must purchase or get a trial version of the unattended RPA add-

on capacity for the tenant in the Microsoft 365 admin portal .

2. The environment admin must assign the available paid or trial unattended add-on
capacities to a specific environment.



3. Makers can now run unattended desktop flows in the environment that has the
unattended capacity.

The unattended add-on is environment-specific. If you have multiple environments that
need to run unattended RPA, you need to assign add-on capacity to each of them.

Also, if you need to run multiple unattended desktop flows in parallel in a single
environment, you need to assign the right number of unattended add-ons to the
environment to support the flow runs.

1. The tenant admin must purchase or get trial a version of the Power Automate
Process plan (previously Power Automate Unattended RPA add-on) capacity for
the tenant. The tenant admin can do this from the Microsoft 365 admin portal .
Just search the purchase services page for the license.

2. The environment admin must assign the available (paid or trial) capacities to a
specific environment.



3. Makers can now run unattended desktop flows within the environment that has
the Process license assigned.

７ Note

The Process license is environment-specific. So, if you have multiple environments
that need to run unattended RPA, you need to assign licenes to each of them. You
need to assign one Process license per machine that is used for unattended
desktop flows. If you need to run multiple unattended desktop flows in parallel on
a machine, you will also need to assign one Process license for each additional
Desktop Flow you want to run concurrently on the machine.

What are the prerequisites for using RPA?
You must have an environment that has Microsoft Dataverse enabled.
You must have a work or school account. You can't start a trial with a personal
account.
The admin needs a paid or trial attended plan or a per-flow plan to start an
unattended trial.

How can I check which license I'm using?
Press Ctrl+Alt+A in Power Automate to check your license status. There isn't a way to
check license status in the user interface. The admin needs a paid or trial Power
Automate Premium (previously Power Automate per user with attended RPA) or a Power
Automate Process plan (previously Power Automate per flow) before they can turn on to
start an unattended trial.



Can trials be disabled for a tenant?
Tenant admins can use PowerShell to disable all trial activations for a tenant.

How can I start an unattended trial?
1. Select Purchase services in the Microsoft 365 admin center, and then search for

Power Automate Process.

2. Select Power Automate unattended RPA add-on Trial.

3. Select Get free trial.

Assign unattended RPA add-on capacity to an
environment
Only admins can assign unattended trial capacity. Assign add-on capacity to each
environment that needs to run RPA unattended. Make sure you assign enough capacity
if you intend to run desktop flows in parallel.

1. Get the add-on.

2. Sign in to the Power Platform admin center .

3. Select Power Automate Process plan

4. Select Get free trial.

Assign Power Automate Process plan (previously Power
Automate process flow) capacity to an environment
Before you can assign capacity, such as trial licenses, you must get the Process licences.

1. Go to the Power Platform admin center .

2. Select Resources > Capacity > Manage.



3. Select the environment to which you want to assign the Power Automate Process
licenses, assign the capacity, and then select Save.

７ Note



You'll need to assign capacity to each environment that needs to run
unattended RPA.
You'll need to ensure you assign enough capacity if you'll run desktop flows in
parallel.
Only admins can assign the capacity.



Enable experimental features in Power
Automate
Article • 07/26/2024

Experimental features provide you early access to functionalities and updates in Power
Automate before they're available worldwide.

Ｕ Caution

Experimental features might change, break, or disappear at any time, and
shouldn't be enabled in production environments.
Microsoft doesn't provide support for experimental features. Microsoft Power
Platform technical support team won’t be able to help you with issues or
questions. Use the Power Automate community forums  for feedback and
help with experimental features.

Follow these steps to enable experimental features in Power Automate.

1. Sign in to Power Automate .

2. Select your environment from the top-right corner.

3. Select Settings (gear icon) > View all Power Automate settings.

4. Set Experimental Features to On, and then select Save.



You will now be able to access all experimental features in Power Automate.

７ Note

Experimental features are available only for the account that turns on experimental
features.

Related information
New expression editor for actions (experimental feature)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Billing and metering questions
Article • 08/01/2023

This article answers frequently asked questions regarding billing and metering in Power
Automate.

Where can I find out what pricing plans are
available?
See the pricing page .

Where can I find out what my plan is?
See this subscription page .

How do I switch plans?
1. Sign in to Power Automate .
2. On the top right of the screen, select ? > Pricing, and then select the plan to which

you want to switch.

What happens if my usage exceeds the limits?
Power Automate throttles your flow runs.

Where can I find more information regarding
the usage limits?

On the pricing page .
On the limits and config page.

What happens if I try to run flows too
frequently?
Your plan determines how often your flows run. For example, your flows may run every
15 minutes if you're on the free plan. If a cloud flow is triggered less than 15 minutes



after its last run, it's queued until 15 minutes elapses.

What counts as a run?
Whenever a cloud flow is triggered, whether by an automatic trigger or manually, this is
considered a run. Checks for new data don't count as runs.

Are there differences between Microsoft
Accounts and work or school accounts for
billing?
Yes. If you sign in with a Microsoft Account (such as an account that ends with
@outlook.com or @gmail.com), you can use only the free plan. To take advantage of the
features in the paid plan, sign in with a work or school email address.

I'm trying to upgrade, but I'm told my account
isn't eligible
To upgrade, use a work or school account, or create a Microsoft 365 trial account .

Why did I run out of runs when my flow only
ran a few times?
Certain flows may run more frequently than you expect. For example, you might create a
cloud flow that sends you a push notification whenever your manager sends you an
email. That flow must run every time you get an email (from anyone) because the flow
must check whether the email came from your manager. This action counts as a run.

You can work around this issue by putting all the filtering you need into the trigger. In
the push notification example, expand the Advanced Options menu, and then provide
your manager's email address in the From field.

Other limits and caveats
Each account may have as many as:

15 custom connectors.
20 connections per API and 100 connections total.



Certain external connectors, such as Twitter, implement connection throttling to
control quality of service. Your flows fail when throttling is in effect. If your flows
are failing, review the details of the run that failed in the flow's run history.

Licenses that can submit support tickets in
Power Automate
If you have one of the following licenses, you can submit a support ticket in Power
Automate

Power Automate Process plan (previously Power Automate per flow)
Power Automate Premium plan (previously Power Automate per user and Power
Automate per user with attended RPA)
PowerApps per user plan
Dynamics Enterprise plan
Dynamics Professional plan



Types of Power Automate licenses
Article • 12/13/2024

７ Note

The new and improved Power Platform admin center is now in public preview! We
designed the new admin center to be easier to use, with task-oriented navigation that
helps you achieve specific outcomes faster. We'll be publishing new and updated
documentation as the new Power Platform admin center moves to general availability.

Power Automate supports both user and capacity licensing. With a Power Automate Premium
user license, users gain the full set of capabilities for cloud and desktop automation including
premium connectors, process and task mining, AI Builder, use of Managed Environments, and
Microsoft Dataverse storage.

For additional capacity, running desktop flows unattended, or licensing flows on their own
without use licenses, subscribe to Power Automate Process licenses or enable pay-as-you-go.
To extend further, additional add-ons are available for hosted machines, RPA unattended bots
expanding Dataverse storage, AI credits, and other resources.

Other licenses across Microsoft 365, Dynamics 365, and the Power Platform include a limited
set of Power Automate capabilities. Learn more about what's included in each license in
Microsoft Power Platform Licensing Guide .

ﾉ Expand table

License License scope Description
type

User User-centric: a user license is assigned to a user. It entitles the user to access specific
license capabilities.

Capacity Automation-centric: a capacity license is allocated It provides the automation
license to a Power Automate automation (cloud flow, entitlements (the same way a user

machine, hosted machine, hosted machine group). license provides entitlements to a
user).



You can subscribe to Power Automate licenses on Power Automate pricing . If you're an
administrator, you can also purchase licenses from the Microsoft 365 admin center.

User licenses

In addition to Power Automate Premium or use rights from other licenses , users can be
licensed with Power Automate trial license to try out premium capabilities. They can also use
the Free license to create cloud flows with standard connectors.

Power Automate Premium license

Power Automate Premium

ﾉ Expand table

License Power Automate Premium
name

License type User license (paid)

Entitlements We recommend the Power Automate Premium license for all users, as it gives them
the full set of capabilities to create both API based and desktop automations.

This license allows users to create, run, and share unlimited cloud flows (within Power
Platform requests (PPR) limits for API-based automation (with standard, premium,
and custom connectors) and to automate their legacy applications simulating a
human behavior such as keyboard or mouse keys and movement (with desktop
flows through robotic process automation (RPA).

More precisely regarding the premium RPA entitlements, this license includes the
ability for users to register their workstation, to create unlimited desktop flows, and
to execute their desktop flows in attended mode on their registered machine
through an attended bot borne by the license.

Additionally, this license also includes full access to process mining capabilities and
the provisioning of AI Builder credits, which support AI consuming scenarios like
form processing, object detection, text classification, and more.



Capacity licenses

In addition to user licenses, organizations can upgrade their automation scenarios with
capacity licenses, which are allocated to Power Automate automations (cloud flows, machines,
hosted machines, hosted machine groups) and provide these automations autonomous
entitlements (regardless of the user license owned by persons interacting with those
automations).

Power Automate Process license

Power Automate Process

ﾉ Expand table

License name Power Automate Process

License type Capacity license (paid)

Allocated - Cloud flow
automation - Standard machine

Entitlements When assigned to a cloud flow, a Power Automate Process license entitles it to
better performance, and allows use of premium and custom connectors regardless
of the owning or triggering user's license. Flows must be in a solution for a Process
license to be assigned.

Allocated to a machine, a Process license becomes an unattended bot that can run
one desktop flow at a time. Up to one cloud flow will automatically inherit the
Process plan from the the related machine or machine group that has Process
capacity assigned. To run multiple unattended desktop flows in parallel, purchase
Process licenses for the maximum number of runs that are needed to execute in
parallel, and allocate Process capacity to the related machines.

To trigger attended or attended desktop flow runs from cloud flows that are
operating under the Process license, the user whose connection is being used to
run the desktop flow needs a Power Automate Premium license (or other user
license with desktop flows entitlement).

Each Process license includes up to 250,000 Power Platform Requests per 24 hours.



License name Power Automate Process

For requests above this, support for stacking capacity from multiple Process
licenses is coming soon. To ensure you purchase sufficient capacity for the flow to
operate, we recommended purchasing Process licenses up to the maximum
requests per 24 hours you anticipate from the process.

Will benefit Organizations looking to automate their business processes at scale using cloud
flows or unattended desktop automations, or maintain a flow without each co-
owner needing a user license.

Learn more about the Power Automate Process license.

） Important

Can my organization only purchase and use capacity licenses within an environment?

Capacity licenses aren't meant to replace user licenses in an environment, as some
essential capabilities are only available to licensed users, including creating and running
automations running desktop flows attended or unattended. create automations. Capacity
licenses can grant higher Power Platform requests (PPR) to such flows built using the
premium user licenses.

Allocation of a Process license to a machine (required by the unattended mode) still
prerequires the machine to have been registered by a Power Automate Premium user.

Multiple monitoring pages in the Power Automate portal (for example, workqueue page,
machine list page, desktop flow list page, and more) are displayed only to Power
Automate Premium users.

Compare Power Automate licenses
The following table details each license entitlement:

ﾉ Expand table

Premium license Process license Hosted Process license

Applied to User - Cloud flow - Hosted machine
- Machine - Hosted machine group

- Cloud flow
- Machine

Capacity Limits



Premium license Process license Hosted Process license

Daily PPR limit1 40k per user 250k per Process 250k per Hosted Process
license2 license3

Process mining data 50 MB per license4 Not included Not included
storage

AI Builder credits 5000 per month 5000 per month 5000 per month

Dataverse database 250 MB per license 50 MB per license 50 MB per license
storage

Dataverse file storage 2 GB per license 200 MB per license 200 MB per license

Connectors

Standard connectors Included Included Included

Premium connectors Included Included Included

Custom connectors Included Included Included

Desktop Automation

Attended RPA One attended bot Not included Not included
included

Unattended RPA Not included One unattended bot One unattended bot
included included3

Hosted RPA Not included Not included One hosted bot included

Other

Process mining Included Not included Not included

Business process flows Included Included Included

On-premises gateways Included Included Included

1 The Power Platform requests are subjected to higher limits during the transition period. Learn
more in Request limits in Power Automate.

2 When multiple units of Process licenses are allocated to a cloud flow, their PPR limits are
stacked.

3 As the Hosted Process license is a superset of the Process license, each hosted bot can also
appear as an unattended bot, which allows to run in unattended mode on the hosted machine
/ hosted machine group.



4 Up to 100 GB per tenant.

License entitlements
Power Automate licenses include entitlements to use specific Power Automate capabilities. This
section lists the supported entitlements.

Connector types

Entitlements to usage of connector types in cloud flows
A connector represents the underlying service (such as OneDrive, SharePoint, Salesforce,
etc.) with which a cloud flow can interact. It provides a way for a user to connect its cloud
flow to a third-party account (such as a Salesforce account) and use a set of prebuilt
actions and triggers.

ﾉ Expand table

Entitlement to Entitlement description

Standard The standard connectors entitlement is needed to add a standard connector to a
connectors cloud flow and trigger it.

Premium The premium connectors entitlement is needed to add a premium connector to a
connectors cloud flow and trigger it.

Custom The custom connectors entitlement is needed to create a connector with its own
connectors triggers and actions when an app / a service does't have a prebuilt connector.

How can I show my current entitlements?
In the Power Automate portal, select Settings > View my licenses:



７ Note

The user license(s) display in the section My licenses.
The capacity license(s) (and capacity add-ons) display in the section Environment
capacities.
The user entitlement (in context of environment capacities) display in the Capabilities
section with a green check mark.

Seeded licenses
Learn more about Power Automate capabilities included in Seeded licenses.

Legacy licenses
Learn more about Power Automate capabilities included in Legacy licenses.



The admin center
Article • 12/16/2022

The admin center is the central location where tenant admins and environment admins
manage an organization’s data policies and environments. Any changes you make in the
admin center are immediately available to users within the organization.

Here's a quick video about the admin center.
https://www.microsoft.com/en-us/videoplayer/embed/RWKZQe?postJsllMsg=true

７ Note

The Power Automate admin center is retired and Power Automate admins will be
automaticaly redirected to the Microsoft Power Platform admin center  to
manage data policies and environments for Power Automate deployments.

Access the admin center
Browse to https://admin.powerplatform.microsoft.com/ .

Environments
Learn more about using environments in the Microsoft Power Platform admin guide to
manage users, permissions and roles.

Data policies
Learn more about using data policies in the Power Platform admin guide to create rules
that manage how business data is shared between services in flows.

Activity logging
Learn more about the logging activities that Power Automate does to keep you
informed about your users' activities.



Administer environments and Power
Automate resources
Article • 05/27/2023

Administer environments
An environment is a space to store, manage, and share your organization's business
data, apps, and flows. It also serves as a container to separate apps that might have
different roles, security requirements, or target audiences. How you choose to use
environments depends on your organization and the apps you build. For example:

You can choose to only build your apps in a single environment.
You might create
separate environments that group the test and production versions of your apps.

You might create separate environments that correspond to specific teams or
departments in your company, each containing the relevant data and apps for
each audience.

You might also create separate environments for different global branches of your
company.

You can create and manage environments using the Power Platform admin center .

Learn all about environments in the Microsoft Power Platform admin guide.

Tools
There are a number of tools available for administering environments and resources.

Power Platform admin center (PPAC)
The Power Platform admin center, or PPAC, (https://aka.ms/ppac ) provides an
interactive experience for performing administrative tasks within Power Platform.

PowerShell cmdlets
PowerShell cmdlets provide a way to automate administrative tasks using PowerShell.
These cmdlets can be used in a sequence to automate multistep administrative actions.



Power Automate commands provide a way to view and modify environments, flows, and
data related to Power Automate.

Management and Admin connectors
Power Automate Management and Admin connectors provide the ability to use flows to
manage and monitor Power Automate and the rest of Power Platform.

Power Automate Management connector is designed to help with administrative
management and monitoring (Power Automate Management).
Microsoft Flow for Admins allows you to complete typical admin actions, such as
disabling a flow and deleting a flow (Power Automate for Admins).
Power Apps for Admins connector can be used to set permissions on Power Apps
or set permissions to a certain connector being used by this app (Power Apps for
Admins).
PowerApps for App Makers can be used by the makers themselves. Some actions
are an overlay to administrational tasks, such as settings permissions to an app as
mentioned previously (Power Apps for Makers).
Power Platform for Admins can be used to perform tasks against platform
components, such as creating an environment, provisioning a Microsoft Dataverse
database, or creating a DLP policy for a specific environment (Power Platform for
Admins).

COE Starter Kit
The Center of Excellence (COE) Starter Kit provides a template implementation using the
Management and Admin connectors. It comes with a Power BI dashboard that can be
leveraged to gain tenant-wide insights.

Tips and tricks

List Flows as Admin action deprecated in favor of List
Flows as Admin (V2)
The List flows as Admin action on the Power Automate Management connector has
been deprecated in favor of the List Flows as Admin (V2) action. The List Flows as Admin
(V2) action can list all flows in an environment. It has higher performance, since it
returns only the identifying information about the flow. To accomplish this performance
increase, the flow definition and some other metadata aren't returned. If the flow
definition or additional metadata is needed, then a subsequent call can be made to the



Get Flow as Admin action.
This community forum post contains more information,
migration guidance, and a Q&A (question and answer) format: Transition to List Flows as
Admin V2 from deprecated List Flows as Admin action



IP address configuration for Power
Automate
Article • 03/28/2025

This article describes the required configuration for:

Power Automate to connect to services in your network by inbound firewall
configuration, and
Your makers and users to access Power Automate to build and use experiences by
outbound firewall configuration.

Allow flows to call your services
The following two sections list the network configuration required for Power Automate
to connect to services in your network. This configuration is needed only if you're
restricting inbound or outbound IP addresses on your network (for example, through a
firewall).

Allow connector calls to your services
Power Automate flows are comprised of actions. Actions can utilize both connector
actions and native actions such as 'HTTP' and 'HTTP + Swagger'. To enable connector
actions to call services hosted in your network, allow traffic into your network from the
AzureConnectors service tag.

Allowlist 'HTTP' and 'HTTP + Swagger' calls to your
services
For flows consisting of actions including 'HTTP' and 'HTTP + Swagger' actions, allow
traffic from all the following service tags:

ﾉ Expand table

Service tag Required?

LogicApps yes

PowerPlatformPlex yes



Allow users on your network to use Power
Automate
This section contains information on providing your makers and users access to the
build and use experiences within Power Automate.

Use the Power Automate web portal
The Power Automate web portal is also known as the maker portal.

The following table lists the services to which Power Automate connects. Ensure none of
these services is blocked on your network.

ﾉ Expand table

Domains Protocols Uses

login.microsoft.com https Access to authentication and
login.windows.net authorization endpoints.
login.microsoftonline.com
login.live.com
secure.aadcdn.microsoftonline-p.com

graph.microsoft.com https Access to Microsoft Graph for
getting user information such as a
profile photo.

*.azure-apim.net https Access to the Runtime for
connectors.

*.azure-apihub.net https Access to the Runtime for
connectors.

*.blob.core.windows.net https Location of exported flows.



Domains Protocols Uses

*.flow.microsoft.com https Access to the Power Automate site.
*.logic.azure.com

*.powerautomate.com https Access to Power Automate site.

*.powerapps.com https Access to the Power Apps site.

*.azureedge.net https Access to Power Automate CDN.

*.azurefd.net https Access to Power Automate CDN.

*.microsoftcloud.com https Access to NPS (Net Promoter
Score).

webshell.suite.office.com https Access to Office for header and
search. Learn more in Office 365
URLs and ranges.

*.dynamics.com https Access to Dataverse tables.

go.microsoft.com https Access to the Power Automate to
check for updates.

download.microsoft.com https Access to the Power Automate to
check for updates.

login.partner.microsoftonline.cn https Access to the Power Automate for
desktop cloud discovery.

s2s.config.skype.com https Access to preview features
use.config.skype.com managed through flighting and
config.edge.skype.com configuration endpoints.

s2s.config.ecs.infra.gov.teams.microsoft.us https Access to preview features
managed through flighting and
configuration endpoints for US
government cloud.

*.api.powerplatform.com https Access to several Power Platform
*.api.powerplatformusercontent.com APIs.
*.api.bap.microsoft.com

*.api.gov.powerplatform.microsoft.us https Access to several Power Platform
*.gov.api.bap.microsoft.us APIs (U.S. Government - GCC only).

*.api.high.powerplatform.microsoft.us https Access to several Power Platform
*.high.api.bap.microsoft.us APIs (U.S. Government - GCC High

only).



Domains Protocols Uses

*.api.appsplatform.us https Access to several Power Platform
*.api.bap.appsplatform.us APIs (U.S. Government - DoD only).

*.api.powerplatform.partner.microsoftonline.cn https Access to several Power Platform
*.api.bap.partner.microsoftonline.cn APIs (21Vianet - China only).

Allow users on your network to use Power Automate
mobile app
The following table lists additional endpoints you need when using Power Automate
mobile app.

ﾉ Expand table

Domains Protocols Uses

*.events.data.microsoft.com https Send telemetry for all production regions and
supported US sovereign clouds from the mobile app.

collector.azure.cn https Send telemetry for the Mooncake region from the
mobile app.

officeapps.live.com https Access to authentication and authorization endpoints
for the mobile app.

Allow machines & users on your network to access Power
Automate desktop services
The following table lists endpoint data requirements for connectivity from a user's
machine for desktop flows runs. Ensure that you authorize global endpoints and the
endpoints corresponding to your cloud.

Global endpoints for desktop flows runtime

ﾉ Expand table

Domains Protocols Uses

server.events.data.microsoft.com https Handles telemetry for users outside EMEA,
US government, and Chinese clouds. Works
as the fallback telemetry endpoint.



Domains Protocols Uses

msedgedriver.azureedge.net https Access to desktop flows WebDriver
chromedriver.storage.googleapis.com downloaders. WebDriver is used to automate

your browser (Microsoft Edge and Google
Chrome).

Global endpoints for Power Automate for desktop MSI installer

ﾉ Expand table

Domains Protocols Uses

*.builds.dotnet.microsoft.com https Downloads the .NET 8 runtime if it isn't already
installed on the machine.

Public endpoints for desktop flows runtime

ﾉ Expand table

Domains Protocols Uses

ocsp.digicert.com http Access to the CRL server for the public cloud.
ocsp.msocsp.com Needed when connecting through the on-
mscrl.microsoft.com premises data gateway.
crl3.digicert.com
crl4.digicert.com

*.servicebus.windows.net https Listens on Service Bus Relay over TCP.
Needed for machine connectivity.

*.gateway.prod.island.powerapps.com https Needed for machine connectivity.

emea.events.data.microsoft.com https Handles telemetry for EMEA users.

*.api.powerplatform.com https Access to several Power Platform APIs
(mandatory for cloud connectors utilization
in desktop flows).

*.dynamics.com https Access to Dataverse tables (mandatory for
custom actions in desktop flows)(also valid
for GCC).

７ Note



If you don’t want to allow the public endpoint *.servicebus.windows.net, you can
allow the list of namespaces individually. Learn more about namespace endpoints
in Allowlist of namespaces endpoints required for desktop flows runtime.

US Government endpoints for desktop flows runtime

ﾉ Expand table

Domains Protocols Uses

ocsp.digicert.com http Access to the CRL server for US government
crl3.digicert.com cloud.
crl4.digicert.com Needed when connecting through the on-

premises data gateway.

*.servicebus.usgovcloudapi.net https Listens on Service Bus Relay for US
government cloud.
Needed for machine connectivity.

*.gateway.gov.island.powerapps.us https Needed for machine connectivity for US
government cloud (GCC and GCCH).

*.gateway.gov.island.appsplatform.us https Needed for machine connectivity for US
government cloud (DOD).

tb.events.data.microsoft.com https Handles telemetry for US government users.

*.api.gov.powerplatform.microsoft.us https Access to several Power Platform APIs
(mandatory for cloud connector action in
desktop flows) (US Government - GCC only).

*.api.high.powerplatform.microsoft.us https Access to several Power Platform APIs
(mandatory for cloud connector actions in
desktop flows) (US Government - GCC High
only).

*.api.appsplatform.us https Access to several Power Platform APIs
(mandatory for cloud connector actions in
desktop flows) (US Government - DoD only).

*.microsoftdynamics.us https Access to Dataverse tables (mandatory for
custom actions in desktop flows)(US
Government - GCC High only).

*.crm.appsplatform.us https Access to Dataverse tables (mandatory for
custom actions in desktop flows)(US
Government - DoD only).



Domains Protocols Uses

*.dynamics.com https Access to Dataverse tables (mandatory for
custom actions in desktop flows)(also valid
for public clouds).

21Vianet endpoints (China) for desktop flows runtime

ﾉ Expand table

Domains Protocols Uses

crl.digicert.cn http Access to the CRL servers for
ocsp.digicert.cn 21Vianet operated cloud.

Needed when connecting through
the on-premises data gateway.

apac.events.data.microsoft.com https Handles telemetry for users in
China.

*.gateway.mooncake.island.powerapps.cn https Needed for machine connectivity
(21Vianet - China only).

*.api.powerplatform.partner.microsoftonline.cn https Access to several Power Platform
APIs (mandatory for cloud
connector actions in desktop flows)
(21Vianet - China only).

*.dynamics.cn https Access to Dataverse tables
(DesktopFlow modules feature)
(21Vianet - China only).

Other IP address articles

Approval email delivery
Learn more about approvals email routing in Power Automate approval email delivery
information .

Azure SQL database
If you need to authorize IP addresses for your Azure SQL database, use the Power
Platform outbound IP addresses.



FAQ

There are lots of details here—what's the high level
recommendation for IP address configuration?
The simplest mechanism to configure a firewall to allow Power Automate cloud flows to
call external services through connectors is to use Azure service tags. The primary
service tag for Logic Apps connectors is AzureConnectors, as described in Power
Platform outbound IP addresses.

If I'm using Azure firewall, do I need to keep track of
individual IP addresses?
You should use Azure service tags. By using service tags in your network security group
rules, you don't need to constantly monitor and manually update IP ranges for each
service.

If I'm using on-premises firewall, do I need to keep track
of individual IP addresses?
You should use the Service Tags with an on-premises firewall so you don't need to
monitor and manually update IP ranges. The Service Tag Discovery API provides access
to the latest IP address ranges associated with each service tag, enabling you to stay
current with changes.

Related information
Azure service tags
Power Platform URLs and IP address ranges

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Support for customer-managed keys
Article • 01/29/2025

All customer data stored in Power Platform is encrypted at rest using Microsoft-
managed keys (MMKs) by default. With customer-managed keys (CMKs), customers can
bring their own encryption keys to protect Power Automate data. This ability allows
customers to have an extra protective layer to manage their Power Platform assets. With
this feature, you can rotate or swap encryption keys on demand. It also prevents
Microsoft’s access to your customer data, if you choose to revoke key access to
Microsoft services at any time.

With CMKs, your workflows and all associated at-rest data are stored and executed on a
dedicated infrastructure partitioned by the environment. This includes your workflow
definitions, both cloud and desktop flows, and workflow execution history with detailed
inputs and outputs.

Prerequisite considerations before protecting
your flows with CMK
Consider the following scenarios when applying the CMK enterprise policy to your
environment.

When the CMK enterprise policy is applied, cloud flows and their data with CMK
are automatically protected. Some flows might continue to be protected by MMKs.
Admins can identify these flows using PowerShell commands.
Creation and updates of flows are blocked during migration. Run history isn't
carried forward. You can request it through a support ticket up to 30 days after
migration.
Currently, CMKs aren't leveraged to encrypt non-OAuth connections. These non-
Microsoft Entra based connections continue to be encrypted at rest using MMKs.
To enable incoming and outgoing network traffic from CMK protected
infrastructure, update your firewall configuration to ensure your flows continue to
work.
If you plan to protect more than 25 environments in your tenant using CMK, create
a support ticket. The default limit of CMK enabled Power Automate environments
per tenant is 25. This number can be extended by engaging the Support team.

Applying an encryption key is a gesture performed by Power Platform admins and is
invisible to users. Users can create, save, and execute Power Automate workflows exactly
the same way as if MMKs encrypted the data.



The CMK feature enables you to leverage the single enterprise policy created on the
environment to secure Power Automate workflows. Learn more about CMK and the
step-by-step instructions to enable CMKs in Manage your customer-managed
encryption key.

Power Automate hosted robotic process automation
(RPA) (preview)
The hosted machine group capability of the Introduction to the Power Automate hosted
RPA solution supports CMKs. After applying CMKs, you must reprovision existing hosted
machine groups by selecting Reprovision group on the machine group details page.
Once reprovisioned, the VM disks for the hosted machine group bots are encrypted with
the CMK.

７ Note

CMK for the hosted machine capability isn't currently available.

Update firewall configuration
Power Automate allows you to build flows that can make HTTP calls. After you apply
CMK, outbound HTTP actions from Power Automate originate from a different IP range
than before. If the firewall was previously configured to allow flow HTTP actions, it's
likely that the configuration needs to be updated to allow for the new IP range.

If you're using Azure Firewall, apply the service tag PowerPlatformPlex  directly to
the configuration for the correct IP range to be configured automatically. Learn
more in Virtual network service tags.
If you're using a different firewall, look up and enable inbound traffic from the IP
range for PowerPlatformPlex  referenced in the download of Azure IP Ranges and
Service Tags - Public Cloud .

If this isn't in place, you might get the error, Http request failed as there is an error: 'No
connection could be made because the target machine actively refused it.'

Power Automate CMK application warning messages
If certain flows continue to be protected by MMKs post CMK application, warnings
surface in the Policy and Environment Management experiences. A message "Power
Automate flows are still protected with the Microsoft Managed Key" displays.



You can leverage PowerShell commands to identify such flows and protect them with
CMKs.

Protect flows that continue to be protected by
MMK
The following categories of flows continue to be protected by MMK after applying the
Enterprise policy. Follow the instructions to protect the flows by CMK.

ﾉ Expand table

Category Approach to protect with CMK

Power App v1 trigger Option 1 (Recommended)
flows that aren't in a Update the flow to use V2 trigger before applying CMK.
solution

Option 2
Post CMK application, use Save as to create a copy of the flow.
Update calling Power Apps to use the new copy of the flow.

HTTP trigger flows and Post enterprise policy application, use Save as to create a copy of the
Teams trigger flows flow. Update calling system to use the URL of the new flow.

This category of flows isn't automatically protected, as a new flow
URL is created in the CMK protected infrastructure. Customers might
be leveraging the URL in their invoking systems.

Parents of flows that can't If a flow can't be migrated, then dependent flows are also not
be automatically migrated migrated to ensure there’s no business disruption.



Category Approach to protect with CMK

Flows using the List flows Flows referencing this legacy action should either be deleted or
as Admin (v1) connector updated to use the List Flows as Admin (V2) action.
action

PowerShell commands
Admins can leverage PowerShell commands as part of pre-flight and post-flight
validations.

Retrieve flows that can't be automatically protected using
CMK
You can use the following command to identify flows that continue to be protected by
MMK post CMK Enterprise application.

> Get-AdminFlowEncryptedByMicrosoftKey -EnvironmentName <Your Environment Id> -

ListCannotMigrateToCustomerManagedKey

ﾉ Expand table

DisplayName FlowName EnvironmentName

Get Invoice HTTP flow-1 environment-1

Pay Invoice from App flow-2 environment-2

Reconcile Account flow-3 environment-3

Retrieve flows not protected by CMK in a given
environment
You can leverage this command before and after executing the CMK Enterprise policy to
identify all flows in the environment that are protected by MMK. Also, you can leverage
this command to assess the progress of CMK application for flows in a given
environment.

> Get-AdminFlowEncryptedByMicrosoftKey -EnvironmentName <Your Environment Id>

ﾉ Expand table



DisplayName FlowName EnvironmentName

Get Invoice HTTP flow-4 environment-4

Learn more in Manage your customer-managed encryption key.

Get run history from the flow Details page
The run history list on the flow Details page displays new runs only post-CMK
application.

If you want to view input/output data, you can use the run history (All Runs view) to
export flow run history to CSV. This history contains both new and existing flow runs
including all the trigger/action inputs and outputs, with a limit of 100 records. This
limitation is in line with existing behavior for the CSV export.

Get run history by support ticket
We provide a summary view for all runs from both existing and new flow runs post CMK
application. This view contains summary information such as run id, start time, duration,
and fail/successs. It doesn't contain input/output data.

Protect flows in environments that are already
protected by CMK
For environments that are already protected by CMK, protecting flows using CMK can
be requested by a Support Ticket.

Limitation on non-solution cloud flows
triggered by Power Apps
Non-solution cloud flows using the Power Apps trigger and are created in CMK-
protected environments can't be referenced from an app. An error results when
attempting to register the flow from Power Apps. Only solution cloud flows can be
referenced from an app in CMK-protected environments. To avoid this situation, flows
should first be added into a Dataverse solution so they can be successfully referenced.
To prevent this situation, the environment setting to automatically create flows in
Dataverse solutions should be enabled in CMK-protected environments. This setting
ensures new flows are solution cloud flows.



Related information
Manage your customer-managed encryption key

Feedback
Was this page helpful?  Yes  No

Provide product feedback



View desktop flows analytics
Article • 06/20/2024

As an admin, you'll need to view the overall status of automation that runs in your
organization. There are three options to monitor the analytics for automation that's built
with desktop flows:

1. Desktop flow activity (directly in Power Automate)
2. The Power Platform admin center . (Note: Local attended runs aren't available in

the Power Platform admin center. Users and admins can monitor them with
Desktop flow activity at the environment level)

3. The Center of Excellence (CoE) Starter Kit.

Learn more
Analyze the desktop flows risk assessment in your environment.
Run desktop flows.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Monitor desktop flows in the Center of
Excellence
Article • 06/20/2024

For an overview of the desktop flows in your environment, visit the Microsoft Power
Platform Center of Excellence.

Learn more
Analyze the desktop flows risk assessment in your environment.
Run desktop flows.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Machine group certificate renewal for
admins
Article • 12/12/2024

The first Power Automate machine that joins a machine group issues a self-signed
certificate used to:

Encrypt Windows credentials in desktop flow connections.
Identify machines with Power Automate.

This certificate is protected with a password only known to the customer.

What happens during the machine group
certificate renewal?

Machine group certificate renewal starts by default six months before the current
certificate is set to expire and finishes when the current certificate has expired. Machine
group certificate renewal won't affect your machine group's ability to run flows as it is
quick, happens between runs, and supports machines on both the current and the new
certificate during the renewal. During that time:

The first machine from the group that connects with Power Automate will issue a
new password-protected certificate.

The next machines from the group that connect with Power Automate will update
their certificate with the new one. This step can happen even if other machines
(even the first one) are offline.

Machines with the new certificate can still be successfully targeted by desktop flow
connections that encrypt credentials with the current certificate.



Desktop flow connections that target the machine or machine group will be
updated automatically after being used in a cloud flow for a desktop flow run.

How often does certificate renewal happen?
By default, machine group certificates expire once every five years. The renewal happens
during the last six months before the expiry. To see information about how to customize
this behavior, go to How to customize certification expiration and renewal durations?.

What if machines missed the machine group
certificate renewal (offline, outdated Power
Automated for desktop, etc.)?
If at least one machine of the group got updated to the latest certificate, other machines
that missed the renewal period will be able to rejoin the group. First, regenerate the
machine group password on the machine that got updated. Then, on other machines,
open the Power Automate machine runtime app, select re-join, and enter the new
machine group password.

If all the machines of a machine group missed the certificate renewal, you can't use this
machine group. You need to delete it, re-create a new machine group, and join the
machines. To find information about identifying machines that missed the group
certificate renewal, go to How το know if a machine has been updated with a new
certificate or not?.

What if desktop flow connections are unused
during the machine group certificate renewal?
If a desktop flow connection is unused during the machine group certificate renewal,
you get ExpiredDesktopFlowConnection  errors when you try to use it. Fix the connection
by:

Go to the Power Automate portal.
Navigate to Data > Connection.
Find the expired connection, select it, select Edit, and reenter the necessary
information.



What if some machines are expected to remain
offline or unused for multiple months?
You'll need to put those machines online and run flows on them during the certificate
renewal period.

1. Find machines that need to have Power Automate for desktop updated.

Your machines must be equipped with Power Automate version 2.23 or above. You
can verify the version of your machine using the Agent Version column in the Flow
Machine table in Dataverse.

2. Find the renewal period for each machine.

You can determine the renewal period for the machines of a given group by
querying the Key Creation Date and Group Key Expiry Grace Period columns ιn
the Flow Machine Group table in Dataverse. The time frame between the Creation
Data and the Creation Date + Grace Period is when each machine of the group
has to go online and retrieve the latest group security.

3. Get reminded to put the machines online during the renewal period.

You can be notified of machine security updates with a cloud flow and the
following Dataverse trigger:

This trigger will be invoked each time the machine security is updated. To find
information about which values to use in the trigger, go to How το know if a
machine has been updated with a new certificate or not?.



Use:

PendingNewKey for machines requiring a security update.
Default for machines that successfully processed a security update.
KeyExpired for machines that failed to get a new certificate during the
renewal period.

７ Note

You can use the additional advanced options to fine-tune the behavior of this
trigger.

4. Validate that machines have the new certificates.

You can verify your machines have retrieved the latest version of the machine
group certificate using the Machine Key Delivery Status column in the Flow
Machine table in Dataverse. If the value is empty or set to default, then your
machine is up-to-date.

5. Run desktop flows with each connection targeting those machines to avoid fixing
them later.

In the Power Automate portal:
a. Go to Monitor > Machines.
b. Select the machine from the list.
c. On the machine’s detail page, locate the connections card and select See all

connections.
d. Run a desktop flow with each of these desktop flow connections.

How to know when the next certificate renewal
is happening?



There are three parameters governing certificate renewal timelines, each available in a
column on the Flow Machine Group record in Dataverse:

The Key Creation Date column records the date on which the certificate was
created.
The Key Validity Period column documents the certificate’s lifetime.
The Key Grace Period column represents the time window where a new certificate
is created and machines and connections are migrated to a new key.

You can find out the precise date of the next certificate renewal using the following
calculation: Key Creation Date + (Key Validity Period – Key Grace Period)

How το know if a machine has been updated with a new
certificate or not?
You can verify your machines have retrieved the latest version of the machine group
certificate using the Machine Key Delivery Status column in the Flow Machine table in
Dataverse:

If the value is empty or set to Default, your machine is up-to-date.
If the value is Pending New Key, the machine is within the renewal period and
hasn't been updated yet. It will update when getting online or within 24 h if
already online.
If the value is Key Expired, the machine has missed the renewal period, and you
must manually rejoin the machine to the group.

How to customize certification expiration and
renewal durations?
Power Automate enables you to customize the certificate lifetime and how early the
renewal is triggered for any machine group. Upcoming renewals will use those



Dataverse columns (updates may take 24 h to be picked up):

ﾉ Expand table

Table Column Usage Boundaries

Flow Group Key Duration in minutes after which the next Minimum: Three
Machine Validity Period certificate issued will be expired. months (129,600
Group minutes)

Maximum: Five years
(2,628,000 minutes).

Flow Group Key Duration in minutes before the machine Minimum: 45 days
Machine Expiry Grace group certificate’s expiration date where (64,800 minutes)
Group Period machines will renew their certificates. Maximum: half of the

Group Key Validity
Period.

The current certificate remains valid until its expiration date. Changes to the validity
period will only apply to the next certificate.

Some special considerations must be kept in mind when changing the validity period
and the grace period:

If the new Group Key Validity Period value is shorter than the current certificate’s
lifetime or falls under the defined grace period, a certificate renewal will
immediately be scheduled. It will start in the following 24 h, assuming some
machines of the group are online. The certificate renewal period will last for the
defined grace period.

If the new Group Key Validity Period value is longer than the current one, nothing
will happen immediately. The current certificate will be kept active until its rotation.
The new certificate will take the new validity period into account.

How to trigger a certificate renewal?
If you want to accelerate certificate renewal, you can edit the Group Key Validity Period
to change the length of the renewal period. This value can't be higher than half the
group key's Validity Period and can't be lower than 45 days.

If you need to invalidate certificates immediately, delete your machine groups in Power
Automate and recreate them. You can do so by deleting the corresponding rows in the
Flow Machine group table.



２ Warning

Deleting machine groups will require fixing your desktop flow connections
targeting these machine groups.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Data loss prevention (DLP) policy creation
Article • 01/14/2025

An organization's data is critical to its success. Its data needs to be readily available for decision-
making, but at the same time, data needs to be protected so that it isn't shared with audiences
that shouldn't have access to it. To protect your business data, Power Automate gives you the
ability to create and enforce policies that define which connectors can access and share it. The
policies that define how data can be shared are referred to as data loss prevention (DLP)
policies.

Administrators control DLP policies. If a DLP policy is blocking your flows from running, contact
your administrator.

Learn more about protecting your data with Power Platform in Data Loss Prevention (DLP)
policies.

Data loss prevention for desktop flows
Power Automate allows you to create and enforce DLP policies that classify desktop flow
modules and individual module actions as Business, Non-business, or Blocked. This
categorization prevents makers from combining modules and actions from different categories
into a desktop flow or between a cloud flow and the desktop flows it uses.

） Important

DLP policy enforcement for desktop flows is available in all environments.
DLP for desktop flows is available for versions of Power Automate for desktop
2.14.173.21294 or later. If you're using an earlier version, uninstall it and update to the
latest version.

View desktop flow action groups
By default, desktop flow action groups don't appear when you're creating a DLP policy. You
need to turn on the Show desktop flow actions in DLP policies setting in your tenant settings.

If you opted for the public preview, the Desktop flow actions in DLP setting is already enabled
and can't be changed.

1. Sign in to the Power Platform admin center .

2. On the left side panel, select Settings.

3. On the Tenant settings page, select Desktop flow actions in DLP.



4. Turn on Show desktop flow actions in DLP policies, and then select Save.

You can now classify desktop flow action groups when you create a data policy.

Create a DLP policy with desktop flow restrictions
When admins edit or create a policy, desktop flow action groups are added to the default group,
and the policy is applied after it's saved. The policy is suspended if the default group is set to
Blocked and the desktop flows are running in the target environments.

You can manage your DLP policies for desktop flows the same way you manage cloud flow
connectors and actions. Desktop flow modules are groups of similar actions as displayed in the
Power Automate for desktop user interface. A module is similar to connectors that are used in
cloud flows. You can define a DLP policy that manages both desktop flow modules and cloud
flow connectors. Some basic modules, such as Variables, can't be managed in the scope of DLP
policy because almost all desktop flows need to use them. Learn more about the fundamentals
of DLP policies and how to create them.

When your tenant is opted into the user experience in the Power Platform, your administrators
automatically see the new desktop flow modules in the default data group of the DLP policy
they're creating or updating.



２ Warning

When desktop flow modules are added to DLP policies, your tenant's desktop flows are
evaluated against them and they're suspended if they're non-compliant. If your
administrator creates or updates the DLP policy without noticing the new modules, desktop
flows can be unexpectedly suspended.

Govern desktop flows outside of DLP
Granular control over the use of desktop flows on all machines as described in the previous
sections applies only to Managed Environments. You have other options to govern desktop
flows.

Ability to govern desktop flow orchestration: The desktop flow connector can be
governed in your policies like any other connector in all environments.

Ability to govern usage of Power Automate for desktop: You can govern Power Automate
for desktop flows through Group Policy objects (GPO). This governance allows you to turn
on or off desktop flows for actions such as to restrict to a set of environments or regions,
limit use of account types, and restrict manual updates.

Learn more about governance in Power Automate.

Desktop flow modules in DLP
The following desktop flow modules are available in DLP:



providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.ActiveDirectory
ActiveDirectory
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.AWS AWS
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Azure Azure
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.WebAutomation
Browser Automation
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Cmd CMD session
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Clipboard Clipboard
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Compression
Compression
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Cryptography
Cryptography
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.CyberArk CyberArk
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Database Database
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Email Email
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Excel Excel
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Exchange Exchange
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.FTP FTP
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.File File
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Folder Folder
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.GoogleCognitive
Google cognitive
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Web HTTP
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.IBMCognitive IBM
cognitive
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Display Message boxes
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.MicrosoftCognitive
Microsoft cognitive
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.MouseAndKeyboard
Mouse and keyboard
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.OCR OCR
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Outlook Outlook
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Pdf PDF
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.PowerAutomateSecretVariables
Power Automate Secret Variables
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Runflow Run flow
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Scripting Scripting
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.System System
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.TerminalEmulation
Terminal emulation
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.UIAutomation UI
automation
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Services Windows
Services



providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.Workstation
Workstation
providers/Microsoft.ProcessSimple/operationGroups/DesktopFlow.XML XML

PowerShell support for desktop flow modules
If you don't want to turn on the Show desktop flow actions in DLP policies setting, you can use
the following PowerShell script to add all desktop flow modules to the Blocked group of a DLP
policy. If you already turned on the setting, you don't need to use this script.

PowerShell

# Step #1: Retrieve a DLP policy named 'My DLP Policy' 
  $dlpPolicies = Get-DlpPolicy  
  $dlpPolicy = $dlpPolicies.value | where {$_.displayName -eq 'My DLP Policy'}  

# Step #2: Get all Power Automate for desktop flow modules 
  $desktopFlowModules = Get-DesktopFlowModules  

# Step #3: Convert the list of Power Automate for desktop flow modules to a format 
that can be added to the policy 
  $desktopFlowModulesToAddToPolicy = @()  
        foreach ($modules in $desktopFlowModules) {  
          $desktopFlowModulesToAddToPolicy += [pscustomobject]@{  
          id=$modules.id  
          name=$modules.Properties.displayName  
          type=$modules.type  
      }  
  }  

# Step #4: Add all desktop flow modules to the 'blocked' category of 'My DLP 
Policy' 
    Add-ConnectorsToPolicy -Connectors $desktopFlowModulesToAddToPolicy -
PolicyName $dlpPolicy.name -classification Blocked -Verbose 

The following PowerShell script adds two specific desktop flow modules to the default data
group of a DLP policy.

PowerShell

# Step #1: Retrieve a DLP policy named 'My DLP Policy' 
  $dlpPolicies = Get-DlpPolicy  
  $dlpPolicy = $dlpPolicies.value | where {$_.displayName -eq 'My DLP Policy'}  

# Step #2: Get all Power Automate for desktop flow modules 
  $desktopFlowModules = Get-DesktopFlowModules  

# Step #3: Create a list with the 'Active Directory' and 'Workstation' modules 
  $desktopFlowModulesToAddToPolicy = @()  
  $activeDirectoryModule = $desktopFlowModules | where {$_.properties.displayName -
eq "Active Directory"}  
  $desktopFlowModulesToAddToPolicy += [pscustomobject]@{  
    id=$activeDirectoryModule.id  
    name=$activeDirectoryModule.Properties.displayName  



    type=$activeDirectoryModule.type  
  }
  $clipboardModule = $desktopFlowModules | where {$_.properties.displayName -eq 
"Workstation"}  
  $desktopFlowModulesToAddToPolicy += [pscustomobject]@{  
    id=$clipboardModule.id  
    name=$clipboardModule.Properties.displayName  
    type=$clipboardModule.type  
  }  

# Step #4: Add both modules to the default data group of 'My DLP Policy' 
  Add-ConnectorsToPolicy -Connectors $desktopFlowModulesToAddToPolicy -
PolicyName $dlpPolicy.name -Classification 
$dlpPolicy.defaultConnectorsClassification -Verbose 

PowerShell script to opt out desktop flows
If you don't want to use the DLP for desktop flows feature, you can use the following PowerShell
script to opt out.

PowerShell

# Step #1: Retrieve the DLP policy named 'My DLP Policy'

$policies = Get-DlpPolicy
$dlpPolicy = $policies.value | Where-Object { $_.displayName -eq "My DLP Policy" }

# Step #2: Get all Power Automate for desktop flow modules

$desktopFlowModules = Get-DesktopFlowModules
 
# Step #3: Remove Desktop Flow modules from all 3 connector groups of the policy

foreach ($connectorGroup in $dlpPolicy.connectorGroups) {
   $connectorGroup.connectors = $connectorGroup.connectors | Where-Object { 
$desktopFlowModules.id -notcontains $_.id }
}

# Step #4: Save the updated policy

Set-DlpPolicy -PolicyName $dlpPolicy.name -UpdatedPolicy $dlpPolicy

After the policy is enabled
If your users don't have the latest Power Automate for desktop, DLP policy enforcement is
limited. They don't see design-time error messages when they're trying to run, debug, or save
desktop flows that violate DLP policies. Background jobs periodically scan desktop flows in the
environment and automatically suspend any that violate DLP policies. Users can't run desktop
flows from a cloud flow if the desktop flow violates any data loss prevention policy.



Makers who have the latest Power Automate for desktop can't debug, run, or save desktop flows
that violate DLP policy. They also can't select a desktop flow that's in violation of a DLP policy
from a cloud flow step.

DLP enforcement and suspension
1. When you create or edit a flow, Power Automate evaluates it against the current set of DLP

policies.
a. Enforcement of flows without a child flow, which is 99% of flows, is synchronous and

occurs in real-time.
b. Enforcement of a flow with a child flow is asynchronous, since the child flows need to be

evaluated as well, and occurs within 24 hours.
2. When you create or change a DLP policy, a background job scans all active flows in the

environment, evaluates them, and then suspends the flows that violate the policy.
Enforcement is asynchronous and occurs within 24 hours. If a DLP policy change occurs
when the previous DLP policy is being evaluated, then the evaluation restarts to make sure
the latest policies are enforced.

3. Weekly, a background job does a consistency check of all active flows in the environment
against the DLP policies to confirm that a DLP policy check wasn't missed.

DLP reactivation
If the DLP enforcement background job finds a desktop flow that no longer violates any DLP
policy, then the background job automatically removes the suspension. However, the DLP
enforcement background job doesn't automatically unsuspend cloud flows.

DLP enforcement change process
Periodically, DLP enforcement needs to change because new DLP capabilities or a bug fix are
rolled out or an enforcement gap is filled. When changes can affect existing flows, apply the
following staged DLP enforcement change management process:

1. Investigating: Confirm the need for a DLP enforcement change and investigate the
specifics of the change.

2. Learning: Implement the change and gather data about the breadth of the effects of the
change. Document DLP enforcement changes to explain the scope of the change. If the
data suggests that customers will be greatly affected, then a communication might be sent
to those customers to let them know that a change is coming. If the change has a broad
impact on existing flows, then at a later stage in the learning phase, when the background
DLP enforcement job finds a violation in an existing flow, Power Automate notifies the flow
owners that the flow will be suspended, so that they have more time to respond.



3. Notify only: Turn on email notifications only for DLP violations so owners of existing flows
get notified about the upcoming DLP enforcement change. When the background DLP
enforcement job finds a violation in an existing flow, notify the flow owners that the flow
will be suspended. This mechanism runs weekly.

4. Design-time enforcement: Turn on design-time enforcement of DLP violations so that
owners of existing flows get notified about the upcoming DLP enforcement change, but
any flows that are changed get a full DLP policy evaluation at design time. This is also
known as soft enforcement.

Design-time: When a flow is updated and saved, use the updated DLP enforcement
and suspend the flow if needed so the maker is immediately aware of the
enforcement.

Background process: When the background DLP enforcement job finds a violation in
a flow, notify the flow owners that the flow will be suspended. This mechanism
includes creation or changes to DLP policy and consistency checks.

5. Full enforcement: Turn on full enforcement of DLP violations, so DLP policies are fully
enforced on all existing and new flows. The DLP policies are fully enforced when flows are
saved during DLP enforcement background job evaluation. This is also known as hard
enforcement.

DLP enforcement change list
The following table lists DLP enforcement changes and the date the changes were effective.

ﾉ Expand table

Date Description Reason for change Stage Design-time Full
enforcement enforcement
availability* availability*

May Delegated DLP policies are enforced on Full June 2, 2022 July 21, 2022
2022 authorization flows that use delegated

background authorization while the flow is
job being saved, but not during
enforcement background job evaluation.

May Request DLP policies weren't enforced Full June 2, 2022 August 25,
2022 apiConnection correctly for some triggers. The 2022

trigger affected triggers have
enforcement type=Request and

kind=apiConnection. Many of
the affected triggers are instant
triggers, which are used in
instant, or manually triggered,
flows. The affected triggers
include the following.



Date Description Reason for change Stage Design-time Full
enforcement enforcement
availability* availability*

- Power BI: Power BI button
clicked
- Teams: From the compose box
(V2)
- OneDrive for Business: For a
selected file
- Dataverse: When a flow step is
run from a business process flow
- Dataverse (legacy): When a
record is selected
- Excel Online (Business): For a
selected row
- SharePoint: For a selected item
- Microsoft Copilot Studio: When
Copilot Studio calls a flow (V2)

July Enforce DLP Enable the enforcement of DLP Full February 14, March 2023
2022 policies on policies to include child flows. If 2023

child flows a violation is found anywhere in
the flow tree, the parent flow is
suspended. After the child flow is
edited and saved to remove the
violation, the parent flows can be
resaved or reactivated to run the
DLP policy evaluation again. A
change to no longer block child
flows when the HTTP connector
is blocked will roll out along with
full enforcement of DLP policies
on child flows. Once full
enforcement is available, the
enforcement includes child
desktop flows.

January Enforce DLP Enable the enforcement of DLP Full - August 2023
2023 policies on policies to include child desktop

child desktop flows. If a violation is found
flows anywhere in the flow tree, the

desktop parent flow is
suspended. After the child
desktop flow is edited and saved
to remove the violation, the
parent desktop flows are
automatically reactivated.

October Enforce Expand enforcement of Learning January 27, February 10,
2024 connector connector action control to 2025 2025

action control ensure that triggers and internal
on triggers and actions are covered. List them in
internal actions Power Platform admin center and



Date Description Reason for change Stage Design-time Full
enforcement enforcement
availability* availability*

enforce blocking them if
individually referenced in DLP
policies or if the DLP policy
doesn't include them as allowed.

*Availability schedule might change and depends on the rollout.

Flow suspension for DLP violation
Suspended flows show as suspended in the Power Automate maker portal and the Power
Platform admin center. When a flow is returned through an API, PowerShell, or the Power
Automate Management connector list flows "as Admin" action, the flow has State=Suspended,
FlowSuspensionReason=CompanyDlpViolation, and a FlowSuspensionTime value indicating
when the flow was suspended.

Known limitations
Learn about DLP known issues.

Related information
Power Platform DLP policies
Learn more about environments
Learn more about Power Automate
Learn more about the admin center

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Power Automate mobile app supports
Microsoft Intune
Article • 10/30/2023

The Power Automate mobile app for iOS and Android supports Intune's Mobile
Application Management (MAM) without device enrollment. Using MAM allows IT
administrators to create and enforce mobile data policies to safeguard organizational
data.

Why Intune support is important
Organizations are looking for more control over the data that resides on employee
mobile devices. Organizations might want to restrict how that data moves to the device
and ensure the data is removed, should the employee leave the organization.

What is Microsoft Application Management
(MAM)
MAM allows organizations to create policies that govern how apps are used within a
tenant. This includes enforcing app data encryption, limiting the ability to copy or
extract data to only approved applications, or enforcing a PIN on a device.

Prerequisites
An Intune app protection policy.
An Microsoft Entra group.
Company Portal. One key benefit of using MAM is that devices don't need to be
enrolled in Intune MAM. All that's required is the Company Portal, which is
available from the App Store and the Google Play store.
Version 2.31.0 of the Power Automate mobile app for iOS, Android, or Windows
Phone.

Create an app protection policy, assign apps to
the policy, define settings, and add users to a
Microsoft Entra group



For the Power Automate mobile app to be managed, you must:

1. Create an app protection policy.
2. Assign the Power Automate mobile app to the app protection policy.
3. Assign the policy settings. For example, you might assign the policy to require a

PIN to access the mobile device that runs the Power Automate mobile app.
4. Apply the app protection policy to a specific Microsoft Entra group.
5. Add all users to which the app protection policy applies to the Microsoft Entra

group.

Follow these steps to create an app protection policy that requires Power Automate
mobile app users to enter a PIN before they can access the app.

Test the app protection policy
After you've created the app protection policy and assigned users to the Microsoft Entra
group, it's time to use the Power Automate mobile app and confirm the policy works.

To confirm the policy works, follow these steps:

1. Install the Power Automate mobile app on a device whose platform matches one
of the platforms you defined in the app protection policy.

2. Sign in to the mobile app with an account that's in the Microsoft Entra group that
restricts use of the mobile app to users who have a PIN.

You'll then be prompted to:

1. Install the Company Portal.
2. Set your PIN if you don't already have a PIN that meets the app protection policy's

criteria.

Learn more
Learn to create an app protection policy.



Learn all about data groups
Article • 12/16/2022

What is a data group?
Data groups are a simple way to categorize services within a data loss prevention (DLP)
policy. The two data groups available are the Business data only group and the No
business data allowed group. Organizations are free to determine which services are
placed into a particular data group. A good way to categorize services is to place them
in groups, based on the impact to the organization. By default, all services are placed
into the No business data allowed data group. You manage the services in a data group
when you create or modify the properties of a DLP policy from the admin center.

Visit the Microsoft Power Platform documentation to learn more about data groups and
data loss prevention policies.

Next steps
Learn more about data loss prevention (DLP) policies
Learn more about environments



Sharing and connectors admin analytics
reports
Article • 12/16/2022

Organizations need insights into how apps are used and who's using them. The Admin
analytics sharing and connectors reports provide insights into how Power Automate is
being used within your tenant.

Use the shared flows report to learn who your app champions are and then empower
them to provide even more automated solutions for your organization. The connectors
report identifies Microsoft, third-party, and custom connectors that are in use within
your organization.

Visit the Microsoft Power Platform documentation to get the details how to:

View the shared flows reports.
View the connectors reports.
Filter views.



Respond to personal data requests
(Microsoft Entra ID)
Article • 10/30/2023

The European Union (EU) General Data Protection Regulation (GDPR) gives significant
rights to individuals regarding their data. Refer to the Microsoft Learn General Data
Protection Regulation Summary for an overview of GDPR, including terminology, an
action plan, and readiness checklists to help you meet your obligations under GDPR
when using Microsoft products and services.

You can learn more about GDPR and how Microsoft helps support it and our customers
who are affected by it.

The Microsoft Trust Center  provides general information, compliance best
practices, and documentation helpful to GDPR accountability, such as Data
Protection Impact Assessments, Data Subject Requests, and data breach
notification.
The Service Trust portal  provides information about how Microsoft services help
support compliance with GDPR.

Power Automate provides tools and resources to help you respond to requests to
correct, export, or delete personal data that resides in the Microsoft cloud. This article
helps you respond to requests from users who authenticate using Microsoft Entra ID.
Respond to requests from users who authenticate using a Microsoft account.

Prerequisites
A paid or trial license  for Power Apps Plan 2
The Microsoft 365 Global Administrator  or Microsoft Entra Global Administrator
role

If you're a member of an unmanaged tenant and don't have a global administrator, you
can export and remove your own personal data. You must have an Microsoft Entra
account with a Power Automate license .

Respond to requests for Power Automate
customer data



Requests from data subjects require one or more of the following actions, depending on
the request:

1. Discover: Use search and discovery tools to find the user's personal data, including
accounts and system-generated logs. Determine whether the request meets your
organization's guidelines for responding to personal data requests.

2. Access: Retrieve personal data that resides in the Microsoft cloud.

3. Correct: Make changes to personal data as requested, if appropriate.

As a data processor, Microsoft doesn't offer the ability to edit system-generated
logs. These logs reflect factual activities and constitute a history of all events within
a service. Learn more about system-generated logs in Power Automate.

4. Restrict: Restrict the processing of personal data, either by removing licenses for
various services or turning off the services where possible. You can also remove
data from the Microsoft cloud and retain it on-premises or at another location.

5. Delete: Permanently remove personal data that resides in Microsoft's cloud.

6. Export: Provide an electronic copy of personal data in a machine-readable format
to the data subject.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Respond to personal data discovery
requests (Microsoft Entra ID)
Article • 10/30/2023

The first step in responding to personal data requests is to find personal data that's
subject to the request. This step helps you to determine whether a request meets your
organization's requirements for honoring or declining the request.

The following table summarizes the Power Automate resources that may contain the
personal data of a user who authenticates using Microsoft Entra ID.

ﾉ Expand table

Resource Purpose

System-generated Records that capture system events and history.
logs

Run history The history of each flow execution for the past 28 days, including the start
time, end time, status, and all inputs and outputs. Learn more .

Activity feed Recaps flow activities, including run status, failures, and notifications.

User jobs Not visible to the user; system jobs that run on behalf of a user for flows to
execute.

Flows The workflow logic that exists for a cloud flow. Learn more.

Flow permissions Permissions that allow other users to share a flow. Learn more.

User details Not visible to the user; details that support flow execution.

Connections Used by connectors to share data with APIs, systems, databases, etc. Learn
more.

Connection Permissions for connections. Learn more.
permissions

Custom connectors Custom connectors that a user has created and published that allow
connections to custom or third-party systems. Learn more

Custom connector Permissions for custom connectors. Learn more.
permissions

Gateway Gateways are on-premises data services that users can install to transfer
data quickly and securely between Power Automate and a data source that
isn't in the cloud. Learn more.



Resource Purpose

Gateway Permissions for gateways. Learn more.
permissions



Respond to personal data export
requests (Microsoft Entra ID)
Article • 08/16/2023

The European Union (EU) General Data Protection Regulation (GDPR) gives significant
rights to individuals regarding their data. Refer to the Microsoft Learn General Data
Protection Regulation Summary for an overview of GDPR, including terminology, an
action plan, and readiness checklists to help you meet your obligations under GDPR
when using Microsoft products and services.

You can learn more about GDPR and how Microsoft helps support it and our customers
who are affected by it.

The Microsoft Trust Center  provides general information, compliance best
practices, and documentation helpful to GDPR accountability, such as Data
Protection Impact Assessments, Data Subject Requests, and data breach
notification.
The Service Trust portal  provides information about how Microsoft services help
support compliance with GDPR.

７ Note

This article provides instructions for exporting personal data from the device or
service and can help you meet your obligations under GDPR. For general
information about GDPR, see the GDPR section of the Microsoft Trust Center
and the GDPR section of the Service Trust portal .

The right of data portability allows data subjects to request a copy of their personal data
in an electronic format that can be transmitted to another data controller.

The following table summarizes where to find and export the personal data of a user
who authenticates by using Microsoft Entra in Power Automate.

Website access: Sign in to the Power Apps admin center  or Power Platform
admin center .
PowerShell access: Use Power Apps Admin PowerShell cmdlets.

Customer data Website access PowerShell access

System-generated Office 365 Service Trust Portal
logs



Customer data Website access PowerShell access

Run history Power Automate maker portal

Flows Power Automate maker portal

Flow permissions Power Automate maker portal and
Power Automate admin center

User details Power Apps cmdlets

Connections Power Automate maker portal Power Apps cmdlets

Connection Power Automate maker portal Power Apps cmdlets
permissions

Custom connectors Power Automate maker portal Power Apps cmdlets

Custom connector Power Automate maker portal Power Apps cmdlets
permissions

Gateway Power Automate maker portal On-premises data gateway
PowerShell cmdlets

Gateway permissions Power Automate maker portal On-premises data gateway
PowerShell cmdlets

Export a cloud flow
1. Sign in to Power Automate .

2. On the left navigation pane, select My flows.

3. Select a flow, select … More, and then select Export.

4. Select Package (.zip).

The flow is downloaded as a zipped archive.

Export run history
Run history lists all executions of a cloud flow. It includes a run's status, start time,
duration, inputs, and outputs.

1. Sign in to Power Automate .

2. On the left navigation pane, select My flows.



3. Select a flow.

4. In the Run history pane, select See all.

5. At the top of the page, select Download CSV.

The run history is downloaded as a .csv file, so that you can open it in Microsoft
Excel or a text editor and analyze the results.

Export a user's activity feed
The activity feed shows a history of a user's activities, flow execution failures, and
notifications.

1. Sign in to Power Automate .
2. Select the bell symbol in the upper-right corner of the page, and then select Show

all activity.
3. Copy the contents of the Activity page, and paste them into a document editor

such as Microsoft Word.

Export a user's connections
1. Sign in to Power Automate .
2. Select the gear symbol in the upper-right corner of the page, and then select

Connections.
3. Copy the list, and paste it into a document editor such as Word.

Export a user's connections using a PowerShell
cmdlet

PowerShell

Add-PowerAppsAccount

#Retrieves all connections for the specified userID
Add-PowerAppsAccount
$userId = "{userID}"
Get-AdminConnection -CreateBy $userId | ConvertTo-Json | Out-File -FilePath 
"UserConnections.txt"



Export a user's connection permissions using
PowerShell cmdlets

PowerShell

Add-PowerAppsAccount
Get-ConnectionRoleAssignment | ConvertTo-Json | Out-File -FilePath 
"ConnectionPermissions.txt"

PowerShell

Add-PowerAppsAccount

#Retrieves all connection permissions for the specified userID
Add-PowerAppsAccount
$userId = "{userID}"
Get-AdminConnectionRoleAssignment -PrincipalObjectId $userId | ConvertTo-
Json | Out-File -FilePath "ConnectionPermissions.txt" 

Export a user's custom connectors
1. Sign in to Power Automate .
2. Select the gear symbol in the upper-right corner of the page, and then select

Custom Connectors.
3. Copy the list, and paste it into a document editor such as Word.

Export a user's custom connectors using
PowerShell cmdlets

PowerShell

Add-PowerAppsAccount
Get-Connector -FilterNonCustomConnectors | ConvertTo-Json | Out-File -
FilePath "CustomConnectors.txt"

PowerShell

Add-PowerAppsAccount

#Retrieves all custom connectors for the specified userID
Add-PowerAppsAccount
$userId = "{userID}"



Get-AdminConnector -CreatedBy $userId | ConvertTo-Json | Out-File -FilePath 
"UserCustomConnectors.txt"  

Export a user's custom connector permissions
using PowerShell cmdlets

PowerShell

Add-PowerAppsAccount
Get-ConnectorRoleAssignment | ConvertTo-Json | Out-File -FilePath 
"CustomConnectorPermissions.txt"

PowerShell

Add-PowerAppsAccount

#Retrieves all connection permissions for the specified userID 
Add-PowerAppsAccount
$userId = "{userID}"
Get-AdminConnectorRoleAssignment -PrincipalObjectId $userId | ConvertTo-Json 
| Out-File -FilePath "CustomConnectorPermissions.txt"   

Export a user's approval history
1. On the web or desktop, open Microsoft Teams .

2. In Teams, follow one of these steps to open the Approvals app:

From the main search bar, search for Approvals.
In the left pane, select the ellipsis (…), and then search for or select
Approvals.

3. On the Received tab, select Export in the upper-right corner to export received
approvals.

4. Select the export dates, and then select Export.

5. On the Sent tab, select Export in the upper-right corner to export sent approvals.

6. Select the export dates, and then select Export.

Repeat the previous procedure for every environment that the user is part. Use the
environment switcher in the upper right of the Approvals app page to switch



environments.

Alternatively, open Power Automate , select Approvals on the left navigation pane,
and select the History tab. You can then manually copy approval contents for received
and sent approvals. To ensure that you get the contents for both types of approvals,
select the appropriate filter (Received or Sent) in the upper-right corner.

Export a user's details using a PowerShell
cmdlet

PowerShell

Add-PowerAppsAccount

Get-AdminFlowUserDetails -UserId {userID}

Export gateway settings
Learn more about responding to data export requests for on-premises data gateways.



Respond to personal data deletion
requests (Microsoft Entra ID)
Article • 08/16/2023

The European Union (EU) General Data Protection Regulation (GDPR) gives significant
rights to individuals regarding their data. Refer to the Microsoft Learn General Data
Protection Regulation Summary for an overview of GDPR, including terminology, an
action plan, and readiness checklists to help you meet your obligations under GDPR
when using Microsoft products and services.

You can learn more about GDPR and how Microsoft helps support it and our customers
who are affected by it.

The Microsoft Trust Center  provides general information, compliance best
practices, and documentation helpful to GDPR accountability, such as Data
Protection Impact Assessments, Data Subject Requests, and data breach
notification.
The Service Trust portal  provides information about how Microsoft services help
support compliance with GDPR.

７ Note

This article provides instructions for deleting personal data from the device or
service and can help you meet your obligations under GDPR. For general
information about GDPR, see the GDPR section of the Microsoft Trust Center
and the GDPR section of the Service Trust portal .

The right of erasure allows data subjects to request the removal of their personal data
from an organization's customer data. This personal data includes system-generated
logs but excludes audit logs.

In addition, when a user leaves your organization, an admin must determine whether to
delete data and resources that the user created as part of their Power Automate flows.
Other personal data is automatically deleted when the user's account is deleted from
Microsoft Entra ID.

The following table shows which personal data is automatically deleted, and which data
an admin must manually review and delete, for users who authenticate by using
Microsoft Entra ID.



Requires manual review and Automatically deleted when the user is deleted from
deletion Microsoft Entra ID

Environment* System-generated logs
Environment permissions** Run history
Flows Activity Feed
Flow permissions Gateway
User details Gateway permissions
Connections*
Connection permissions
Custom connector*
Custom connector
permissions

* Each of these resources contains "Created By" and "Modified By" records that include
personal data. For security reasons, these records are retained until the resource is
deleted.

** For environments that include a Dataverse database, environment permissions (that
is, which users are assigned to the Environment Maker and Admin roles) are stored as
records in Dataverse. Learn more about running data requests against Dataverse
customer data.

The following table summarizes where to find and delete a user's personal data in Power
Automate.

Website access: Sign in to the Power Apps admin center  or Power Platform
admin center .
PowerShell access: Use Power Apps Admin PowerShell cmdlets.

Resources containing Website access PowerShell Automated deletion
personal data access

System-generated logs Office 365 Service
Trust Portal

Environment Power Automate Power Apps
admin center cmdlets

Environment Power Automate Power Apps
permissions* admin center cmdlets

Run history Deleted through the 28-day
retention policy

Activity feed Deleted through the 28-day
retention policy



Resources containing Website access PowerShell Automated deletion
personal data access

User jobs

Flows Power Automate
maker portal**

Flow permissions Power Automate
maker portal

User details Power Apps
cmdlets

Connections Power Automate
maker portal

Connection permissions Power Automate
maker portal

Custom connector Power Automate
maker portal

Custom connector Power Automate
permissions maker portal

Approval history Power Apps maker
portal*

* For environments that include a Dataverse database, environment permissions and
model-driven app permissions are stored as records in Dataverse. Learn more about
running data requests against Dataverse customer data.

** An admin can access these resources from the Power Automate maker portal only if
the admin has been assigned access from the Power Automate admin center.

Run data deletion requests
） Important

To avoid data corruption, follow these steps in order.

1. Reassign and copy the user's flows.
2. Delete the user's approval history.
3. Delete connections created by the user.
4. Delete the user's permissions to shared connections.



5. Delete custom connectors created by the user.
6. Delete the user's permissions to shared custom connectors.
7. Delete or reassign environments created by the user.
8. Delete gateway settings.
9. Delete the user's details.

10. Delete the user from Microsoft Entra ID.

Reassign and copy the user's flows
If a departing user or a user who has requested the deletion of their personal data has
created flows that are widely used in your organization, don't delete them. Instead, copy
them, assign the copies to new owners, and establish new connections. When the flows
are copied, personal identifier linkages to the departing user are deleted.

1. Sign in to Power Platform admin center .
2. Select the environment that contains the user's flows.
3. Select Resources > Flows, and then select a flow to reassign.
4. Select Manage sharing, and add yourself as an owner.
5. Select Save.
6. Sign in to Power Automate .
7. Select My flows > Team flows.
8. In the list of flows, select the vertical ellipsis (⋮) for the flow that you want to copy,

and then select Save As.
9. Establish any connections that are required, and then select Continue.

10. Enter a new name for the flow, and then select Save.
11. Turn on the copied flow.
12. Delete the original flow.
13. Select the ellipsis (…), and then select Delete.
14. Select Delete again when you're prompted.

Delete the user's approval history
Approval responses include personal information in the form of approval assignments
and comments.

1. Sign in to Power Automate  or PowerApps .

2. On the left navigation pane, select Data, and then select Tables.

3. Select the All tab.

4. Find the Approvals table, and select the vertical ellipsis (⋮).



5. Select Edit or Edit in new tab.

Alternatively, select Edit data in Excel to work in Excel and delete the records there.

6. If the Owner column doesn't appear, select the +<number> more column
heading, select Owner, and then select Save.

7. Select the Owner column heading, and then select Filter by.

8. Enter the name of the user whose data you want to delete, and then select Delete
records.

9. Go back to the main table list that you found in step 3, and repeat steps 4 through
8 for each of the following tables:

Approval Requests
Approval Response
Basic Approval Model Data
Await All Approval Model
Await All Action Approval model
Approval step
Action Approval Model

To learn more, go to Responding to Data Subject Rights (DSR) requests for Microsoft
Dataverse customer data.

Delete connections created by the user
Connections include references to the user who created them. Users can delete their
own connections by using PowerShell cmdlets. In addition, admins can use the cmdlets
to delete users' connections. Learn more about Power Apps PowerShell cmdlets.

The following PowerShell script deletes connections that were created by the user who
runs the script:

PowerShell

Add-PowerAppsAccount

#Retrieves all connections for the calling user and deletes them
Get-AdminPowerAppConnection | Remove-Connection

The following PowerShell script deletes connections that were created by the user who
has the specified userID  value:



PowerShell

Add-PowerAppsAccount

$deleteDsrUserId = "{userID}"
#Retrieves all connections for the specified userID and deletes them 
Get-AdminPowerAppConnection -CreatedBy $deleteDsrUserId | Remove-
AdminConnection 

Delete the user's permissions to shared connections
Users can delete their own connection role assignments for shared connections by using
PowerShell cmdlets. In addition, admins can use the cmdlets to delete users' connection
permissions. Learn more about Power Apps PowerShell cmdlets.

The following PowerShell script deletes connection role assignments for the user who
runs the script:

PowerShell

Add-PowerAppsAccount

#Retrieves all connection role assignments for the calling user and deletes 
them
Get-ConnectionRoleAssignment | Remove-ConnectionRoleAssignment

The following PowerShell script deletes connection role assignments for the user who
has the specified userID  value:

PowerShell

Add-PowerAppsAccount

$deleteDsrUserId = "{userID}"
#Retrieves all shared connections for the specified userID and deletes their 
permissions 
Get-AdminConnectionRoleAssignment -PrincipalObjectId $deleteDsrUserId | 
Remove-AdminConnectionRoleAssignment  

７ Note

Owner role assignments can't be deleted unless the connection resource is deleted
first.



Delete custom connectors created by the user
Custom connectors include references to the user who created them. Users can delete
their own custom connectors by using PowerShell cmdlets. In addition, admins can use
the cmdlets to delete users' custom connectors. Learn more about Power Apps
PowerShell cmdlets.

The following PowerShell script deletes custom connectors that were created by the user
who runs the script:

PowerShell

Add-PowerAppsAccount

#Retrieves all custom connectors for the calling user and deletes them
Get-Connector -FilterNonCustomConnectors | Remove-Connector

The following PowerShell script deletes connection role assignments for the user who
has the specified userID  value:

PowerShell

Add-PowerAppsAccount

$deleteDsrUserId = "{userID}"
#Retrieves all custom connectors created by the specified userID and deletes 
them 
Get-AdminConnector -CreatedBy $deleteDsrUserId | Remove-AdminConnector  

Delete the user's permissions to shared custom
connectors
Users can delete their own custom connector role assignments by using PowerShell
cmdlets. In addition, admins can use the cmdlets to delete users' custom connector role
assignments. Learn more about Power Apps PowerShell cmdlets.

The following PowerShell script deletes custom connector role assignments for the user
who runs the script:

PowerShell

Add-PowerAppsAccount

#Retrieves all connector role assignments for the calling user and deletes 



them
Get-ConnectorRoleAssignment | Remove-ConnectorRoleAssignment

The following PowerShell script deletes custom connector role assignments for the user
who has the specified userID  value:

PowerShell

Add-PowerAppsAccount

$deleteDsrUserId = "{userID}"
#Retrieves all custom connector role assignments for the specified userID 
and deletes them 
Get-AdminConnectorRoleAssignment -PrincipalObjectId $deleteDsrUserId | 
Remove-AdminConnectorRoleAssignment  

７ Note

Owner role assignments can't be deleted unless the connection resource is deleted
first.

Delete or reassign environments created by the user
As an admin who is responding to a user's data deletion request, you have two options
for each environment that the user created:

If you determine that the environment isn't being used by anyone else in your
organization, you can delete it.
If you determine that the environment is still required, you can add yourself or
another user in your organization as an Environment Admin.

） Important

if you delete an environment, you permanently delete all resources in it, including
apps, flows, and connections. Always review the contents of an environment before
you delete it.

Delete the user's permissions in all environments or give other
users access to the user's environments



You can remove the user's role assignments in all environments in your organization.
You can also grant admin access to an environment that the user created. Learn more
about managing environments.

Delete gateway settings
Learn more about responding to data export requests for on-premises data gateways.

Delete the user's details
Before you perform this step, make sure that you've reassigned and deleted all the
user's flows. Otherwise, the PowerShell cmdlet returns an error.

PowerShell

Add-PowerAppsAccount
Remove-AdminFlowUserDetails -UserId {userID}

Delete the user from Microsoft Entra ID
The final step is to delete the user's Microsoft Entra account.

７ Note

For information about viewing, deleting, and exporting personal data, see Azure
Data Subject Requests for GDPR. For general information about GDPR, see the
GDPR section of the Microsoft Trust Center  and the GDPR section of the
Service Trust portal .

Delete the user from an unmanaged tenant
If the user is a member of an unmanaged tenant, you can close the user's account from
the Work and School Privacy portal.

To determine whether the user is a member of a managed or unmanaged tenant, follow
these steps:

1. Open the following URL in a browser. Replace foobar@contoso.com  with the user's
email address.



https://login.microsoftonline.com/common/userrealm/foobar@contoso.com?api-

version=2.1

2. If the response includes "IsViral": true , the user is a member of an unmanaged
tenant.

{
    "Login": "foobar@unmanagedcontoso.com",
    "DomainName": "unmanagedcontoso.com",
    "IsViral": true,
}

Otherwise, the user is a member of a managed tenant.



Respond to personal data requests
(Microsoft account)
Article • 10/30/2023

The European Union (EU) General Data Protection Regulation (GDPR) gives significant
rights to individuals regarding their data. Refer to the Microsoft Learn General Data
Protection Regulation Summary for an overview of GDPR, including terminology, an
action plan, and readiness checklists to help you meet your obligations under GDPR
when using Microsoft products and services.

You can learn more about GDPR and how Microsoft helps support it and our customers
who are affected by it.

The Microsoft Trust Center  provides general information, compliance best
practices, and documentation helpful to GDPR accountability, such as Data
Protection Impact Assessments, Data Subject Requests, and data breach
notification.
The Service Trust portal  provides information about how Microsoft services help
support compliance with GDPR.

Power Automate provides tools and resources to help you respond to requests to
correct, export, or delete personal data that resides in the Microsoft cloud. This article
helps you respond to requests from users who authenticate using a Microsoft account.
Respond to requests from users who authenticate using Microsoft Entra ID.

Prerequisites
A Microsoft account with a free Power Automate license

Respond to requests
Requests from data subjects require one or more of the following actions, depending on
the request:

1. Discover: Use search and discovery tools to find the user's personal data, including
accounts and system-generated logs. Determine whether the request meets your
organization's guidelines for responding to personal data requests.

2. Access: Retrieve personal data that resides in the Microsoft cloud.



3. Correct: Make changes to personal data as requested, if appropriate.

As a data processor, Microsoft doesn't offer the ability to edit system-generated
logs. These logs reflect factual activities and constitute a history of all events within
a service. Learn more about system-generated logs in Power Automate.

4. Restrict: Restrict the processing of personal data, either by removing licenses for
various services or turning off the services where possible. You can also remove
data from the Microsoft cloud and retain it on-premises or at another location.

5. Delete: Permanently remove personal data that resides in Microsoft's cloud. Learn
more about closing a Microsoft account.

6. Export: Provide an electronic copy of personal data in a machine-readable format
to the data subject.



Respond to personal data discovery
requests (Microsoft account)
Article • 05/03/2023

The first step in responding to personal data requests is to find personal data that's
subject to the request. This step helps you to determine whether a request meets your
organization's requirements for honoring or declining the request.

The following table summarizes the Power Automate resources that may contain the
personal data of a user who authenticates using a Microsoft account.

ﾉ Expand table

Resource Purpose

Run history The history of each flow execution for the past 28 days, including the start time,
end time, status, and all inputs and outputs. Learn more .

Activity feed Recaps flow activities, including run status, failures, and notifications.

Flows The workflow logic that exists for a cloud flow. Learn more.

Connections Used by connectors to share data with APIs, systems, databases, etc. Learn more.



Respond to personal data export
requests (Microsoft account)
Article • 08/16/2023

The European Union (EU) General Data Protection Regulation (GDPR) gives significant
rights to individuals regarding their data. Refer to the Microsoft Learn General Data
Protection Regulation Summary for an overview of GDPR, including terminology, an
action plan, and readiness checklists to help you meet your obligations under GDPR
when using Microsoft products and services.

You can learn more about GDPR and how Microsoft helps support it and our customers
who are affected by it.

The Microsoft Trust Center  provides general information, compliance best
practices, and documentation helpful to GDPR accountability, such as Data
Protection Impact Assessments, Data Subject Requests, and data breach
notification.
The Service Trust portal  provides information about how Microsoft services help
support compliance with GDPR.

７ Note

This article provides instructions for exporting personal data from the device or
service and can help you meet your obligations under GDPR. For general
information about GDPR, see the GDPR section of the Microsoft Trust Center
and the GDPR section of the Service Trust portal .

The right of data portability allows data subjects to request a copy of their personal data
in an electronic format that can be transmitted to another data controller.

The following table summarizes where to find and export the personal data of a user
who authenticates by using a Microsoft account in Power Automate.

Microsoft privacy dashboard
Power Automate maker portal

ﾉ Expand table

Personal data Location

Product and service activity Microsoft privacy dashboard



Personal data Location

Flows Power Automate maker portal

Run history Power Automate maker portal

Activity Feed Power Automate maker portal

Connections Power Automate maker portal

Export product and service activity
1. Sign in to the Microsoft privacy dashboard  by using your Microsoft account.
2. Select Download your data, and then select Create new archive.
3. Select App & service usage and any other data that you want to download.
4. Select Create archive.
5. Select Download in the archive list to save the exported data to your local drive.

Export a cloud flow
1. Sign in to Power Automate .

2. On the left navigation pane, select My flows.

3. Select a flow, select … More, and then select Export.

4. Select Package (.zip).

The flow is downloaded as a zipped archive.

Export run history
Run history lists all executions of a cloud flow. It includes a run's status, start time,
duration, inputs, and outputs.

1. Sign in to Power Automate .

2. On the left navigation pane, select My flows.

3. Select a flow.

4. In the Run history pane, select See all.

5. At the top of the page, select Download CSV.



The run history is downloaded as a .csv file, so that you can open it in Microsoft
Excel or a text editor and analyze the results.

Export a user's activity feed
The activity feed shows a history of a user's activities, flow execution failures, and
notifications.

1. Sign in to Power Automate .
2. Select the bell symbol in the upper-right corner of the page, and then select Show

all activity.
3. Copy the contents of the Activity page, and paste them into a document editor

such as Microsoft Word.

Export a user's connections
1. Sign in to Power Automate .
2. Select the gear symbol in the upper-right corner of the page, and then select

Connections.
3. Copy the list, and paste it into a document editor such as Word.



Respond to personal data deletion
requests (Microsoft account)
Article • 05/03/2023

The European Union (EU) General Data Protection Regulation (GDPR) gives significant
rights to individuals regarding their data. Refer to the Microsoft Learn General Data
Protection Regulation Summary for an overview of GDPR, including terminology, an
action plan, and readiness checklists to help you meet your obligations under GDPR
when using Microsoft products and services.

You can learn more about GDPR and how Microsoft helps support it and our customers
who are affected by it.

The Microsoft Trust Center  provides general information, compliance best
practices, and documentation helpful to GDPR accountability, such as Data
Protection Impact Assessments, Data Subject Requests, and data breach
notification.
The Service Trust portal  provides information about how Microsoft services help
support compliance with GDPR.

７ Note

This article provides instructions for deleting personal data from the device or
service and can help you meet your obligations under GDPR. For general
information about GDPR, see the GDPR section of the Microsoft Trust Center
and the GDPR section of the Service Trust portal .

The right to erasure allows data subjects to request the removal of their personal data,
including system-generated logs but not audit logs, from an organization's customer
data. Also, when a user leaves your organization, an admin must determine whether to
delete data and resources that the user created as part of their Power Automate flows.
Other personal data is automatically deleted when the user's Microsoft account is
closed.

The following table shows which personal data is automatically deleted, and which data
requires an administrator to manually review and delete, for users who authenticate
using a Microsoft account.

ﾉ Expand table



Requires the user to review and delete Automatically deleted

Product and service activity Run history

Flows Activity Feed

Connections

Delete personal data
The following steps describe how to self-serve data deletion requests.

Delete product and service activity
1. Sign in to the Microsoft Privacy Dashboard  with your Microsoft account.

2. Select Activity history.

3. Search or browse your activity history for the Microsoft applications and services
that you use, including Power Automate.

4. Select Delete to remove specific product or service activity events.

List and delete flows
1. Sign in to Power Automate , and then select My flows.

2. In the list of flows, select the flow menu (…) for the flow you want to delete, and
then select Delete.



Delete connections
Connections include references to the user who creates them. You can delete these
references at any time.

1. Sign in to Power Automate , select the gear icon in the upper-right corner of the
window, and then select Connections.

2. Select the connection that you'd like to delete, select the menu (…), and then
select Delete.

3. Select Delete when you're prompted to confirm you want to delete the
connection.

７ Note

If other flows use the connection you're deleting, you're notified that a new
connection is required. Otherwise, select Delete to continue.

Learn more
Get started with Power Automate
Learn what's new with Power Automate



Respond to requests to close a
Microsoft account
Article • 05/03/2023

The European Union (EU) General Data Protection Regulation (GDPR) gives significant
rights to individuals regarding their data. Refer to the Microsoft Learn General Data
Protection Regulation Summary for an overview of GDPR, including terminology, an
action plan, and readiness checklists to help you meet your obligations under GDPR
when using Microsoft products and services.

You can learn more about GDPR and how Microsoft helps support it and our customers
who are affected by it.

The Microsoft Trust Center  provides general information, compliance best
practices, and documentation helpful to GDPR accountability, such as Data
Protection Impact Assessments, Data Subject Requests, and data breach
notification.
The Service Trust portal  provides information about how Microsoft services help
support compliance with GDPR.

７ Note

This article provides instructions for deleting personal data from the device or
service and can help you meet your obligations under GDPR. For general
information about GDPR, see the GDPR section of the Microsoft Trust Center
and the GDPR section of the Service Trust portal .

The right to erasure allows data subjects to request the removal of their personal data,
including system-generated logs but not audit logs, from an organization's customer
data. When a user decides to close their Microsoft account, their underlying data is also
deleted.

The following personal data is automatically deleted when a user closes their Microsoft
account:

Product and service activity
Run history
Flows
Activity Feed
User details



Connections

Close a Microsoft account
The following steps describe how to self-serve account close requests.

1. Sign in to the Microsoft Account Close Portal  with your Microsoft account.

2. Read the list of actions you should take before you close your Microsoft account,
and perform all that apply to you.

3. When you've completed all the preclose actions that apply to you, select Next.

4. Acknowledge that you understand the consequences of closing your Microsoft
account, and then select Mark account for closure.

Your account will be closed in 30 days. You may reopen it at any time during this 30-day
period.



Learn more
Get started with Power Automate
Learn what's new with Power Automate



Power Automate US Government
Article • 06/20/2024

In response to the unique and evolving requirements of the United States public sector,
Microsoft has created Power Automate US Government plans. This section provides an
overview of features that are specific to Power Automate US Government. We
recommend that you read this supplementary section as well as the Power Automate
service getting started topic. For brevity, this service is commonly referred to as Power
Automate Government Community Cloud (GCC), Power Automate Government
Community Cloud – High (GCC High), or Power Automate Department of Defense
(DoD).

The Power Automate US Government Service Description serves as an overlay to the
general Power Automate Service Description. It defines the unique commitments and
differences compared to the general Power Automate offerings that have been available
to our customers since October 2016.

About Power Automate US Government
environments and plans
Power Automate US Government plans are monthly subscriptions and it can be licensed
to an unlimited number of users.

The Power Automate GCC environment is compliant with the Federal requirements for
cloud services, including FedRAMP High, and DoD DISA IL2. It is also compliant with the
criminal justice systems (CJI data types) requirements.

In addition to the features and capabilities of Power Automate, organizations that use
Power Automate US Government benefit from the following unique features:

Your organization's customer content is physically separated from customer
content in commercial offering of Power Automate.

Your organization's customer content is stored within the United States.

Access to your organization's customer content is restricted to screened Microsoft
personnel.

Power Automate US Government complies with all certifications and accreditations
that US Public Sector customers require.



Beginning September 2019, eligible customers can choose to deploy Power Automate
US Government to the GCC High environment, which enables single sign-on and
seamless integration with Microsoft Office 365 GCC High deployments.

Microsoft has designed the platform and our operational procedures to meet the
requirements aligning with the DISA SRG IL4 compliance framework. We anticipate the
US Department of Defense contractor customer base and other Federal agencies
currently leveraging Office 365 GCC High to use the Power Automate US Government
GCC High deployment option. This option enables and requires the customer to
leverage Microsoft Entra Government for customer identities, in contrast to GCC, which
leverages the public Microsoft Entra ID. For the US Department of Defense contractor
customer base, Microsoft operates the service in a manner that enables these customers
to meet ITAR commitment and DFARS acquisition regulations, as documented and
required by their contracts with the US Department of Defense. A Provisional Authority
to Operate has been granted by DISA.

Beginning April, 2021, eligible customers may now choose to deploy Power Automate
US Government to the "DoD" environment, which enables single sign-on and seamless
integration with Microsoft 365 DoD deployments. Microsoft has designed the platform
and operational procedures in accordance with the DISA SRG IL5 compliance framework.
DISA has granted a Provisional Authority to Operate.

Customer eligibility
Power Automate US Government is available to (1) US federal, state, local, tribal, and
territorial government entities, and (2) other entities, which handle data that is subject to
government regulations and requirements and where use of Power Automate US
Government is appropriate to meet these requirements, subject to validation of
eligibility. Microsoft's validation of eligibility includes confirmation of handling data
subject to International Traffic in Arms Regulations (ITAR), law enforcement data subject
to the FBI's Criminal Justice Information Services (CJIS) Policy, or other government-
regulated or controlled data. Validation may require sponsorship by a government entity
with specific requirements for the handling of data.

Entities with questions about eligibility for Power Automate US Government should
consult their account team. Microsoft re-validates eligibility when it renews customer
contracts for Power Automate US Government.

７ Note

Power Automate US Government DoD is only available to DoD entities.



Power Automate US Government plans
Access to Power Automate US Government plans is restricted to the offerings described
in the following section; each plan is offered as a monthly subscription and can be
licensed to an unlimited number of users:

Power Automate Process plan (previously Power Automate per flow) for
Government

Power Automate Premium plan (Power Automate per user) for Government

In addition to the standalone plans, Microsoft 365 US Government and Dynamics
365 US Government plans also include the Power Apps and Power Automate
capabilities, allowing customers to extend and customize Microsoft 365 and
customer engagement apps (Dynamics 365 Sales, Dynamics 365 Customer Service,
Dynamics 365 Field Service, and Dynamics 365 Project Service Automation).

Additional information and details regarding the differences in functionality between
these groups of licenses are described in more detail here: Power Automate licensing
information .

Power Automate US Government is available through the Volume Licensing and Cloud
Solution Provider purchasing channels. The Cloud Solution Provider program is not
currently available for GCC High customers.

Differences between customer data and
customer content
Customer data, as defined in the Online Service Terms, means all data, including all text,
sound, video, or image files, and software that are provided to Microsoft by, or on
behalf of, customers through the use of an Online Service.

Customer content refers to a specific subset of customer data that has been directly
created by users, such as content stored in databases through entries in the Dataverse
entities (for example, contact information). Content is generally considered confidential
information, and in normal service operations, is not sent through the Internet without
encryption.

For more information on how Power Automate protects customer data, see the
Microsoft Online Services Trust Center .



Data segregation for Government Community
Cloud
When provisioned as part of Power Automate US Government, the Power Automate
service is offered in accordance with the National Institute of Standards and Technology
(NIST) Special Publication 800-145.

In addition to the logical separation of customer content at the application layer, the
Power Automate Government service provides your organization with a secondary layer
of physical segregation for customer content by using infrastructure that is separate
from the infrastructure used for commercial Power Automate customers. This includes
using Azure services in Azure’s Government Cloud. To learn more, see Azure
Government .

Customer content located within the United
States
Power Automate US Government runs in datacenters physically located in the United
States and stores customer content at rest in datacenters physically located only in the
United States.

Restricted data access by administrators
Access to Power Automate US Government customer content by Microsoft
administrators is restricted to personnel who are US citizens. These personnel undergo
background investigations in accordance with relevant government standards.

Power Automate support and service engineering staff do not have standing access to
customer content hosted in Power Automate US Government. Any staff who requests
temporary permission elevation, which would grant access to customer content must
first have passed the following background checks.

ﾉ Expand table

Microsoft Personnel Description
Screening and
Background Checks 1

U.S. citizenship Verification of U.S. citizenship

Employment history check Verification of seven (7) year employment history



Microsoft Personnel Description
Screening and
Background Checks 1

Education verification Verification of highest degree attained

Social Security number Verification that the SSN the employees provides is valid
(SSN) search

Criminal history check A seven (7) year criminal record check for felony and misdemeanor
offenses at the state, county, and local level and at the federal level

Office of Foreign Assets Validation against the Department of Treasury list of groups with
Control list (OFAC) whom U.S. persons are not allowed to engage in trade or financial

transactions

Bureau of Industry and Validation against the Department of Commerce list of individuals
Security list (BIS) and entities barred from engaging in export activities

Office of Defense Trade Validation against the Department of State list of individuals and
Controls Debarred Persons entities barred from engaging in export activities related to the
list (DDTC) defense industry

Fingerprinting check Fingerprint background check against FBI databases

CJIS background screening State-adjudicated review of federal and state criminal history by
state CSA appointed authority within each state that has signed up
for the Microsoft CJIS IA program

Department of Defense IT- Staff who request elevated permissions to customer data or
2 privileged administrative access to DoD SRG L5 service capacities

must pass DoD IT-2 adjudication, based on a successful OPM Tier 3
investigation.

1 Applies only to personnel with temporary or standing access to customer content
hosted in Power Automate US Governments (GCC, GCC High, and DoD).

Certifications and accreditations
Power Automate US Government is designed to support the Federal Risk and
Authorization Management Program (FedRAMP) accreditation at a High Impact level.
This program infers alignment to DoD DISA IL2. FedRAMP artifacts are available for
review by federal customers who are required to comply with FedRAMP. Federal
agencies can peruse these artifacts in support of their review to grant an Authority to
Operate (ATO).

７ Note



Power Automate is authorized as a service within the Azure Government FedRAMP
ATO. For more information, including how to access the FedRAMP documents,
review the FedRAMP Marketplace .

Power Automate US Government has features designed to support customers' CJIS
Policy requirements for law enforcement agencies. Visit the Power Automate US
Government products page in the Trust Center for more detailed information related to
certifications and accreditations.

Microsoft designed this platform and its operational procedures to meet the
requirements for the DISA SRG IL4 and IL5 compliance frameworks and has received the
requisite DISA Provisional Authorities to Operate. Microsoft anticipates that the US
Department of Defense contractor customer base and other Federal agencies currently
leveraging Microsoft Office 365 GCC High to use the Power Automate US Government
GCC High deployment option, which enables and requires customers to leverage
Microsoft Entra Government for customer identities, in contrast to GCC, which leverages
the public Microsoft Entra ID. For the US Department of Defense contractor customer
base, Microsoft operates the service in a manner that enables these customers to meet
ITAR commitment and DFARS acquisition regulations. Further, Microsoft expects its US
Department of Defense customers who currently use Microsoft 365 DoD to use the
Power Automate US Government DoD deployment option.

Power Automate US Government and other
Microsoft services
Power Automate US Government includes several features that allow users to connect
to, and integrate with, other Microsoft enterprise service offerings such as Office 365 US
Government, Dynamics 365 US Government, and Power Apps US Government.

Power Automate US Government runs within Microsoft datacenters in a manner
consistent with a multi-tenant, public cloud deployment model; however, client
applications including, but not limited to the web-user client, Power Automate mobile
application (when available), and any third-party client application that connects to
Power Automate US Government, are not part of Power Automate US Government's
accreditation boundary. Government customers are responsible for managing them.

Power Automate US Government leverages the Office 365 customer administrator UI for
customer administration and billing.

Power Automate US Government maintains the actual resources, information flow, and
data management, while relying on Office 365 to provide the visual styles that are



presented to the customer administrator through their management console. For
purposes of FedRAMP ATO inheritance, Power Automate US Government leverages
Azure (including Azure for Government and Azure DoD) ATOs for infrastructure and
platform services, respectively.

If you adopt the use of Active Directory Federation Services (AD FS) 2.0 and set up
policies to help ensure your users connect to the services through single sign-on, any
customer content that is temporarily cached will be located in the United States.

Power Automate US Government and third-
party services
Power Automate US Government provides the ability to integrate third-party
applications into the service through Connectors. These third-party applications and
services might involve storing, transmitting, and processing your organization’s
customer data on third-party systems that are outside of the Power Automate US
Government infrastructure and therefore are not covered by the Power Automate US
Government compliance and data protection commitments.

 Tip

Review the privacy and compliance statements provided by the third parties when
assessing the appropriate use of these services for your organization.

Power Apps and Power Automate Governance Considerations can help your
organization bring awareness about the capabilities available across several related
themes, such as architecture, security, alert and action, and monitoring.

Configure mobile clients
Here are the steps that you must take to sign in with the Power Automate mobile client.

1. On the sign-in page, select  (a wifi icon with a gear sign) in the upper-right
corner.

2. Select Region settings.
3. Select GCC: US Government GCC
4. Select OK.
5. On the sign-in page, select Sign in.



The mobile application will now use the US Government Cloud.

Power Automate US Government and Azure
Services
The Power Automate US Government services are deployed to Microsoft Azure
Government. Microsoft Entra is not part of the Power Automate US Government
accreditation boundary, but takes a reliance on a customer’s Microsoft Entra ID  tenant
for customer tenant and identity functions, including authentication, federated
authentication, and licensing.

When a user of an organization employing ADFS attempts to access Power Automate
US Government, the user is redirected to a login page hosted on the organization’s
ADFS server.

The user provides credentials to their organization's ADFS server. The organization's
ADFS server attempts to authenticate the credentials using the organization’s Active
Directory infrastructure.

If authentication is successful, the organization’s ADFS server issues a SAML (Security
Assertion Markup Language) ticket that contains information about the user’s identity
and group membership.

The customer’s ADFS server signs this ticket using one half of an asymmetric key pair
and then it sends the ticket to Microsoft Entra via encrypted TLS. Microsoft Entra ID
validates the signature using the other half of the asymmetric key pair and then grants
access based on the ticket.

The user's identity and group membership information remain encrypted in Microsoft
Entra ID. In other words, only limited user-identifiable information is stored in Microsoft
Entra ID.

You can find full details of the Microsoft Entra security architecture and control
implementation in the Azure SSP.

The Microsoft Entra account management services are hosted on physical servers
managed by the Microsoft Global Foundation Services (GFS). Network access to these
servers is controlled by GFS-managed network devices using rules set by Azure. Users
do not interact directly with Microsoft Entra ID.

Power Automate US Government service URLs



You use a different set of URLs to access Power Automate US Government
environments, as shown in the following table. The table includes the commercial URLs
too for contextual reference, in case they are more readily familiar to you.

ﾉ Expand table

Commercial version US Government version

https://flow.microsoft.com https://gov.flow.microsoft.us (GCC) ,
https://high.flow.microsoft.us (GCC High) , and
https://flow.appsplatform.us (DoD)

https://admin.powerplatform.microsoft.com/ https://gcc.admin.powerplatform.microsoft.us/
(GCC) ,
https://high.admin.powerplatform.microsoft.us/
(GCC High) , and
https://admin.appsplatform.us  (DoD)

https://flow.microsoft.com/connectors https://gov.flow.microsoft.us/connectors
(GCC) ,
https://high.flow.microsoft.us/connectors (GCC
High) ,
https://flow.appsplatform.us/connectors/
(DoD)

https://make.powerautomate.com https://make.gov.powerautomate.us (GCC) ,
https://make.high.powerautomate.us (GCC
High) , and
https://make.powerautomate.appsplatform.us
(DoD)

For those customers who implement network restrictions, ensure access to the following
domains is made available to your end-users’ access points:

GCC Customers:
.microsoft.us
.azure-apihub.us
.azure.us
.usgovcloudapi.net
.microsoftonline.com
.microsoft.com
.windows.net
.azureedge.net
.azure.net
.crm9.dynamics.com



.powerautomate.us

Refer to the IP ranges  for AzureCloud.usgovtexas and AzureCloud.usgovvirginia to
enable access to Dataverse instances that users and administrators may create within
your Tenant.

GCC High Customers:
.microsoft.us
.azure-apihub.us
.azure.us
.usgovcloudapi.net
.microsoftonline.us
.azureedge.net
.azure.net
.crm.microsoftdynamics.us(GCC High)
*.high.dynamics365portals.us (GCC High)
*.crm.appsplatform.us (DoD)
*.appsplatformportals.us (DoD)

Also, refer to the IP ranges  to enable you to access other Dataverse environments that
users and administrators may create within your tenant and other Azure services that
the platform leverages, including:

GCC and GCC High: Focus on AzureCloud.usgovtexas and
AzureCloud.usgovvirginia.
DoD: Focus on USDoD East and USDoD Central.

Connectivity between Power Automate US
Government and Public Azure Cloud services
Azure is distributed among multiple clouds. By default, tenants are allowed to open
firewall rules to a cloud-specific instance, but cross-cloud networking is different and
requires opening specific firewall rules to communicate between services. If you are a
Power Automate customer and you have existing SQL instances in azure public cloud,
which you need to access, you must open specific firewall ports in SQL to the Azure
Government Cloud IP space for the following datacenters:

USGov Virginia
USGov Texas
US DoD East



US DoD Central

Refer to the Azure IP Ranges and Service Tags – US Government Cloud  document,
focusing attention on AzureCloud.usgovtexas, and AzureCloud.usgovvirginia, and/or US
DoD East, and US DoD Central as noted previously in this article. Also note that these
are the IP ranges required for your end-users to have access to the service URLs.

On-premises Data Gateway configuration
Install an on-premises data gateway to transfer data quickly and securely between a
canvas app that's built in Power Automate and a data source that isn't in the cloud.
Examples include on-premises SQL Server databases or on-premises SharePoint sites.

If your organization (tenant) has configured and successfully connected the on-premises
data gateway for PowerBI US Government, then the process your organization followed
to enable that also enables on-premises connectivity for Power Automate.

Formerly, US Government customers needed to contact support before configuring their
first on-premises data gateway, because support would need to give permission to the
tenant to allow gateway use. This is no longer necessary. If you encounter any issues
configuring or using the on-premises data gateway, you may contact support for
assistance.

Power Automate US Government feature
limitations
Microsoft strives to maintain functional parity between our commercially available
service and those enabled through our US Government clouds. These services are
referred to as Power Automate Government Community Cloud (GCC) and GCC High.
Refer to the Global Geographic Availability  tool to see where Power Automate is
available throughout the world, including approximate availability timelines.

There are exceptions to the principle of maintaining product functional parity within the
US Government clouds. For more information about feature availability, download this
file: Business Applications US Government - Availability Summary .

See also
Desktop flows.

Dynamics 365 US Government.



Power Apps US Government.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Power Automate regions overview
Article • 10/08/2024

In Power Automate, your flows are created within your Microsoft Power Platform
environment. These environments are specific to a region, which corresponds to the
location of the data centers where your Microsoft Power Platform environment is stored.

In other words, your flows are deployed in the data center region  that hosts your
Microsoft Power Platform environment.

More information about Microsoft Power
Platform regions
Overview of Power Platform regions

Azure geographies

Region mappings for Power Automate and
gateways
The region where the gateway is installed must map to your Power Automate region.
Cross geographic boundaries aren't supported.

Here's the mapping information:

ﾉ Expand table

Power Platform Gateway region
region

Asia East Asia, Southeast Asia

Australia Australia East, Australia Southeast, Australia Central

Canada Canada Central, Canada East

Europe North Europe, West Europe

France France Central, France South

Germany Germany North, Germany West Central

India Central India, South India, West India, North India



Power Platform Gateway region
region

Japan Japan East, Japan West

Korea Korea South

Norway Norway East, Norway West

Singapore Southeast Asia, East Asia

South Africa South Africa North

South America Brazil South

Switzerland Switzerland North, Switzerland West

United Arab Emirates UAE Central, UAE North

United Kingdom UK South, UK West, UK East

United States Central US, East US, East US 2, East US 3, North Central US, South Central
including Preview US, West US, West US 2, West US 3, West Central US

Frequently asked questions

What region should I use?
It's a good idea to create your flow in an environment that's in the region closest to your
customers. When the data centers that host your environment are closer to the people
accessing the information, you're likely to see better performance.

How can I find out the region where my flow is deployed?
Administrators can identify the region by signing in to the Power Platform admin
center . The Environments tab lists all existing environments and their regions.

Is Power Automate available in national clouds?
Yes. Learn more.

What outbound IP addresses are used in each region?



Learn about outbound IP addresses in each region in Power Automate IP address
configuration.

Can region be changed?
A support case is needed to change environment region.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Limits of automated, scheduled, and
instant flows
Article • 02/11/2025

This article contains information about the limits that apply to automated, scheduled,
and instant flows, depending on which Power Automate license  you have.

Performance profiles
A flow's performance profile determines its Power Platform request limits. The following
table describes the plans that are associated with each of the four performance profiles.

Learn more about how Power Automate consumes Power Platform requests in Types of
Power Automate licenses - Power Platform requests.

ﾉ Expand table

Performance Plans
profile

Low - Free
- Microsoft 365 plans
- Power Apps Plan 1, Per App plans
- Power Automate Plan 1
- All license trials
- Dynamics 365 Team Member
- Microsoft Power Apps for Developer

Medium - Power Apps triggered flows, manual flows, child flows, Power Apps Plan 2,
Power Apps per user plan
- Power Automate Plan 2, Power Automate Premium (previously Power
Automate per user), Power Automate Premium plans (previously Power
Automate per user with Attended RPA plans)
Dynamics 365 Enterprise plans, Dynamics 365 Professional plans
- Dynamics 365 non-licensed users, application users, users with special free
licenses

High Power Automate Process plan, Power Automate per flow plan

Unlimited Pay-as-you-go flows, Dynamics in context flows running under service
Extended principal

If a user has multiple plans, such as a Microsoft 365 plan and a Dynamics 365 plan, the
flow has the performance profile of the higher of the plans. For the exact set of plans



that include Power Automate, refer to the Power Platform licensing guide .

To determine which plan you have, select Settings on the Power Automate title bar, and
then select View My Licenses.

A cloud flow uses the plan of its owner. If a cloud flow is shared with multiple people,
then generally the owner is the flow's creator. If you're unsure, you can use the Web API
to change the owner. If the original owner leaves the organization, the flow reverts to
the Low performance profile.

Flow definition limits
The following table describes the limits for a single flow definition.

ﾉ Expand table

Name Limit Notes

Actions per workflow 500 Flows with a large number of actions might encounter
performance issues while you edit them, even if they have
fewer than 500. Consider using child flows to reduce the
number of actions in a single flow or if you need more
than 500.

Allowed nesting 8 Add child flows if you need more than eight levels of
depth for actions nesting.

Switch scope cases 25
limit

Variables per 250
workflow



Name Limit Notes

Length of action  or 80
trigger  name characters

Characters per 8,192
expression

Length of 256
description characters

Maximum size of 16,000
trackedProperties characters

My flows limit
The following table describes the limit for the My flows and Team flows tabs.

ﾉ Expand table

Name Limit Notes

Number of flows owned by a single 600 Use flows under solutions if you need more than
user 600.

Duration and retention limits
The following tables describe the duration and retention limits.

Duration limits
The following table describes the duration limits for a single flow run.

ﾉ Expand table

Name Limit Notes

Run duration 30 days Run duration is calculated using a run's start time
and includes flows with pending steps like
approvals. After 30 days, any pending steps time
out.

Run retention 30 days Run retention is calculated using a run's start
in storage time.



Name Limit Notes

Minimum 60 seconds
recurrence
interval

Maximum 500 days
recurrence
interval

Minimum 5 seconds for Low, 1
postpone second for all other
interval performance profiles

Retention limits
The following table describes the limits on how long flows remain turned on before they
expire and get turned off.

ﾉ Expand table

Name Limit Notes

Flows with 14 days A cloud flow that has a trigger or actions that fail continuously is
errors turned off. Fix your trigger or actions and turn on the flow. These

flows have FlowSuspensionReason=AlwaysFailingDetected.

Not 90 days for A cloud flow that has no successful triggers expires and is turned
triggered free, trial, off. After 90 days of inactivity, the flow creator and co-owners
(dormant) community, receive an email. If no action is taken in next 30 days, the flow is
flows and systematically turned off, and the creator and co-owners are

Microsoft notified in an email. For enterprise scenarios, we recommend you
365 Plans. buy a standalone Power Automate license listed on Power
No Automate pricing  to ensure your flow isn’t turned off due to
expiration inactivity. You can turn your cloud flows back on anytime. These
limit for all flows have FlowSuspensionReason=NeverTriggeringDetected.
others.

Consistently 14 days A cloud flow that's consistently throttled for 14 days is turned off.
throttled The flow creator and co-creators get an email when the flow starts
flows throttling and when the flow is turned off. For enterprise scenarios,

we recommend you buy a standalone Power Automate license
listed on Power Automate pricing  to get higher action limits. You
can turn your cloud flows back on anytime.

Premium 14 days Flows that were created with premium features (premium
flows connectors, custom connectors, HTTP connectors, on premises
without gateway, and business process flows) but don't have a premium



Name Limit Notes

premium Power Automate license are turned off after 14 days. This situation
licenses happens if the original owner leaves the organization, or if they

have an expired trial or premium license. The flow owner and co-
owners get an email when the trial or premium license expires, or
when the owner isn't found in Microsoft Entra ID (Microsoft Entra
ID). The flow continues to work for 14 days. If a premium license
isn't assigned to the flow within 14 days, the flow is automatically
turned off, and the owner and co-owners are notified through
email. Newly created or edited premium flows without a premium
license are saved but turned off. Once a premium Power Automate
license is assigned to the owner or flow, you can turn on the flow.
Admins can find these flows. Assign a Power Automate Process
license or a per user license to the owner to keep the flow running.

Concurrency, looping, and debatching limits
The following table describes the concurrency, looping, and debatching limits for a
single flow run.

ﾉ Expand table

Name Limit Notes

Concurrent - Unlimited for flows This is the limit for how many runs a flow can have at
runs with Concurrency the same time.

Control turned off Note: Concurrency Control is set in the flow's trigger
- 1 to 100 when settings and is off by default. Turning on Concurrency
Concurrency Control Control can't be undone without deleting and re-
is turned on (defaults adding the trigger.
to 25)

Waiting runs - Not applicable when This limit describes the highest number of flow runs
Concurrency Control that can be queued when the flow is at its maximum
is off number of concurrent runs.
- 10 plus the degree Note: Additional triggers that arrive while the waiting
of parallelism (1-100) runs limit is met might be re-tried by the connector.
when Concurrency However, the retry attempts might not succeed if the
Control is on maximum waiting limit continues to be met for an

extended period of time. To ensure all triggers result in
flow runs, leave the Concurrency Control setting off in
the flow's trigger.

Apply to each 5,000 for Low, 100,000 This limit describes the highest number of array items
array item for all others that an "apply to each" loop can process.

To filter larger arrays, you can use the query action.



Name Limit Notes

Apply to each 1 is the default limit. This limit is highest number of "apply to each" loop
concurrency You can change the iterations that can run at the same time, or in parallel.

default to a value
between 1 and 50
inclusively.

Split on items - 5,000 for Low For triggers that return an array, you can specify an
without trigger expression that uses a 'SplitOn' property that splits or
concurrency debatches array items into multiple workflow instances
- 100,000 for all others for processing, rather than use a "Foreach" loop. This
without trigger expression references the array to use for creating and
concurrency running a workflow instance for each array item.
- 100 with trigger Note: When concurrency is turned on, the Split on limit
concurrency is reduced to 100 items.

Until - Default: 60
iterations - Maximum: 5,000

Paginated 5,000 for Low, 100,000 To process more items, trigger multiple flow runs over
items for all others your data.

Throughput limits
The following sections describe the time-bound limits for a single version of a cloud
flow definition. These limits apply across all runs of the flow version and are calculated
on sliding windows.

If a cloud flow exceeds one of the limits, flow activity is slowed. It automatically resumes
when the sliding window has activity below the limit. However, if a cloud flow
consistently remains above the limits for 14 days, it's turned off. Be sure to monitor
email for notifications about such flows. If a cloud flow consistently exceeds the limits,
you need to revise it to remain below the limits to prevent it from being turned off.

 Tip

Because these limits are for a single version, if you update your flow, it resets the
limits.

Power Platform request limits
As of October 2019, there are limits on the number of Power Platform requests an
account can make across all its flows, Power Apps, and any applications that call



Dataverse. No performance is guaranteed above these limits, although enforcement of
the limits isn't as strict during the licensing transition period. Learn more about request
limits and allocations.

These requests are counted for all types of actions, including connector actions, HTTP
actions, and built-in actions, from initializing variables to a simple compose action. Both
successful and failed actions count toward the limits. Retries and requests from
pagination also count as action runs.

To view the number of actions your flow has run, select Analytics on the flow details
page and check the Actions tab.

The following table describes the limits on requests.

ﾉ Expand table

Name Transition Notes
period limit

Power 100,000 Distribute the workload across more than one flow as
platform necessary.
requests per
5 minutes

Power 10,000 for Low; These limits represent approximations of how many requests
platform 200,000 for are allowed daily. They aren't guarantees. Actual amounts
requests per Medium; might be smaller, but are greater than the documented
24 hours 500,000 for request limits and allocations during the licensing transition

High; 10,000,000 period. The documented limits were substantially increased in
for Unlimited late 2021. View detailed Power Platform request usage
Extended information in the Power Platform admin center (preview). Any

potential enforcement of high usage based on the
documented limits doesn't start until six months after reports
are made generally available. Distribute the workload across
more than one flow as necessary.

Concurrent 500 for Low; You can reduce the number of concurrent requests or reduce
outbound 2,500 for all the duration as necessary.
calls others

 Tip

Individual connectors have their own limits, which often are reached before the
limits mentioned previously. Be sure to check the documentation for your
connector.



Runtime endpoint request limits
The runtime endpoint is the direct access URL for a given flow. It starts with something
like: https://prod-00.westus.logic.azure.com:443/ .

The following table describes the limits on runtime endpoint requests.

ﾉ Expand table

Name Limit Notes

Concurrent ~1,000 You can reduce the number of concurrent requests or reduce
inbound calls the duration as necessary.

Read calls per 5 6,000 for Low; This limit applies to calls that get the raw inputs and outputs
minutes 60,000 for all from a cloud flow's run history. You can distribute the

others workload across more than one flow as necessary.

Invoke calls per 4,500 for Low; You can distribute workload across more than one flow as
5 minutes 45,000 for all necessary.

others

Content throughput limits
The following table describes the content throughput limits, which refer to the amount
of data that is read from or written to the run history of the cloud flow.

ﾉ Expand table

Name Limit Transition period Notes
limits

Content 120 MB for Low; 1.2 Unchanged during You can distribute
throughput per 5 GB for all others transition period workload across more than
minutes one flow as necessary.

Content 200 MB for Low; 2 2.5 GB for Low; 20 GB You can distribute
throughput per GB for Medium; 10 for Medium; 50 GB for workload across more than
24 hours GB for High High one flow as necessary.

Gateway limits
Power Automate supports write operations, including inserts and updates, through the
gateway. However, these operations have limits on their payload size.



Request limits
The following sections describe the limits for a single outgoing or incoming HTTP call.

Timeout
Some connector operations make asynchronous calls or listen for webhook requests, so
the timeout for these operations might be longer than these limits. For more
information, refer to the technical details for the specific connector.

The following table describes the timeout limits.

ﾉ Expand table

Name Limit Notes

Outbound 120 seconds (2 Examples of outbound requests include calls made by HTTP
synchronous minutes) triggers.
request Tip: For longer-running operations, use an asynchronous

polling pattern or an "Until" loop. To work around timeout
limits when you call another flow that has a callable
endpoint, use the built-in action instead, which you can find
in the connector picker under Built-in.

Outbound Configurable
asynchronous up to 30 days
request

Inbound request 120 seconds (2 Examples of inbound requests include requests to trigger
minutes) instant flows and flows with the HTTP Request trigger.

Flows that contain a response action including Respond to
Copilot, HTTP Response, and Respond to a PowerApp or
flow always returns a response within this limit.
Child flows that are started before the response action
continue running separately, and actions after the response
action continue running beyond this limit, enabling a flow
to respond and continue running other operations.

If you test a cloud flow that runs for longer than 10 minutes, you might get a timeout
message in Power Automate, even though the flow continues to run in the background.
If this happens, reopen the view to receive the current status.

Message size
The following table describes the limits on message size.



ﾉ Expand table

Name Limit Notes

Message size 100 To work around this limit, consider allowing chunking under the action
MB content transfer settings. However, some connectors and APIs might

not support chunking or even the default limit.
Note: When you send files through a connector, the overall size of the
payload and not just the file needs to be under 100 MB.

Message size 1 GB This limit applies to actions that either natively support chunking or let
with chunking you enable chunking in their runtime configuration.

Character limits
The following table describes the limits on the number of characters in expressions and
request URLs.

ﾉ Expand table

Name Limit Notes

Expression 131,072 The @concat() , @base64() , and @string()  expressions
evaluation limit characters can't be longer than this limit.

Request URL 16,384
character limit characters

Retry policy
The following sections describe the limits on retries when a flow fails.

Default retry policy
The following table describes the default retry limits.

ﾉ Expand table

Performance Description
profile

Low This policy sends up to two retries at exponentially increasing intervals, which
scale by 5 minutes up to an interval of approximately 10 minutes for the last
retry.



Performance Description
profile

Medium, High This policy sends up to eight retries at exponentially increasing intervals, which
scale by 7 seconds up to an interval of approximately 15 minutes for the last
retry.

Retry setting limits
The following table describes the limits on retry settings.

To change the default settings, use the retry policy parameter.

ﾉ Expand table

Name Limit

Retry attempts 90

Retry maximum delay 1 day

Retry minimum delay 5 seconds

Learn more about retry policies.

Turn off or delete flows
When you turn off a cloud flow, no new runs are started. All in-progress and pending
runs continue until they finish.

When you delete a cloud flow, no new runs are started. All in-progress and pending
runs are canceled. If you have thousands of runs, cancellation might take significant time
to complete.

Custom connector limits
The following table describes the limits on custom connectors that you can create from
web APIs.

ﾉ Expand table

Name Limit Notes

Number of custom connectors 50 per user



Name Limit Notes

Number of requests per minute for a custom 500 requests per minute per
connector connection

You must have a premium or trial license to run any flow that uses a custom connector.

SharePoint limits
There are limitations on how you can use Microsoft SharePoint with Power Automate
and Power Apps.

 Tip

For detailed information about using SharePoint with Power Automate, go to the
SharePoint documentation.

IP addresses
Learn more in IP address configuration for Power Automate. Specific endpoint
information for desktop flows runtime is listed in this section.

Allowlist of namespaces endpoints required for
desktop flows runtime
By default, administrators need to authorize endpoints, including
*.servicebus.windows.net, to allow desktop flow runs. If you don't want to authorize this
public endpoint, you can alternatively allow all the following namespace endpoints.

７ Note

This list of namespace endpoints can evolve. Therefore, you should regularly check
this page to keep your authorized endpoints up to date.

ﾉ Expand table



URI Power Is
Platform preview
Region

prodnorwayeastmmrns-1-whuok7nwdzy2s.servicebus.windows.net Norway No

prodnorwaywestmmrns-1-oa47o5hk7gvoo.servicebus.windows.net Norway No

prdnorwayeastmmrns-V2-2- Norway No
krfr46pug63oqdbm1ts0nj7y6s.servicebus.windows.net

prdnorwaywestmmrns-V2-2- Norway No
zr6e9v54qli9y9uhjkko13uoh2.servicebus.windows.net

prodkoreacentralmmrns-1-4gkez6gmtnxxy.servicebus.windows.net Korea No

prodkoreasouthmmrns-1-o7ut2fobjmj7k.servicebus.windows.net Korea No

prdkoreacentralmmrns-V2-2- Korea No
7oogvhdpr45v1f7q2deylnb9.servicebus.windows.net

prdkoreasouthmmrns-V2-2- Korea No
7jvgkvkqli22srx9w3epmrdq8j.servicebus.windows.net

prdnzammrns-1- South Africa No
8vyvi02tfal5rjlmfsqvqs7dtx9ph4xegxxh.servicebus.windows.net

prdsouthafricawestmmrns-V2-2- South Africa No
vm94ckkkxsacbvjis6shh.servicebus.windows.net

prdnzammrns-1- South Africa No
8vyvi02tfal5rjlmfsqvqs7dtx9ph4xegxxh.servicebus.windows.net

prdsouthafricanorthmmrns-V2-2- South Africa No
h4fi6ckdkb13ngd42ov2.servicebus.windows.net

prdeusmmrns-3- United Yes
gh4xbnrswp4annlprgyqmdwyziat22jn2hmt.servicebus.windows.net States

prdeusmmrns-3- United Yes
ju5nmbisb8h7216w1o1md66mv77e0uh0gbqt.servicebus.windows.net States

previeweastusmmrns-1-fmkqes4e4ximc.servicebus.windows.net United Yes
States

previeweastusmmrns-2-HWd3f6eulXLM.servicebus.windows.net United Yes
States

previewwestusmmrns-1-uwbsm24d2qrgi.servicebus.windows.net United Yes
States

previewwestusmmrns-2-J5NRqQ0tPJ3n.servicebus.windows.net United Yes



URI Power Is
Platform preview
Region

States

prdeusmmrns-11- United No
u9pep9gw4ehrsgnxtu72spfhhrsmmgbom99.servicebus.windows.net States

prdeusmmrns-11- United No
vi712adqt8zhhekoz48g0rj96ahcs2lngln.servicebus.windows.net States

prdeusmmrns-12- United No
kkx3ko9h7a3q8fyzodjpc9s2n6l6emux4le.servicebus.windows.net States

prdeusmmrns-12- United No
p04f5v86v08h7bckioz41ml1nchtgged6jn.servicebus.windows.net States

prdeusmmrns-13- United No
mt5nm5ozm9y379uildo40xevuc7i6og9jib.servicebus.windows.net States

prdeusmmrns-13- United No
nsa7ru2qzbhpdbjkqn1xe0tr35y03igcvpg.servicebus.windows.net States

prdeusmmrns-16- United No
1httpeaxvd89sv9y92f3tsabapkcrsa2t8f.servicebus.windows.net States

prdeusmmrns-17- United No
3zk2vbt7quh9qmfd81la44igwcw2claddv8.servicebus.windows.net States

prdeusmmrns-17- United No
w641qe2st5y4iif6hts0p9xzo17m6yxzhc2.servicebus.windows.net States

prdeusmmrns-18- United No
cxlk5673wpp7ced81cdeykv71er75pkq2r0.servicebus.windows.net States

prdeusmmrns-19- United No
738isaepl448wtnw0210lqytrtiz4hvrzjf.servicebus.windows.net States

prdeusmmrns-20- United No
34ftg033c3iylghwgj16m3dqpccd4nbigp0.servicebus.windows.net States

prdeusmmrns-20- United No
fdacpnw20pftxqx9bmn7137pqrn5o1g4tnl.servicebus.windows.net States

prdwusmmrns-10- United No
1agsripqec30708vj3ithv3dp8lg5kr5s3n.servicebus.windows.net States

prdwusmmrns-10- United No
ebhaiy2tuf6jrr41h531fhdct7iu4v7idm4.servicebus.windows.net States

prdwusmmrns-14- United No



URI Power Is
Platform preview
Region

8pj3mtexc3t96c6to5denqxm2rq7w01s6nw.servicebus.windows.net States

prdwusmmrns-14- United No
u8lv1g6tp94vvp06h847g4zczi9s8fob3wu.servicebus.windows.net States

prdwusmmrns-15- United No
wrozqfemq1qibz5ykjjzjkpm5s80bogumtd.servicebus.windows.net States

prdwusmmrns-15- United No
xebdresepogmc40q3nznan4w1wvtooaa20k.servicebus.windows.net States

prdwusmmrns-16- United No
mphmqg4oagnzzci27l1sd5ggamvhr9vayx8.servicebus.windows.net States

prdwusmmrns-18- United No
cb9mb3sevtl0au7kvr5h7xft35nnzvaiby7.servicebus.windows.net States

prdwusmmrns-19- United No
zv1krgy2m185ioa8vk8dvqmc8omimizwew3.servicebus.windows.net States

prdwusmmrns-21- United No
naj2wt2tqebvv102pz8embfe50se1gdpb4i.servicebus.windows.net States

prdwusmmrns-21- United No
t5svpy06ve482zb6oljzrqdohkrfx42xvxz.servicebus.windows.net States

prdwusmmrns-23- United No
hisirbhw8e6hi1hdg37354tvv4rtyvosxui.servicebus.windows.net States

prdwusmmrns-23- United No
pflxh92egchq0oxbef9hy49s5p5eucq5oij.servicebus.windows.net States

prdwusmmrns-25- United No
8rz4j9842zpjqr8e7vrjjykzr3fnxypmad0.servicebus.windows.net States

prdwusmmrns-25- United No
ct38n2ulxz7081mttf5sha5n2kq2skl1sux.servicebus.windows.net States

prdwusmmrns-26- United No
cgqwgm01glorgvdrblvr9uzf80e45skb2xo.servicebus.windows.net States

prdwusmmrns-26- United No
o3ljq2nytljdghu6h1wqbpyqaxbiqbi4pte.servicebus.windows.net States

prdwusmmrns-27- United No
der2ntjxpz5i2uqshm9vznltkhngn06xlyg.servicebus.windows.net States

prdwusmmrns-28- United No



URI Power Is
Platform preview
Region

t4d8h0j42o6jjs2i2e3fm6fj30wy7j3k7ip.servicebus.windows.net States

prdwusmmrns-29- United No
9zr3xphm5vb2snbr9d8fay99ejze0ggwvue.servicebus.windows.net States

prdwusmmrns-29- United No
aerqzlinnqitgyqsa0lmh5lbrs1ady3nfck.servicebus.windows.net States

prdwusmmrns-34- United No
mmpbgjlfm4ydo3amtopfs2moy9b2zo1xoo8.servicebus.windows.net States

prdwusmmrns-34- United No
rp998x7g6h4lu5ksitso69xwvky5oh3cxfq.servicebus.windows.net States

prdwusmmrns-6- United No
04hdqdf3chg2n2t4siaal0v5hwqas9zbt6vx.servicebus.windows.net States

prdwusmmrns-6- United No
cwodfc8u8qqrqielru8w7ckyrj5le87q1ozi.servicebus.windows.net States

prdeusmmrns-22- United No
wsbpw23z70wq24aypvkvtlgbhzp0xe70ne2.servicebus.windows.net States

prdeusmmrns-22- United No
x6bcxy40pv2hpfpzrjx21ssdu8rvawtr8w8.servicebus.windows.net States

prdeusmmrns-24- United No
suv0kt1lf0ok7hua0ccogywp15p6kcx04x2.servicebus.windows.net States

prdeusmmrns-24- United No
y9wy0tcmsgspsjhf8ur7z08mjztmffq9goe.servicebus.windows.net States

prdeusmmrns-27- United No
8t7l05rslj7qwfsgxu18q3h7aypmztd5fdj.servicebus.windows.net States

prdeusmmrns-28- United No
0cprxw2r4q5sw0c94hcsf0dme1y4svhlm8o.servicebus.windows.net States

prdeusmmrns-3- United No
1fmod9del85tghiub70xfpgavep5tpqbixbq.servicebus.windows.net States

prdeusmmrns-3- United No
xgpjelrz4vp0e5dt2nnl8l29tiu6r3ksg174.servicebus.windows.net States

prdeusmmrns-30- United No
ft1ogu8rkhcami798vghm3lye1y9ca4nq6g.servicebus.windows.net States

prdeusmmrns-30- United No



URI Power Is
Platform preview
Region

v63cua3zd53b7dznsybo56mdb5112f30wlr.servicebus.windows.net States

prdeusmmrns-32- United No
1e8py596s9z03jv9brc4p1u89h9pr7ka52j.servicebus.windows.net States

prdeusmmrns-32- United No
91xx20kvkw12y878prtg9uq2z3a4nxcb4sh.servicebus.windows.net States

prdeusmmrns-33- United No
83pgwjs703eluiqyo20zgkqpi79y41w0zyj.servicebus.windows.net States

prdeusmmrns-33- United No
t46vqpf8wplhrjsp9yqfn1tzaoq1sft1tsm.servicebus.windows.net States

prdeusmmrns-4- United No
c31zz9l8qalw7h1pvr18glfxqptzq6ph34dl.servicebus.windows.net States

prdeusmmrns-4- United No
r2gcr4bg70k14spwohd1yeijpvstud3deq82.servicebus.windows.net States

prdeusmmrns-5- United No
3jof0fvvl3astjtfo2gikxpimouynog68o6r.servicebus.windows.net States

prdeusmmrns-5- United No
5x8c4o299zquku2yauz4yo813as2g22zhsf9.servicebus.windows.net States

prdeusmmrns-9- United No
6nsicrn14urv2cjs87z4955gptr3s0x8plbv.servicebus.windows.net States

prdeusmmrns-9- United No
rgbo8j4gzrecu7x89g76kxggt23lz58npwsm.servicebus.windows.net States

prdwusmmrns-7- United No
7tmen1irly7syq5c0fthjskb0lf1613g6ymt.servicebus.windows.net States

prdwusmmrns-7- United No
i48wrshewyk88q4s5kp39zrd498usidvd9z0.servicebus.windows.net States

prdwusmmrns-8- United No
jrn8ds8r8py7w4gi2wk1vpymyqkxionnli2s.servicebus.windows.net States

prdwusmmrns-8- United No
wwr2q3m9lkv3f49ondkfj3x8yc2iradok3pz.servicebus.windows.net States

prodeastusmmrns-1-plck7l3prc43s.servicebus.windows.net United No
States

prodeastusmmrns-2-uvq9wfwvvrbqg.servicebus.windows.net United No



URI Power Is
Platform preview
Region

States

prodwestusmmrns-1-3r77ocb7nmtak.servicebus.windows.net United No
States

prodwestusmmrns-2-wt88pe23kbp8g.servicebus.windows.net United No
States

prdeusmmrns-31- United No
awy3sb1iblyim8xdejbyg4xtt4revfqjai3.servicebus.windows.net States

prdeusmmrns-31- United No
bai0vj8wzgejcj6xzbukvvfcaqpiouccjmb.servicebus.windows.net States

prdwestusmmrns-V2-35- United No
9yojrmcrrhkvb3kgvbwdgcz6rxzi4.servicebus.windows.net States

prdwestusmmrns-V2-36- United No
ygezplol2wtqo6r23n0pn10t0sr6c.servicebus.windows.net States

prdwestusmmrns-V2-37- United No
w100sq07i1bthsjwwraneco5ovjz1.servicebus.windows.net States

prdwestusmmrns-V2-38- United No
83d3w34iag22wmmf614rz2oe25osj.servicebus.windows.net States

prdwestusmmrns-V2-39- United No
pw2nf6u8c7wzajiay6nulledljqq4.servicebus.windows.net States

prdwestusmmrns-V2-40- United No
7mkckny4vplgxa8t8nveqjyoddlsp.servicebus.windows.net States

prdwestusmmrns-V2-41- United No
mc8mpw4prh91b6yb91no6auastbna.servicebus.windows.net States

prdwestusmmrns-V2-42- United No
8qrayj6suic4dxzh0htqxjuzckfya.servicebus.windows.net States

prdwestusmmrns-V2-43- United No
58oef0oa78ogh9szchw8fhphy8n5x.servicebus.windows.net States

prdwestusmmrns-V2-44- United No
4x62nyqh5gerut8wpiuaqtixris04.servicebus.windows.net States

prdwestusmmrns-V2-45- United No
vkip2h4v74s1rfiq5tlgzqymw84ff.servicebus.windows.net States

prdwestusmmrns-V2-46- United No



URI Power Is
Platform preview
Region

l2iuzacshf2fgehpn9mt9lcwhqst5.servicebus.windows.net States

prdwestusmmrns-V2-47- United No
lsuvqs749alxtum82z2awd6u2tazu.servicebus.windows.net States

prdwestusmmrns-V2-48- United No
7vp2cw6tbzunj61sj54ljvv5k1gq3.servicebus.windows.net States

prdwestusmmrns-V2-49- United No
ukbo4afyvjnubzcov99qfjfrql2yb.servicebus.windows.net States

prdwestusmmrns-V2-50- United No
1cs26o00qnou1t313cgu9qhx75z2k.servicebus.windows.net States

prdwestusmmrns-V2-51- United No
ern8s3iyl7kz2tk23bg7tuw8glaba.servicebus.windows.net States

prdwestusmmrns-V2-52- United No
ogiekpkhbmhj2vfzz2epg7jdonhlx.servicebus.windows.net States

prdwestusmmrns-V2-53- United No
914rc4oqybob24rim6678py209ezy.servicebus.windows.net States

prdwestusmmrns-V2-54- United No
tgcafienq51kbhem2yvtn6oyg6iu5.servicebus.windows.net States

prdwestusmmrns-V2-55- United No
mm7e6ozjd3if2hkmo2m1u08xxeft7.servicebus.windows.net States

prdwestusmmrns-V2-56- United No
nzg387e1az6y3e5n8xew2wil5npdt.servicebus.windows.net States

prdwestusmmrns-V2-57- United No
leae8gnt9eomqn7eag51qhl9vrkc1.servicebus.windows.net States

prdwestusmmrns-V2-58- United No
5teg8uogvs3ymsuntyouhyihga77g.servicebus.windows.net States

prdwestusmmrns-V2-59- United No
situ7t5ki2ouao7qgh8cxuf2x9p9s.servicebus.windows.net States

prdwestusmmrns-V2-60- United No
0xvg3z3555dmlu76s9d9vy0ce93mq.servicebus.windows.net States

prdwestusmmrns-V2-61- United No
t2k9lvl1k4a8cj12ymqw1f2urlyqx.servicebus.windows.net States

prdeastusmmrns-V2-4- United Yes



URI Power Is
Platform preview
Region

0x7gx7q02cuwgkl01cj6yi1y643lr0.servicebus.windows.net States

prdeastusmmrns-V2-5- United Yes
xavi5w8ktgelbvo0pw66j5ynmqsdmr.servicebus.windows.net States

prdeastusmmrns-V2-6- United Yes
6bmlfsdr9ak2qt0gbsrrv7elo5nw0x.servicebus.windows.net States

prdwestusmmrns-V2-4- United Yes
867f0r3j4ezv0qq69iv8fz7a8fgv2c.servicebus.windows.net States

prdwestusmmrns-V2-5- United Yes
a2nsev8iww4mjnoxcdl7se6ep7r0z3.servicebus.windows.net States

prdwestusmmrns-V2-6- United Yes
7or97u45f1dgig81011b4gl4bnn1k1.servicebus.windows.net States

prdeastusmmrns-V2-64- United No
7yxummj5ggu50cszggpmk9bhn6die.servicebus.windows.net States

prdeastusmmrns-V2-65- United No
eirp8jk3iikkdi5jfmtjclv405twx.servicebus.windows.net States

prdeastusmmrns-V2-66- United No
8i47c1hfh2xeq2jzsgktsrb5nyv3x.servicebus.windows.net States

prdeastusmmrns-V2-67- United No
wvuupsoh1mdkxkuboloyfjc2n4ypr.servicebus.windows.net States

prdeastusmmrns-V2-68- United No
bnlo3xxsgqfv7afs2zjdhype672wa.servicebus.windows.net States

prdwestusmmrns-V2-66- United No
l3nf5sxu8syzo5tc1ealcfso0h1yl.servicebus.windows.net States

prdwestusmmrns-V2-67- United No
fqflahcd0nsvblzqc6as2rayw9d81.servicebus.windows.net States

prdwestusmmrns-V2-68- United No
f13samd2h5a9se2lq52aqw3fj9nkl.servicebus.windows.net States

prdwestusmmrns-V2-62- United No
p89r60qezeqi85kpxukusx7p4bq4o.servicebus.windows.net States

prdwestusmmrns-V2-63- United No
9zss4wcr5mz0h2s739jsa8xkf4b2a.servicebus.windows.net States

prdwestusmmrns-V2-64- United No



URI Power Is
Platform preview
Region

16jpbysgs1kefka1hq8odxyeao3rg.servicebus.windows.net States

prdwestusmmrns-V2-65- United No
qzuyklg01vkzintjoe4jd6c6k4v9m.servicebus.windows.net States

prdeastusmmrns-V2-58- United No
j9soi0y9likgttodbaduxk95kca42.servicebus.windows.net States

prdeastusmmrns-V2-59- United No
lxa51zcgb2uqw76dl8cfytbrzfgmw.servicebus.windows.net States

prdeastusmmrns-V2-60- United No
fddx9hsk2rqfs6qfp28b08co0tgxv.servicebus.windows.net States

prdeastusmmrns-V2-61- United No
glul50ja90cs99b2i33afqwwwwn9z.servicebus.windows.net States

prdeastusmmrns-V2-62- United No
7z0dmfgzxu61bgp1n4ylxa6myf1bt.servicebus.windows.net States

prdeastusmmrns-V2-63- United No
riflpzj44caie3ffbf8ql37t4uw44.servicebus.windows.net States

prdeastusmmrns-V2-40- United No
l40vv4fw7j84kkylaw7sgi5btmbsv.servicebus.windows.net States

prdeastusmmrns-V2-41- United No
b4e1d5quo208oz41ev8uuidvgx4mo.servicebus.windows.net States

prdeastusmmrns-V2-42- United No
f9xpybueng1ifjgxksl6yiu5jfc6a.servicebus.windows.net States

prdeastusmmrns-V2-43- United No
mm7zgyzthsh2gejykykq59caol9ui.servicebus.windows.net States

prdeastusmmrns-V2-44- United No
xwxq5qhmd2xananbtfmk5wsuhto9j.servicebus.windows.net States

prdeastusmmrns-V2-45- United No
jvitwflye80p003mqhy4tndv3opu0.servicebus.windows.net States

prdeastusmmrns-V2-46- United No
02w3igz0m2f2ixhbeghwjpu6mgldw.servicebus.windows.net States

prdeastusmmrns-V2-35- United No
pqmiztrnm758n2w2ixcgggyvw268r.servicebus.windows.net States

prdeastusmmrns-V2-36- United No



URI Power Is
Platform preview
Region

qvceaidputc674iz1wfuk6yq5l7pu.servicebus.windows.net States

prdeastusmmrns-V2-37- United No
67gv0wavysz7ged3iltaqdqkqntn4.servicebus.windows.net States

prdeastusmmrns-V2-38- United No
ep340abfrvn0i395xn3mouhjqpgp8.servicebus.windows.net States

prdeastusmmrns-V2-39- United No
dajlhp88bld5c02r82xfzr7z8ge9n.servicebus.windows.net States

prdeastusmmrns-V2-47- United No
urirei2x23vgwr8bjoh67et5j69ee.servicebus.windows.net States

prdeastusmmrns-V2-48- United No
zsxtyqwtlgr5oy3h3r91sjpkpntoc.servicebus.windows.net States

prdeastusmmrns-V2-56- United No
l9qqe1of3zg3fmkv6aazxbxugyb0h.servicebus.windows.net States

prdeastusmmrns-V2-51- United No
q732z9ssw5i8bfn678wg404ncqnj7.servicebus.windows.net States

prdeastusmmrns-V2-52- United No
1hk7nyzldwyuxz8wft3wxpwz49v2x.servicebus.windows.net States

prdeastusmmrns-V2-53- United No
h6vaxo6zz06g267jpyyn0cp3r81mt.servicebus.windows.net States

prdeastusmmrns-V2-54- United No
xha5q7i13wba2buxtyn78hlxu6rp5.servicebus.windows.net States

prdeastusmmrns-V2-55- United No
4bi6qgfmu7olfcnuh6lr32121r5he.servicebus.windows.net States

prdeastusmmrns-V2-57- United No
6tnrtyh5tvl593c33fe8rq4j9surl.servicebus.windows.net States

prdeastusmmrns-V2-49- United No
bv9at1w8ykynukqwbrx4ltmrpyd3v.servicebus.windows.net States

prdeastusmmrns-V2-50- United No
c9toid8pj41qyr0brftpypow5ep83.servicebus.windows.net States

prdwukmmrns-2- United No
655eda4qyw2sv8yoh48rvypa4cgywlbwcqhv.servicebus.windows.net Kingdom

prdwukmmrns-2- United No



URI Power Is
Platform preview
Region

vn35h7uhxr3nriaunptdudd0avl6nzhnglhr.servicebus.windows.net Kingdom

produksouthmmrns-1-cx4kejh3frvae.servicebus.windows.net United No
Kingdom

produkwestmmrns-1-ndmh2gqzqj6e4.servicebus.windows.net United No
Kingdom

prdukwestmmrns-V2-3- United No
pix6zz16y94l8lbbcad1woq8gbdq4g.servicebus.windows.net Kingdom

prduksouthmmrns-V2-3- United No
mnju2mj25hyj4ig3gp5uqpedwdo8h.servicebus.windows.net Kingdom

prdukwestmmrns-V2-4- United No
c07nmhjdwly1mqqyy4mfsw4eomli4x.servicebus.windows.net Kingdom

prduksouthmmrns-V2-4- United No
uagkjreb03usrqw5clyadknb5q529.servicebus.windows.net Kingdom

prodjapaneastmmrns-1-nafowbv7uqqzi.servicebus.windows.net Japan No

prodjapanwestmmrns-1-7fhv7yfs3b7oo.servicebus.windows.net Japan No

prdwjpmmrns-5- Japan No
alkrfltpxcxxjdgdvullh28wv064it08xh7p.servicebus.windows.net

prdwjpmmrns-6- Japan No
4zas09oyw0z88m15l32s4hqcfrlavchfpso8.servicebus.windows.net

prdwjpmmrns-6- Japan No
r9onumpa34h1abopfbtz7387zvqmwdk9yz52.servicebus.windows.net

prdwjpmmrns-7- Japan No
59gnwfs0axi99oh46nieh0amw9lz8rvkm0ev.servicebus.windows.net

prdwjpmmrns-7- Japan No
94nw9gtat4zpo97jcgudkgvc2ge48b2zdylb.servicebus.windows.net

prdwjpmmrns-9- Japan No
mf0gib6ot7yzs53fon9908m9abwa7tqlqmbf.servicebus.windows.net

prdwjpmmrns-9- Japan No
rysrv03djr8ojnp0e0lo60k6fp0ppa8aka9z.servicebus.windows.net

prdwjpmmrns-3- Japan No
jrzvs2jn2wfqhqdm78w4opp4j07woaerh9a4.servicebus.windows.net



URI Power Is
Platform preview
Region

prdwjpmmrns-13- Japan No
dz20gg7ban7335qy3uuu2bhdokzhqguluxi.servicebus.windows.net

prdwjpmmrns-5- Japan No
183yd443d6abopy05eqhnx6ppzgdlz9cg0lw.servicebus.windows.net

prdwjpmmrns-2- Japan No
z1iyi9x93h8a5p2rf0bxpa3xkr3s1st0shem.servicebus.windows.net

prdwjpmmrns-2- Japan No
zwl9wqzfhhuj8de04s6iyo320gmvbshaqwpr.servicebus.windows.net

prdwjpmmrns-15- Japan No
mzoitgrmkb9x8qt7shqm1a3ad3t45qb3l75.servicebus.windows.net

prdwjpmmrns-3- Japan No
h62j5nlty1v9x4auvdejpwe7ngo3lsgau6fb.servicebus.windows.net

prdejpmmrns-14- Japan No
osbksh1kc2h9bc5zynk6485ttm162r7qmb8.servicebus.windows.net

prdejpmmrns-15- Japan No
tovckjt2c987eih8021ez4pa1hrwcrd3043.servicebus.windows.net

prdejpmmrns-4- Japan No
0bq94lkcwh89ljh00y238hjallak9rtw5mwo.servicebus.windows.net

prdejpmmrns-4- Japan No
8ox2iqi1zw8g4g6npao62epqsif70pxqwhlt.servicebus.windows.net

prdejpmmrns-8- Japan No
rja3avsyaksfqqkfmsxejpt1f5gw0l5rjhek.servicebus.windows.net

prdejpmmrns-8- Japan No
yqkn1hnj6urmthhsi2nd3r6tmacw06k6s0xl.servicebus.windows.net

prdwjpmmrns-10- Japan No
i4t18vcq6bymi0q41ct6l9omrsmpu1xb66q.servicebus.windows.net

prdwjpmmrns-11- Japan No
db2a6de90pl6bqjuorg331y7hwlt3ksb9je.servicebus.windows.net

prdwjpmmrns-13- Japan No
yctdcx8q7te9y7q36umn9nrp6cxdss5gd6t.servicebus.windows.net

prdejpmmrns-10- Japan No
bstijlyba2qkct0t5sre5vfbtr0k3r2756i.servicebus.windows.net



URI Power Is
Platform preview
Region

prdejpmmrns-11- Japan No
j5a9t7g5ye30tcbyr3qeylocw36g4fw5jiz.servicebus.windows.net

prdejpmmrns-12- Japan No
pje8gv6enxklxo1fuhiztzlpxdf6hrn0y5c.servicebus.windows.net

prdejpmmrns-12- Japan No
xzbymnq8jbxzzf8rw0gd9amryk5y0sqkuhi.servicebus.windows.net

prdejpmmrns-14- Japan No
j9jags4umi7jkuje9a7syf8wo9wrk9p1sma.servicebus.windows.net

prdjapanwestmmrns-V2-22- Japan No
cc3hqdic1qtkcbjunlkau1xhcj.servicebus.windows.net

prdjapaneastmmrns-V2-16- Japan No
3u0n4qybma9gm458dcljua1lgg.servicebus.windows.net

prdjapaneastmmrns-V2-17- Japan No
ugpm8yigk1hcbkjptbqsz7tkzh.servicebus.windows.net

prdjapaneastmmrns-V2-18- Japan No
wajxi5464611wdiz2icaoscdum.servicebus.windows.net

prdjapaneastmmrns-V2-19- Japan No
6cnmtsx3o9an43slncs8kx8u3m.servicebus.windows.net

prdjapaneastmmrns-V2-20- Japan No
nyln4xrnf62gfy4mp44f0peo2v.servicebus.windows.net

prdjapaneastmmrns-V2-21- Japan No
pljfc1cnc4ie8xfki5d5q5af9o.servicebus.windows.net

prdjapaneastmmrns-V2-22- Japan No
d184ecglhplm3grf2mb3tr19j4.servicebus.windows.net

prdjapanwestmmrns-V2-16- Japan No
dwz439851f3hext8w186412q29.servicebus.windows.net

prdjapanwestmmrns-V2-17- Japan No
5a65ic1lt0ml4rjy49pcycy4dt.servicebus.windows.net

prdjapanwestmmrns-V2-18- Japan No
r9k6oblb8niz7rri9q5zk84baz.servicebus.windows.net

prdjapanwestmmrns-V2-19- Japan No
xyvjl78qwp2jp572yqxpx8hckb.servicebus.windows.net



URI Power Is
Platform preview
Region

prdjapanwestmmrns-V2-20- Japan No
asapau6qmt86l1vw8ov5onqvtc.servicebus.windows.net

prdjapanwestmmrns-V2-21- Japan No
3y18tudg2lxt46v7flp1enxdmx.servicebus.windows.net

prdsinmmrns-2- India No
yg3uf3bg2tx76131363l5twjngscb68cdztl.servicebus.windows.net

prdcinmmrns-3- India No
wnn89ixhem8i605q4edtwo9r8r0t2796kx3d.servicebus.windows.net

prdsinmmrns-2- India No
rdf8f0ew8d30vxdo2y9l17npmi44q7s6w7z9.servicebus.windows.net

prdcinmmrns-3- India No
t2y6tdtbryy4k4c1l4tffmdx0b7k4ikerkaa.servicebus.windows.net

prodsouthindiammrns-1-7kqjp7tvfvvku.servicebus.windows.net India No

prodcentralindiammrns-1-h34hrnss44v7s.servicebus.windows.net India No

prdcentralindiammrns-V2-4- India No
ee92anj5viy0erkmknu4ct03.servicebus.windows.net

prdcentralindiammrns-V2-5- India No
m3oh8k94epa6ftlnj15v12ti.servicebus.windows.net

prdcentralindiammrns-V2-6- India No
1kxdtzdle2v85f11noj58sda.servicebus.windows.net

prdsouthindiammrns-V2-4- India No
e41a018a0nkeypn3wmmo4tc7hg.servicebus.windows.net

prdsouthindiammrns-V2-5- India No
csu0sz9mtazr236ey7adgfpfrv.servicebus.windows.net

prdsouthindiammrns-V2-6- India No
p0cf9pk42vxyzri7tmo2bcxue0.servicebus.windows.net

prodfrancecentralmmrns-1-xzhxhbzl7vhc6.servicebus.windows.net France No

prodfrancesouthmmrns-1-xorsknhtb2lm2.servicebus.windows.net France No

prdfrancecentralmmrns-V2-2- France No
ey8pb34ahkh5lww22p4fbjy.servicebus.windows.net

prdfrancesouthmmrns-V2-2- France No



URI Power Is
Platform preview
Region

mpm8f0c4822ei4rs4lop2y3vi.servicebus.windows.net

prdweummrns-26- Europe No
ldz8cnwwyocr0ejev8xvyhiezuxmdq1yxqk.servicebus.windows.net

prdweummrns-6- Europe No
715t9odrb0d5xqu9mcvl95tl3vss0h4ywvql.servicebus.windows.net

prdweummrns-6- Europe No
k903fojp2zajhe9m2uy026gmd8o92j7egocc.servicebus.windows.net

prdweummrns-7- Europe No
ieo6v7w85hvc7kfspwkn5iwga4sfx906lb4n.servicebus.windows.net

prdweummrns-7- Europe No
mxvjm5wdlp57s36i1tnari51ork5qz16q1f2.servicebus.windows.net

prdweummrns-9- Europe No
igv6i1ythpy1wz7sayq1fvnxh5bkakwz06i3.servicebus.windows.net

prdweummrns-9- Europe No
ngzlxpwmf83v36kz9qf7xlnexgbf5v8fpggk.servicebus.windows.net

prodnortheuropemmrns-1-jc3usmvyk4wcy.servicebus.windows.net Europe No

prodnortheuropemmrns-2-y9bgs3kphntyf.servicebus.windows.net Europe No

prodwesteuropemmrns-1-il3kcpbupz3gm.servicebus.windows.net Europe No

prodwesteuropemmrns-2-p1m53clst99fe.servicebus.windows.net Europe No

prdneummrns-10- Europe No
dfsba8r6fetlj0naynltmekwrx8s8mgbb26.servicebus.windows.net

prdneummrns-10- Europe No
xlb6mnbn4oo6i2836ys0z23370t9qmg1z8v.servicebus.windows.net

prdneummrns-11- Europe No
4h432bhqewib20lftea3c7xrlmuzr8a66pc.servicebus.windows.net

prdneummrns-11- Europe No
fc9x0e1i5yf1rb37iug3bend5k0v32rq59k.servicebus.windows.net

prdneummrns-12- Europe No
q8mb2fc6q3h1kuct9tvxhya46eyuso4e8iz.servicebus.windows.net

prdneummrns-12- Europe No
qfegk9w902b6b3difrniuhv2hyo9lug1yxk.servicebus.windows.net



URI Power Is
Platform preview
Region

prdneummrns-15- Europe No
2wuay5ujwfhkb3tkk4tt05g6qj7k5p3jkve.servicebus.windows.net

prdneummrns-15- Europe No
xxqly3x8p04ydglxhb8p7pyup7jngl8apy5.servicebus.windows.net

prdneummrns-17- Europe No
6ku1rh49w81ofdmrr3c5bo8ssui68zbozjl.servicebus.windows.net

prdneummrns-17- Europe No
argn0agthuw69l4njzblsmbi697b77nz62l.servicebus.windows.net

prdweummrns-13- Europe No
3d8l3g60vj020rzpnv0vb7hrk348wymi9fb.servicebus.windows.net

prdweummrns-13- Europe No
xvjnyxshe38m9o8bwp8axrxoqlg4tjbyrle.servicebus.windows.net

prdweummrns-14- Europe No
m17rqz9zbhu9d98tttthmxy4no6ou21268v.servicebus.windows.net

prdweummrns-14- Europe No
oz7piy3p711feggc608fa8isdynyis8sffv.servicebus.windows.net

prdweummrns-16- Europe No
2rhp0evcj8avmcvwzdls9r4n8byctxnyb7p.servicebus.windows.net

prdweummrns-16- Europe No
soafhbsvtlwquwzxi03onf8oa25f93kcboi.servicebus.windows.net

prdweummrns-19- Europe No
yeh6wlbkp1av8roke94xgi3iqpx2a3xtvj9.servicebus.windows.net

prdweummrns-20- Europe No
jfd262oyt2s5i2m9afvhmmn7oh8m9ylt87t.servicebus.windows.net

prdweummrns-20- Europe No
kb4j7ljpdtkqjzzd1cf2y7ud79apid1azpx.servicebus.windows.net

prdweummrns-22- Europe No
roua85rgg4d3omi9cnq0gm3q5ykjej2fp48.servicebus.windows.net

prdweummrns-23- Europe No
pxf43dpfsyd3m6dqldszf6735fqy419mxw8.servicebus.windows.net

prdweummrns-24- Europe No
ho7hs6f61184mawfirly3xohh3hqtwm7cpv.servicebus.windows.net



URI Power Is
Platform preview
Region

prdweummrns-25- Europe No
czz7mnkehsuki22mmitllf8mo7klfqwpkkg.servicebus.windows.net

prdneummrns-18- Europe No
6e9asgh3q54wug2g85c7dvtwysx5vg38qn4.servicebus.windows.net

previewnortheuropemmrns-1-ny3jbez7yclw4.servicebus.windows.net Europe Yes

previewwesteuropemmrns-1-pli5p5xheu4lc.servicebus.windows.net Europe Yes

prdneummrns-18- Europe No
6ycvn49mc7zhbshadks0tfjwjg6g1q9f6g2.servicebus.windows.net

prdneummrns-19- Europe No
0pfazhfb4vytcl52r6dryrgi71aufv5pw14.servicebus.windows.net

prdneummrns-21- Europe No
rx2d4tdu9zyhb9br9n6v06xhlnyd9em854v.servicebus.windows.net

prdneummrns-21- Europe No
y72fn30ujex4govc1yzvpvyp2j782gd2zwc.servicebus.windows.net

prdneummrns-22- Europe No
xzhu3hmk0w19hprhbce39d18b5lioem8ywk.servicebus.windows.net

prdneummrns-23- Europe No
1jsqh281qvmjp09kut3auw06bad16ht2z6f.servicebus.windows.net

prdneummrns-24- Europe No
est7ogob7mhkjqygi9fncj64cp1f92olgkx.servicebus.windows.net

prdneummrns-25- Europe No
l16teela0xo5gj401u2bqjx8lvevpkv4yy5.servicebus.windows.net

prdneummrns-26- Europe No
6v8e6mten7nvn78qpgfrke2ogedjedwxdqe.servicebus.windows.net

prdneummrns-3- Europe No
ijnvx1ne9xr4cdg4boj0ko17o6r0mo01fxry.servicebus.windows.net

prdneummrns-3- Europe No
w7wi2kmzbqlyhbgz8or8ccsv6dt4kcq7wng4.servicebus.windows.net

prdneummrns-4- Europe No
6eadpq66lmsng2z3qfbt5h0dz8y1ev1g7f9f.servicebus.windows.net

prdneummrns-4- Europe No
saphm2ye8z0dvr0cjifyo7nq1e20umpb3ulp.servicebus.windows.net



URI Power Is
Platform preview
Region

prdneummrns-5- Europe No
2ksg36axkdor8krdojxudtq9kaylps6amcf0.servicebus.windows.net

prdneummrns-5- Europe No
qphyin8kfcgypsb7b6wjf6lxijd8v3xx2of9.servicebus.windows.net

prdneummrns-8- Europe No
ieav13ew8673n0h1okr1ehlg65hr90vzwq57.servicebus.windows.net

prdneummrns-8- Europe No
o2j51ngtrr5uevmw8af9jfpnz8ycydpghlv5.servicebus.windows.net

prdwesteuropemmrns-V2-29- Europe No
w9862tvv9uythyjg9r01qil6s.servicebus.windows.net

prdwesteuropemmrns-V2-30- Europe No
h9hg4sx9g24al243oy48041bv.servicebus.windows.net

prdwesteuropemmrns-V2-31- Europe No
hk40s1sgeyz3gnl94d18j6gjb.servicebus.windows.net

prdwesteuropemmrns-V2-32- Europe No
269lf3o8gruyxgq3oeytc9b1k.servicebus.windows.net

prdwesteuropemmrns-V2-33- Europe No
gwo4l5zh4e92fsvgkys9dpoi0.servicebus.windows.net

prdwesteuropemmrns-V2-34- Europe No
8fwip55lhldk5brxune2zp5el.servicebus.windows.net

prdwesteuropemmrns-V2-42- Europe No
oljf96sfrmuxqpeid4ts04opq.servicebus.windows.net

prdwesteuropemmrns-V2-35- Europe No
yvjsbpymqy15c64fim2e0sgin.servicebus.windows.net

prdwesteuropemmrns-V2-36- Europe No
u72st7yjqvbccejiks6mbw6xy.servicebus.windows.net

prdwesteuropemmrns-V2-37- Europe No
z6479bvg0redxmeionnp1glwe.servicebus.windows.net

prdwesteuropemmrns-V2-38- Europe No
srn8subki2xzoafw0u15manv2.servicebus.windows.net

prdwesteuropemmrns-V2-39- Europe No
mzwc5obnkbwgdmf43kunjqj0x.servicebus.windows.net



URI Power Is
Platform preview
Region

prdwesteuropemmrns-V2-40- Europe No
tkypm6qg1h80di5f3z8sxbl9o.servicebus.windows.net

prdwesteuropemmrns-V2-41- Europe No
l6alycm6v76vr7lk692e99m89.servicebus.windows.net

prdwesteuropemmrns-V2-43- Europe No
gniz6cwl3bj0wolnfpyxxcrni.servicebus.windows.net

prdnortheuropemmrns-V2-43- Europe No
bnzmk7yw7ovun3dvscvg1ps3.servicebus.windows.net

prdwesteuropemmrns-V2-27- Europe No
sdxs8kpou1ymj71wyp907zmlj.servicebus.windows.net

prdnortheuropemmrns-V2-31- Europe No
dcqi9v8o0haz0b2fsdbh9aau.servicebus.windows.net

prdnortheuropemmrns-V2-27- Europe No
sok4f6mpwbmm8sq92t7matlu.servicebus.windows.net

prdnortheuropemmrns-V2-32- Europe No
r619ji6q6pf4xqppmof6ccvb.servicebus.windows.net

prdnortheuropemmrns-V2-33- Europe No
credxaax6n3542hpvb0fjgrm.servicebus.windows.net

prdnortheuropemmrns-V2-34- Europe No
95vbolmzsywv1ieqgvw21980.servicebus.windows.net

prdnortheuropemmrns-V2-35- Europe No
3be6udc31v261pyu3s5f20ow.servicebus.windows.net

prdnortheuropemmrns-V2-36- Europe No
1fez4d7eu22p1vgtkw9wkvip.servicebus.windows.net

prdnortheuropemmrns-V2-37- Europe No
txqy5uktu2fco5w62eo9jfh5.servicebus.windows.net

prdnortheuropemmrns-V2-38- Europe No
vi70m67wn4q99j8btm80wzy6.servicebus.windows.net

prdnortheuropemmrns-V2-39- Europe No
11tdmg71hg91a27bojbrsxsc.servicebus.windows.net

prdnortheuropemmrns-V2-40- Europe No
oczrsc5wx0vn68blgsahxibi.servicebus.windows.net



URI Power Is
Platform preview
Region

prdnortheuropemmrns-V2-41- Europe No
kt2dvss1iymweq51myzovdjy.servicebus.windows.net

prdnortheuropemmrns-V2-42- Europe No
anpfzeh6irytj397emkjcgxx.servicebus.windows.net

prdnortheuropemmrns-V2-44- Europe No
s4z883nis6r7ojk64uy5do60.servicebus.windows.net

prdwesteuropemmrns-V2-28- Europe No
dz1xl3q5hieatveth3pxhfj87.servicebus.windows.net

prdwesteuropemmrns-V2-44- Europe No
rex1ejrmnhnpn1jtkfocn3rvy.servicebus.windows.net

prdnortheuropemmrns-V2-28- Europe No
gwhxf94sdepv464u9sf4e2r5.servicebus.windows.net

prdnortheuropemmrns-V2-29- Europe No
cjwdz6e4eyw0tuvmu29fv4v5.servicebus.windows.net

prdnortheuropemmrns-V2-30- Europe No
8d8fsnxlukj5kj0i72k7c97y.servicebus.windows.net

prdndemmrns-2- Germany No
go7xeqf077mt2vuq4dyth0gwfm9s2aemmjm9.servicebus.windows.net

prdndemmrns-2- Germany No
yqlb2eueujjpuxauq3us19ia6pboepamtmdh.servicebus.windows.net

prodgermanynorthmmrns-1-q7unzu7nsvdxg.servicebus.windows.net Germany No

prodgermanywestcentralmmrns-1- Germany No
zqcmawxslzfbi.servicebus.windows.net

prdgermanynorthmmrns-V2-3- Germany No
nx19493gwmdkl77m937j6hzi.servicebus.windows.net

prdgermanywestcentralmmrns-V2-3- Germany No
kqsb9hxeyg46m8n14r.servicebus.windows.net

prdnchmmrns-2- Switzerland No
6aufi5bwfag8r54td32bjj8bpl845eagkz2y.servicebus.windows.net

prdnchmmrns-2- Switzerland No
d8hfqw2v8niumsl2jaqjrqq4lhp10rvjnjc9.servicebus.windows.net

prodswitzerlandnorthmmrns-1-2d2uums4njavc.servicebus.windows.net Switzerland No



URI Power Is
Platform preview
Region

prdswitzerlandnorthmmrns-V2-3- Switzerland No
pvisj74nv8loqz4tmn17.servicebus.windows.net

prdswitzerlandwestmmrns-V2-3- Switzerland No
x9re2bnt17mpe41zn2tp1.servicebus.windows.net

prodswitzerlandwestmmrns-1-n3jwwj2am7fgy.servicebus.windows.net Switzerland No

prdccammrns-2- Canada No
8s6kb0vay4f0koa6jsws726gyns43uh4591e.servicebus.windows.net

prdecammrns-2- Canada No
ginyhguvgct78u1knii7f1m6vfrsubf8gr8f.servicebus.windows.net

prodcanadacentralmmrns-1-r7keih3ctpbo4.servicebus.windows.net Canada No

prodcanadaeastmmrns-1-vmq2eniku7w3e.servicebus.windows.net Canada No

previewcanadacentralmmrns-1-s4wweqcy62z32.servicebus.windows.net Canada Yes

previewcanadaeastmmrns-1-35pw2xpwvfyrq.servicebus.windows.net Canada Yes

prdcanadacentralmmrns-V2-6- Canada No
c082k61uzumunkg4r7r9b0q.servicebus.windows.net

prdcanadaeastmmrns-V2-6- Canada No
cb9ej0r35jbk52finxcr1nc9h4.servicebus.windows.net

prdcanadacentralmmrns-V2-3- Canada No
vl607weynuziswx7c1h8ift.servicebus.windows.net

prdcanadacentralmmrns-V2-4- Canada No
8fh11lit8oc1nkfr4bg5ujf.servicebus.windows.net

prdcanadacentralmmrns-V2-5- Canada Yes
lnfn39ay9gmssh4kdp5o8ce.servicebus.windows.net

prdcanadaeastmmrns-V2-3- Canada Yes
j5vwggt3rb5dbv39942w21uh6i.servicebus.windows.net

prdcanadaeastmmrns-V2-4- Canada Yes
0iq6u9cwlu138ef5i67sjykca9.servicebus.windows.net

prdcanadaeastmmrns-V2-5- Canada Yes
70iiq4ryuvmy6l3jyacmyj6k1d.servicebus.windows.net

prdsbrmmrns-2- South No
69n5a3ojd4crv4qpj93l0vi9xwul5qygykqu.servicebus.windows.net America



URI Power Is
Platform preview
Region

prdsbrmmrns-2- South No
gh3flzhrf9ax9glm87xs23dxrykcuoakpics.servicebus.windows.net America

prdsbrmmrns-3- South No
4ex758s96an2i2hfd1ypws4s59qre3fruvb5.servicebus.windows.net America

prdsbrmmrns-3- South No
ufhjfys24383anexi9oioic5z8ub5smb3ogo.servicebus.windows.net America

prodbrazilsouthmmrns-1-duxgufn3xsxm6.servicebus.windows.net South No
America

prodsouthcentralusmmrns-1-v2gwsxxmesfkw.servicebus.windows.net South No
America

prdbrazilsoutheastmmrns-V2-4- South No
w9t5y3wmh9rcrv5x6sh1z.servicebus.windows.net America

prdbrazilsoutheastmmrns-V2-5- South No
2zrb3wwtelahcjumgb63m.servicebus.windows.net America

prdbrazilsouthmmrns-V2-4- South No
kvwoyt51n45knkl8fiigga5sl.servicebus.windows.net America

prdbrazilsouthmmrns-V2-5- South No
etonhht5qkuj13txix4zdull3.servicebus.windows.net America

prdeaummrns-2- Australia No
if84st2om5meh741f8vanxwcz07mnq6vgpgz.servicebus.windows.net

prdeaummrns-2- Australia No
z1cqmm14ao5gt1nqpqx9llazq1vd0dg8418w.servicebus.windows.net

prdseaummrns-3- Australia No
5gveu7rksy51oh4rfx54fbc4qt5qc8502bh.servicebus.windows.net

prdseaummrns-3- Australia No
aiqa1jis4kacxb46aqyb0n01gvih0zuwctd.servicebus.windows.net

prodaustraliaeastmmrns-1-broykyq53frty.servicebus.windows.net Australia No

prodaustraliasoutheastmmrns-1- Australia No
g7yhvdys4yu2s.servicebus.windows.net

previewaustraliaeastmmrns-1-e5g6njcwtfobg.servicebus.windows.net Australia Yes

previewaustraliasoutheastmmrns-1- Australia Yes
onma5d3r2tevi.servicebus.windows.net



URI Power Is
Platform preview
Region

prdaustraliaeastmmrns-V2-4- Australia No
i1p40k20qtbf1w763m2pfyw.servicebus.windows.net

prdaustraliaeastmmrns-V2-5- Australia No
o70p1sirgcvbjjwfx821wih.servicebus.windows.net

prdaustraliasoutheastmmrns-V2-4- Australia No
gk4psheqriftcd9c7y.servicebus.windows.net

prdaustraliasoutheastmmrns-V2-5- Australia No
4kp3u28uu4godpvvfz.servicebus.windows.net

prdeasmmrns-2- Asia No
1lngpyk311cxsmgr513wlgj053ezi6lj2eks.servicebus.windows.net

prdeasmmrns-2- Asia No
bmrbhomvn76odohg3wy43lmaj8i3y2lyfdif.servicebus.windows.net

prdeasmmrns-6- Asia No
dy3qfh1dr2jlqy20o7q5jpgx8i5f7f4lutsv.servicebus.windows.net

prdeasmmrns-7- Asia No
imtver1279xmke7qe3s57b3l80a6tf1bf1l7.servicebus.windows.net

prdeasmmrns-7- Asia No
r96lkkijqfgi4e7ujfnp4wb5s9msitwar29g.servicebus.windows.net

prdseasmmrns-3- Asia No
dj4e6cmp72khzsmxzrna6i7twn3i9z8la04.servicebus.windows.net

prdseasmmrns-3- Asia No
o8i3mkmfo6n3xt40j91ps6bh51kysnejk5r.servicebus.windows.net

prdseasmmrns-4- Asia No
02brgu6vvf454a96wtwaq4sza2uvgaze5m8.servicebus.windows.net

prdseasmmrns-4- Asia No
tvhxmw4xs4voyhiafd0wyj7rzj3nzslx8in.servicebus.windows.net

prdseasmmrns-5- Asia No
97zsx33ra6s2esktyr6pnj4hp9ppnl4zkmu.servicebus.windows.net

prdseasmmrns-5- Asia No
yuj2dcu7yyw305zlob38zdrdynodyc2s27w.servicebus.windows.net

prdseasmmrns-6- Asia No
2ubnk0mpzbeng7m3465wmvxbdkqozp7e9ig.servicebus.windows.net



URI Power Is
Platform preview
Region

prodeastasiammrns-1-a7p5u2p76nykc.servicebus.windows.net Asia No

prodsoutheastasiammrns-1-2zisdacd3p4yq.servicebus.windows.net Asia No

prdsoutheastasiammrns-V2-10- Asia No
ss3rst3qe8pnqi12byefko.servicebus.windows.net

prdsoutheastasiammrns-V2-11- Asia No
fegbzrmqgpd67045gjyh51.servicebus.windows.net

prdsoutheastasiammrns-V2-12- Asia No
9dnu834oklwjlmpdn2t7ie.servicebus.windows.net

prdsoutheastasiammrns-V2-8- Asia No
4e6rrq6ugt9l73sj7i6v5oq.servicebus.windows.net

prdsoutheastasiammrns-V2-9- Asia No
ocus0ag2in80zkr49pln2kb.servicebus.windows.net

prdeastasiammrns-V2-10- Asia No
7uot7yabvskiu79tz1mq5h5rbiz.servicebus.windows.net

prdeastasiammrns-V2-11- Asia No
7nnmb84bu2gag1r11l4pgo3c0iv.servicebus.windows.net

prdeastasiammrns-V2-12- Asia No
mex8iew1ulesrikd5719fkabs5o.servicebus.windows.net

prdeastasiammrns-V2-8- Asia No
2jwmci9cif6gd9asvgac6w4l3pma.servicebus.windows.net

prdeastasiammrns-V2-9- Asia No
qkow6tk3o2itnbwr3ikwnxvi13r8.servicebus.windows.net

produaecentralmmrns-1-6v46fkb43e56k.servicebus.windows.net United Arab No
Emirates

produaenorthmmrns-1-6rlrfzdyg6y2s.servicebus.windows.net United Arab No
Emirates

prduaecentralmmrns-V2-2- United Arab No
gvau95gf8stxbizt653fwqkp9a.servicebus.windows.net Emirates

prduaecentralmmrns-V2-3- United Arab No
hv31xuc13f25vrsive9474d9am.servicebus.windows.net Emirates

prduaenorthmmrns-V2-2- United Arab No
xw6tohq9uramo9j1xadcey3uknhm.servicebus.windows.net Emirates



URI Power Is
Platform preview
Region

prdsoutheastasiammrns-V2-1- Singapore No
3f5supeetlux990ykp28ojy.servicebus.windows.net

prdsoutheastasiammrns-V2-2- Singapore No
5jgzzrf81e1tuk7j2tu8trq.servicebus.windows.net

prdswedencentralmmrns-V2-1- Sweden No
p0cx598kocgtifk2llkf9uv.servicebus.windows.net

Other configuration details
Learn more about how to permit access to automated, scheduled, and instant flows,
including required endpoints in IP address configuration.

Flow suspension because of runtime limits
Suspended flows are shown as suspended in the Power Automate maker portal and the
Power Platform admin center. When a flow is returned through an API, PowerShell, or a
Power Automate Management connector list flows 'as Admin' action, the flow has
State=Suspended with appropriate FlowSuspensionReason and FlowSuspensionTime
values.

The following items are the FlowSuspensionReason values for runtime limits:

AllActionsFailingDetected
AlwaysFailingDetected
ApiCallOverageDetected
BillingConsumption
BillingConsumptionMissingRPALicense
NeverTriggeringDetected

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Frequently asked questions
FAQ

Audience and strategy
What is Power Automate?
Power Automate is a cloud-based service that makes it practical and simple for line-of-
business users to build workflows that automate time-consuming business tasks and
processes across applications and services.

Who is the intended audience for Power
Automate?
Power Automate has two distinct audiences:

Line-of-business “Citizen Integrators” in enterprise organizations who partner with
IT to move responsibility for business solutions closer to the business itself.
IT decision makers who want to empower line-of-business partners to create their
own solutions so IT professionals and integration specialists can focus their
expertise on more advanced integration tools, such as Azure Logic Apps.

How do Power Automate and Logic Apps relate
to each other?
Power Automate provides features that help line-of-business users create automated
workflows. Logic Apps is an Azure service that provides the same great features of
Power Automate, plus features such as integration with Azure Resource Manager and
the Azure Portal, PowerShell and xPlat CLI, Visual Studio, and additional connectors.
Learn more about Logic Apps .

How does Power Automate fit in Microsoft’s
overall business application platform strategy?
Power Automate is part of a powerful and adaptable business application platform that
includes Power Apps, Microsoft Dataverse, Dynamics 365, and Office 365. This platform
allows our customers, our partners, and our ISV partners to create purpose-built
solutions for their own companies, their industry, for functional roles or even for specific



geographies. Line-of-business users, who understand their business needs best, can now
easily analyze, compose, and streamline data and processes. Professional developers can
easily extend the automation, analytics and apps line-of-business to leverage Azure
services like Functions, App Service, and Logic Apps. API connectors, gateways, and
Microsoft Dataverse make it possible to get more value out of services or data already in
use, either in the cloud or on-premises.

Functionality
What do I need to use Power Automate?
To use Power Automate, all you need is a web browser and an email address.

What browsers and devices can I use with Power
Automate?
You can run Power Automate on all modern devices, and browsers.

Supported devices
Power Automate runs great on modern devices. If you need to manage Power Automate
from a mobile device, try the Power Automate mobile app that's available on iPhone ,
Android , and Windows Phone .

Supported browsers
We recommend that you use the most up-to-date browser that's compatible with your
operating system. We support the following browsers:

Microsoft Edge
Safari
Chrome
Firefox

Which email addresses are supported?
Power Automate supports email addresses that end with anything except .gov and .mil.

Is Power Automate available on-premises?



Power Automate is a public cloud service only. However, you can securely connect to
your own on-premises services through the on-premises data gateway.

What services can Power Automate connect to?
Power Automate connects to more than 100 data sources out of the box, and we’re
adding more all the time. Some examples of data sources and services include the
following:

SharePoint
Dynamics 365
OneDrive
OneDrive for Business
Google Drive
Google Sheets
Trello
Twitter
Box
Facebook
SalesForce.com
Mailchimp
Customer APIs

You can find a full list of available connectors here.

You can access data sources in your own IT infrastructure through the on-premises data
gateway.

What are templates?
Templates are pre-built flows for popular and common scenarios. Using a template only
requires you to have access to the services in the template and to fill out any required
settings.

What data sources will I be able to connect to?
You can connect to more than 100 standard services from Microsoft and third parties,
such Office 365, Twitter, SharePoint, OneDrive, Dropbox, SQL Server, and more. You can
also connect to premium services such as Salesforce and Microsoft Dataverse.

How do I connect to a REST API in my flow?



You can connect to any REST API that uses JSON and supports at least one of more than
10 authentication methods by creating a custom connector.

How do I connect to SQL Server and other on-
premises data sources?
You can connect to services on your local network using the on-premises data gateway.

Can I share the flows I create?
You can share flows in either of these ways:

You can add co-workers or groups in your organization as owners on your flows,
so they can also edit and manage the flow.
For flows that can be run manually, you can also grant other people or groups in
your organization permission to just run the flow.

How many flows can I have?
You can create an unlimited number of flows, depending on the type of license  you
hold.

Where do I get started with Power Automate?
Get started with the following resources:

Blog
YouTube channel
Topic
Community

What operating systems does the mobile app for
Power Automate support?
The Power Automate mobile app is available on Android , iOS , or Windows Phone .

Can flows be turned off or disabled?
Yes, each flow has an on/off switch that enables you to stop the flow from processing
requests.



See the following table to understand how your flow responds when it's turned back on.

ﾉ Expand table

Trigger type Description

Polling, such as the When the flow is turned on again, all unprocessed/pending events
Recurrence trigger are processed. Delete your flow if you don't want to process

pending items.

Webhook When the flow is turned on again, it only processes new events
that are generated after the flow is turned on.

What regions and languages does Power
Automate support?
Power Automate is available in 42 languages and six regions. To see the languages that
are available:

1. Sign into the Power Platform admin center > Environments
2. Select your environment
3. Select Settings on the top menu bar.
4. Select Product > Languages

How does Power Automate compare to
SharePoint Designer 2013?
Power Automate is the successor to SharePoint Designer for many common business
scenarios such as approvals, document review, and onboarding/offboarding. It will be
the default tool for building business automation in SharePoint moving forward.

How does Power Automate ensure that
corporate data isn't accidentally released to
social media services?
Administrators can create data loss prevention policies to ensure that only sanctioned
services are used in Power Automate.



Does Power Automate support service accounts?
While you can create flows with a service account, we don't recommend doing so if the
credentials for the service account are shared.

Licensing
Will Power Automate still have a free or trial
option?
Yes. You can use our free offering, which has limited user rights, or you can sign up for a
free 90-day trial of Power Automate. You can activate your subscription at any time
during your trial.

What pricing plans do you offer?
Power Automate offers both free and paid service levels. Learn more about pricing.

Learn more
Take a guided learning tour of Power Automate
Learn the basics of Power Automate in the getting started guide

Feedback
Was this page helpful?  Yes  No

Provide product feedback



Power Automate Glossary
Article • 06/20/2024

The following terms are commonly used in Power Automate.

A
Action: An action is the task that's started when a trigger is invoked. Flows can have one
or many actions, depending on what's needed to complete a particular flow. With
actions, you can perform operations such as Create, Update, Delete, or Assign.

 Add an action

Action items: The Action items screen shows the status of approvals and business
process flows. Action items is located on the left navigation pane in Power Automate.

Approvals (approval requests): Approvals refer to the actions in approving a cloud flow.
It might be a basic approve or reject action. It could be a custom approval flow where
the sender can request any sign off, including multiple choice. To create an approval
workflow, add an approval action. After you add this action, your flow can manage the
approval of documents or processes

 Introducing the Unified Action Center

Automated flow: Automated flows are triggered by a predetermined event. Automated
flows run when an event triggers the flow to run. For example: when a row is created,
deleted, or updated in Dataverse, the flow will run if that is the trigger you chose.

 Create a cloud flow in Power Automate

B
Business process flow: A business process flow ensures that everyone in your company
follows the same process. You'll define a set of steps for people to follow. For example,
you might want to create a business process flow so everyone handles customer service
requests the same way. You might require people get approval for an invoice before
submitting an order.

 Business process flows overview

C



Conditions: Conditions tell flow to perform actions based on predetermined logic set in
the flow. If certain conditions are true, then one or more tasks will be completed. For
example, users can create conditions that specify that you'll get an email when a tweet
that contains a keyword is retweeted at least 10 times.

 Add a condition to a cloud flow

Connectors: Connectors allow users to connect popular services (such as Twitter,
Outlook, Gmail, and more) to Microsoft Power Automate, Microsoft Power Apps, and
Azure Logic Apps. They contain a set of pre-built triggers ("when a new email arrives"…)
and actions ("upload email attachment to SharePoint and My App") to be used in apps
and workflows.

 Connectors documentation

Custom connectors: Custom connecters allow users to connect a web service to Power
Automate. Users teach Power Automate about the characteristics of the web service
which include authentication, the triggers and actions that it supports, and the
parameters and outputs for each of those actions. Custom connectors must be
registered before they can be shared with your organization.

Start to build with Power Automate

D
Data loss prevention: Data loss prevention provides you with the ability to create and
enforce policies that define which connectors can access and share business data. This is
a key feature to help ensure that your business data is protected.

 Data loss prevention policies

F
Flow checker: Flow checker is a diagnostic tool that points to specific occurrences within
the flow where improvements may be required to run a cloud flow. For each identified
issue, the flow checker appears in the designer's command bar. It will show a red dot
when one or more errors are identified in your flow.

 Find and fix errors with Flow Checker

Flow types: Automated, instant, scheduled, UI flows and business process flow.

 Get started with Power Automate



Flow designer: The flow designer is the studio where makers create flows from blank or
start from a template (that they can customize or add steps to).

I
Instant flow: Instant flow allows users to trigger repetitive tasks from the mobile or
desktop app manually. For example, by selecting a button on a mobile app, it will send a
reminder email to your team before a meeting.

 Run instant flows

Item: As a Power Automate trigger, an item represents a row in a Microsoft SharePoint
list. What it actually is depends on the user's list. For example, it can be a row in
Microsoft Excel, or a table in a Microsoft Word document.

M
Microsoft Dataverse: A cloud-scale database used to store data for business
applications such as Power Automate and Power Apps. It's an abstraction on top of
underlying Azure cloud data management services to make it easier to build business
applications.

 What is Microsoft Dataverse?

Microsoft Dataverse for Teams: A common cloud data platform for Microsoft Teams.
Microsoft Dataverse for Teams enables everyone to quickly build and deploy apps and
intelligent chatbots in Teams with Microsoft Power Apps and Microsoft Copilot Studio.

Multistep flows: A multistep flow uses more than one action to accomplish a task.

R
Robotic Process Automation (RPA): Automation using a software application that
replicates the actions of a human being interacting with the user interface of a computer
system.

S
Scheduled flows: Scheduled flows run on a schedule defined by the maker. Scheduled
flows can repeat on the following cadences: every second, minute, hour, day, week,



and/or month. For example, users can schedule an automation such as daily data upload
to SharePoint or a database.

 Run flows on a schedule

Steps: There's a button at the bottom of each step (action) labeled +New step in the
flow designer that lets the user add another action.

T
Templates: Templates are prebuilt set of triggers and actions that are designed to help
users easily create flows that meet their specific business needs. Templates can be
customized. There are hundreds of flow templates that cater to many types of common
automation scenarios.

 Power Automate Templates

Trigger: A trigger is an event that starts a cloud flow. For example, if you create a cloud
flow: “when an email with an attachment arrives, automatically upload the file to
OneDrive” - the arrival of the email with an attachment is the trigger of such flow.

Flows can have one or more triggers.

U
UI Flows (RPA): UI flows enable users to automate repetitive tasks in Windows and web
applications. UI flows record and playback user interface actions (clicks, keyboard input,
etc.) for applications that don't have easy-to-use or complete APIs available.

Introduction to UI flows

W
Workflow: A sequence of actions that takes a task from initiation to completion.

Learn more
Take a guided learning tour of Power Automate
Learn the basics of Power Automate in the getting started guide



Feedback
Was this page helpful?  Yes  No

Provide product feedback



Classic Dataverse background workflows
Article • 12/16/2022

Workflows automate business processes without a user interface. People usually use
workflow processes to initiate automation that doesn’t require any user interaction.

There are two types of workflows:

1. Real-time workflows. See the Power Apps documentation for more details about
real-time workflows.

2. Background workflows.

To create background workflows, you must select the Run this workflow in the
background (recommended) check box, as displayed in the following image.

See other topics here in the Power Automate documentation to learn more about
background workflows.

Learn more
Configure background workflow stages and steps.
Monitor and manage background workflow processes
Best practices for background workflow processes.



Replace background workflows with flows



Configure background workflow stages
and steps
Article • 12/16/2022

When you design workflows you have the option to contain the logic you want to
perform in stages and steps.

Stages make the workflow logic easier to read, and explain the workflow logic. However,
stages do not affect the logic or behavior of workflows. If a process has stages, all the
steps within the process must be contained with a stage.

Steps are a unit of business logic within a workflow. Steps can include conditions,
actions, other steps, or a combination of these elements.

Actions that background workflow processes
can perform
Background workflow processes can perform the actions listed in the following table.

Action Description

Create Creates a new row for a table and assigns values you choose to columns.
row

Update You can update the row that the background workflow is running on, any of the rows
row linked to that row in an N:1 relationships, or any rows created by earlier steps.

Assign You can assign the row that the background workflow is running on, any of the rows
row linked to that row with an N:1 relationship, or any rows created by earlier steps.

Send Sends an email. You can choose to create a new email message or use an email
Email template configured for the table of the row that the background workflow is

running on or any tables that have an N:1 relationship with the table, or the table for
any rows created by earlier steps.

Start Starts a background workflow process that has been configured as a child workflow.
Child
Workflow

Change Changes the status of the row that the process is running on, any of the rows linked
Status to that row with an N:1 relationship, or any rows created by earlier steps.

Stop Stops the current workflow. You can set a status of either Succeeded or Canceled and
Workflow specify a status message.



Action Description

Custom Developers can create custom background workflow steps that define actions. There
Step are no custom steps available by default.

Setting row values
When you create a row you can set values for the row. When you update a row you can
set, append, increment, decrement, multiply, or clear values.

When you select Set Properties, a dialog box opens showing you the default form for
the table.

At the bottom of the dialog box you can see a list of additional columns not present in
the form.

For any column, you can set a static value and that will be set by the workflow.

On the right side of the dialog box, the Form Assistant gives you the ability to set or
append dynamic values from the context of the current row. This includes values from
related rows that can be accessed from the N:1 (many-to-one) relationships for the
table.

The options available in the Form Assistant depend on the column you have selected in
the form. When you set a dynamic value, you will see a yellow placeholder known as a
‘slug’ that shows where the dynamic data will be included. If you want to remove the
value, just select the slug and delete it. For text columns, you can use a combination of
static and dynamic data.

With dynamic values, you don’t know for certain that a column or related table has the
value you want to set. You can actually set a number of columns to try to set the value
and sort them in order using the green arrows. If the first column doesn’t have data, the
second column will be tried and so on. If none of the columns has data, you can specify
a default value to be used.

Setting conditions for background workflow
actions
The actions that you will apply often depend on conditions. Background workflow
processes provide several ways to set conditions and create branching logic to get the
results you want. You can check values of the row that the background workflow process



is running against, any of the rows linked to that row with an N:1 relationship, or values
within the process itself.

Condition Description
Type

Check A logical "if <condition> then" statement.

Condition

You can check the current values for the row that the background workflow is
running on, any of the rows linked to that row in an N:1 relationships, or any rows
created by earlier steps. Based on these values you can define additional steps
when the condition is true.


In the "if <condition> then" statement, you can use the following operators:
Equals, Does Not Equal, Contains Data, Does Not Contain Data, Under and Not
Under. 


Note: The Under and Not Under are hierarchical operators. They can only be used
on the tables that have a hierarchical relationship defined. If you’re trying to use
these operators on the tables that don’t have the hierarchical relationship defined,
you’ll see the error message: “You’re using a hierarchical operator on a table that
doesn’t have a hierarchical relationship defined. Either make the table hierarchical
(by marking a relationship as hierarchical) or use a different operator.”


For more information about hierarchical relationships, see Define and query
hierarchically related data. A screenshot that follows the table is an example of the
definition of the background workflow process that uses the Under and Not Under
hierarchical operators.

Conditional A logical "else-if-then" statement. The editor uses the text “Otherwise, if
Branch <condition> then:”


Select a check condition you have previously defined and you can add a
conditional branch to define additional steps when the check condition returns
false.

Default A logical "else" statement. The editor uses the text “Otherwise:”

Action

Select a check condition, conditional branch, wait condition, or parallel wait branch
that you have previously defined and you can use a default action to define steps
for all cases that do not match the criteria defined in condition or branch elements.

Wait Enables a background workflow to pause itself until the criteria defined by the
Condition condition have been met. The background workflow starts again automatically

when the criteria in the wait condition have been met.



Condition Description
Type

Parallel Defines an alternative wait condition for a background workflow with a
Wait corresponding set of additional steps that are performed only when the initial
Branch criterion is met. You can use parallel wait branches to create time limits in your

background workflow logic. They help prevent the background workflow from
waiting indefinitely until the criteria defined in a wait condition have been met.

Custom Developers can create custom background workflow steps that define conditions.
Step There are no custom steps available by default.

The following screenshot contains an example of the background workflow process
definition with the Under and Not Under hierarchical operators. In our example, we
apply two different discounts to two groups of accounts. In Add Step, we selected the
Check Condition to specify the if-then condition containing the Under or Not Under
operators. The first if-then condition applies to all accounts that are Under the Alpine
Ski House account. These accounts receive a 10 percent discount on purchased goods
and services. The second if-then condition applies to all accounts that are Not Under
the Alpine Ski House account and they receive a 5 percent discount. Then, we selected
Update row to define the action to be performed based on the condition.

Next steps



Create custom business logic through processes 
Workflow processes overview 

Monitor and manage background workflow processes 
Best practices for background workflow processes



Monitor and manage background
workflow processes
Article • 12/16/2022

To monitor and manage processes, you must locate the process, evaluate the status, and
perform any actions necessary to address problems.

Monitoring background workflows
Background workflows generate System Job rows to track their status. You can access
information about these system jobs in several places within the application:

Settings > System Jobs

This will include all types of system jobs. You will need to filter rows to those where
System Job Type is Workflow.

From the background workflow process

Open the background workflow definition and go to the Process Session tab. This
will show only the system jobs for this background workflow.

From the row

You can edit the table form so that the navigation will include the Background
Processes relationship. This will show all the system jobs that have been started in
the context of the row.

７ Note

If an asynchronous system job (workflow) fails several times consecutively, the
system starts to postpone execution of that job for longer and longer time intervals
so that the administrator or app maker can investigate and resolve the issue. Once
the job starts succeeding again, it will resume executing normally.

Actions on running background workflows
While a background workflow is running, you have options to Cancel, Pause, or
Postpone the workflow. If you have previously paused a workflow, you can Resume it.



Status of background workflow processes
When you view a list of background workflow processes, any individual process can
have one of the following State and Status Reason values:

State Status Reason

Ready Waiting for Resources

Suspended Waiting

Locked In Progress


Pausing


Canceling

Completed Succeeded


Failed


Canceled

Deleting process log rows
If your organization uses background workflows or business process flows that run
frequently, the amount of process log rows can become large enough to cause
performance issues as well as consume significant amounts of storage. To delete process
log rows not removed sufficiently by one of the standard bulk row deletion jobs, you
can use the bulk delete system jobs feature to create a custom bulk row deletion job.

1. Go to Settings > Data Management > Bulk Row Deletion.

2. From the Bulk Row Deletion area, select New.

3. On the Bulk Deletion Wizard start page, select Next.

4. In the Look for list, select System Jobs.

5. The following conditions are used to create a bulk row deletion job to delete
process log rows:

System Job Type Equals Workflow. This targets background workflow rows.
Status Equals Completed. Only completed workflows are valid to run the job
against.
Status Reason Equals Succeeded. Delete successful, canceled, and failed jobs.



Completed On Older than X Days 30. Use the Completed On column to only
delete background workflow process log rows that are older than 30 days.

6. Select Next.

7. Set the frequency that your bulk delete job will run. You can schedule your job to
run at set intervals or create a one-time bulk deletion job Using the Immediately
option. In this example, a recurring job is set to run on May 21, 2018, and every 30
days thereafter.



Using the Immediately option
Notice that you have the option of performing an immediate synchronous bulk delete of
the rows by selecting the Immediately option. This delete is performed with direct SQL
Server execution rather than passing each row through the delete event pipeline, which
can reduce the impact to system performance. This is a good option if you want to
quickly clean up the extra background workflow rows instead of the bulk delete job
waiting in the asynchronous queue for processing.

The Immediately option is enabled when the following conditions are true:

Bulk delete job is for the System Jobs table.
The search criteria has the condition System Job Type Equals Workflow.
The user creating the bulk delete job has global depth for the delete privilege on
the AsyncOperation table. The System Administrator security role has this privilege.

The synchronous bulk delete will only delete AsyncOperation rows in the completed
state. A maximum of 1 million rows are processed for each invocation. You will need to
execute the job multiple times if your environment has more than 1 million rows to
remove.

Troubleshoot issues



Workflow run failure after change in owner
When a workflow owner user is deactivated, no longer has permissions to run
workflows, or is changed by an administrator, runs that were previously started and are
still in Waiting state will fail to run as they belong to the previous owner. In this
situation, it is recommended to Cancel the waiting runs that belong to the previous
owner. If you have runs that cannot be cancelled and need to be updated to the new
owner, (contact support)[/power-platform/admin/get-help-support] for assistance.

Next step
Best practices for background workflow processes 




Best practices for background workflow
processes
Article • 12/16/2022

This topic contains best practices for creating and managing background workflow
processes.

Avoid infinite loops
It’s possible to create logic in a background workflow that initiates an infinite loop,
which consumes server resources and affects performance. The typical situation where
an infinite loop might occur is if you have a background workflow configured to start
when an column is updated and then updates that column in the logic of the workflow.
The update action triggers the same background workflow that updates the row and
triggers the background workflow again and again.

The workflows you create include logic to detect and stop infinite loops. If a background
workflow process is run more than a certain number of times on a specific row in a short
period of time, the process fails with the following error: This workflow job was
canceled because the workflow that started it included an infinite loop. Correct the
workflow logic and try again. The limit of times is 16.

Use background workflow templates
If you have workflows that are similar and you anticipate creating more workflows that
follow the same pattern, save your background workflow as a workflow template. This
way, the next time you need to create a similar workflow, use the template to create the
background workflow and avoid entering all the conditions and actions from scratch.

In the Create Process dialog box, choose New process from an existing template
(select from list).

Use child workflows
If you apply the same logic in different workflows or in conditional branches, define that
logic as a child workflow so you don’t have to replicate that logic manually in each
background workflow or conditional branch. This helps make your workflows easier to
maintain. Instead of examining many workflows that might apply the same logic, you
can just update one workflow.



Automatically delete completed background
workflow jobs
For background (asynchronous) workflows, we recommend selecting the Automatically
delete completed workflow jobs (to save disk space) option in the background
workflow definition. Selecting this check box allows the system to delete background
workflow logs for successful executions to save space. Notice that logs from failed
background workflow executions will always be saved for troubleshooting.

Limit the number of workflows that update the
same table
Running more than one background workflow that updates the same table can cause
resource lock issues. Imagine several workflows running where every opportunity update
triggers an update to the associated account. Multiple instances of these workflows
running and attempting to update the same account row at the same time can result in
resource locking issues. Background workflow failures occur and an error message, such
as SQL Timeout: Cannot obtain lock on resource resource name, is recorded.

Use Notes to keep track of changes
When you edit workflows you should use the Notes tab and type what you did and why.
This allows others to understand the changes you made.

Next steps
Configure background workflow processes

Monitor and manage background workflow processes



Replace classic Microsoft Dataverse
workflows with flows
Article • 02/09/2023

This topic compares Power Automate capabilities with classic workflow.

Power Automate has significant advantages over the classic background workflow
model; you should consider using Power Automate to automate your processes instead
of classic workflow.

Create flows instead of classic Microsoft Dataverse workflows to build new automation
processes. Additionally, you should review your existing classic background workflow
processes and consider replacing them with flows.

Feature capability comparison
This table summarizes a comparison between Power Automate and classic workflows
capabilities.

We are continuously adding new capabilities to Power Automate. We'll update
information in this table as Power Automate gains capabilities; check back often! For
information about upcoming capabilities that will help you replace classic background
workflows with flows, see What's new and planned for Power Automate.

Capability Power Classic
Automate Workflow

Modeling Conditional branching Yes Yes

Looping Yes No

Wait conditions on columns No Yes

Parallel branch Yes No

Out-of-the-box connectors to external systems Yes No
(trigger and
perform actions in external services)

Composition Dynamic content Yes Yes

Access to pre-image of event data No Yes

Run child workflows Yes Yes

Run Microsoft Dataverse actions (including custom) Yes Yes



Run custom background workflow activities No Yes

Group steps to run in a transaction Yes No
(changesets)

Approval workflows Yes No

Execution Trigger on column changes Yes Yes

Trigger conditionally on column values (For example, No No
on a
certain date in a date column)

Trigger on multiple Dataverse table events Yes Yes

Run on-demand Yes Yes

Run-as scopes
 Yes Yes
(for example, organization, business unit, user)

Run on a schedule Yes No

Run synchronously (real-time) No Yes

History Auditing Yes Yes

Run analytics Yes No

Authoring Solution support Yes Yes
and
portability Modern designer Yes No

AI-assisted authoring Yes No

Example scenario: Replace a background
workflow with a cloud flow
Imagine a sales scenario where you have put together a quotation for a customer and
now you need to request approval from your management team before you send the
quotation to the customer. With classic workflows, this isn't easy and most solutions to
this require a developer to write custom background workflow activities to retrieve
quote line items.

With flows, this scenario is easier to build, as demonstrated in the walkthrough later that
covers some of the Power Automate capabilities. These capabilities include:

Creating a cloud flow that runs on demand.
Getting a list of rows that are related to a Dataverse table.
Looping over a list of rows.



Sending approval requests.

To allow the sales person to trigger the approval request on demand:

1. Sign in to Power Automate  and create a cloud flow in a solution.

2. From the list of triggers, select Microsoft Dataverse – When a row is selected, and
then select Quotes as the table.

This trigger allows a cloud flow to run on-demand on a row or set of rows.

3. With the trigger configured, add actions to run in the flow. This provides the
approver with the summary detail that they need to identify the quoted items and
values. Begin by adding the Microsoft Dataverse – List rows action. The goal is to
get the individual items from a Quote, so set the Table name to Quote lines. To
ensure the list contains only those quote line items that belong to the Quote for
which the flow was triggered, we’ll specify an OData style filter criterion. In the
Filter Query box, type _quoteid_value eq and then select Quote from the list of
dynamic values that appear.

4. Because we want to summarize quote line items for the approval, add the Initialize
variable action. Set Name to Quote line summary, and Type to String (from the
drop-down list), and leave Value empty.

5. Add the Append to string variable action and then select the Quote line summary
variable we created earlier. In the Value box, select Quantity, Name, Price Per Unit,
Extended amount, and Manual discount from the list of dynamic values. The
Power Automate designer identifies that these values are from a list of quote line
items, and adds this action in an Apply to each loop to ensure information from
each line item is added to this summary.



6. To request approval on the quote summary we’ve created, add the Approval –
Start and wait for an approval action. Select an Approval type (for example,
Approve/Reject – First to respond), give the approval request a Title (for example,
the name of the quote for which approval is being requested, picked from the list
of dynamic values), and enter the email address for the person who needs to
review and approve the quote in the Assigned to box. In the Details box, add the
Quote line summary variable, along with any other information that might be
relevant using the dynamic value picker (for example, Total Amount).



7. To determine what happens once an approval is accepted or rejected, add the
Condition action. Select Outcome from the list of dynamic values from the first
field in the condition, contains from the drop-down list in the second field, and
enter Approve in the third field of the condition. Finally, add actions based on the
outcome of the approval (for example, send a notification email).

We now have the approval structure created so the approver has all of the information
needed to make a decision on next steps. Here's the full example:



When you run this flow against your quote, it summarizes quote line items for that
quote and sends an approval request that the approver can respond to from Power
Automate, or the actionable email they receive. Here's an example of the display:



Recommended patterns
Workflows with complex else-if conditional logic

Instead of using conditions, we recommend using the switch action.

Workflows that run from plug-in/code

We recommend redesigning the flow to start with triggers:

Use Microsoft Dataverse triggers to run flows based on events in it.



To run flows based on events in an external service, leverage more than 260
out-of-the-box connectors.

For scenarios where a connector you need isn’t available out-of-the-box, easily
create your own custom connector. More information: Create a custom
connector from scratch

Finally, if there are scenarios where you can't trigger your flow using one of the
prebuilt connectors or by creating a custom connector, use the When an HTTP
request is received trigger to invoke the flow.

Workflows that run recursively

Use the do-until or apply to each loop in flows instead.

Workflows that need a list of rows

Use the list rows action. When using this action, define the row filtering criteria
using OData syntax to optimize the action by minimizing the number of rows you
want to retrieve.

Workflows that sleep to run on a schedule

Use the recurrence trigger to run business logic at periodic intervals.

Workflows for which runs were managed to ensure activities were executed in a
single transaction

Use the changeset action to ensure that all actions within it are performed as a
single, atomic unit in which either all succeed, or fail as a group. If any one of the
actions in a change set fails, changes made by completed operations are rolled
back.

Monitor background workflow runs for failures

In Power Automate, use the run-after setting on an action to configure it to run
when the previous action fails. For example, send a Power Automate mobile
notification when the update a row action fails, or times out.

FAQs
I have a Dynamics 365 license. Can I use Power Automate?

Every Dynamics 365 user is entitled to use Power Automate. Review our licensing
information.



How often can my flows be triggered?

Dynamics 365 (or Microsoft Dataverse) flows run near real-time after the trigger
because they use webhooks (no polling required).

As with direct API access, there are throttles/limits in the system. More
information: Limits and configuration in Power Automate
Specifically, there is a limit of 100,000 actions per 5 minutes, per flow. A single
loop in a cloud flow cannot process more than 100,000 items at once.
Maximum of 6 GB of throughput per 5 minutes.

How long can a single flow run?

A single flow run times out after 30 days.

How do I move my flows between environments?

Just like classic workflows, you can create flows in solutions to support the full
application lifecycle for processes.

Are Power Automate dependencies tracked in Microsoft Dataverse?

Similar to other components in a solution, all dependencies for flows in solutions
are tracked in Microsoft Dataverse.

What about synchronous workflows?

We've seen feedback that synchronous workflows are a significant contributor to
end-user performance issues. We recommend that you evaluate whether your
objective, or parts of the background workflow, can be built using a cloud flow. If
you can split actions out as asynchronous, the user can continue their activity while
Power Automate completes the action.

Using Power Automate, will my data stay within region (that is, the same region
as my Dynamics 365 or Microsoft Dataverse environment)?

Yes, Power Automate always uses the same region as Microsoft Dataverse.

Do I need to make proxy/firewall changes?

Refer to the IP address configuration reference to determine whether you need to
make any proxy/firewall changes.



Create a mobile task flow
Article • 12/16/2022

Design a cloud flow in Dynamics 365 for phones or Dynamics 365 for tablets based on
common tasks your users perform. For example, if they need to regularly perform a
series of follow-up steps after client meetings, create a task flow. When users tap the
new task in their mobile app, it will lead them through from start to finish so they don't
forget an important step.

Task flows can use multi-table forms and logic, and can have form logic that runs across
the task flow pages.

Create a task flow
1. Make sure that you have the System Administrator, or System Customizer security

role or equivalent permissions. The Manager, Vice President, or CEO-Business
Manager, security roles can also create mobile task flows.

2. Open solution explorer and select Processes.

3. On the Actions toolbar, select New.

4. In the Create Process dialog box, complete the required fields:

Enter a process name.

In the Category list, select Business Process Flow.

In the Table list, select the table you want.

5. Select the Run process as a task flow (Mobile online) option.

6. Select OK.

The task flow designer opens in a new window.



7. If your users will progress from one page to another in order, drag the Page
component from the Components tab on the right side of the screen and drop it
on the + sign in the appropriate spot. To add a name for a page, select the page,
select the Properties tab, type a new name, and then select Apply.

8. To add a branch to the task flow, drag the Condition component from the
Components tab and drop it on the + sign in the appropriate spot. To set
properties for the condition, select the condition, set the properties in the
Properties tab, and then select Apply.

７ Note

As you add pages and conditions to the task flow, you'll see a minimap in the
lower-left corner of the window that shows all the pages and conditions in the
task flow.

9. To add a field, label, or section label to a page, drag Field, Label, or Section Label
from the Components tab to the appropriate page. To change the properties for
one of these items, select the item, set the properties in the Properties tab, and
then select Apply.

10. To validate the task flow, select Validate on the action bar.

11. To save the process as a draft, select Save at the top of the screen. (As long as a
process is a draft, people won’t be able to use it.)

12. To activate the task flow so that people can use it, select Activate.

 Tip



Here are a few tips to keep in mind as you work on your task flow in the designer
window:

To take a snapshot of everything in the task flow window, select Snapshot on
the action bar.
To connect a valid component to another valid component in the designer,
select Connector on the action bar.
You can make the images on the screen larger or smaller by selecting the
Increase the zoom level or Decrease the zoom level buttons in the upper-
right corner of the screen. Select the Fit to canvas button to blow the images
up to the largest size that fits on the screen.

Next steps
Create a business process flow



Use Dataverse dialogs for guided
processes (Deprecated)
Article • 12/16/2022

Dialogs are deprecated. You should replace dialogs with business process flows or
canvas apps. More information: Replace dialogs with business process flows or canvas
apps

Dialogs are the synchronous or interactive processes in Dataverse that collect and
process information by using step-by-step scripts to direct users through a process. For
example, you can create dialogs to act as a guide for your service representatives for
case resolution and case escalation. Similarly, you can create dialogs for standardizing
sales processes such as opportunity qualification and lead scoring.

Differences between workflows and dialogs
The following table provides information about the differences between Dataverse
workflows and dialogs.

Workflows Dialogs

Can be either started by a user or can be Must be started by a user.
automated.

Are asynchronous or real-time processes, Are real-time processes that require user input to
and do not require user input to run to run to completion. When you run these processes,
completion. Asynchronous processes run in a wizard-like interface is presented to you so you
the background while real-time processes can make appropriate selections to run the
run immediately. processes.

The table that stores the details about a The table that stores information generated by a
running asynchronous workflow is running dialog is the ProcessSession  table.
AsyncOperation  while a Process  is used for a
real-time workflow.

Triggers are supported for workflows. For a Triggers are not supported for dialogs.
list of supported triggers, see Supported
Types, Triggers, and Tables for Processes.

See also
Replace dialogs with business process flows or canvas apps



Replace dialogs with business process
flows or canvas apps
Article • 12/16/2022

Dialogs are deprecated, and should be replaced by business process flows or canvas
apps. This article describes different capabilities of these options. You'll also learn about
situations where a business process flow or canvas app embedded in a model-driven
form can be used to replace an existing dialog.

Feature capability comparison
This table lists the set of dialog capabilities and the equivalent capabilities in business
process flows and canvas apps.

Dialog capability Capability in business Capability in canvas apps?
process flows?

Page Yes 
 Yes 

(business process stage) (app screen)

Prompt only No Yes 

(labels)

Prompt and Yes 
 Yes 

response (table columns only) (labels and input fields)

Input arguments Limited 
 Yes 

(steps in business (query string parameters)
process stage)

Variables No Yes

Query variables No Yes

Conditional Yes Yes 

branching logic (navigate to any screen within app)

Reuse 
 No Yes 

(launch as a child (navigate to any screen within app, launch a
dialog) different app in a new window)

Run workflows on Yes No 

start/end (use a cloud flow instead)



Dialog capability Capability in business Capability in canvas apps?
process flows?

Run workflows on Yes No 

input (use a cloud flow instead)

Run workflows on Yes No 

page transition (use a cloud flow instead)

Start using a URL No Yes

Session logging Yes No

SDK support Yes Yes

Additional capabilities with business process flows
Process analytics (views, charts, and time spent in a stage)
Custom controls

Additional capabilities with canvas apps
App analytics (app usage & performance)
Multi-table page composition
Run flows
Data connectors (standard and custom)
Launch as a stand-alone app
Configurable layout

Choosing between a business process flow or
canvas app
When you choose your dialog replacement, it is important to account for the user
experience you want to deliver. Also keep in mind, almost any dialog can be modeled
using a canvas app.

Business process flows are best suited to replace dialogs that model processes providing
guidance across an overarching workstream that requires collaboration across groups of
individuals and Dynamics 365 app context. For example, quote review and routing.

Alternatively, canvas apps can be used to replace dialogs that model prescriptive tasks
such as a call script for lead prospecting or to simplify the user experience for other



tasks, such as updating an opportunity. Notice that these scenarios may even benefit
from having a stand-alone canvas app.

Dialog replacement using business process
flow scenario
Imagine you have a dialog that, over a series of pages, requests key pieces of
information from the user, generates a quote, sends an email to reviewers to accept or
reject the quote, before emailing it to the customer. This type of process is modeled
more effectively using a business process flow.

To replace the dialog, you begin by identifying the key stages in the process. These
might include a Prepare Content stage to ensure all the products are listed and
discounts are applied, a Generate Quote stage to create the quote and review it for
accuracy of format, a Primary Review stage to send the quote for review and approval, a
Secondary Review stage to review the quote under certain circumstances and finally, a
Deliver Quote stage to send the quote to the customer.

Next, identify the key steps that users must follow in the process. For instance, the
Prepare Content stage might contain a simple true or false step for the user to double
check the products to be quoted, a mandatory lookup step to select a price list, and a
numeric step to enter a discount before moving on to the next stage. The Generate
Quote stage might have an action step to create a quote based on all the information
previously captured in the Prepare Content stage and its related Dynamics 365 row. The
Primary Review and Secondary Review stages might have several true or false steps to
guide quote review, along with a required step to capture the approval status, and
ensure the process can only be moved to the next stage once approval is received.
Configure column level security on this step to make sure that only authorized reviewers
can provide approval on the quote. Additionally, one can add a workflow to the Primary
Review and Secondary Review stages, such that on enter, an email notification is sent to
all reviewers.

Finally, configure your business process flow stages and steps, along with the
conditional logic to guide the process flow. For this example, you might add a
conditional branch following the Primary Review stage, such that, if a step indicates the
need for a second level of review, the next stage in the process is the Secondary Review
stage, else, it’s the Deliver Quote stage.

To make this business process flow available to users, ensure the right users have
privileges to the business process flow and then activate it.



For more information about how to create a business process flow, see Tutorial: Create a
business process flow to standardize processes.

Dialog replacement using canvas app scenario
Suppose you have a dialog, which follows a call script that guides sales reps through
cold calling leads. This process can easily be captured using a canvas app.

Begin with connecting to the data sources you’ll need to read and write data. In this
example, a connection to Dynamics 365 is used for lead, account, and contact
information.

Begin by identifying the number of screens needed. For this example, you may decide to
have five screens.

Screen 1. To select a lead from a list to call.
Screen 2. For introductions, checking availability for a conversation, and scheduling
a call-back at a later date.
Screen 3. For determining BANT (budget, authority, need, and timeline).
Screen 4. To capture next steps and schedule follow-up calls.
Screen 5. Thank the lead for their time at the end of the call.

Next, build each screen. In the first screen, build a gallery of leads that need to be called.
In the second, use labels to title the screen and provide the call script, while using
controls like radio buttons to capture whether it is a good time for the person to talk. If
it is, use conditional logic to enable a button to navigate to the next screen and if not,
reveal a script on the same screen to attempt to schedule a call back with the customer.
Similarly, define your call script across subsequent screens.

Finally, define navigation across screens. In this example, in addition to navigating
through the screens sequentially, you might want to navigate the user from the second
screen to the last screen (the end of the script thanking the lead for their time) if the
lead is not interested in having a conversation.

To make this app available to users, publish the app. Consider how such a scenario
might be transformed through the availability of a standalone app that provides call
scripts and supports quick data entry.

Imagine you want to embed this experience in Dynamics 365 Sales. To do this, begin
with creating an iframe on a Dynamics 365 Sales form. Next, navigate to the Apps
section from the Power Apps menu, select the app you just published, copy the web link
under the Details tab and paste it as the URL for the iframe.



Taking this a step further, suppose you’d like for this app to be available right within the
lead main form, and be in the context of the lead so that the app doesn’t require the
user to select a lead in the first screen. To pass relevant information to the app, you
simply modify the iframe URL to append a query string containing this information, such
as lead or account Ids, using JavaScript that runs on a certain event, such as on form
load. Next, update the app to remove the first screen (for lead selection) and instead
access the values passed to the app via the query string using the Param function.

Dialog replacement FAQ
Are dependencies on canvas apps be tracked?

Dependencies on canvas apps are tracked in the same way as dependencies in
Dynamics 365 apps.

Can I launch a canvas app as a popup from a button in the command bar?

Yes. To do this, simply set the target URL to that of your canvas app, obtained from
the app's Details section as described earlier.

Can workflows be called from a canvas app?

This isn't supported. We recommend using a cloud flow instead.

Can I automatically convert dialogs to business process flows or canvas apps?

There is no automated way to convert dialogs to business process flows or canvas
apps.

See also
Tutorial: Create a business process flow to standardize processes 

What are canvas apps in Power Apps?



Responsible AI FAQs for Power
Automate
Article • 04/04/2025

An AI system includes not only the technology, but also the people who use it, the
people affected by it, and the environment in which it's deployed. Microsoft's
Responsible AI FAQs are intended to help you understand how AI technology works, the
choices system owners and users can make that influence system performance and
behavior, and the importance of thinking about the whole system, including the
technology, the people, and the environment. You can use Responsible AI FAQs to
better understand specific AI systems and features that Microsoft develops.

Responsible AI FAQs are part of a broader effort to put Microsoft's AI principles into
practice. To find out more, see Microsoft AI principles .

AI-driven features in this app
This app contains a growing list of AI-driven features. To learn about the capabilities and
impact of specific features, select a feature name from the list.

Get started with Copilot in cloud flows
FAQ for Copilot in cloud flows
Create, update, and fix expressions with Copilot expression assistant (preview)
FAQ for Copilot expression assistant
Create generative actions in cloud flows (preview)
FAQ for generative actions in cloud flows
Copilot in Process Mining ingestion (preview)
Copilot in Process Mining process analytics (preview)
FAQ for Copilot in Power Automate Process Mining
FAQ for Copilot data security and privacy in Microsoft Power Platform

Feedback
Was this page helpful?  Yes  No

Provide product feedback



FAQ for Copilot in cloud flows
Article • 04/04/2025

These frequently asked questions (FAQ) describe the AI impact of Power Automate's
Copilot in cloud flows feature.

What is Copilot in cloud flows?
The copilot in cloud flows experience in Power Automate is a new way to build
automation (at this time cloud flows specifically) with the help of an AI assistant—the
copilot. The copilot in Power Automate stays with you in your flow building journey and
helps you build, set up, and run an automation on your behalf through a chat
experience. It helps answer flow and product questions, too. It takes your input and
provides either documentation, links, or answers in the copilot chat pane. As an
alternative, it makes changes to the flow per your natural language description.

What are the system’s capabilities?
The system is a copilot embedded in the cloud flows designer with copilot. It helps you
create or edit your flow. The system can:

Create a new flow from scratch.

Edit an existing flow according to instructions.

Answer questions about the current flow being edited.

Create a description for the current flow.

Answer general documentation questions about Power Automate.

Filter out questions not related to Power Automate or the current flow.

The copilot also provides buttons to prompt you to save or test your flow occasionally.

What is the system’s intended use?
The system's intended use is to help you build automation easily and quickly, to start
getting value out of automation as soon as possible.



How was copilot in cloud flows evaluated?
What metrics are used to measure
performance?
We have a robust set of metrics we're tracking to measure the performance of the
model and resulting customer experience. We track copilot's SLA to make sure it's
always available to you. We track the telemetry of thumb up and thumb down gestures
present in the AI copilot for each AI output where you can submit feedback.

You can provide feedback for copilot when the results are biased or inappropriate. We
track this feedback to ensure that copilot is compliant, appropriate, and bias-free.

What are the limitations of copilot in cloud
flows? How can users minimize the impact of
the copilot limitations when using the system?
Copilot can render flows and edit flows in a limited manner at this time. It supports only
a subset of connectors available with Power Platform. Copilot also isn't equipped to help
with fixing flow errors currently. You're made aware of this limitation throughout the
experience. We attempt to keep you from landing in a faulty state that causes data
crashes or loss, as our support is limited. We block you from using the feature when
there's a possibility it might break or corrupt your data.

If you want to turn off copilot in cloud flows within your organization, ask your Power
Platform admin to turn off the feature. Admins contact Microsoft support to do this.

What operational factors and settings allow for
effective and responsible use of the system?
Copilot is available only in the new designer. When editing a flow, you can choose to
use the new designer or the old designer.

If you're using the new designer, all changes done by copilot should be reviewed in the
designer. You can undo your changes.

Related information
Get started with Copilot in cloud flows



Use Copilot to analyze desktop flow activity (preview)
FAQ for Copilot data security and privacy in Microsoft Power Platform

Feedback
Was this page helpful?  Yes  No

Provide product feedback



FAQ for Copilot expression assistant
Article • 12/13/2024

These frequently asked questions (FAQ) describe the AI impact of Copilot expression
assistant feature in Power Automate.

What is Copilot expression assistant?
This feature is designed to help makers build expressions (involving functions, static or
dynamic data in the flow) using natural language. Makers need to provide a prompt
describing the expression they want to build, reference dynamic data in the flow by their
name, and copilot generates a working Power Automate expression on their behalf.

What are capabilities of the Copilot expression
assistant?
It can understand your intent of expression creation, understand what dynamic values
you want to put in your expression, and return a Power Automate expression.

What is the intended use of the Copilot
expression assistant?
Write Power Automate expressions using natural language.

How was Copilot expression assistant
evaluated? What metrics are used to measure
performance?
Copilot expression assistant underwent substantial testing before the feature was
released. We have a diverse test set pair of prompts->desired expression, which is used
for benchmarking the model’s quality.

What are the limitations of Copilot expression
assistant? How can users minimize the impact



of the Copilot expression assistant limitations
when using the system?
Expression assistant produces mostly accurate answers but isn't always factual. Because
the underlying technology behind content rewrite uses AI that has been trained on a
wide range of Internet sources, some text suggestions might include questionable or
inappropriate content. It's your responsibility to edit generated suggestions so that your
final copy is accurate and appropriate.

It needs a descriptive name when you want to reference dynamic content in the
expression. It might pick a different dynamic content when you have multiple similar
sounding dynamic content in your flow.

What operational factors and settings allow for
effective and responsible use of the feature?

Ensure that your prompt is clear and descriptive.
Ensure that your prompt isn't too long.
Always review and test before applying copilot generated expression to your flow
and running in production.

Related information
Create, update, and fix expressions with Copilot expression assistant (preview)

Feedback
Was this page helpful?  Yes  No

Provide product feedback



FAQ for Copilot in automation center
Article • 01/23/2025

Copilot in automation center enables makers, business analysts, and members of the
CoE team to easily retrieve information about past flow runs, work queue performance,
and general Power Automate product features (referred to as generative answers) by
asking questions in natural language. For example, users can ask about the number of
flows that ran yesterday, which machine ran the most flows, or how many flows are
currently queued. In response, Copilot generates outputs that provide insights and
answers to the questions asked.

What can Copilot in automation center do?
Copilot in automation center is able to answer questions about the following four skills:

ﾉ Expand table

Index Skill Questions skill can answer

1 Cloud flow run logs Cloud flow run status, trigger type, run duration, failure
rate

2 Desktop flow run logs Desktop flow run status, used machine, run mode, failure
rate

3 Work queue data Work queue items statuses, SLA attainment, processor
counts

4 Documentation (generative General Power Automate feature questions such as how to
answers) analyze activity with Copilot

The first three skills listed in the table translate natural language queries (questions)
entered by users into Microsoft Dataverse FetchXML query syntax. This allows users to
easily retrieve information about their automation data by asking questions in natural
language. Additionally, Copilot determines the most suitable output visualization, such
as a table, pie chart, bar chart, or line chart to effectively present the insights and
information to the user.

The fourth skill uses the Azure OpenAI service to search for answers in Power Automate
for desktop's public documentation based on user prompts.



What is Copilot in automation center's general
intended use?
The purpose of this system is to enable users to retrieve information about their
automation activity data, and general product features by asking questions in natural
language.

What is Copilot in automation center's
intended use for generative answers?
The intended use of Copilot's generative answers is to help users find quick and
accurate answers to product related questions without having to navigate away from
Power Automate for desktop.

How was Copilot in automation center
evaluated? What metrics are used to measure
performance?

The performance of Copilot in automation center was evaluated using a
comprehensive set of metrics. The copilot interface includes thumbs up and
thumbs down gestures, allowing users to submit feedback on the AI outputs. This
feedback is closely monitored to ensure that Copilot remains compliant,
appropriate, and free of bias.

How was Copilot's generative answers in
automation center evaluated? What metrics are
used to measure performance?

Copilot's generative answers capability has been evaluated against real-world
scenarios in each phase of its design, development, and release. Using a
combination of research and business impact studies, we've evaluated various
quantitative and qualitative metrics about Copilot, including its accuracy,
usefulness, and agent trust.
We have a robust set of metrics we're tracking to measure the model's
performance and resulting customer experience. We follow the feature's SLA to
make sure it's always available to you. We track the telemetry of thumbs up and



thumbs down gestures present in the UI experience for each AI output that you
can submit feedback for.

What operational factors and settings allow for
effective and responsible use of Copilot in
automation center?

Effective and responsible use of Copilot in automation center can be achieved by
ensuring that the user has the appropriate rights to access the relevant data in
Dataverse. This means that Copilot only answers questions based on data the user
has permission to access. Additionally, it's important for users to understand the
scope and limitations of Copilot, and to phrase their queries accordingly.
For generative answers, you should constantly review the answers provided by
Copilot's generative answers capability before using them.

What are the limitations of Copilot in
automation center? How can users minimize
the impact of Copilot in automation center’s
limitations when using the system?
One of the limitations of Copilot in automation center is that it currently only supports
answering questions about cloud and desktop flow activity, work queues, and Power
Automate documentation, and not yet about other topics such as capacity. Additionally,
the supported language is currently English and only available in Dataverse
environments provisioned in the United States region. To minimize the impact of these
limitations, users can ensure that their queries are specific to supported product areas
and are phrased in English.

What are the limitations of Copilot in
automation center's generative answers? How
can users minimize the impact of Copilot's
generative answers's limitations when using the
system?



The generative answers capability can only answer to product related features. It
can't answer general questions or anything unrelated to the product.
There's a limit of 200 characters to describe the question.

Related information
Use Copilot in automation center
Use Copilot to analyze desktop flow activity
Get started with Copilot in cloud flows
FAQ for Copilot in cloud flows
FAQ for Copilot in Power Automate Process Mining
FAQ for Copilot data security and privacy in Microsoft Power Platform

Feedback
Was this page helpful?  Yes  No

Provide product feedback



FAQ for Copilot in desktop flow activity
Article • 01/21/2025

Copilot in desktop flow activity enables administrators, CoE teams, business users, and
makers to easily retrieve information about past flow runs by asking questions in natural
language. For example, users can ask about the number of flows that ran yesterday,
which machine ran the most flows, or how many flows are currently queued. In
response, Copilot generates outputs that provide insights and answers to the questions
asked.

What can Copilot in desktop flow activity do?
Copilot in desktop flow activity is capable of translating natural language queries into
Microsoft Dataverse FetchXML query syntax, specifically optimized for desktop flow
activity such as desktop flow runs, machines, and errors. This allows users to easily
retrieve information about their automation data by asking questions in natural
language. Additionally, Copilot determines the most suitable output visualization, such
as a table, pie chart, bar chart, or line chart, to effectively present the insights and
information to the user.

What is Copilot in desktop flow activity’s
intended use?
The purpose of this system is to enable users to retrieve information about their
automation activity data by asking questions in natural language.

How was Copilot in desktop flow activity
evaluated? What metrics are used to measure
performance?
The performance of Copilot in desktop flow activity was evaluated using a
comprehensive set of metrics. The Copilot interface includes thumb up and thumb down
gestures, allowing users to submit feedback on the AI outputs. This feedback is closely
monitored to ensure that Copilot remains compliant, appropriate, and free of bias.



What are the limitations of Copilot in desktop
flow activity? How can users minimize the
impact of Copilot in desktop flow activity’s
limitations when using the system?
One of the limitations of Copilot in desktop flow activity is that it currently only supports
answering questions about desktop flow activity, and not yet about cloud flows activity.
Additionally, the language currently supported with Copilot is English and only available
in Dataverse environments provisioned in the United States region. To minimize the
impact of these limitations, users can ensure that their queries are specific to desktop
flow activity and are phrased in English.

What operational factors and settings allow for
effective and responsible use of Copilot in
desktop flow activity?
Effective and responsible use of Copilot in desktop flow activity can be achieved by
ensuring that the user has the appropriate rights to access the desktop flow activity data
in Dataverse. This means that Copilot only answers questions based on the data the user
has permission to access. Additionally, it's important for users to understand the scope
and limitations of Copilot, and to phrase their queries accordingly.

Related information
Use Copilot to analyze desktop flow activity
Get started with Copilot in cloud flows
FAQ for Copilot in cloud flows
FAQ for Copilot in Power Automate Process Mining
FAQ for Copilot data security and privacy in Microsoft Power Platform

Feedback
Was this page helpful?  Yes  No

Provide product feedback



FAQ for Copilot in Power Automate
Process Mining
Article • 04/01/2025

What is Copilot in Power Automate Process
Mining?
Copilot in Process Mining enables users to streamline data ingestion and provides
process insights through quick and easy natural language expression. With Copilot in
ingestion, identify your process during data ingestion and auto map your data to the
required data schema. Copilot can also surface insights on your process and
recommend solutions through natural language in Power Automate process mining.

What are the systems capabilities?
The system is a copilot embedded in process mining ingestion and the desktop
application. It helps you get to actionable insights of your process faster. The system
can:

Discover your selected process in Bring Your Own Azure Data Lake.
Give automapping recommendations to required data schema.
Surface top insights in your process.
Offer recommendations on automation.
Answer questions on your process data.
Answer general questions about processes.
Filter out questions not related to the analyzed process or processes in general.

What is the system's intended use?
The systems intended use is to help you ingest your data into process mining and help
you surface actionable insights easily and quickly.

How was Copilot in Process Mining evaluated?
What metrics are used to measure
performance?



We have a robust set of metrics we're tracking to measure the performance of the
model and resulting customer experience. We track Copilot's Service Level Agreement
(SLA) to make sure it's always available to you. We track the telemetry of thumbs up and
thumbs down gestures present in the AI Copilot for each AI output that you can submit
feedback for.

You can provide feedback for Copilot when the results are biased or inappropriate. We
track this feedback to ensure that Copilot is compliant, appropriate, and bias-free.

What are the limitations of Copilot? How can
users minimize the impact of the Copilot
limitations when using the system?
Copilot can support ingestion only in a process created through Azure Data Lake as a
source. It supports only analytics driven through the Power Automate Process Mining
desktop application. It isn't equipped with transforming or preparing any ETL work on
behalf of the users. You're made aware of these limitations throughout the experience
with warnings that AI outputs must be validated. You'll also only be surfaced copilot
prompts and experiences in the sections of the products without limitations.

There's also an option to disable the Copilot within the admin center, and the user
always has the option to close the Copilot and not engage with the feature.

What operational factors and setting allow for
effective and responsible use of the system?
Copilot is only available in the Azure Data Lake ingestion experience and within the
Power Automate Process Mining desktop app. The user can always close Copilot and
not elect to interact with Copilot.

Related information
Copilot in Process Mining ingestion (preview)
Copilot in Process Mining process analytics (preview)
FAQ for Copilot data security and privacy in Microsoft Power Platform

Feedback



Was this page helpful?  Yes  No

Provide product feedback



FAQ for Copilot in Power Automate for
desktop
Article • 04/01/2025

These frequently asked questions (FAQ) describe the AI impact of the Copilot
functionality in Power Automate for desktop.

What is Copilot in Power Automate for
desktop?
Power Automate for desktop offers a new way of building desktop flows by the help of
an AI assistant. Copilot in Power Automate for desktop accompanies you throughout
your flow-building journey, assisting you in creating flows from scratch or enhancing
your existing automation with new steps through an interactive chat experience. Simply,
describe the flow that you want to create, and Copilot generates all the necessary
actions on your behalf. It can also help you by answering desktop flow and product-
related questions.

What can Copilot in Power Automate for
desktop do?
Copilot in Power Automate for desktop can be used in multiple scenarios. The system’s
intended uses include:

Creating flows using natural language instructions: From the Power Automate for
desktop’s console or designer, you can create a new flow by describing your
automation in the Copilot’s chat area.
Add steps to an existing desktop flow: From the Power Automate for desktop’s
designer, you can add one or more actions to your flow by describing them in the
Copilot’s chat area.
Answer documentation questions about Power Automate for desktop: From the
Power Automate for desktop’s console or designer, you can ask product related
questions in the Copilot's chat area.

What are the system’s intended uses?



Copilot can help you create new flows or add actions to an existing flow with ease
without having to manually add the actions.
Copilot's generative answers capability searches for answers to your product
related questions in Power Automate for desktop's public documentation using
Azure OpenAI and Bing search.

How was Copilot evaluated? What metrics are
used to measure performance?
Copilot in Power Automate for desktop has been evaluated against real-world scenarios
in each phase of its design, development, and release. Using a combination of research
and business impact studies, we evaluated various quantitative and qualitative metrics
about copilot, including its accuracy, usefulness, and agent trust. We have a robust set
of metrics we're tracking to measure the model's performance and resulting customer
experience. We follow the feature's SLA to make sure it's always available to you. We
track the telemetry of thumbs-up and thumbs-down gestures present in the UI
experience for each AI output that you can submit feedback for.

What are the limitations of Copilot? How can
users minimize the impact of Copilot’s
limitations when using the system?

The generative answers capability is available to environments deployed in the
following regions: Asia Pacific, Australia, Canada, France, Germany, India, Japan,
Korea, Norway, Singapore, South Africa, Switzerland, United Arab Emirates, United
Kingdom and United States.

The flow creation with natural language using Copilot and the generate actions
description capabilties are only available to US-based environments.

The flow creation with natural language capability only supports the following
action groups:

Clipboard
CMD session
Compression
Conditionals
Database
Date Time
Email



Excel
File
Flow Control
Folder
HTTP
Loops
Message Boxes
Mouse and Keyboard
Outlook
PDF
Scripting
System
Text
Variables
Word
XML

The generative answers capability can only answer to product-related features. It
can't answer general questions or anything unrelated to the product.

There's a limit of 500 characters to describe a flow that you want to create or ask a
question that you have about the product.

You can disable Copilot in Power Automate for desktop by contacting support or
closing the Copilot chat panel and not interacting with it.

Copilot is available only to users with a work or school account.

What operational factors and settings allow for
effective and responsible use of Copilot in
Power Automate for desktop?

The system is only available in Power Automate for desktop console and designer
components.
When creating a new flow or adding steps to an existing flow, you can review the
actions that were generated in the Copilot panel in the designer. Additionally, all
the AI generated actions in the designer, are included within two comments: “Start
of AI generated actions” and “End of AI generated actions”.
The system marks specific generated actions for user’s review in the designer’s
Copilot side panel. Specifically, actions from the Scripting, Database, File and
Folder actions groups might be marked for you to review.



Feedback
Was this page helpful?  Yes  No

Provide product feedback



FAQ for Repair with Copilot at runtime
in Power Automate for desktop
Article • 04/01/2025

These frequently asked questions (FAQ) describe the AI impact of the Repair with
Copilot at runtime functionality in Power Automate for desktop.

What is Repair with Copilot at runtime feature?
In Power Automate for desktop, a common issue is the failure to locate UI elements
during UI and Web automation actions at runtime. To address this issue, this feature
enables Power Automate for desktop to employ Copilot capabilities to automatically
locate the required UI element in a failure. This way, the execution continues, and
automation is completed successfully, achieving the required goal.

What can Repair with Copilot at runtime
feature do?
The specific feature provides the user the capability to repair UI and Browser automation
related issues at runtime, automatically, with the use of Copilot. More specifically:

Feature is applied when a desktop flow is executed through the Power Automate
portal in attended or unattended mode as part of a cloud flow - use of action ‘Run
a flow built with Power Automate for desktop’ - and a UI/Browser automation
action is about to fail because the UI element to interact with can't be found.
Power Automate for desktop provides as input to the Copilot one or more old
selectors of the UI element (which is/are invalid) and the hierarchy tree of all UI
elements that are contained in the respective window/pane/web tab.
The Copilot locates the UI element in the provided hierarchy tree and has as
output the UI element ID (unique identifier in the tree).
Power Automate for desktop generates the new selector for the indicated UI
element and repairs the old selector.
Action is performed with the new, repaired, selector, and execution of the flow
continues.
User can either use the repaired selector only in the context of the specific
execution or save the repaired selector for future execution as well.



What is the system’s intended uses?
1. Execution of a UI/Browser automation action can be performed even if one or

more selectors of the related UI element is invalid.
2. The selector of a UI element can be repaired automatically and saved by the user

and increase the success rate of the future executions of the specific flow.

How was Repair with Copilot at runtime feature
evaluated? What metrics are used to measure
performance?
This feature in Power Automate for desktop is evaluated against real-world scenarios in
each phase of its design, development, and release. Using a combination of research
and business impact studies, we evaluated various quantitative and qualitative metrics
about copilot, including its accuracy, usefulness, and AI service trust. We have a robust
set of metrics we're tracking to measure the model's performance and resulting
customer experience. We follow the feature's SLA to make sure it's always available to
you. We track the telemetry of thumbs-up and thumbs-down gestures present in the UI
experience for each AI output that you can submit feedback for.

What are the limitations of Suggesting fixes to
user at runtime feature? How can users
minimize the impact of Suggesting fixes to user
at runtime feature’s limitations when using the
system?

This feature is currently in preview for environments located in the United States
and only supports English.
This feature is currently available only to Work or School accounts.
This feature refers only to attended or unattended execution through Power
Automate portal as part of a cloud flow (use of action ‘Run a flow built with Power
Automate for desktop’).
This feature can fix only cases where a UI element can't be found because the
existing selector isn't valid, meaning that can't locate successfully the element in
the screen at the moment of the UI/Browser automation action’s execution.
The feature can tackle issues only for leaf level UI element – invalid screens’
selectors isn't handled.



There's a specific time window that notification window waits for the user to
interact with. After the window closes, the fix isn't applied, and the action fails.
You can completely disable the feature in Power Automate for desktop, from the
admin center or from the desktop flow’s properties window.

What operational factors and settings allow for
effective and responsible use of the feature in
Power Automate for desktop?

The system is only available in attended and unattended executions of a desktop
flow through the Power Automate portal component, as part of a cloud flow (use
of action ‘Run a flow built with Power Automate for desktop’).
Feature can be turned off either for a specific desktop flow (through its properties)
or for the whole environment in Power Platform Admin Center.
Notification window indicates that the suggestion is generated with the use of AI.
When Copilot suggests a UI element and its repaired selector, the user must
approve it in order for the recommendation to be effective. User is eligible to
reject it and either fix the issue manually (by indicating the respective UI element in
the screen manually) or fail the execution.
In case the user saves the generated, repaired selector for the specific UI element,
at any point, they can edit it or delete it.

Feedback
Was this page helpful?  Yes  No

Provide product feedback



FAQ for generative actions in cloud
flows
Article • 12/20/2024

These frequently asked questions (FAQ) describe the AI impact of the generative actions
feature in Power Automate.

What are generative actions?
Generative actions are a new type of action that's authored, tested, and executed
through an AI runtime. You specify only the intent of the automation and the AI chooses
the right set of actions in the right order based on your input, context, and intent.

） Important

This is a preview feature.
Preview features aren’t meant for production use and may have restricted
functionality. These features are available before an official release so that
customers can get early access and provide feedback.

What are capabilities of generative actions?
Generative actions simplify automation by reducing the need for detailed specifications,
adapt to changing scenarios using AI intelligence, and handle complex tasks involving
multiple steps and integrations.

Generative actions can create a set plan for flow execution through natural
language. Generative actions can simplify and accelerate the automation process
by reducing the need for specifying the conditions and action sets to execute. It
surfaces recommended inputs, outputs, and actions to complete the described
task. The user is then asked to validate these recommendations before running the
generative actions and is allowed to make any changes necessary.

Generative actions can adapt to changing scenarios and data sources by
leveraging the AI runtime's intelligence and reasoning capabilities. Generative
action can orchestrate actions within the flow based on reasoning over inputs and
knowledge documents. It then executes the plan by filling in the required inputs
for the flow.



Generative actions can handle complex and dynamic tasks that involve multiple
steps, conditions, loops, branches, and integrations. Once it is complete it shares
the actions it executed and the reasoning behind parameter filling.

What is the intended use of generative actions?
You can use generative action to intelligently orchestrate, and parameter fill actions
within your flow. The generative action can act based on the defined inputs.

How was the generative actions feature
evaluated? What metrics are used to measure
performance?
The generative actions feature is evaluated for end-to-end quality at each step of the
process. Quality is measured in terms of how well the system creates and executes a
plan that successfully addresses the user prompt. We evaluate quality over various user
queries, prompts, and actions. We also evaluate how well the system does at ignoring
malicious content from users and authors, and how well the system avoids producing
harmful content.

What are the limitations of generative actions?
How can users minimize the impact of
generative action limitations when using the
system?
For best results, make sure your generative action prompt includes high-quality
descriptions. The generative action can only act on the inputs and reference document
given, be sure that the content is complete for the best performance. The generative
action can also only orchestrate the actions that were defined and authenticated.

What operational factors and settings allow for
effective and responsible use of generative
actions?
The generative actions feature is currently English only. Once you create a generative
action, you can test the system to see how well it performs using test. You can run the



test and manually trigger actions to understand how your generative action will
perform. You can always edit or modify the prompt to change the way the generative
action performs.

What kinds of issues might arise when using
generative actions?
Actions might not always work as intended. Errors might occur when preparing the
input for the action or when generating a response based on the action's output. Your
generative action might also call the wrong action during the orchestration of the given
actions. To mitigate the risk of such errors, make sure you have high quality, relevant,
and unambiguous descriptions configured for the actions. Also limit what actions the
generative action might be able to use in the execution of the plan.

What protections does Power Automate have
in place for responsible AI?
There are many mitigation features in place to protect your flows. You can configure
your generative action with a set of references and input values defined within your
flow. Generative actions never take an action that isn't part of their plan. Generative
actions respect organizations' Data Loss Prevention (DLP) policy. Any disallowed action
for the flow is blocked in the generative action.

In addition, we have classifiers that look at input to the system to detect harmful content
and jailbreak attacks. According to our tests, these classifiers have a high success rate at
blocking harmful content and jailbreak attacks, while also having high success at not
blocking content that isn't harmful or a jailbreak attack. However, classifiers can't be
perfect so there are risks of a generative action producing harmful content or
responding to a jailbreak attack. These risks include cross-domain prompt injection
attacks, where instructions could be added to the output of an action or a knowledge
source that the generative action then tries to follow.

Related information
Create generative actions in cloud flows (preview)

Feedback



Was this page helpful?  Yes  No

Provide product feedback



FAQ for Power Automate for desktop
natural language to code in scripting
actions
Article • 04/01/2025

What is natural language to code in scripting
actions?
Natural language to code is a new AI capability that we added in Power Automate for
desktop. It lets you quickly generate code used in the scripting actions by describing it.
This feature is available in the "Run PowerShell," "Run VBScript," "Run DOS command,"
"Run Python," and "Run JavaScript" actions. You can describe with natural language
what you want to achieve, and copilot's AI capabilities generate the script for you. This
feature makes it easy for users unfamiliar with scripting languages to automate their
tasks.

What can the natural language to code in
scripting actions do?
Copilot's natural language to code in scripting actions can generate the code to be
executed in the various scripting actions in Power Automate for desktop. To do so, the
only thing that the user needs to do is to provide a description, and the AI responds
with the generated code.

What is/are natural language to code in
scripting actions' intended use(s)?
The intended use is to allow users to create scripts quickly and with ease, by just
providing a description of the script instead of developing it from scratch.

How was natural language to code in scripting
actions evaluated? What metrics are used to
measure performance?



There's a robust set of metrics we're tracking to measure the model's performance
and resulting customer experience. We track the feature's SLA to make sure it's
always available to you. We track the telemetry of thumbs-up and thumbs-down
gestures present in the UI experience for each AI output that you can submit
feedback for.
You can provide feedback on this functionality when the results are biased or
inappropriate. We track this feedback to ensure that copilot is compliant,
appropriate, and bias-free.
We tested the AI model through various internal processes and reviews to make
sure that we provided the best possible quality and adhere to the highest of
standards when it comes to security and reliability.

What are the limitations of natural language to
code in scripting actions? How can users
minimize the impact of natural language to
code in scripting action's limitations when
using the system?

The natural language to code in scripting actions capability can only generate
scripts. It can't answer general questions or anything unrelated to the specific
scripting language where the user launched the functionality. Currently, all the
scripting actions are supported, but they run a .NET action.
The natural language to code in scripting actions capability is available to
environments deployed in the following regions: Asia Pacific, Australia, Canada,
France, Germany, India, Japan, Korea, Norway, Singapore, South Africa, Switzerland,
United Arab Emirates, United Kingdom, and United States.
This capability is available only to users using a work or school account.

What operational factors and settings allow for
effective and responsible use of natural
language to code in scripting actions?

Natural language to code in scripting actions is only available and can only be
accessed from these scripting actions in Power Automate for desktop's designer:
Run PowerShell, Run VBScript, Run DOS command, Run Python, and Run JavaScript
actions.
Always review results from copilot.



Get the best out of copilot
When you're interacting with copilot, it's essential to keep in mind that the structure of
the questions can significantly affect the response that copilot gives. To interact with
copilot effectively, is crucial to ask clear and specific questions and provide context to
help the AI better understand your intent.

Related information
Natural Language to code in scripting actions
FAQ for Copilot data security and privacy in Microsoft Power Platform

Feedback
Was this page helpful?  Yes  No

Provide product feedback



FAQ for Power Automate for desktop
suggested actions
Article • 04/01/2025

What is the suggested actions functionality
Suggested actions are a new AI capability that we added in Power Automate for desktop
that allows you to quickly view suggestions on what your next action should be while
designing your flow in the designer.

What can the suggested actions do?
Suggested actions can help you discover the next step of your automation by analyzing
your flow and suggesting action candidates that you can include by selecting them.

What is/are action suggestions intended
use(s)?
The intended use of suggested actions is to allow users to quickly discover actions that
can be used as the next building steps in their automation without searching the full list
of actions in the designer.

How can I use the suggested actions
functionality?
You can access the new functionality by signing in with your work or school account in
Power Automate for desktop and either creating a new flow or editing an existing one.
When hovering over an action, select the plus icon, and the suggested actions panel
opens.

How was suggested actions evaluated? What
metrics are used to measure performance?
We have a robust set of metrics we track to measure the performance of the model and
resulting customer experience. We track the feature’s SLA to make sure it's always



available to you. We track the telemetry of thumbs up and thumbs down gestures
present in the UI experience for each AI output that you can submit feedback for.

You can provide feedback on this functionality when the results are biased or
inappropriate. We track this feedback to ensure that AI feature is compliant, appropriate,
and bias-free.

We meticulously tested the AI model through various internal processes and reviews in
order to make sure that we provided the best possible quality and adhere to the highest
of standards when it comes to security and reliability.

What are the limitations of the suggested
actions? How can the users minimize the
impact of feature when using the system?

The suggested actions Copilot capability can only propose actions currently
available in the Power Automate for desktop’s standard library of actions. It can't
propose actions that are custom-made by an organization (custom actions).
The suggested actions Copilot capability is available to environments deployed in
the following regions: Asia Pacific, Australia, Canada, France, Germany, India, Japan,
Korea, Norway, Singapore, South Africa, Switzerland, United Arab Emirates, United
Kingdom, and United States.
This capability is available only to users with a work or school account.

Related information
Configure actions and the actions pane

Feedback
Was this page helpful?  Yes  No

Provide product feedback



FAQ for generating a flow description
using Copilot
Article • 04/01/2025

These frequently asked questions (FAQ) describe the AI impact of generating flow
descriptions using Copilot functionality in Power Automate for desktop.

What is the generate flow description with
Copilot capability?
Generate flow description with Copilot is a new AI capability that we added in the
properties of desktop flows in both Power Automate for desktop and the desktop flows
area in Power Automate (make.powerautomate.com). The feature is available by going
to the flow details.

What can the generate flow description with
Copilot feature do?
Generate flow description with Copilot reads and analyzes the actions inside a flow and
automatically creates a flow description. This feature saves the user valuable time from
having to read through the whole flow to understand what it does.

What is the generate flow description with
Copilot intended use?
The intended use of the generate flow description using Copilot feature is for users to
generate flow descriptions easily without having to go through the whole flow action by
action to understand its functionality.

How was generate description using Copilot
evaluated? What metrics are used to measure
performance?

The generate flow description with Copilot capability has been evaluated against
real world scenarios in each phase of its design, development, and release. Using a



combination of research and business impact studies, we’ve evaluated various
quantitative and qualitative metrics about Copilot, including its accuracy,
usefulness, and agent-trust.
We have a robust set of metrics we're tracking to measure the performance of the
model and resulting customer experience. We track the feature’s SLA to make sure
it's always available to you. We track the telemetry of thumbs up and thumbs
down gestures present in the UI experience for each AI output that you can submit
feedback for.

What are the limitations of the generate flow
description with Copilot capability? How can
users minimize the impact of the generate flow
description with Copilot limitations when using
the system?

The generate flow description with Copilot capability is available to environments
deployed in the following regions: Asia Pacific, Australia, Canada, France, Germany,
India, Japan, Korea, Norway, Singapore, South Africa, Switzerland, United Arab
Emirates, United Kingdom, and United States.
This capability is currently available only to users using a work or school account.

What operational factors and settings allow for
effective and responsible use of the generate
flow description with Copilot capability?
You should always review the descriptions generated by the Copilot's generate flow
description capability before saving the flow properties.

Related information
Power Automate for desktop console
FAQ for Copilot data security and privacy in Microsoft Power Platform

Feedback



Was this page helpful?  Yes  No

Provide product feedback